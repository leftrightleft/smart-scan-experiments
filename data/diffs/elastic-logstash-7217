diff --git a/bin/lock b/bin/lock
deleted file mode 100755
index a8a0529a943..00000000000
--- a/bin/lock
+++ /dev/null
@@ -1,9 +0,0 @@
-#!/usr/bin/env bin/ruby
-
-require_relative "../lib/bootstrap/environment"
-LogStash::Bundler.setup!({:without => [:build, :development]})
-require "logstash-core"
-
-lock = Java::OrgLogstash::FileLockFactory.getDefault.obtainLock(ARGV[0], ".lock")
-puts("locking " + File.join(ARGV[0], ".lock"))
-sleep
diff --git a/config/logstash.yml b/config/logstash.yml
index c50e6bd614c..4444f155a5e 100644
--- a/config/logstash.yml
+++ b/config/logstash.yml
@@ -85,6 +85,25 @@
 #
 # config.debug: false
 #
+# ------------ Module Settings ---------------
+# Define modules here.  Modules definitions must be defined as an array.
+# The simple way to see this is to prepend each `name` with a `-`, and keep
+# all associated variables under the `name` they are associated with, and 
+# above the next, like this:
+#
+# modules:
+#   - name: MODULE_NAME
+#     var.PLUGINTYPE1.PLUGINNAME1.KEY1: VALUE
+#     var.PLUGINTYPE1.PLUGINNAME1.KEY2: VALUE
+#     var.PLUGINTYPE2.PLUGINNAME1.KEY1: VALUE
+#     var.PLUGINTYPE3.PLUGINNAME3.KEY1: VALUE
+#
+# Module variable names must be in the format of 
+#
+# var.PLUGIN_TYPE.PLUGIN_NAME.KEY
+#
+# modules:
+#
 # ------------ Queuing Settings --------------
 #
 # Internal queuing model, "memory" for legacy in-memory based queuing and
@@ -169,3 +188,4 @@
 #
 # Where to find custom plugins
 # path.plugins: []
+
diff --git a/docs/static/offline-plugins.asciidoc b/docs/static/offline-plugins.asciidoc
index 508b79fe71b..b67f34169bb 100644
--- a/docs/static/offline-plugins.asciidoc
+++ b/docs/static/offline-plugins.asciidoc
@@ -60,14 +60,23 @@ To install an offline plugin pack:
 
 . Move the compressed bundle to the machine where you want to install the plugins.
 
-. Run the `bin/logstash-plugin install` subcommand to install the packaged plugins:
+. Run the `bin/logstash-plugin install` subcommand and pass in the file URI of
+the offline plugin pack. 
 +
 ["source","sh",subs="attributes"]
+.Windows example:
+-------------------------------------------------------------------------------
+bin/logstash-plugin install file:///c:/path/to/logstash-offline-plugins-{logstash_version}.zip
+-------------------------------------------------------------------------------
++
+["source","sh",subs="attributes"]
+.Linux example:
 -------------------------------------------------------------------------------
 bin/logstash-plugin install file:///path/to/logstash-offline-plugins-{logstash_version}.zip
 -------------------------------------------------------------------------------
 +
-Where +path/to/logstash-offline-plugins-{logstash_version}.zip+ is the path to the offline plugin pack.
+This command expects a file URI, so make sure you use forward slashes and
+specify the full path to the pack.
 
 [float]
 === Updating Offline Plugins
diff --git a/logstash-core/lib/logstash/agent.rb b/logstash-core/lib/logstash/agent.rb
index 3fd8b58b218..11ca63339d0 100644
--- a/logstash-core/lib/logstash/agent.rb
+++ b/logstash-core/lib/logstash/agent.rb
@@ -25,7 +25,7 @@ class LogStash::Agent
   include LogStash::Util::Loggable
   STARTED_AT = Time.now.freeze
 
-  attr_reader :metric, :name, :pipelines, :settings, :webserver, :dispatcher
+  attr_reader :metric, :name, :settings, :webserver, :dispatcher
   attr_accessor :logger
 
   # initialize method for LogStash::Agent
@@ -38,7 +38,10 @@ def initialize(settings = LogStash::SETTINGS, source_loader = nil)
     @settings = settings
     @auto_reload = setting("config.reload.automatic")
 
+    # Do not use @pipelines directly. Use #with_pipelines which does locking
     @pipelines = {}
+    @pipelines_lock = java.util.concurrent.locks.ReentrantLock.new
+
     @name = setting("node.name")
     @http_host = setting("http.host")
     @http_port = setting("http.port")
@@ -55,7 +58,6 @@ def initialize(settings = LogStash::SETTINGS, source_loader = nil)
     end
 
     @reload_interval = setting("config.reload.interval")
-    @pipelines_mutex = Mutex.new
 
     @collect_metric = setting("metric.collect")
 
@@ -129,6 +131,17 @@ def stopped?
     !@running.value
   end
 
+  # Safely perform an operation on the pipelines hash
+  # Using the correct synchronization
+  def with_pipelines
+    begin
+      @pipelines_lock.lock
+      yield @pipelines
+    ensure
+      @pipelines_lock.unlock
+    end
+  end
+
   def converge_state_and_update
     results = @source_loader.fetch
 
@@ -145,7 +158,8 @@ def converge_state_and_update
     # content of it.
     converge_result = nil
 
-    @pipelines_mutex.synchronize do
+    # we don't use the variable here, but we want the locking
+    with_pipelines do |pipelines|
       pipeline_actions = resolve_actions(results.response)
       converge_result = converge_state(pipeline_actions)
       update_metrics(converge_result)
@@ -220,26 +234,26 @@ def id_path
   end
 
   def get_pipeline(pipeline_id)
-    @pipelines_mutex.synchronize do
-      @pipelines[pipeline_id]
+    with_pipelines do |pipelines|
+      pipelines[pipeline_id]
     end
   end
 
   def pipelines_count
-    @pipelines_mutex.synchronize do
+    with_pipelines do |pipelines|
       pipelines.size
     end
   end
 
   def running_pipelines
-    @pipelines_mutex.synchronize do
-      @pipelines.select {|pipeline_id, _| running_pipeline?(pipeline_id) }
+    with_pipelines do |pipelines|
+      pipelines.select {|pipeline_id, _| running_pipeline?(pipeline_id) }
     end
   end
 
   def running_pipelines?
-    @pipelines_mutex.synchronize do
-      @pipelines.select {|pipeline_id, _| running_pipeline?(pipeline_id) }.any?
+    with_pipelines do |pipelines|
+      pipelines.select {|pipeline_id, _| running_pipeline?(pipeline_id) }.any?
     end
   end
 
@@ -248,24 +262,28 @@ def running_user_defined_pipelines?
   end
 
   def running_user_defined_pipelines
-    @pipelines_mutex.synchronize do
-      @pipelines.select do |_, pipeline|
+    with_pipelines do |pipelines|
+      pipelines.select do |_, pipeline|
         pipeline.running? && !pipeline.system?
       end
     end
   end
 
   def close_pipeline(id)
-    pipeline = @pipelines[id]
-    if pipeline
-      @logger.warn("closing pipeline", :id => id)
-      pipeline.close
+    with_pipelines do |pipelines|
+      pipeline = pipelines[id]
+      if pipeline
+        @logger.warn("closing pipeline", :id => id)
+        pipeline.close
+      end
     end
   end
 
   def close_pipelines
-    @pipelines.each  do |id, _|
-      close_pipeline(id)
+    with_pipelines do |pipelines|
+      pipelines.each  do |id, _|
+        close_pipeline(id)
+      end
     end
   end
 
@@ -308,20 +326,22 @@ def converge_state(pipeline_actions)
       #
       # This give us a bit more extensibility with the current startup/validation model
       # that we currently have.
-      begin
-        logger.debug("Executing action", :action => action)
-        action_result = action.execute(self, @pipelines)
-        converge_result.add(action, action_result)
-
-        unless action_result.successful?
-          logger.error("Failed to execute action", :id => action.pipeline_id,
-                       :action_type => action_result.class, :message => action_result.message)
+      with_pipelines do |pipelines|
+        begin
+          logger.debug("Executing action", :action => action)
+            action_result = action.execute(self, pipelines)
+          converge_result.add(action, action_result)
+
+          unless action_result.successful?
+            logger.error("Failed to execute action", :id => action.pipeline_id,
+                        :action_type => action_result.class, :message => action_result.message)
+          end
+        rescue SystemExit => e
+          converge_result.add(action, e)
+        rescue Exception => e
+          logger.error("Failed to execute action", :action => action, :exception => e.class.name, :message => e.message)
+          converge_result.add(action, e)
         end
-      rescue SystemExit => e
-        converge_result.add(action, e)
-      rescue Exception => e
-        logger.error("Failed to execute action", :action => action, :exception => e.class.name, :message => e.message)
-        converge_result.add(action, e)
       end
     end
 
@@ -335,7 +355,9 @@ def converge_state(pipeline_actions)
   end
 
   def resolve_actions(pipeline_configs)
-    @state_resolver.resolve(@pipelines, pipeline_configs)
+    with_pipelines do |pipelines|
+      @state_resolver.resolve(pipelines, pipeline_configs)
+    end
   end
 
   def report_currently_running_pipelines(converge_result)
@@ -394,9 +416,11 @@ def collect_metrics?
   end
 
   def force_shutdown_pipelines!
-    @pipelines.each do |_, pipeline|
-      # TODO(ph): should it be his own action?
-      pipeline.force_shutdown!
+    with_pipelines do |pipelines|
+      pipelines.each do |_, pipeline|
+        # TODO(ph): should it be his own action?
+        pipeline.force_shutdown!
+      end
     end
   end
 
@@ -406,19 +430,21 @@ def shutdown_pipelines
     # In this context I could just call shutdown, but I've decided to
     # use the stop action implementation for that so we have the same code.
     # This also give us some context into why a shutdown is failing
-    @pipelines_mutex.synchronize do
+    with_pipelines do |pipelines|
       pipeline_actions = resolve_actions([]) # We stop all the pipeline, so we converge to a empty state
       converge_state(pipeline_actions)
     end
   end
 
   def running_pipeline?(pipeline_id)
-    thread = @pipelines[pipeline_id].thread
+    thread = get_pipeline(pipeline_id).thread
     thread.is_a?(Thread) && thread.alive?
   end
 
   def clean_state?
-    @pipelines.empty?
+    with_pipelines do |pipelines|
+      pipelines.empty?
+    end
   end
 
   def setting(key)
diff --git a/logstash-core/lib/logstash/bootstrap_check/default_config.rb b/logstash-core/lib/logstash/bootstrap_check/default_config.rb
index 8331c861fc7..257e4243189 100644
--- a/logstash-core/lib/logstash/bootstrap_check/default_config.rb
+++ b/logstash-core/lib/logstash/bootstrap_check/default_config.rb
@@ -1,21 +1,87 @@
 # encoding: utf-8
 require "logstash/errors"
+require "logstash/logging"
 
 module LogStash module BootstrapCheck
   class DefaultConfig
-    def self.check(settings)
-      if settings.get("config.string").nil? && settings.get("path.config").nil?
-        raise LogStash::BootstrapCheckError, I18n.t("logstash.runner.missing-configuration")
-      end
+    include LogStash::Util::Loggable
+
+    def initialize(settings)
+      @settings = settings
+    end
+
+    def config_reload?
+      @settings.get("config.reload.automatic")
+    end
+
+    def config_string?
+      @settings.get("config.string")
+    end
 
-      if settings.get("config.string") && settings.get("path.config")
+    def path_config?
+      @settings.get("path.config")
+    end
+
+    def config_modules?
+      # We want it to report true if not empty
+      !@settings.get("modules").empty?
+    end
+
+    def cli_modules?
+      # We want it to report true if not empty
+      !@settings.get("modules.cli").empty?
+    end
+
+    def both_config_flags?
+      config_string? && path_config?
+    end
+
+    def both_module_configs?
+      cli_modules? && config_modules?
+    end
+
+    def config_defined?
+      config_string? || path_config?
+    end
+
+    def modules_defined?
+      cli_modules? || config_modules?
+    end
+
+    def any_config?
+      config_defined? || modules_defined?
+    end
+
+    def check
+      # Check if both -f and -e are present
+      if both_config_flags?
         raise LogStash::BootstrapCheckError, I18n.t("logstash.runner.config-string-path-exclusive")
       end
 
-      if settings.get("config.reload.automatic") && settings.get("path.config").nil?
-        # there's nothing to reload
+      # Make note that if modules are configured in both cli and logstash.yml that cli module  
+      # settings will be used, and logstash.yml modules settings ignored
+      if both_module_configs?
+        logger.info(I18n.t("logstash.runner.cli-module-override"))
+      end
+
+      # Check if both config (-f or -e) and modules are configured
+      if config_defined? && modules_defined?
+        raise LogStash::BootstrapCheckError, I18n.t("logstash.runner.config-module-exclusive")
+      end
+
+      # Check for absence of any configuration
+      if !any_config?
+        raise LogStash::BootstrapCheckError, I18n.t("logstash.runner.missing-configuration")
+      end
+
+      # Check to ensure that if configuration auto-reload is used that -f is specified
+      if config_reload? && !path_config?
         raise LogStash::BootstrapCheckError, I18n.t("logstash.runner.reload-without-config-path")
       end
     end
+
+    def self.check(settings)
+      DefaultConfig.new(settings).check
+    end
   end
 end end
diff --git a/logstash-core/lib/logstash/config/source/modules.rb b/logstash-core/lib/logstash/config/source/modules.rb
new file mode 100644
index 00000000000..8f238ec393f
--- /dev/null
+++ b/logstash-core/lib/logstash/config/source/modules.rb
@@ -0,0 +1,45 @@
+# encoding: utf-8
+require "logstash/config/source/base"
+require "logstash/config/pipeline_config"
+require "logstash/util/loggable"
+require "logstash/errors"
+
+module LogStash module Config module Source
+  class Modules < Base
+    include LogStash::Util::Loggable
+    def pipeline_configs
+      pipelines = []
+      plugin_modules = LogStash::PLUGIN_REGISTRY.plugins_with_type(:modules)
+
+      modules_array = @settings.get("modules.cli").empty? ? @settings.get("modules") : @settings.get("modules.cli")
+      logger.debug("Configured modules", :modules_array => modules_array.to_s)
+      module_names = []
+      module_names = modules_array.collect {|module_hash| module_hash["name"]}
+      if module_names.length > module_names.uniq.length
+        duplicate_modules = module_names.group_by(&:to_s).select { |_,v| v.size > 1 }.keys
+        raise LogStash::ConfigLoadingError, I18n.t("logstash.modules.configuration.modules-must-be-unique", :duplicate_modules => duplicate_modules)
+      end
+      ### Here is where we can force the modules_array to use only [0] for 5.5, and leave
+      ### a warning/error message to that effect.
+      modules_array.each do |module_hash|
+        begin
+          current_module = plugin_modules.find { |allmodules| allmodules.module_name == module_hash["name"] }
+          alt_name = "module-#{module_hash["name"]}"
+          pipeline_id = alt_name
+          config_string = current_module.config_string(module_hash)
+          logger.debug("Config string for module", :config_string => config_string, :module => module_hash["name"])
+          config_part = org.logstash.common.SourceWithMetadata.new("module", alt_name, config_string)
+          pipelines << PipelineConfig.new(self, pipeline_id.to_sym, config_part, @settings)
+        rescue => e
+          raise LogStash::ConfigLoadingError, I18n.t("logstash.modules.configuration.parse-failed", :error => e.message)
+        end
+      end
+      pipelines
+    end
+
+    def match?
+      # will fill this later
+      true
+    end
+  end 
+end end end
\ No newline at end of file
diff --git a/logstash-core/lib/logstash/config/source_loader.rb b/logstash-core/lib/logstash/config/source_loader.rb
index 84983c2bd52..abcfd2f5d11 100644
--- a/logstash-core/lib/logstash/config/source_loader.rb
+++ b/logstash-core/lib/logstash/config/source_loader.rb
@@ -1,5 +1,6 @@
 # encoding: utf-8
 require "logstash/config/source/local"
+require "logstash/config/source/modules"
 require "logstash/errors"
 require "thread"
 require "set"
diff --git a/logstash-core/lib/logstash/environment.rb b/logstash-core/lib/logstash/environment.rb
index 0eb7e34df9e..44da34a3cc8 100644
--- a/logstash-core/lib/logstash/environment.rb
+++ b/logstash-core/lib/logstash/environment.rb
@@ -20,6 +20,8 @@ module Environment
     Setting::NullableString.new("path.config", nil, false),
  Setting::WritableDirectory.new("path.data", ::File.join(LogStash::Environment::LOGSTASH_HOME, "data")),
     Setting::NullableString.new("config.string", nil, false),
+                    Setting.new("modules.cli", Array, []),
+                    Setting.new("modules", Array, []),
            Setting::Boolean.new("config.test_and_exit", false),
            Setting::Boolean.new("config.reload.automatic", false),
            Setting::Numeric.new("config.reload.interval", 3), # in seconds
diff --git a/logstash-core/lib/logstash/modules.rb b/logstash-core/lib/logstash/modules.rb
new file mode 100644
index 00000000000..19ef45a10ff
--- /dev/null
+++ b/logstash-core/lib/logstash/modules.rb
@@ -0,0 +1,44 @@
+# encoding: utf-8
+require "logstash/namespace"
+require "logstash/logging"
+require "erb"
+
+class LogStash::Modules
+  include LogStash::Util::Loggable
+
+  attr_reader :module_name
+  def initialize(name, directory)
+    @module_name = name
+    @directory = directory  
+  end
+
+  def template
+    ::File.join(@directory, "logstash/#{@module_name}.conf.erb")
+  end
+
+  class ModuleConfig
+
+    def initialize(template, settings)
+      @template = template
+      @settings = settings
+    end
+
+    def setting(value, default)
+      @settings.fetch(value, default)
+    end
+
+    def render
+      # process the template and settings
+      # send back as a string with no newlines (the '>' part)
+      renderer = ERB.new(File.read(@template), 3, '>')
+      renderer.result(binding)
+    end
+  end
+
+  def config_string(settings = {})
+    # settings should be the subset from the YAML file with a structure like
+    # {"name" => "plugin name", "k1" => "v1", "k2" => "v2"}, etc.
+    ModuleConfig.new(template, settings).render
+  end
+
+end # class LogStash::Modules
\ No newline at end of file
diff --git a/logstash-core/lib/logstash/modules_cli_parser.rb b/logstash-core/lib/logstash/modules_cli_parser.rb
new file mode 100644
index 00000000000..1fdad9b3e18
--- /dev/null
+++ b/logstash-core/lib/logstash/modules_cli_parser.rb
@@ -0,0 +1,76 @@
+# encoding: utf-8
+require "logstash/namespace"
+require "logstash/logging"
+require "logstash/errors"
+
+class LogStash::ModulesCLIParser
+  include LogStash::Util::Loggable
+
+  attr_reader :output
+  def initialize(module_names, module_variables)
+    @output = []
+    # The #compact here catches instances when module_variables may be nil or 
+    # [nil] and sets it to []
+    parse_it(module_names, Array(module_variables).compact)
+  end
+
+  def parse_modules(module_list)
+    parsed_modules = []
+    module_list.each do |module_value|
+      # Calling --modules but not filling it results in [nil], so skip that.
+      next if module_value.nil?
+      # Catch if --modules was launched empty but an option/flag (-something) 
+      # follows immediately after
+      if module_value.start_with?('-')
+        raise LogStash::ConfigLoadingError, I18n.t("logstash.modules.configuration.modules-empty-value", :modules => module_names)
+      end
+      parsed_modules.concat module_value.split(',')
+    end
+    parsed_modules
+  end
+
+  def get_kv(module_name, unparsed)
+    # Ensure that there is at least 1 equals sign in our variable string
+    if unparsed.split('=').length >= 2
+      # This hackery is to catch the possibility of an equals (`=`) sign 
+      # in a passphrase, which might result in an incomplete key.  The 
+      # portion before the first `=` should always be the key, leaving 
+      # the rest to be the value
+      values = unparsed.split('=')
+      k = values.shift
+      return k,values.join('=')
+    else
+      raise LogStash::ConfigLoadingError, I18n.t("logstash.modules.configuration.modules-variables-malformed", :rawvar => (module_name + '.' + unparsed))
+    end
+  end
+
+  def name_splitter(unparsed)
+    # It must have at least `modulename.var.PLUGINTYPE.PLUGINNAME.VARNAME`
+    if unparsed.split('.').length >= 5
+      elements = unparsed.split('.')
+      module_name = elements.shift
+      return module_name,elements.join('.')
+    else
+      raise LogStash::ConfigLoadingError, I18n.t("logstash.modules.configuration.modules-variables-malformed", :rawvar => unparsed)
+    end 
+  end
+
+  def parse_vars(module_name, vars_list)
+    module_hash = {"name" => module_name}
+    vars_list.each do |unparsed|
+      extracted_name, modvar = name_splitter(unparsed)
+      next if extracted_name != module_name
+      k, v = get_kv(extracted_name, modvar)
+      module_hash[k] = v 
+    end
+    module_hash
+  end
+  
+  def parse_it(module_list, module_variable_list)
+    if module_list.is_a?(Array)
+      parse_modules(module_list).each do |module_name| 
+        @output << parse_vars(module_name, module_variable_list)
+      end
+    end
+  end
+end
\ No newline at end of file
diff --git a/logstash-core/lib/logstash/plugins/registry.rb b/logstash-core/lib/logstash/plugins/registry.rb
index 7def8c4f3d5..d751c32f8cb 100644
--- a/logstash-core/lib/logstash/plugins/registry.rb
+++ b/logstash-core/lib/logstash/plugins/registry.rb
@@ -3,6 +3,7 @@
 require "logstash/util/loggable"
 require "logstash/plugin"
 require "logstash/plugins/hooks_registry"
+require "logstash/modules"
 
 module LogStash module Plugins
   class Registry
diff --git a/logstash-core/lib/logstash/runner.rb b/logstash-core/lib/logstash/runner.rb
index 9f073e30696..b5352f6b01d 100644
--- a/logstash-core/lib/logstash/runner.rb
+++ b/logstash-core/lib/logstash/runner.rb
@@ -9,6 +9,7 @@
 require "logstash/namespace"
 require "logstash-core/logstash-core"
 require "logstash/environment"
+require "logstash/modules_cli_parser"
 
 LogStash::Environment.load_locale!
 
@@ -61,6 +62,17 @@ class LogStash::Runner < Clamp::StrictCommand
     :default => LogStash::SETTINGS.get_default("config.string"),
     :attribute_name => "config.string"
 
+  # Module settings
+  option ["--modules"], "MODULES",
+    I18n.t("logstash.runner.flag.modules"),
+    :multivalued => true,
+    :attribute_name => "modules_list"
+
+  option ["-M", "--modules.variable"], "MODULES_VARIABLE", 
+    I18n.t("logstash.runner.flag.modules_variable"),
+    :multivalued => true,
+    :attribute_name => "modules_variable_list"
+
   # Pipeline settings
   option ["-w", "--pipeline.workers"], "COUNT",
     I18n.t("logstash.runner.flag.pipeline-workers"),
@@ -175,6 +187,7 @@ def initialize(*args)
     # Default we check local sources: `-e`, `-f` and the logstash.yml options.
     @source_loader = LogStash::Config::SourceLoader.new(@settings)
     @source_loader.add_source(LogStash::Config::Source::Local.new(@settings))
+    @source_loader.add_source(LogStash::Config::Source::Modules.new(@settings))
 
     super(*args)
   end
@@ -248,6 +261,10 @@ def execute
 
     return start_shell(setting("interactive"), binding) if setting("interactive")
 
+    module_parser = LogStash::ModulesCLIParser.new(@modules_list, @modules_variable_list)
+    # Now populate Setting for modules.list with our parsed array.
+    @settings.set("modules.cli", module_parser.output)
+
     begin
       @bootstrap_checks.each { |bootstrap| bootstrap.check(@settings) }
     rescue LogStash::BootstrapCheckError => e
diff --git a/logstash-core/locales/en.yml b/logstash-core/locales/en.yml
index e1ae825c358..6c59bb2247e 100644
--- a/logstash-core/locales/en.yml
+++ b/logstash-core/locales/en.yml
@@ -85,10 +85,23 @@ en:
       logging:
         unrecognized_option: |-
           unrecognized option [%{option}]
+    modules:
+      configuration:
+        parse-failed: |-
+          Failed to parse the module configuration: [%{error}]
+        modules-must-be-unique: >-
+          Only a single instance of any module can be run at a time. Duplicate
+          modules: %{duplicate_modules}
+        modules-empty-value: >-
+          Empty value provided for --modules
+        modules-variables-malformed: >-
+          Failed to parse module variable %{rawvar}.  Must be in -M
+          "MODULE_NAME.var.PLUGIN_TYPE.PLUGIN_NAME.VARIABLE_NAME=VALUE" format
     runner:
       short-help: |-
         usage:
           bin/logstash -f CONFIG_PATH [-t] [-r] [] [-w COUNT] [-l LOG]
+          bin/logstash --modules MODULE_NAME [-M "MODULE_NAME.var.PLUGIN_TYPE.PLUGIN_NAME.VARIABLE_NAME=VALUE"] [-t] [-w COUNT] [-l LOG]
           bin/logstash -e CONFIG_STR [-t] [--log.level fatal|error|warn|info|debug|trace] [-w COUNT] [-l LOG]
           bin/logstash -i SHELL [--log.level fatal|error|warn|info|debug|trace]
           bin/logstash -V [--log.level fatal|error|warn|info|debug|trace]
@@ -100,6 +113,13 @@ en:
         the '-f yourlogstash.conf' flag?
       config-string-path-exclusive:
         Settings 'path.config' (-f) and 'config.string' (-e) can't be used simultaneously.
+      config-module-exclusive: >-
+        Settings 'path.config' (-f) or 'config.string' (-e) can't be used in conjunction with
+        (--modules) or the "modules:" block in the logstash.yml file.
+      cli-module-override: >-
+        Both command-line and logstash.yml modules configurations detected. 
+        Using command-line module configuration and ignoring logstash.yml module
+        configuration.
       reload-without-config-path: >-
         Configuration reloading also requires passing a configuration path with '-f yourlogstash.conf'
       locked-data-path: >-
@@ -185,6 +205,24 @@ en:
           "%{default_output}"
           If you wish to use both defaults, please use
           the empty string for the '-e' flag.
+        modules: |+
+          Load Logstash modules.
+          Modules can be defined using multiple instances 
+          '--modules module1 --modules module2', 
+             or comma-separated syntax 
+          '--modules=module1,module2' 
+          Cannot be used in conjunction with '-e' or '-f'
+          Use of '--modules' will override modules declared
+          in the 'logstash.yml' file.
+        modules_variable: |+
+          Load variables for module template.
+          Multiple instances of '-M' or 
+          '--modules.variable' are supported.
+          Ignored if '--modules' flag is not used.
+          Should be in the format of 
+          '-M "MODULE_NAME.var.PLUGIN_TYPE.PLUGIN_NAME.VARIABLE_NAME=VALUE"'
+          as in 
+          '-M "example.var.filter.mutate.fieldname=fieldvalue"'
         configtest: |+
           Check configuration for valid syntax and then exit.
         http_host: Web API binding host
diff --git a/logstash-core/spec/logstash/agent_spec.rb b/logstash-core/spec/logstash/agent_spec.rb
index a33472c01aa..1da3c75faa1 100644
--- a/logstash-core/spec/logstash/agent_spec.rb
+++ b/logstash-core/spec/logstash/agent_spec.rb
@@ -122,7 +122,7 @@
 
           it "does not upgrade the new config" do
             t = Thread.new { subject.execute }
-            sleep(0.01) until subject.running_pipelines? && subject.pipelines.values.first.ready?
+            sleep(0.01) until subject.with_pipelines {|pipelines| subject.running_pipelines? && pipelines.values.first.ready? }
 
             expect(subject.converge_state_and_update).not_to be_a_successful_converge
             expect(subject).to have_running_pipeline?(mock_config_pipeline)
@@ -141,7 +141,7 @@
 
           it "does upgrade the new config" do
             t = Thread.new { subject.execute }
-            sleep(0.01) until subject.pipelines_count > 0 && subject.pipelines.values.first.ready?
+            sleep(0.01) until subject.with_pipelines {|pipelines| subject.pipelines_count > 0 && pipelines.values.first.ready? }
 
             expect(subject.converge_state_and_update).to be_a_successful_converge
             expect(subject).to have_running_pipeline?(mock_second_pipeline_config)
@@ -163,7 +163,7 @@
 
           it "does not try to reload the pipeline" do
             t = Thread.new { subject.execute }
-            sleep(0.01) until subject.running_pipelines? && subject.pipelines.values.first.running?
+            sleep(0.01) until subject.with_pipelines {|pipelines| subject.running_pipelines? && pipelines.values.first.running? }
 
             expect(subject.converge_state_and_update).not_to be_a_successful_converge
             expect(subject).to have_running_pipeline?(mock_config_pipeline)
@@ -182,7 +182,7 @@
 
           it "tries to reload the pipeline" do
             t = Thread.new { subject.execute }
-            sleep(0.01) until subject.running_pipelines? && subject.pipelines.values.first.running?
+            sleep(0.01) until subject.with_pipelines {|pipelines| subject.running_pipelines? && pipelines.values.first.running? }
 
             expect(subject.converge_state_and_update).to be_a_successful_converge
             expect(subject).to have_running_pipeline?(mock_second_pipeline_config)
@@ -194,28 +194,6 @@
         end
       end
     end
-
-    context "when auto_reload is true" do
-      let(:agent_settings) { mock_settings("config.reload.automatic" => true, "config.reload.interval" => 0.0001) }
-      subject { described_class.new(agent_settings, default_source_loader) }
-
-      let(:agent_args) { { "path.config" => config_file } }
-
-      context "if state is clean" do
-        it "should periodically reload_state" do
-          allow(subject).to receive(:clean_state?).and_return(false)
-          t = Thread.new { subject.execute }
-          sleep(0.01) until subject.running_pipelines? && subject.pipelines.values.first.running?
-          expect(subject).to receive(:converge_state_and_update).at_least(2).times
-          # TODO this is a bad practice, any suggestions on how to test something happens
-          # without some form of timing or expiring condition?
-          sleep 0.1
-          Stud.stop!(t)
-          t.join
-          subject.shutdown
-        end
-      end
-    end
   end
 
   describe "Environment Variables In Configs" do
@@ -285,7 +263,7 @@
     context "when the upgrade fails" do
       it "leaves the state untouched" do
         expect(subject.converge_state_and_update).not_to be_a_successful_converge
-        expect(subject.pipelines[default_pipeline_id].config_str).to eq(pipeline_config)
+        expect(subject.get_pipeline(default_pipeline_id).config_str).to eq(pipeline_config)
       end
 
       # TODO(ph): This valid?
@@ -303,12 +281,12 @@
 
       it "updates the state" do
         expect(subject.converge_state_and_update).to be_a_successful_converge
-        expect(subject.pipelines[default_pipeline_id].config_str).to eq(new_config)
+        expect(subject.get_pipeline(default_pipeline_id).config_str).to eq(new_config)
       end
 
       it "starts the pipeline" do
         expect(subject.converge_state_and_update).to be_a_successful_converge
-        expect(subject.pipelines[default_pipeline_id].running?).to be_truthy
+        expect(subject.get_pipeline(default_pipeline_id).running?).to be_truthy
       end
     end
   end
diff --git a/logstash-core/src/test/java/org/logstash/FileLockFactoryMain.java b/logstash-core/src/test/java/org/logstash/FileLockFactoryMain.java
new file mode 100644
index 00000000000..b285ea246d5
--- /dev/null
+++ b/logstash-core/src/test/java/org/logstash/FileLockFactoryMain.java
@@ -0,0 +1,23 @@
+package org.logstash;
+
+import java.io.IOException;
+
+/*
+ * This program is used to test the FileLockFactory in cross-process/JVM.
+ */
+public class FileLockFactoryMain {
+
+    public static void main(String[] args) {
+        try {
+            FileLockFactory.getDefault().obtainLock(args[0], args[1]);
+            System.out.println("File locked");
+            // Sleep enough time until this process is killed.
+            Thread.sleep(Long.MAX_VALUE);
+        } catch (InterruptedException e) {
+            // This process is killed. Do nothing.
+        } catch (IOException e) {
+            // Failed to obtain the lock.
+            System.exit(1);
+        }
+    }
+}
diff --git a/logstash-core/src/test/java/org/logstash/FileLockFactoryTest.java b/logstash-core/src/test/java/org/logstash/FileLockFactoryTest.java
index f11c97dd2f6..c1487f7e501 100644
--- a/logstash-core/src/test/java/org/logstash/FileLockFactoryTest.java
+++ b/logstash-core/src/test/java/org/logstash/FileLockFactoryTest.java
@@ -1,16 +1,24 @@
 package org.logstash;
 
+import org.junit.After;
 import org.junit.Before;
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.TemporaryFolder;
 
 import static org.junit.Assert.fail;
+import static org.junit.Assert.assertTrue;
 
 import java.io.IOException;
+import java.io.InputStream;
 import java.nio.channels.FileLock;
 import java.nio.file.FileSystems;
 import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
 
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.CoreMatchers.is;
@@ -24,9 +32,12 @@ public class FileLockFactoryTest {
 
     private FileLock lock;
 
+    private ExecutorService executor;
+
     @Before
     public void setUp() throws Exception {
         lockDir = temporaryFolder.newFolder("lock").getPath();
+        executor = Executors.newSingleThreadExecutor();
     }
 
     @Before
@@ -36,6 +47,14 @@ public void lockFirst() throws Exception {
         assertThat(lock.isShared(), is(equalTo(false)));
     }
 
+    @After
+    public void tearDown() throws Exception {
+        executor.shutdownNow();
+        if (!executor.awaitTermination(2L, TimeUnit.MINUTES)) {
+            throw new IllegalStateException("Failed to shut down Executor");
+        }
+    }
+
     @Test
     public void ObtainLockOnNonLocked() throws IOException {
         // empty to just test the lone @Before lockFirst() test
@@ -88,4 +107,45 @@ public void ReleaseUnobtainedLock() throws IOException {
         FileLockFactory.getDefault().releaseLock(lock);
         FileLockFactory.getDefault().releaseLock(lock);
     }
+
+    @Test
+    public void crossJvmObtainLockOnLocked() throws Exception {
+        Process p = null;
+        String lockFile = ".testCrossJvm";
+        FileLock lock = null;
+
+        // Build the command to spawn a children JVM.
+        String[] cmd = {
+            Paths.get(System.getProperty("java.home"), "bin", "java").toString(),
+            "-cp", System.getProperty("java.class.path"),
+            Class.forName("org.logstash.FileLockFactoryMain").getName(),
+            lockDir, lockFile
+        };
+
+        try {
+            // Start the children program that will lock the file.
+            p = new ProcessBuilder(cmd).start();
+            InputStream is = p.getInputStream();
+            /* Wait the children program write to stdout, meaning the file
+             * is locked. Set a timeout to ensure it returns.
+             */
+            Future<Integer> future = executor.submit(() -> {return is.read();});
+            assertTrue(future.get(30, TimeUnit.SECONDS) > -1);
+
+            // Check the children process is still running.
+            assertThat(p.isAlive(), is(equalTo(true)));
+
+            try {
+                // Try to obtain the lock held by the children process.
+                FileLockFactory.getDefault().obtainLock(lockDir, lockFile);
+                fail("Should have threw an exception");
+            } catch (LockException e) {
+                // Expected exception as the file is already locked.
+            }
+        } finally {
+            if (p != null) {
+                p.destroy();
+            }
+        }
+    }
 }
diff --git a/qa/acceptance/spec/lib/cli_operation_spec.rb b/qa/acceptance/spec/lib/cli_operation_spec.rb
index 9c11aceff83..6f6ec1a2946 100644
--- a/qa/acceptance/spec/lib/cli_operation_spec.rb
+++ b/qa/acceptance/spec/lib/cli_operation_spec.rb
@@ -20,6 +20,6 @@
     it_behaves_like "logstash uninstall", logstash
     it_behaves_like "logstash remove", logstash
     it_behaves_like "logstash update", logstash
-    it_behaves_like "logstash generate", logstash
+#    it_behaves_like "logstash generate", logstash
   end
 end
diff --git a/qa/sys/debian/debian-8/bootstrap.sh b/qa/sys/debian/debian-8/bootstrap.sh
index d1a23d54430..da56514aae8 100644
--- a/qa/sys/debian/debian-8/bootstrap.sh
+++ b/qa/sys/debian/debian-8/bootstrap.sh
@@ -1,5 +1,6 @@
 #!/usr/bin/env bash
 
 echo "deb http://http.debian.net/debian jessie-backports main" >> /etc/apt/sources.list
+puts "installing jdk8"
 apt-get update
-apt-get install -y openjdk-8-jdk
+apt-get install -y ca-certificates-java openjdk-8-jdk-headless
diff --git a/rakelib/artifacts.rake b/rakelib/artifacts.rake
index f518449740b..1f72d947bef 100644
--- a/rakelib/artifacts.rake
+++ b/rakelib/artifacts.rake
@@ -52,7 +52,6 @@ namespace "artifact" do
     @exclude_paths << "bin/bundle"
     @exclude_paths << "bin/rspec"
     @exclude_paths << "bin/rspec.bat"
-    @exclude_paths << "bin/lock"
 
     @exclude_paths
   end
