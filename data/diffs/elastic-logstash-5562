diff --git a/config/logstash.yml b/config/logstash.yml
index 99cad344dfa..f9b91601a10 100644
--- a/config/logstash.yml
+++ b/config/logstash.yml
@@ -50,6 +50,18 @@
 #
 # pipeline.unsafe_shutdown: false
 #
+# Defaults to false. Setting this to true will catch all unexpected errors in the
+# pipeline without terminating logstash.
+# Logstash will do all of the following: drop the erroring event,
+# log an error-level message, and continue processing. This will also increment
+# the 'errored' count in the pipeline stats API at /_node/pipeline/events.
+#
+# If set to false logstash will immediately exit with an error in these
+# conditions, which may be more safe since potentially fewer events would be dropped.
+#
+# pipeline.continue_on_error: true
+#
+#
 # ------------ Pipeline Configuration Settings --------------
 #
 # Where to fetch the pipeline configuration for the main pipeline
diff --git a/logstash-core/lib/logstash/api/commands/stats.rb b/logstash-core/lib/logstash/api/commands/stats.rb
index 533d3e7e862..16921d29207 100644
--- a/logstash-core/lib/logstash/api/commands/stats.rb
+++ b/logstash-core/lib/logstash/api/commands/stats.rb
@@ -29,7 +29,7 @@ def process
         def events
           extract_metrics(
             [:stats, :events],
-            :in, :filtered, :out
+            :in, :filtered, :out, :errored
           )
         end
 
diff --git a/logstash-core/lib/logstash/environment.rb b/logstash-core/lib/logstash/environment.rb
index 560629ff47f..96895c6cd16 100644
--- a/logstash-core/lib/logstash/environment.rb
+++ b/logstash-core/lib/logstash/environment.rb
@@ -20,6 +20,7 @@ module LogStash
            Setting::Numeric.new("pipeline.batch.size", 125),
            Setting::Numeric.new("pipeline.batch.delay", 5), # in milliseconds
            Setting::Boolean.new("pipeline.unsafe_shutdown", false),
+           Setting::Boolean.new("pipeline.continue_on_error", false),
                     Setting.new("path.plugins", Array, []),
             Setting::String.new("interactive", nil, false),
            Setting::Boolean.new("config.debug", false),
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 024f75c7f1a..a0c1a63defd 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -33,7 +33,9 @@ module LogStash; class Pipeline
     :thread,
     :config_str,
     :settings,
-    :metric
+    :metric,
+    :namespace_events,
+    :namespace_pipeline
 
   MAX_INFLIGHT_WARN_THRESHOLD = 10_000
 
@@ -47,6 +49,7 @@ def initialize(config_str, settings = LogStash::SETTINGS, namespaced_metric = ni
     @settings = settings
     @pipeline_id = @settings.get_value("pipeline.id") || self.object_id
     @reporter = LogStash::PipelineReporter.new(@logger, self)
+    @continue_on_error = LogStash::SETTINGS.get("pipeline.continue_on_error")
 
     @inputs = nil
     @filters = nil
@@ -58,6 +61,15 @@ def initialize(config_str, settings = LogStash::SETTINGS, namespaced_metric = ni
     # sure the metric instance is correctly send to the plugins to make the namespace scoping work
     @metric = namespaced_metric.nil? ? LogStash::Instrument::NullMetric.new : namespaced_metric
 
+    @namespace_events = metric.namespace([:stats, :events])
+    @namespace_pipeline = metric.namespace([:stats, :pipelines, pipeline_id.to_s.to_sym, :events])
+
+    # Zero out these counters
+    [:in, :filtered, :out, :errored].each do |name|
+      @namespace_events.increment(name, 0)
+      @namespace_pipeline.increment(name, 0)
+    end
+    
     grammar = LogStashConfigParser.new
     @config = grammar.parse(config_str)
     if @config.nil?
@@ -221,10 +233,7 @@ def start_workers
   # Repeatedly takes batches off the queue, filters, then outputs them
   def worker_loop(batch_size, batch_delay)
     running = true
-
-    namespace_events = metric.namespace([:stats, :events])
-    namespace_pipeline = metric.namespace([:stats, :pipelines, pipeline_id.to_s.to_sym, :events])
-
+    
     while running
       # To understand the purpose behind this synchronize please read the body of take_batch
       input_batch, signal = @input_queue_pop_mutex.synchronize { take_batch(batch_size, batch_delay) }
@@ -284,21 +293,12 @@ def take_batch(batch_size, batch_delay)
   def filter_batch(batch)
     batch.reduce([]) do |acc,e|
       if e.is_a?(LogStash::Event)
-        filtered = filter_func(e)
+        filtered = with_pipeline_rescue(e) { filter_func(e) }
+        next acc if filtered.nil? # with_pipeline_rescue may return nil!
         filtered.each {|fe| acc << fe unless fe.cancelled?}
       end
       acc
     end
-  rescue Exception => e
-    # Plugins authors should manage their own exceptions in the plugin code
-    # but if an exception is raised up to the worker thread they are considered
-    # fatal and logstash will not recover from this situation.
-    #
-    # Users need to check their configuration or see if there is a bug in the
-    # plugin.
-    @logger.error("Exception in pipelineworker, the pipeline stopped processing new events, please check your filter configuration and restart Logstash.",
-                  "exception" => e, "backtrace" => e.backtrace)
-    raise
   end
 
   # Take an array of events and send them to the correct output
@@ -310,7 +310,7 @@ def output_batch(batch)
 
       # output_func should never return anything other than an Array but we have lots of legacy specs
       # that monkeypatch it and return nil. We can deprecate  "|| []" after fixing these specs
-      outputs_for_event = output_func(event) || []
+      outputs_for_event = with_pipeline_rescue(event) { output_func(event) } || []
 
       outputs_for_event.each { |output| acc[output] << event }
       acc
@@ -318,7 +318,31 @@ def output_batch(batch)
 
     # Now that we have our output to event mapping we can just invoke each output
     # once with its list of events
-    outputs_events.each { |output, events| output.multi_receive(events) }
+    outputs_events.each do |output, events|
+      with_pipeline_rescue(events) do
+        output.multi_receive(events)
+      end
+    end
+  end
+
+  def with_pipeline_rescue(event_or_events)
+    yield
+  rescue Exception => e
+    events = Array(event_or_events)
+    namespace_events.increment(:errored, events.size)
+    namespace_pipeline.increment(:errored, events.size)
+    
+    logger_opts = {:message => e.message, :class => e.class.name}
+    logger_message = "Exception in pipelineworker!"
+
+    if @logger.info?
+      logger_opts[:events] = events.map(&:to_hash)
+    end
+    
+    logger_message << "Enable info logging to see failed events" if !@logger.info?
+    
+    raise unless @continue_on_error
+    nil
   end
 
   def set_current_thread_inflight_batch(batch)
diff --git a/logstash-core/spec/api/lib/api/node_stats_spec.rb b/logstash-core/spec/api/lib/api/node_stats_spec.rb
index 44cc0a3c37e..e3eeb535d57 100644
--- a/logstash-core/spec/api/lib/api/node_stats_spec.rb
+++ b/logstash-core/spec/api/lib/api/node_stats_spec.rb
@@ -14,7 +14,8 @@
     "events"=>{
       "in"=>Numeric,
       "filtered"=>Numeric,
-      "out"=>Numeric
+      "out"=>Numeric,
+      "errored"=>Numeric
     },
     "jvm"=>{
       "threads"=>{
diff --git a/logstash-core/spec/logstash/pipeline_spec.rb b/logstash-core/spec/logstash/pipeline_spec.rb
index 823e2cb5df9..be034c35829 100644
--- a/logstash-core/spec/logstash/pipeline_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_spec.rb
@@ -100,6 +100,90 @@ class TestPipeline < LogStash::Pipeline
     pipeline_settings_obj.reset
   end
 
+  describe "rescuing pipeline exceptions" do
+    before(:each) do
+      allow(LogStash::Plugin).to receive(:lookup).with("input", "dummyinput").and_return(DummyInput)
+      allow(LogStash::Plugin).to receive(:lookup).with("codec", "plain").and_return(DummyCodec)
+      allow(LogStash::Plugin).to receive(:lookup).with("output", "dummyoutput").and_return(DummyOutput)
+      allow(LogStash::Plugin).to receive(:lookup).with("filter", "dummyfilter").and_return(DummyFilter)
+      allow(LogStash::Plugin).to receive(:lookup).with("filter", "dummysafefilter").and_return(DummySafeFilter)
+    end
+
+    let(:config) do
+      <<-eos
+        input {
+          dummyinput {}
+        }
+
+        filter {
+          if [foo] > 2 { # Intentionally omit nil check
+            dummyfilter {}
+          }
+        }
+
+        output {
+          if [foo] > 2 {
+             dummyoutput {}
+          }
+        }
+        eos
+    end
+
+    let(:pipeline) { TestPipeline.new(config, pipeline_settings_obj) }
+
+    context "when pipeline.continue_on_error is false" do
+      before(:each) do
+        pipeline_settings_obj.set("pipeline.continue_on_error", false)
+      end
+      
+      it "should raise an exception when filtering bad events" do
+        expect do
+          pipeline.filter_batch([LogStash::Event.new])
+        end.to raise_error(NoMethodError)
+      end
+
+      it "should raise an exception when outputting bad events" do
+        expect do
+          pipeline.output_batch([LogStash::Event.new])
+        end.to raise_error(NoMethodError)
+      end
+    end
+
+    context "when pipeline.continue_on_error is true" do
+      before(:each) do
+        pipeline_settings_obj.set("pipeline.continue_on_error", true)
+      end
+      
+      it "should raise an exception when filtering bad events" do
+        expect do
+          pipeline.filter_batch([LogStash::Event.new])
+        end.not_to raise_error
+      end
+
+      it "should raise an exception when outputting bad events" do
+        expect do
+          pipeline.output_batch([LogStash::Event.new])
+        end.not_to raise_error
+      end
+
+      describe "metrics" do
+        before(:each) do
+          allow(pipeline.namespace_events).to receive(:increment).with(any_args)
+          allow(pipeline.namespace_pipeline).to receive(:increment).with(any_args)
+          pipeline.output_batch([LogStash::Event.new])
+        end
+        
+        it "should increment the global errored count for metrics" do
+          expect(pipeline.namespace_events).to have_received(:increment).with(:errored, 1)
+        end
+
+        it "should increment the pipeline specific errored count for metrics" do
+          expect(pipeline.namespace_pipeline).to have_received(:increment).with(:errored, 1)
+        end
+      end
+    end
+  end
+
   describe "defaulting the pipeline workers based on thread safety" do
     before(:each) do
       allow(LogStash::Plugin).to receive(:lookup).with("input", "dummyinput").and_return(DummyInput)
