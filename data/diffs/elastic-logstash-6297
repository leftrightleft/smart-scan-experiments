diff --git a/logstash-core-queue-jruby/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueExtLibrary.java b/logstash-core-queue-jruby/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueExtLibrary.java
index 30e12b94af9..cf63c360c9d 100644
--- a/logstash-core-queue-jruby/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueExtLibrary.java
+++ b/logstash-core-queue-jruby/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueExtLibrary.java
@@ -57,22 +57,24 @@ public Queue getQueue() {
         }
 
         // def initialize
-        @JRubyMethod(name = "initialize", optional = 6)
+        @JRubyMethod(name = "initialize", optional = 7)
         public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args)
         {
-            args = Arity.scanArgs(context.runtime, args, 6, 0);
+            args = Arity.scanArgs(context.runtime, args, 7, 0);
 
             int capacity = RubyFixnum.num2int(args[1]);
             int maxUnread = RubyFixnum.num2int(args[2]);
             int checkpointMaxAcks = RubyFixnum.num2int(args[3]);
             int checkpointMaxWrites = RubyFixnum.num2int(args[4]);
             int checkpointMaxInterval = RubyFixnum.num2int(args[5]);
+            long queueMaxBytes = RubyFixnum.num2long(args[6]);
 
             Settings s = new FileSettings(args[0].asJavaString());
             PageIOFactory pageIOFactory = (pageNum, size, path) -> new MmapPageIO(pageNum, size, path);
             CheckpointIOFactory checkpointIOFactory = (source) -> new FileCheckpointIO(source);
             s.setCapacity(capacity);
             s.setMaxUnread(maxUnread);
+            s.setQueueMaxBytes(queueMaxBytes);
             s.setCheckpointMaxAcks(checkpointMaxAcks);
             s.setCheckpointMaxWrites(checkpointMaxWrites);
             s.setCheckpointMaxInterval(checkpointMaxInterval);
diff --git a/logstash-core-queue-jruby/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueMemoryExtLibrary.java b/logstash-core-queue-jruby/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueMemoryExtLibrary.java
index 3ba29210867..90fe314823d 100644
--- a/logstash-core-queue-jruby/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueMemoryExtLibrary.java
+++ b/logstash-core-queue-jruby/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueMemoryExtLibrary.java
@@ -57,19 +57,21 @@ public Queue getQueue() {
         }
 
         // def initialize
-        @JRubyMethod(name = "initialize", optional = 3)
+        @JRubyMethod(name = "initialize", optional = 4)
         public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args)
         {
-            args = Arity.scanArgs(context.runtime, args, 3, 0);
+            args = Arity.scanArgs(context.runtime, args, 4, 0);
 
             int capacity = RubyFixnum.num2int(args[1]);
             int maxUnread = RubyFixnum.num2int(args[2]);
+            long queueMaxBytes = RubyFixnum.num2long(args[3]);
 
             Settings s = new MemorySettings(args[0].asJavaString());
             PageIOFactory pageIOFactory = (pageNum, size, path) -> new ByteBufferPageIO(pageNum, size, path);
             CheckpointIOFactory checkpointIOFactory = (source) -> new MemoryCheckpointIO(source);
             s.setCapacity(capacity);
             s.setMaxUnread(maxUnread);
+            s.setQueueMaxBytes(queueMaxBytes);
             s.setElementIOFactory(pageIOFactory);
             s.setCheckpointIOFactory(checkpointIOFactory);
             s.setElementClass(Event.class);
diff --git a/logstash-core/lib/logstash/environment.rb b/logstash-core/lib/logstash/environment.rb
index a8badea05df..2931f3bf065 100644
--- a/logstash-core/lib/logstash/environment.rb
+++ b/logstash-core/lib/logstash/environment.rb
@@ -42,6 +42,7 @@ module Environment
             Setting::String.new("http.environment", "production"),
             Setting::String.new("queue.type", "memory", true, ["persisted", "memory", "memory_acked"]),
             Setting::Bytes.new("queue.page_capacity", "250mb"),
+            Setting::Bytes.new("queue.max_bytes", "1024mb"),
             Setting::Numeric.new("queue.max_events", 0), # 0 is unlimited
             Setting::Numeric.new("queue.checkpoint.acks", 1024), # 0 is unlimited
             Setting::Numeric.new("queue.checkpoint.writes", 1024), # 0 is unlimited
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 039868d179e..6b244c80312 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -118,21 +118,22 @@ def initialize(config_str, settings = SETTINGS, namespaced_metric = nil)
   def build_queue_from_settings
     queue_type = settings.get("queue.type")
     queue_page_capacity = settings.get("queue.page_capacity")
-    max_events = settings.get("queue.max_events")
+    queue_max_bytes = settings.get("queue.max_bytes")
+    queue_max_events = settings.get("queue.max_events")
     checkpoint_max_acks = settings.get("queue.checkpoint.acks")
     checkpoint_max_writes = settings.get("queue.checkpoint.writes")
     checkpoint_max_interval = settings.get("queue.checkpoint.interval")
 
     if queue_type == "memory_acked"
       # memory_acked is used in tests/specs
-      LogStash::Util::WrappedAckedQueue.create_memory_based("", queue_page_capacity, max_events)
+      LogStash::Util::WrappedAckedQueue.create_memory_based("", queue_page_capacity, queue_max_events, queue_max_bytes)
     elsif queue_type == "memory"
       # memory is the legacy and default setting
       LogStash::Util::WrappedSynchronousQueue.new()
     elsif queue_type == "persisted"
       # persisted is the disk based acked queue
       queue_path = settings.get("path.queue")
-      LogStash::Util::WrappedAckedQueue.create_file_based(queue_path, queue_page_capacity, max_events, checkpoint_max_writes, checkpoint_max_acks, checkpoint_max_interval)
+      LogStash::Util::WrappedAckedQueue.create_file_based(queue_path, queue_page_capacity, queue_max_events, checkpoint_max_writes, checkpoint_max_acks, checkpoint_max_interval, queue_max_bytes)
     else
       raise(ConfigurationError, "invalid queue.type setting")
     end
diff --git a/logstash-core/lib/logstash/util/wrapped_acked_queue.rb b/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
index da9b3a6d753..ffac9eaab4c 100644
--- a/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
+++ b/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
@@ -19,15 +19,15 @@ class WrappedAckedQueue
     class QueueClosedError < ::StandardError; end
     class NotImplementedError < ::StandardError; end
 
-    def self.create_memory_based(path, capacity, size)
+    def self.create_memory_based(path, capacity, max_events, max_bytes)
       self.allocate.with_queue(
-        LogStash::AckedMemoryQueue.new(path, capacity, size)
+        LogStash::AckedMemoryQueue.new(path, capacity, max_events, max_bytes)
       )
     end
 
-    def self.create_file_based(path, capacity, size, checkpoint_max_writes, checkpoint_max_acks, checkpoint_max_interval)
+    def self.create_file_based(path, capacity, max_events, checkpoint_max_writes, checkpoint_max_acks, checkpoint_max_interval, max_bytes)
       self.allocate.with_queue(
-        LogStash::AckedQueue.new(path, capacity, size, checkpoint_max_writes, checkpoint_max_acks, checkpoint_max_interval)
+        LogStash::AckedQueue.new(path, capacity, max_events, checkpoint_max_writes, checkpoint_max_acks, checkpoint_max_interval, max_bytes)
       )
     end
 
diff --git a/logstash-core/spec/logstash/pipeline_pq_file_spec.rb b/logstash-core/spec/logstash/pipeline_pq_file_spec.rb
index 9349868eac6..b715f457f0d 100644
--- a/logstash-core/spec/logstash/pipeline_pq_file_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_pq_file_spec.rb
@@ -78,6 +78,7 @@ def close
   let(:worker_thread_count) { 8 } # 1 4 8
   let(:number_of_events) { 100_000 }
   let(:page_capacity) { 1 * 1024 * 512 } # 1 128
+  let(:max_bytes) { 1024 * 1024 * 1024 } # 1 gb
   let(:queue_type) { "persisted" } #  "memory" "memory_acked"
   let(:times) { [] }
 
@@ -95,6 +96,7 @@ def close
     allow(pipeline_workers_setting).to receive(:default).and_return(worker_thread_count)
     pipeline_settings.each {|k, v| pipeline_settings_obj.set(k, v) }
     pipeline_settings_obj.set("queue.page_capacity", page_capacity)
+    pipeline_settings_obj.set("queue.max_bytes", max_bytes)
     Thread.new do
       # make sure we have received all the generated events
       while counting_output.event_count < number_of_events do
@@ -121,6 +123,7 @@ def close
     expect(_metric[:out].value).to eq(number_of_events)
     STDOUT.puts "  queue.type: #{pipeline_settings_obj.get("queue.type")}"
     STDOUT.puts "  queue.page_capacity: #{pipeline_settings_obj.get("queue.page_capacity") / 1024}KB"
+    STDOUT.puts "  queue.max_bytes: #{pipeline_settings_obj.get("queue.max_bytes") / 1024}KB"
     STDOUT.puts "  workers: #{worker_thread_count}"
     STDOUT.puts "  events: #{number_of_events}"
     STDOUT.puts "  took: #{times.first}s"
diff --git a/logstash-core/spec/logstash/pipeline_spec.rb b/logstash-core/spec/logstash/pipeline_spec.rb
index 49cbb651e9c..919dffaa52d 100644
--- a/logstash-core/spec/logstash/pipeline_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_spec.rb
@@ -450,6 +450,7 @@ class TestPipeline < LogStash::Pipeline
       allow(settings).to receive(:get).with("queue.type").and_return("memory")
       allow(settings).to receive(:get).with("queue.page_capacity").and_return(1024 * 1024)
       allow(settings).to receive(:get).with("queue.max_events").and_return(250)
+      allow(settings).to receive(:get).with("queue.max_bytes").and_return(1024 * 1024 * 1024)
       allow(settings).to receive(:get).with("queue.checkpoint.acks").and_return(1024)
       allow(settings).to receive(:get).with("queue.checkpoint.writes").and_return(1024)
       allow(settings).to receive(:get).with("queue.checkpoint.interval").and_return(1000)
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/FileSettings.java b/logstash-core/src/main/java/org/logstash/ackedqueue/FileSettings.java
index 8267cfa5c99..c627e3f6165 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/FileSettings.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/FileSettings.java
@@ -9,6 +9,7 @@ public class FileSettings implements Settings {
     private PageIOFactory pageIOFactory;
     private Class elementClass;
     private int capacity;
+    private long queueMaxBytes;
     private int maxUnread;
     private int checkpointMaxAcks;
     private int checkpointMaxWrites;
@@ -42,6 +43,12 @@ public Settings setElementClass(Class elementClass) {
         return this;
     }
 
+    @Override
+    public Settings setQueueMaxBytes(long size) {
+        this.queueMaxBytes = size;
+        return this;
+    }
+
     @Override
     public Settings setCapacity(int capacity) {
         this.capacity = capacity;
@@ -106,6 +113,11 @@ public String getDirPath() {
         return dirForFiles;
     }
 
+    @Override
+    public long getQueueMaxBytes() {
+        return queueMaxBytes;
+    }
+
     @Override
     public int getCapacity() {
         return capacity;
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/MemorySettings.java b/logstash-core/src/main/java/org/logstash/ackedqueue/MemorySettings.java
index f83f6e42171..3d9ea6672bd 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/MemorySettings.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/MemorySettings.java
@@ -8,6 +8,7 @@ public class MemorySettings implements Settings {
     private PageIOFactory pageIOFactory;
     private Class elementClass;
     private int capacity;
+    private long queueMaxBytes;
     private final String dirPath;
     private int maxUnread;
     private int checkpointMaxAcks;
@@ -50,6 +51,12 @@ public Settings setCapacity(int capacity) {
         return this;
     }
 
+    @Override
+    public Settings setQueueMaxBytes(long size) {
+        this.queueMaxBytes = size;
+        return this;
+    }
+
     @Override
     public Settings setMaxUnread(int maxUnread) {
         this.maxUnread = maxUnread;
@@ -108,6 +115,11 @@ public String getDirPath() {
         return this.dirPath;
     }
 
+    @Override
+    public long getQueueMaxBytes() {
+        return this.queueMaxBytes;
+    }
+
     @Override
     public int getCapacity() {
         return this.capacity;
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java b/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
index bd561d80a83..6f9b48bcb7c 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
@@ -41,9 +41,12 @@ public class Queue implements Closeable {
 
     protected volatile long unreadCount;
 
+    protected volatile long currentByteSize;
+
     private final CheckpointIO checkpointIO;
     private final PageIOFactory pageIOFactory;
     private final int pageCapacity;
+    private final long maxBytes;
     private final String dirPath;
     private final int maxUnread;
     private final int checkpointMaxAcks;
@@ -65,6 +68,7 @@ public Queue(Settings settings) {
         this(
                 settings.getDirPath(),
                 settings.getCapacity(),
+                settings.getQueueMaxBytes(),
                 settings.getCheckpointIOFactory().build(settings.getDirPath()),
                 settings.getPageIOFactory(),
                 settings.getElementClass(),
@@ -75,9 +79,10 @@ public Queue(Settings settings) {
         );
     }
 
-    public Queue(String dirPath, int pageCapacity, CheckpointIO checkpointIO, PageIOFactory pageIOFactory, Class elementClass, int maxUnread, int checkpointMaxWrites, int checkpointMaxAcks, int checkpointMaxInterval) {
+    public Queue(String dirPath, int pageCapacity, long maxBytes, CheckpointIO checkpointIO, PageIOFactory pageIOFactory, Class elementClass, int maxUnread, int checkpointMaxWrites, int checkpointMaxAcks, int checkpointMaxInterval) {
         this.dirPath = dirPath;
         this.pageCapacity = pageCapacity;
+        this.maxBytes = maxBytes;
         this.checkpointIO = checkpointIO;
         this.pageIOFactory = pageIOFactory;
         this.elementClass = elementClass;
@@ -89,6 +94,7 @@ public Queue(String dirPath, int pageCapacity, CheckpointIO checkpointIO, PageIO
         this.checkpointMaxWrites = checkpointMaxWrites;
         this.checkpointMaxInterval = checkpointMaxInterval;
         this.unreadCount = 0;
+        this.currentByteSize = 0;
 
         // retrieve the deserialize method
         try {
@@ -135,6 +141,7 @@ public void open() throws IOException {
             Checkpoint tailCheckpoint = this.checkpointIO.read(this.checkpointIO.tailFileName(pageNum));
 
             PageIO pageIO = this.pageIOFactory.build(pageNum, this.pageCapacity, this.dirPath);
+
             add(tailCheckpoint, pageIO);
         }
 
@@ -146,6 +153,7 @@ public void open() throws IOException {
 
             PageIO headPageIO = this.pageIOFactory.build(headCheckpoint.getPageNum(), this.pageCapacity, this.dirPath);
             this.headPage = new HeadPage(headCheckpoint, this, headPageIO);
+            this.currentByteSize += headPageIO.getCapacity();
 
             // but checkpoint it to update the firstUnackedPageNum if it changed
             this.headPage.checkpoint();
@@ -153,6 +161,7 @@ public void open() throws IOException {
             // head page is non-empty, transform it into a tail page and create a new empty head page
 
             PageIO pageIO = this.pageIOFactory.build(headCheckpoint.getPageNum(), this.pageCapacity, this.dirPath);
+
             TailPage p = new TailPage(headCheckpoint, this, pageIO);
             p.checkpoint();
             add(headCheckpoint, pageIO);
@@ -197,6 +206,7 @@ private void add(Checkpoint checkpoint, PageIO pageIO) throws IOException {
             this.tailPages.add(p);
             this.unreadTailPages.add(p);
             this.unreadCount += p.unreadCount();
+            this.currentByteSize += pageIO.getCapacity();
 
             // for now deactivate all tail pages, we will only reactivate the first one at the end
             pageIO.deactivate();
@@ -215,7 +225,7 @@ private void newCheckpointedHeadpage(int pageNum) throws IOException {
         PageIO headPageIO = this.pageIOFactory.build(pageNum, this.pageCapacity, this.dirPath);
         this.headPage = new HeadPage(pageNum, this, headPageIO);
         this.headPage.forceCheckpoint();
-
+        this.currentByteSize += headPageIO.getCapacity();
     }
 
     // @param element the Queueable object to write to the queue
@@ -290,7 +300,11 @@ public long write(Queueable element) throws IOException {
     public boolean isFull() {
         // TODO: I am not sure if having unreadCount as volatile is sufficient here. all unreadCount updates are done inside syncronized
         // TODO: sections, I believe that to only read the value here, having it as volatile is sufficient?
-        return (this.maxUnread > 0) ? this.unreadCount >= this.maxUnread : false;
+        if ((this.maxBytes > 0) && this.currentByteSize >= this.maxBytes) {
+            return true;
+        } else {
+            return ((this.maxUnread > 0) && this.unreadCount >= this.maxUnread);
+        }
     }
 
     // @param seqNum the element sequence number upper bound for which persistence should be garanteed (by fsync'ing)
@@ -481,6 +495,7 @@ public void ack(List<Long> seqNums) throws IOException {
 
                     // remove page data file regardless if it is the first or a middle tail page to free resources
                     result.page.purge();
+                    this.currentByteSize -= result.page.getPageIO().getCapacity();
 
                      if (result.index == 0) {
                         // if this is the first page also remove checkpoint file
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/Settings.java b/logstash-core/src/main/java/org/logstash/ackedqueue/Settings.java
index 1276660af77..c64e33117f9 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/Settings.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/Settings.java
@@ -12,6 +12,8 @@ public interface Settings {
 
     Settings setCapacity(int capacity);
 
+    Settings setQueueMaxBytes(long size);
+
     Settings setMaxUnread(int maxUnread);
 
     Settings setCheckpointMaxAcks(int checkpointMaxAcks);
@@ -30,6 +32,8 @@ public interface Settings {
 
     int getCapacity();
 
+    long getQueueMaxBytes();
+
     int getMaxUnread();
 
     int getCheckpointMaxAcks();
diff --git a/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java b/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
index 81b00d68553..13a777a7d63 100644
--- a/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
+++ b/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
@@ -390,4 +390,121 @@ public void reachMaxUnreadWithAcking() throws IOException, InterruptedException,
         assertThat(q.unreadCount, is(equalTo(1L)));
     }
 
+    @Test(timeout = 5000)
+    public void reachMaxSizeTest() throws IOException, InterruptedException, ExecutionException {
+        Queueable element = new StringElement("0123456789"); // 10 bytes
+
+        int singleElementCapacity = ByteBufferPageIO.HEADER_SIZE + ByteBufferPageIO._persistedByteCount(element.serialize().length);
+
+        // allow 10 elements per page but only 100 events in total
+        Settings settings = TestSettings.getSettings(singleElementCapacity * 10, singleElementCapacity * 100);
+
+        TestQueue q = new TestQueue(settings);
+        q.open();
+
+        int ELEMENT_COUNT = 90; // should be able to write 99 events before getting full
+        for (int i = 0; i < ELEMENT_COUNT; i++) {
+            long seqNum = q.write(element);
+        }
+
+        assertThat(q.isFull(), is(false));
+
+        // we expect this next write call to block so let's wrap it in a Future
+        Callable<Long> write = () -> {
+            return q.write(element);
+        };
+
+        ExecutorService executor = Executors.newFixedThreadPool(1);
+        Future<Long> future = executor.submit(write);
+
+        while (!q.isFull()) { Thread.sleep(10); }
+
+        assertThat(q.isFull(), is(true));
+
+        executor.shutdown();
+    }
+
+    @Test(timeout = 5000)
+    public void resumeWriteOnNoLongerFullQueueTest() throws IOException, InterruptedException, ExecutionException {
+
+        Queueable element = new StringElement("0123456789"); // 10 bytes
+
+        int singleElementCapacity = ByteBufferPageIO.HEADER_SIZE + ByteBufferPageIO._persistedByteCount(element.serialize().length);
+
+        // allow 10 elements per page but only 100 events in total
+        Settings settings = TestSettings.getSettings(singleElementCapacity * 10, singleElementCapacity * 100);
+
+        TestQueue q = new TestQueue(settings);
+        q.open();
+
+        int ELEMENT_COUNT = 90; // should be able to write 90 events (9 pages) before getting full
+        for (int i = 0; i < ELEMENT_COUNT; i++) {
+            long seqNum = q.write(element);
+        }
+
+        assertThat(q.isFull(), is(false));
+
+        // we expect this next write call to block so let's wrap it in a Future
+        Callable<Long> write = () -> {
+            return q.write(element);
+        };
+
+        ExecutorService executor = Executors.newFixedThreadPool(1);
+        Future<Long> future = executor.submit(write);
+
+        while (!q.isFull()) { Thread.sleep(10); }
+
+        assertThat(q.isFull(), is(true));
+
+        Batch b = q.readBatch(10); // read 1 page (10 events)
+        b.close();  // purge 1 page
+
+        // spin wait until data is written and write blocks
+        while (q.isFull()) { Thread.sleep(10); }
+
+        assertThat(q.isFull(), is(false));
+
+        executor.shutdown();
+    }
+
+    @Test(timeout = 5000)
+    public void queueStillFullAfterPartialPageAckTest() throws IOException, InterruptedException, ExecutionException {
+
+        Queueable element = new StringElement("0123456789"); // 10 bytes
+
+        int singleElementCapacity = ByteBufferPageIO.HEADER_SIZE + ByteBufferPageIO._persistedByteCount(element.serialize().length);
+
+        // allow 10 elements per page but only 100 events in total
+        Settings settings = TestSettings.getSettings(singleElementCapacity * 10, singleElementCapacity * 100);
+
+        TestQueue q = new TestQueue(settings);
+        q.open();
+
+        int ELEMENT_COUNT = 90; // should be able to write 99 events before getting full
+        for (int i = 0; i < ELEMENT_COUNT; i++) {
+            long seqNum = q.write(element);
+        }
+
+        assertThat(q.isFull(), is(false));
+
+        // we expect this next write call to block so let's wrap it in a Future
+        Callable<Long> write = () -> {
+            return q.write(element);
+        };
+
+        ExecutorService executor = Executors.newFixedThreadPool(1);
+        Future<Long> future = executor.submit(write);
+
+        while (!q.isFull()) { Thread.sleep(10); }
+
+        assertThat(q.isFull(), is(true));
+
+        Batch b = q.readBatch(9); // read 90% of page (9 events)
+        b.close();  // this should not purge a page
+
+        assertThat(q.isFull(), is(true)); // queue should still be full
+
+        executor.shutdown();
+    }
+
 }
\ No newline at end of file
diff --git a/logstash-core/src/test/java/org/logstash/ackedqueue/TestSettings.java b/logstash-core/src/test/java/org/logstash/ackedqueue/TestSettings.java
index 7478c2ec70f..cda45aa3e64 100644
--- a/logstash-core/src/test/java/org/logstash/ackedqueue/TestSettings.java
+++ b/logstash-core/src/test/java/org/logstash/ackedqueue/TestSettings.java
@@ -20,6 +20,19 @@ public static Settings getSettings(int capacity) {
         return s;
     }
 
+    public static Settings getSettings(int capacity, long size) {
+        MemoryCheckpointIO.clearSources();
+        Settings s = new MemorySettings();
+        PageIOFactory pageIOFactory = (pageNum, pageSize, path) -> new ByteBufferPageIO(pageNum, pageSize, path);
+        CheckpointIOFactory checkpointIOFactory = (source) -> new MemoryCheckpointIO(source);
+        s.setCapacity(capacity);
+        s.setQueueMaxBytes(size);
+        s.setElementIOFactory(pageIOFactory);
+        s.setCheckpointIOFactory(checkpointIOFactory);
+        s.setElementClass(StringElement.class);
+        return s;
+    }
+
     public static Settings getSettingsCheckpointFilePageMemory(int capacity, String folder) {
         Settings s = new FileSettings(folder);
         PageIOFactory pageIOFactory = (pageNum, size, path) -> new ByteBufferPageIO(pageNum, size, path);
