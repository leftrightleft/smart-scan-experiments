diff --git a/lib/logstash/outputs/elasticsearch.rb b/lib/logstash/outputs/elasticsearch.rb
index 7687f1dbd44..27608584536 100644
--- a/lib/logstash/outputs/elasticsearch.rb
+++ b/lib/logstash/outputs/elasticsearch.rb
@@ -1,6 +1,7 @@
 # encoding: utf-8
 require "logstash/namespace"
 require "logstash/outputs/base"
+require "socket" # for Socket.gethostname
 require "stud/buffer"
 
 # This output lets you store logs in Elasticsearch and is the most recommended
diff --git a/lib/logstash/outputs/s3.rb b/lib/logstash/outputs/s3.rb
index 257356b25e8..c39e4a5c3de 100644
--- a/lib/logstash/outputs/s3.rb
+++ b/lib/logstash/outputs/s3.rb
@@ -1,14 +1,15 @@
 # encoding: utf-8
 require "logstash/outputs/base"
 require "logstash/namespace"
+require "socket" # for Socket.gethostname
 
-# TODO integrate aws_config in the future 
+# TODO integrate aws_config in the future
 #require "logstash/plugin_mixins/aws_config"
 
 # INFORMATION:
 
 # This plugin was created for store the logstash's events into Amazon Simple Storage Service (Amazon S3).
-# For use it you needs authentications and an s3 bucket. 
+# For use it you needs authentications and an s3 bucket.
 # Be careful to have the permission to write file on S3's bucket and run logstash with super user for establish connection.
 
 # S3 plugin allows you to do something complex, let's explain:)
@@ -22,9 +23,9 @@
 
 # "ip-10-228-27-95" : indicate you ip machine, if you have more logstash and writing on the same bucket for example.
 # "2013-04-18T10.00" : represents the time whenever you specify time_file.
-# "tag_hello" : this indicate the event's tag, you can collect events with the same tag. 
-# "part0" : this means if you indicate size_file then it will generate more parts if you file.size > size_file. 
-#           When a file is full it will pushed on bucket and will be deleted in temporary directory. 
+# "tag_hello" : this indicate the event's tag, you can collect events with the same tag.
+# "part0" : this means if you indicate size_file then it will generate more parts if you file.size > size_file.
+#           When a file is full it will pushed on bucket and will be deleted in temporary directory.
 #           If a file is empty is not pushed, but deleted.
 
 # This plugin have a system to restore the previous temporary files if something crash.
@@ -34,7 +35,7 @@
 ## If you specify size_file and time_file then it will create file for each tag (if specified), when time_file or
 ## their size > size_file, it will be triggered then they will be pushed on s3's bucket and will delete from local disk.
 
-## If you don't specify size_file, but time_file then it will create only one file for each tag (if specified). 
+## If you don't specify size_file, but time_file then it will create only one file for each tag (if specified).
 ## When time_file it will be triggered then the files will be pushed on s3's bucket and delete from local disk.
 
 ## If you don't specify time_file, but size_file  then it will create files for each tag (if specified),
@@ -45,15 +46,15 @@
 
 # INFORMATION ABOUT CLASS:
 
-# I tried to comment the class at best i could do. 
+# I tried to comment the class at best i could do.
 # I think there are much thing to improve, but if you want some points to develop here a list:
 
-# TODO Integrate aws_config in the future 
+# TODO Integrate aws_config in the future
 # TODO Find a method to push them all files when logtstash close the session.
 # TODO Integrate @field on the path file
-# TODO Permanent connection or on demand? For now on demand, but isn't a good implementation. 
+# TODO Permanent connection or on demand? For now on demand, but isn't a good implementation.
 #      Use a while or a thread to try the connection before break a time_out and signal an error.
-# TODO If you have bugs report or helpful advice contact me, but remember that this code is much mine as much as yours, 
+# TODO If you have bugs report or helpful advice contact me, but remember that this code is much mine as much as yours,
 #      try to work on it if you want :)
 
 
@@ -62,30 +63,30 @@
 # This is an example of logstash config:
 
 # output {
-#    s3{ 
+#    s3{
 #      access_key_id => "crazy_key"             (required)
 #      secret_access_key => "monkey_access_key" (required)
 #      endpoint_region => "eu-west-1"           (required)
-#      bucket => "boss_please_open_your_bucket" (required)         
+#      bucket => "boss_please_open_your_bucket" (required)
 #      size_file => 2048                        (optional)
 #      time_file => 5                           (optional)
-#      format => "plain"                        (optional) 
+#      format => "plain"                        (optional)
 #      canned_acl => "private"                  (optional. Options are "private", "public_read", "public_read_write", "authenticated_read". Defaults to "private" )
 #    }
 # }
 
 # We analize this:
 
-# access_key_id => "crazy_key" 
+# access_key_id => "crazy_key"
 # Amazon will give you the key for use their service if you buy it or try it. (not very much open source anyway)
 
 # secret_access_key => "monkey_access_key"
 # Amazon will give you the secret_access_key for use their service if you buy it or try it . (not very much open source anyway).
 
-# endpoint_region => "eu-west-1" 
+# endpoint_region => "eu-west-1"
 # When you make a contract with Amazon, you should know where the services you use.
 
-# bucket => "boss_please_open_your_bucket" 
+# bucket => "boss_please_open_your_bucket"
 # Be careful you have the permission to write on bucket and know the name.
 
 # size_file => 2048
@@ -94,7 +95,7 @@
 
 # time_file => 5
 # Means, in minutes, the time  before the files will be pushed on bucket. Is useful if you want to push the files every specific time.
- 
+
 # format => "plain"
 # Means the format of events you want to store in the files
 
@@ -104,7 +105,7 @@
 # LET'S ROCK AND ROLL ON THE CODE!
 
 class LogStash::Outputs::S3 < LogStash::Outputs::Base
- #TODO integrate aws_config in the future 
+ #TODO integrate aws_config in the future
  #  include LogStash::PluginMixins::AwsConfig
 
  config_name "s3"
@@ -112,7 +113,7 @@ class LogStash::Outputs::S3 < LogStash::Outputs::Base
 
  # Aws access_key.
  config :access_key_id, :validate => :string
- 
+
  # Aws secret_access_key
  config :secret_access_key, :validate => :string
 
@@ -124,24 +125,24 @@ class LogStash::Outputs::S3 < LogStash::Outputs::Base
                                         "eu-west-1", "ap-southeast-1", "ap-southeast-2",
                                         "ap-northeast-1", "sa-east-1", "us-gov-west-1"], :default => "us-east-1"
 
- # Set the size of file in KB, this means that files on bucket when have dimension > file_size, they are stored in two or more file. 
+ # Set the size of file in KB, this means that files on bucket when have dimension > file_size, they are stored in two or more file.
  # If you have tags then it will generate a specific size file for every tags
- ##NOTE: define size of file is the better thing, because generate a local temporary file on disk and then put it in bucket. 
+ ##NOTE: define size of file is the better thing, because generate a local temporary file on disk and then put it in bucket.
  config :size_file, :validate => :number, :default => 0
 
- # Set the time, in minutes, to close the current sub_time_section of bucket. 
+ # Set the time, in minutes, to close the current sub_time_section of bucket.
  # If you define file_size you have a number of files in consideration of the section and the current tag.
  # 0 stay all time on listerner, beware if you specific 0 and size_file 0, because you will not put the file on bucket,
  # for now the only thing this plugin can do is to put the file when logstash restart.
- config :time_file, :validate => :number, :default => 0 
- 
+ config :time_file, :validate => :number, :default => 0
+
  # The event format you want to store in files. Defaults to plain text.
  config :format, :validate => [ "json", "plain", "nil" ], :default => "plain"
 
  ## IMPORTANT: if you use multiple instance of s3, you should specify on one of them the "restore=> true" and on the others "restore => false".
- ## This is hack for not destroy the new files after restoring the initial files. 
+ ## This is hack for not destroy the new files after restoring the initial files.
  ## If you do not specify "restore => true" when logstash crashes or is restarted, the files are not sent into the bucket,
- ## for example if you have single Instance. 
+ ## for example if you have single Instance.
  config :restore, :validate => :boolean, :default => false
 
  # Aws canned ACL
@@ -160,7 +161,7 @@ def aws_s3_config
     :secret_access_key => @secret_access_key,
     :s3_endpoint => @endpoint_region
   )
-  @s3 = AWS::S3.new 
+  @s3 = AWS::S3.new
 
  end
 
@@ -180,9 +181,9 @@ def time_alert(interval)
 
  # this method is used for write files on bucket. It accept the file and the name of file.
  def write_on_bucket (file_data, file_basename)
- 
+
   # if you lose connection with s3, bad control implementation.
-  if ( @s3 == nil) 
+  if ( @s3 == nil)
     aws_s3_config
   end
 
@@ -194,31 +195,31 @@ def write_on_bucket (file_data, file_basename)
   # prepare for write the file
   object = bucket.objects[file_basename]
   object.write(:file => file_data, :acl => @canned_acl)
- 
+
   @logger.debug "S3: has written "+file_basename+" in bucket "+@bucket + " with canned ACL \"" + @canned_acl + "\""
 
  end
-  
+
  # this method is used for create new path for name the file
  def getFinalPath
-   
-   @pass_time = Time.now 
+
+   @pass_time = Time.now
    return @temp_directory+"ls.s3."+Socket.gethostname+"."+(@pass_time).strftime("%Y-%m-%dT%H.%M")
 
  end
 
- # This method is used for restore the previous crash of logstash or to prepare the files to send in bucket. 
- # Take two parameter: flag and name. Flag indicate if you want to restore or not, name is the name of file 
+ # This method is used for restore the previous crash of logstash or to prepare the files to send in bucket.
+ # Take two parameter: flag and name. Flag indicate if you want to restore or not, name is the name of file
  def upFile(flag, name)
-   
+
    Dir[@temp_directory+name].each do |file|
      name_file = File.basename(file)
-    
+
      if (flag == true)
       @logger.warn "S3: have found temporary file: "+name_file+", something has crashed before... Prepare for upload in bucket!"
      end
-    
-     if (!File.zero?(file))  
+
+     if (!File.zero?(file))
        write_on_bucket(file, name_file)
 
        if (flag == true)
@@ -235,7 +236,7 @@ def upFile(flag, name)
 
  # This method is used for create new empty temporary files for use. Flag is needed for indicate new subsection time_file.
  def newFile (flag)
-  
+
    if (flag == true)
      @current_final_path = getFinalPath
      @sizeCounter = 0
@@ -257,7 +258,7 @@ def register
    if (@tags.size != 0)
        @tag_path = ""
        for i in (0..@tags.size-1)
-          @tag_path += @tags[i].to_s+"." 
+          @tag_path += @tags[i].to_s+"."
        end
    end
 
@@ -266,16 +267,16 @@ def register
     Dir.mkdir(@temp_directory)
    else
     @logger.debug "S3: Directory "+@temp_directory+" exist, nothing to do"
-   end 
-   
+   end
+
    if (@restore == true )
      @logger.debug "S3: is attempting to verify previous crashes..."
-   
-     upFile(true, "*.txt")    
+
+     upFile(true, "*.txt")
    end
-   
+
    newFile(true)
-   
+
    if (time_file != 0)
       first_time = true
       @thread = time_alert(@time_file*60) do
@@ -288,14 +289,14 @@ def register
        end
      end
    end
- 
+
  end
- 
+
  public
  def receive(event)
   return unless output?(event)
-   
-  # Prepare format of Events 
+
+  # Prepare format of Events
   if (@format == "plain")
      message = self.class.format_message(event)
   elsif (@format == "json")
@@ -303,20 +304,20 @@ def receive(event)
   else
      message = event.to_s
   end
-  
+
   if(time_file !=0)
      @logger.debug "S3: trigger files after "+((@pass_time+60*time_file)-Time.now).to_s
   end
 
   # if specific the size
   if(size_file !=0)
-    
+
     if (@tempFile.size < @size_file )
 
        @logger.debug "S3: File have size: "+@tempFile.size.to_s+" and size_file is: "+ @size_file.to_s
        @logger.debug "S3: put event into: "+File.basename(@tempFile)
 
-       # Put the event in the file, now! 
+       # Put the event in the file, now!
        File.open(@tempFile, 'a') do |file|
          file.puts message
          file.write "\n"
@@ -330,8 +331,8 @@ def receive(event)
        newFile(false)
 
      end
-     
-  # else we put all in one file 
+
+  # else we put all in one file
   else
 
     @logger.debug "S3: put event into "+File.basename(@tempFile)
@@ -340,7 +341,7 @@ def receive(event)
       file.write "\n"
     end
   end
-    
+
  end
 
  def self.format_message(event)
