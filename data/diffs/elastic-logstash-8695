diff --git a/logstash-core/src/main/java/org/logstash/config/ir/DSL.java b/logstash-core/src/main/java/org/logstash/config/ir/DSL.java
index 1b878dd667e..a73d76901a4 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/DSL.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/DSL.java
@@ -314,10 +314,10 @@ public static PluginVertex gPlugin(PluginDefinition.Type type, String pluginName
 
 
     public static IfVertex gIf(SourceWithMetadata meta, BooleanExpression expression) {
-       return new IfVertex(meta, expression);
+       return new IfVertex(expression);
     }
 
     public static IfVertex gIf(BooleanExpression expression) {
-       return new IfVertex(null, expression);
+       return new IfVertex(expression);
     }
 }
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java b/logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
index fe1745ef71e..8be172521b5 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
@@ -14,7 +14,7 @@
  */
 public final class PipelineIR implements Hashable {
 
-    private String uniqueHash;
+    private final String uniqueHash;
 
     public Graph getGraph() {
         return graph;
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/graph/Edge.java b/logstash-core/src/main/java/org/logstash/config/ir/graph/Edge.java
index 97a18c0d0c0..09c43213814 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/graph/Edge.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/graph/Edge.java
@@ -1,17 +1,34 @@
 package org.logstash.config.ir.graph;
 
-import org.logstash.config.ir.SourceComponent;
-import org.logstash.config.ir.InvalidIRException;
-import org.logstash.common.SourceWithMetadata;
-
 import java.util.stream.Stream;
+import org.logstash.common.SourceWithMetadata;
+import org.logstash.config.ir.InvalidIRException;
+import org.logstash.config.ir.SourceComponent;
 
 /**
  * Created by andrewvc on 9/15/16.
  */
 public abstract class Edge implements SourceComponent {
+
+    private final Vertex from;
+
+    private final Vertex to;
+
     private Graph graph;
 
+    protected Edge(Vertex from, Vertex to) throws InvalidIRException {
+        this.from = from;
+        this.to = to;
+
+        if (this.from == this.to) {
+            throw new InvalidIRException("Cannot create a cyclic vertex! " + to);
+        }
+
+        if (!this.from.acceptsOutgoingEdge(this)) {
+            throw new Vertex.InvalidEdgeTypeException(String.format("Invalid outgoing edge %s for edge %s", this.from, this));
+        }
+    }
+
     public void setGraph(Graph graph) {
         if (this.graph == graph) {
             return;
@@ -22,15 +39,29 @@ public void setGraph(Graph graph) {
         }
     }
 
+    @Override
+    public final int hashCode() {
+        return 37 * from.hashCode() + to.hashCode();
+    }
+
+    @Override
+    public final boolean equals(final Object other) {
+        if (this == other) {
+            return true;
+        }
+        if (this.getClass() != other.getClass()) {
+            return false;
+        }
+        final Edge that = (Edge) other;
+        return this.from.equals(that.from) && this.to.equals(that.to);
+    }
+
     public abstract Edge copy(Vertex from, Vertex to) throws InvalidIRException;
 
-    public static abstract class EdgeFactory {
+    public abstract static class EdgeFactory {
         public abstract Edge make(Vertex from, Vertex to) throws InvalidIRException;
     }
 
-    private final Vertex from;
-    private final Vertex to;
-
     public Stream<Edge> ancestors() {
        // Without all the distinct calls this can be slow
        return Stream.concat(this.from.incomingEdges(), this.from.incomingEdges().flatMap(Edge::ancestors).distinct()).distinct();
@@ -45,19 +76,6 @@ public Stream<Edge> lineage() {
         return Stream.concat(Stream.concat(ancestors(), Stream.of(this)), descendants());
     }
 
-    public Edge(Vertex from, Vertex to) throws InvalidIRException {
-        this.from = from;
-        this.to = to;
-
-        if (this.from == this.to) {
-            throw new InvalidIRException("Cannot create a cyclic vertex! " + to);
-        }
-
-        if (!this.from.acceptsOutgoingEdge(this)) {
-            throw new Vertex.InvalidEdgeTypeException(String.format("Invalid outgoing edge %s for edge %s", this.from, this));
-        }
-    }
-
     public Vertex getTo() {
         return to;
     }
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/graph/Graph.java b/logstash-core/src/main/java/org/logstash/config/ir/graph/Graph.java
index 6762f7ba35d..627f87aaa07 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/graph/Graph.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/graph/Graph.java
@@ -18,12 +18,12 @@
 /**
  * Created by andrewvc on 9/15/16.
  */
-public class Graph implements SourceComponent, Hashable {
-    public final Set<Vertex> vertices = new HashSet<>();
-    private final Set<Edge> edges = new HashSet<>();
-    private Map<Vertex, Integer> vertexRanks = new HashMap<>();
-    private final Map<Vertex,Set<Edge>> outgoingEdgeLookup = new HashMap<>();
-    private final Map<Vertex,Set<Edge>> incomingEdgeLookup = new HashMap<>();
+public final class Graph implements SourceComponent, Hashable {
+    private final Set<Vertex> vertices = new LinkedHashSet<>();
+    private final Set<Edge> edges = new LinkedHashSet<>();
+    private Map<Vertex, Integer> vertexRanks = new LinkedHashMap<>();
+    private final Map<Vertex,Set<Edge>> outgoingEdgeLookup = new LinkedHashMap<>();
+    private final Map<Vertex,Set<Edge>> incomingEdgeLookup = new LinkedHashMap<>();
     private List<Vertex> sortedVertices;
 
     // Builds a graph that has the specified vertices and edges
@@ -79,14 +79,16 @@ public Vertex getVertexById(String id) {
     }
 
     private Graph addEdge(Edge e, boolean doRefresh) throws InvalidIRException {
-        if (!(this.getVertices().contains(e.getFrom()) && this.getVertices().contains(e.getTo()))) {
+        if (!(vertices.contains(e.getFrom()) && vertices.contains(e.getTo()))) {
             throw new InvalidIRException("Attempted to add edge referencing vertices not in this graph!");
         }
 
         this.edges.add(e);
 
-        BiFunction<Vertex, Set<Edge>, Set<Edge>> lookupComputeFunction = (vertex, edgeSet) -> {
-            if (edgeSet == null) edgeSet = new HashSet<>();
+        final BiFunction<Vertex, Set<Edge>, Set<Edge>> lookupComputeFunction = (vertex, edgeSet) -> {
+            if (edgeSet == null) {
+                edgeSet = new LinkedHashSet<>();
+            }
             edgeSet.add(e);
             return edgeSet;
         };
@@ -114,11 +116,11 @@ public Graph copy() throws InvalidIRException {
     // Returns a new graph that is the union of all provided graphs.
     // If a single graph is passed in this will return a copy of it
     public static GraphCombinationResult combine(Graph... graphs) throws InvalidIRException {
-        Map<Vertex, Vertex> oldToNewVertices = new HashMap<>();
-        Map<Edge,Edge> oldToNewEdges = new HashMap<>();
+        Map<Vertex, Vertex> oldToNewVertices = new LinkedHashMap<>();
+        Map<Edge,Edge> oldToNewEdges = new LinkedHashMap<>();
 
         for (Graph graph : graphs) {
-            graph.vertices().forEach(v -> oldToNewVertices.put(v, v.copy()));
+            graph.vertices().forEachOrdered(v -> oldToNewVertices.put(v, v.copy()));
 
             for (Edge e : graph.getEdges()) {
                 Edge copy = e.copy(oldToNewVertices.get(e.getFrom()), oldToNewVertices.get(e.getTo()));
@@ -147,7 +149,7 @@ public static final class GraphCombinationResult {
       the other graph's root
     */
     public Graph chain(Graph otherGraph) throws InvalidIRException {
-        if (otherGraph.getVertices().size() == 0) return this.copy();
+        if (otherGraph.vertices.isEmpty()) return this.copy();
         if (this.isEmpty()) return otherGraph.copy();
 
         GraphCombinationResult combineResult = Graph.combine(this, otherGraph);
@@ -305,7 +307,7 @@ public Collection<Vertex> getRoots() {
     // Vertices which are partially leaves in that they support multiple
     // outgoing edge types but only have one or fewer attached
     public Stream<Vertex> allLeaves() {
-        return vertices.stream().filter(Vertex::isPartialLeaf);
+        return vertices().filter(Vertex::isPartialLeaf);
     }
 
     // Get all leaves whether partial or not
@@ -314,7 +316,7 @@ public Collection<Vertex> getAllLeaves() {
     }
 
     public Stream<Vertex> leaves() {
-        return vertices.stream().filter(Vertex::isLeaf);
+        return vertices().filter(Vertex::isLeaf);
     }
 
     public Collection<Vertex> getLeaves() {
@@ -325,13 +327,13 @@ public Set<Vertex> getVertices() {
         return vertices;
     }
 
-    public Set<Edge> getEdges() {
+    public Collection<Edge> getEdges() {
         return edges;
     }
 
     public String toString() {
         final Stream<Edge> edgesToFormat = sortedEdges();
-        String edgelessVerticesStr;
+        final String edgelessVerticesStr;
         if (this.isolatedVertices().count() > 0) {
             edgelessVerticesStr = "\n== Vertices Without Edges ==\n" +
                     this.isolatedVertices().map(Vertex::toString).collect(Collectors.joining("\n"));
@@ -348,7 +350,7 @@ public String toString() {
     }
 
     public Stream<Vertex> isolatedVertices() {
-        return this.getVertices().stream().filter(v -> v.getOutgoingEdges().isEmpty() && v.getIncomingEdges().isEmpty());
+        return vertices().filter(v -> v.getOutgoingEdges().isEmpty() && v.getIncomingEdges().isEmpty());
     }
 
     public List<Vertex> getSortedVertices() {
@@ -369,11 +371,8 @@ public List<Vertex> getSortedVerticesAfter(Vertex start) {
     }
 
     public List<Vertex> getSortedVerticesBetween(Vertex start, Vertex end) {
-        List<Vertex> sortedVertices = getSortedVertices();
-
         int startIndex = start == null ? 0 : sortedVertices.indexOf(start);
         int endIndex = end == null ? sortedVertices.size() : sortedVertices.indexOf(end);
-
         return sortedVertices.subList(startIndex+1, endIndex);
     }
 
@@ -391,11 +390,11 @@ public boolean sourceComponentEquals(SourceComponent sourceComponent) {
 
     // returns true if this graph has a .sourceComponentEquals equivalent edge
     public boolean hasEquivalentEdge(Edge otherE) {
-        return this.getEdges().stream().anyMatch(e -> e.sourceComponentEquals(otherE));
+        return edges().anyMatch(e -> e.sourceComponentEquals(otherE));
     }
 
     public boolean hasEquivalentVertex(Vertex otherV) {
-        return this.getVertices().stream().anyMatch(v -> v.sourceComponentEquals(otherV));
+        return vertices().anyMatch(v -> v.sourceComponentEquals(otherV));
     }
 
     @Override
@@ -404,7 +403,7 @@ public SourceWithMetadata getSourceWithMetadata() {
     }
 
     public boolean isEmpty() {
-        return (this.getVertices().size() == 0);
+        return vertices.isEmpty();
     }
 
     public Stream<Vertex> vertices() {
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/graph/IfVertex.java b/logstash-core/src/main/java/org/logstash/config/ir/graph/IfVertex.java
index c720363e3f1..62c4caa115e 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/graph/IfVertex.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/graph/IfVertex.java
@@ -20,8 +20,8 @@ public BooleanExpression getBooleanExpression() {
 
     private final BooleanExpression booleanExpression;
 
-    public IfVertex(SourceWithMetadata meta, BooleanExpression booleanExpression) {
-        super(meta);
+    public IfVertex(BooleanExpression booleanExpression) {
+        super();
         this.booleanExpression = booleanExpression;
     }
 
@@ -72,8 +72,8 @@ public Collection<BooleanEdge> getOutgoingBooleanEdges() {
         return getOutgoingEdges().stream().map(e -> (BooleanEdge) e).collect(Collectors.toList());
     }
 
-    public Collection<BooleanEdge> getOutgoingBooleanEdgesByType(Boolean edgeType) {
-        return getOutgoingBooleanEdges().stream().filter(e -> e.getEdgeType().equals(edgeType)).collect(Collectors.toList());
+    public Collection<BooleanEdge> getOutgoingBooleanEdgesByType(boolean edgeType) {
+        return getOutgoingBooleanEdges().stream().filter(e -> e.getEdgeType() == edgeType).collect(Collectors.toList());
     }
 
     // The easiest readable version of this for a human.
@@ -89,7 +89,7 @@ public String humanReadableExpression() {
 
     @Override
     public IfVertex copy() {
-        return new IfVertex(getSourceWithMetadata(),getBooleanExpression());
+        return new IfVertex(booleanExpression);
     }
 
     @Override
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/graph/PluginVertex.java b/logstash-core/src/main/java/org/logstash/config/ir/graph/PluginVertex.java
index 56c190f49cd..3bbc01fc50e 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/graph/PluginVertex.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/graph/PluginVertex.java
@@ -24,7 +24,7 @@ public SourceWithMetadata getSourceWithMetadata() {
 
     public PluginVertex(SourceWithMetadata meta, PluginDefinition pluginDefinition) {
         // We know that if the ID value exists it will be as a string
-        super(meta, (String) pluginDefinition.getArguments().get("id"));
+        super((String) pluginDefinition.getArguments().get("id"));
         this.meta = meta;
         this.pluginDefinition = pluginDefinition;
     }
@@ -50,7 +50,7 @@ public String calculateIndividualHashSource() {
 
     @Override
     public PluginVertex copy() {
-        return new PluginVertex(meta, getPluginDefinition());
+        return new PluginVertex(meta, pluginDefinition);
     }
 
     @Override
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/graph/QueueVertex.java b/logstash-core/src/main/java/org/logstash/config/ir/graph/QueueVertex.java
index 6001e76753b..a902431a4e6 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/graph/QueueVertex.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/graph/QueueVertex.java
@@ -6,10 +6,7 @@
 /**
  * Created by andrewvc on 9/15/16.
  */
-public class QueueVertex extends Vertex {
-    public QueueVertex() {
-        super(null);
-    }
+public final class QueueVertex extends Vertex {
 
     @Override
     public String getId() {
@@ -32,7 +29,6 @@ public QueueVertex copy() {
 
     @Override
     public boolean sourceComponentEquals(SourceComponent other) {
-        if (other == null) return false;
         return other instanceof QueueVertex;
     }
 
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java b/logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
index 474709aa2ab..063a2840110 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
@@ -1,10 +1,10 @@
 package org.logstash.config.ir.graph;
 
+import java.util.concurrent.atomic.AtomicInteger;
 import org.logstash.common.Util;
 import org.logstash.config.ir.HashableWithSource;
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.algorithms.DepthFirst;
 
 import java.nio.charset.StandardCharsets;
@@ -18,24 +18,25 @@
  * Created by andrewvc on 9/15/16.
  */
 public abstract class Vertex implements SourceComponent, HashableWithSource {
-    private final SourceWithMetadata sourceWithMetadata;
-    private Graph graph = this.getGraph();
+
+    private static final AtomicInteger SEQUENCE = new AtomicInteger();
+
+    private final int hashCode = SEQUENCE.incrementAndGet();
+
+    private final String explicitId;
+
+    private Graph graph;
+
     private volatile String contextualHashCache;
     private volatile String hashCache;
     private volatile String individualHashSourceCache;
-    private final String explicitId;
     private volatile String generatedId;
 
-    public Vertex() {
+    protected Vertex() {
         this(null);
     }
 
-    public Vertex(SourceWithMetadata sourceWithMetadata) {
-        this(sourceWithMetadata, null);
-    }
-
-    public Vertex(SourceWithMetadata sourceWithMetadata, String explicitId) {
-        this.sourceWithMetadata = sourceWithMetadata;
+    protected Vertex(String explicitId) {
         this.explicitId = explicitId;
     }
 
@@ -49,11 +50,20 @@ public InvalidEdgeTypeException(String s) {
         }
     }
 
-    public Graph getGraph() {
+    @Override
+    public final int hashCode() {
+        return hashCode;
+    }
+
+    public final boolean equals(final Object other) {
+        return this == other;
+    }
+
+    public final Graph getGraph() {
         return this.graph;
     }
 
-    public void setGraph(Graph graph) {
+    public final void setGraph(Graph graph) {
         if (this.graph == graph) {
             return;
         } else if (this.graph == null) {
@@ -104,11 +114,11 @@ public Stream<Vertex> incomingVertices() {
     }
 
     public Stream<Edge> incomingEdges() {
-        return this.getGraph().getIncomingEdges(this).stream();
+        return this.graph.getIncomingEdges(this).stream();
     }
 
     public Stream<Edge> outgoingEdges() {
-        return this.getGraph().getOutgoingEdges(this).stream();
+        return this.graph.getOutgoingEdges(this).stream();
     }
 
     public Stream<Vertex> ancestors() {
@@ -150,10 +160,7 @@ public String uniqueHash() {
 
         // The lineage can be quite long and we want to avoid the quadratic complexity of string concatenation
         // Thus, in this case there's no real way to get the hash source, we just hash as we go.
-        lineage().
-                map(Vertex::contextualHashSource).
-                sorted().
-                forEachOrdered(v -> {
+        lineage().map(Vertex::contextualHashSource).forEachOrdered(v -> {
                     byte[] bytes = v.getBytes(StandardCharsets.UTF_8);
                     lineageDigest.update(bytes);
                 });
@@ -192,7 +199,7 @@ public String contextualHashSource() {
         return this.contextualHashCache;
     }
 
-    public String individualHashSource() {
+    public final String individualHashSource() {
         if (this.individualHashSourceCache != null) {
             return this.individualHashSourceCache;
         }
@@ -209,7 +216,7 @@ public String individualHashSource() {
     // a partial leaf.
     public Collection<Edge.EdgeFactory> getUnusedOutgoingEdgeFactories() {
        if (!this.hasOutgoingEdges()) {
-           return Collections.singletonList(new PlainEdge.PlainEdgeFactory());
+           return Collections.singletonList(PlainEdge.factory);
        }
        return Collections.emptyList();
     }
@@ -239,7 +246,7 @@ public String getId() {
         // they have no source metadata. This might also be used in the future by alternate config languages which are
         // willing to take the hit.
         if (this.getSourceWithMetadata() != null) {
-            generatedId = Util.digest(this.getGraph().uniqueHash() + "|" + this.getSourceWithMetadata().uniqueHash());
+            generatedId = Util.digest(this.graph.uniqueHash() + "|" + this.getSourceWithMetadata().uniqueHash());
         } else {
             generatedId = this.uniqueHash();
         }
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/imperative/IfStatement.java b/logstash-core/src/main/java/org/logstash/config/ir/imperative/IfStatement.java
index a77af33a7b4..a9ed5b78dbd 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/imperative/IfStatement.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/imperative/IfStatement.java
@@ -89,7 +89,7 @@ public Graph toGraph() throws InvalidIRException {
         Collection<Vertex> trueRoots = trueGraph.roots().map(combination.oldToNewVertices::get).collect(Collectors.toList());
         Collection<Vertex> falseRoots = falseGraph.roots().map(combination.oldToNewVertices::get).collect(Collectors.toList());
 
-        IfVertex ifVertex = new IfVertex(this.getSourceWithMetadata(), this.booleanExpression);
+        IfVertex ifVertex = new IfVertex(this.booleanExpression);
         newGraph.addVertex(ifVertex);
 
         for (Vertex v : trueRoots) {
diff --git a/logstash-core/src/test/java/org/logstash/config/ir/ConfigCompilerTest.java b/logstash-core/src/test/java/org/logstash/config/ir/ConfigCompilerTest.java
index 6a2f89f33d7..1e4e076c5d3 100644
--- a/logstash-core/src/test/java/org/logstash/config/ir/ConfigCompilerTest.java
+++ b/logstash-core/src/test/java/org/logstash/config/ir/ConfigCompilerTest.java
@@ -1,6 +1,10 @@
 package org.logstash.config.ir;
 
+import java.io.ByteArrayOutputStream;
+import java.io.InputStream;
 import org.junit.Test;
+import org.logstash.common.IncompleteSourceWithMetadataException;
+import org.logstash.config.ir.graph.Graph;
 
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -14,4 +18,50 @@ public void testConfigToPipelineIR() throws Exception {
         assertThat(pipelineIR.getOutputPluginVertices().size(), is(1));
         assertThat(pipelineIR.getFilterPluginVertices().size(), is(0));
     }
+
+    /**
+     * Tests that repeatedly parsing the same config (containing a large number of duplicated sections)
+     * into a {@link Graph} repeatedly results in a graph with a constant (i.e. deterministic)
+     * hash code as returned by {@link Graph#uniqueHash()}.
+     * @throws Exception On Failure
+     */
+    @Test
+    public void testConfigDuplicateBlocksToPipelineIR() throws Exception {
+        final String condition = "if [message] == 'foo' {\nif [message] == 'foo' {drop {}}}\n";
+        final StringBuilder source = new StringBuilder().append("filter {\n");
+        for (int i = 0; i < 100; ++i) {
+            source.append(condition);
+        }
+        final String config = source.append('}').toString();
+        final String first = graphHash(config);
+        for (int run = 0; run < 5; ++run) {
+            assertThat(graphHash(config), is(first));
+        }
+    }
+
+    /**
+     * Tests that repeatedly parsing the same complex config String into a {@link Graph} repeatedly
+     * results in a graph with a constant (i.e. deterministic) hash code as returned by
+     * {@link Graph#uniqueHash()}.
+     * @throws Exception On Failure
+     */
+    @Test
+    public void testComplexConfigToPipelineIR() throws Exception {
+        final ByteArrayOutputStream baos = new ByteArrayOutputStream();
+        try (final InputStream src = getClass().getResourceAsStream("complex.cfg")) {
+            int read;
+            final byte[] buffer = new byte[1024];
+            while ((read = src.read(buffer)) >= 0) {
+                baos.write(buffer, 0, read);
+            }
+        }
+        final String config = baos.toString("UTF-8");
+        final String first = graphHash(config);
+        assertThat(graphHash(config), is(first));
+    }
+
+    private static String graphHash(final String config)
+        throws IncompleteSourceWithMetadataException {
+        return ConfigCompiler.configToPipelineIR(config, false).uniqueHash();
+    }
 }
diff --git a/logstash-core/src/test/java/org/logstash/config/ir/graph/GraphTest.java b/logstash-core/src/test/java/org/logstash/config/ir/graph/GraphTest.java
index ae877065d2b..03cc77b6ea4 100644
--- a/logstash-core/src/test/java/org/logstash/config/ir/graph/GraphTest.java
+++ b/logstash-core/src/test/java/org/logstash/config/ir/graph/GraphTest.java
@@ -119,7 +119,7 @@ public void testThreadingMulti() throws InvalidIRException {
     @Test
     public void testThreadingTyped() throws InvalidIRException {
         Graph graph = Graph.empty();
-        Vertex if1 = new IfVertex(null, createTestExpression());
+        Vertex if1 = new IfVertex(createTestExpression());
         Vertex condT = IRHelpers.createTestVertex();
         Edge tEdge = graph.chainVertices(BooleanEdge.trueFactory, if1, condT).stream().findFirst().get();
         assertThat(tEdge, instanceOf(BooleanEdge.class));
diff --git a/logstash-core/src/test/java/org/logstash/config/ir/graph/IfVertexTest.java b/logstash-core/src/test/java/org/logstash/config/ir/graph/IfVertexTest.java
index d7ad532b9bd..e7f742816c0 100644
--- a/logstash-core/src/test/java/org/logstash/config/ir/graph/IfVertexTest.java
+++ b/logstash-core/src/test/java/org/logstash/config/ir/graph/IfVertexTest.java
@@ -60,7 +60,7 @@ public void testEdgeTypeHandling() throws InvalidIRException {
     }
 
     public IfVertex testIfVertex() throws InvalidIRException {
-        return new IfVertex(testMetadata(), createTestExpression());
+        return new IfVertex(createTestExpression());
     }
 
 }
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/10-input-beats.conf b/logstash-core/src/test/resources/org/logstash/config/ir/10-input-beats.conf
deleted file mode 100644
index 1751b04468a..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/10-input-beats.conf
+++ /dev/null
@@ -1,10 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-input {
-  beats {
-    port => 5044
-	tags => [ "beats" ]
-	id => "input_beats"
-  }
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/10-input-netflow.conf b/logstash-core/src/test/resources/org/logstash/config/ir/10-input-netflow.conf
deleted file mode 100644
index bbb5f68d78f..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/10-input-netflow.conf
+++ /dev/null
@@ -1,13 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-input {
-	udp {
-		port => 9995
-		type => "netflow"
-		codec => netflow {
-			versions => [5, 9]
-		}
-		id => "input_udp_netflow"
-	}	
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/10-input-snmptrap.conf b/logstash-core/src/test/resources/org/logstash/config/ir/10-input-snmptrap.conf
deleted file mode 100644
index 3bdb3dcce6c..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/10-input-snmptrap.conf
+++ /dev/null
@@ -1,11 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-input {
-	snmptrap {
-		tags => ["SNMP Trap", "Ready"]
-		type => snmptrap
-		community => "public"
-		id => "input_snmptrap"
-	}
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/10-input-syslog-cisco.conf b/logstash-core/src/test/resources/org/logstash/config/ir/10-input-syslog-cisco.conf
deleted file mode 100644
index 5552a4efb4b..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/10-input-syslog-cisco.conf
+++ /dev/null
@@ -1,15 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-input {
-	tcp {
-		port => 8514
-		type => "ciscosyslog"
-		id => "input_tcp_cisco-syslog"
-	}
-	udp {
-		port => 8514
-		type => "cisco-syslog"
-		id => "input_udp_cisco-syslog"
-	}
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/10-input-syslog.conf b/logstash-core/src/test/resources/org/logstash/config/ir/10-input-syslog.conf
deleted file mode 100644
index 93ce3c26e48..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/10-input-syslog.conf
+++ /dev/null
@@ -1,10 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-input {
-	syslog {
-		port => 5514
-		type => syslog
-		id => "input_syslog"
-	}
-}
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/20-filter-tagging.conf b/logstash-core/src/test/resources/org/logstash/config/ir/20-filter-tagging.conf
deleted file mode 100644
index ae3b967cc9f..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/20-filter-tagging.conf
+++ /dev/null
@@ -1,24 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-filter {
-	if [type] == "syslog" {
-		mutate {
-			add_tag => "syslog"
-			id => "filter_mutate_add_syslog_tag"
-		}
-		if [logsource] =~ "pfsense.*" {
-		  mutate {
-			add_tag => ["pfsense", "firewall"]
-			id => "filter_mutate_add_pfsense_tag"
-		  }
-		}	
-		if [logsource] =~ "freenas.*" {
-			if [program] == "snmpd" {
-				drop { 
-					id => "filter_drop_freenas_snmpd"
-				}
-			}
-		}
-	}	
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/21-filter-dhcpd.conf b/logstash-core/src/test/resources/org/logstash/config/ir/21-filter-dhcpd.conf
deleted file mode 100644
index b0b3c3fe140..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/21-filter-dhcpd.conf
+++ /dev/null
@@ -1,37 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-filter {
-	if ("syslog" in [tags] or "pfsense" in [tags]) {
-		if [program] =~ /^dhcpd$/ {
-			mutate {
-				add_tag => [ "dhcp" ]
-				id => "filter_mutate_add_dhcp_tag"
-			}
-			if [message] =~ /^DHCPACK|^DHCPREQUEST|^DHCPOFFER/ {
-				grok {
-					patterns_dir => [ "/etc/logstash/patterns" ]
-					patterns_files_glob => "dhcpd"
-					match => { "message" => "%{DHCPACK}" }
-					id => "filter_grok_dhcpack"
-				}
-			}
-			if [message] =~ /^DHCPDISCOVER/ {
-				grok {
-					patterns_dir => [ "/etc/logstash/patterns" ]
-					patterns_files_glob => "dhcpd"
-					match => { "message" => "%{DHCPDISCOVER}" }
-					id => "filter_grok_dhcpdiscover"
-				}
-			}
-			if [message] =~ /^DHCPINFORM/ {
-				grok {
-					patterns_dir => [ "/etc/logstash/patterns" ]
-					patterns_files_glob => "dhcpd"
-					match => { "message" => "%{DHCPINFORM}" }
-					id => "filter_grok_dhcpinform"
-				}
-			}
-		}	
-	}
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/21-filter-pfsense.conf b/logstash-core/src/test/resources/org/logstash/config/ir/21-filter-pfsense.conf
deleted file mode 100644
index 0b17e2ba9fb..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/21-filter-pfsense.conf
+++ /dev/null
@@ -1,164 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-# pfSense
-filter {
-	if [type] == "syslog" and "pfsense" in [tags] {
-		grok {
-			match => { "message" => "(?<msg>.*)" }
-			id => "filter_grok_pfsense_message"
-		}
-		mutate {
-			gsub => [ "timestamp", "  ", " " ]
-			replace => { "message" => "%{msg}" }
-			replace => { "host" => "%{logsource}" }
-			remove_field => [ "msg" ]			
-			id => "filter_mutate_pfsense_tidy_message"
-		}
-		dns {
-			resolve => [ "host" ]
-			action => "replace"
-			id => "filter_dns_pfsense_host"
-		}		
-		if [program] == "filterlog" {
-			mutate {
-				remove_field => [ "msg" ]    
-				replace => { "type" => "filterlog" }
-				id => "filter_mutate_pfsense_filterlog_remove_fields"
-			}
-			grok {
-				patterns_dir => [ "/etc/logstash/patterns" ]
-				patterns_files_glob => "pfsense*"
-				match => { "message" => "%{LOG_DATA}%{IP_SPECIFIC_DATA}%{IP_DATA}(%{PROTOCOL_DATA})?" }
-				id => "filter_grok_pfsense_filterlog"
-			}
-			if "_grokparsefailure" not in [tags] {
-				geoip {
-					add_tag => [ "GeoIP_src" ]
-					source => "src_ip"
-					target => "geoip_src_ip"
-					id => "filter_geoip_pfsense_filterlog_src"
-				}
-				geoip {
-					add_tag => [ "GeoIP_dest" ]
-					source => "dest_ip"
-					target => "geoip_dest_ip"
-					id => "filter_geoip_pfsense_filterlog_dest"
-				}		
-				mutate {
-					add_field => { "src_host" => "%{src_ip}" }
-					add_field => { "dest_host" => "%{dest_ip}" }
-					lowercase => [ "%{proto}" ]
-					id => "filter_mutate_pfsense_filterlog_add_fields"					
-				}
-
-				dns {
-					action => "replace"
-					reverse => [ "src_host" ]
-					id => "filter_dns_pfsense_filterlog_src"
-				}
-				dns {
-					action => "replace"
-					reverse => [ "dest_host" ]
-					id => "filter_dns_pfsense_filterlog_dest"
-				}
-			}
-		}			
-		if [program] == "suricata" {
-			mutate {
-				add_tag => [ "suricata" ]
-				id => "filter_mutate_pfsense_suricata_tag"
-			}
-		}
-	}
-
-	# Snort
-	if [program] == "snort" {
-		mutate {
-			add_tag => [ "snort" ]
-			add_field => { "src_host" => "%{src_ip}" }
-			add_field => { "dest_host" => "%{dest_ip}" }
-			id => "filter_mutate_pfsense_snort_tags"
-		}
-		grok {
-			match => { "message" => ["\[%{INT:ids_gid}\:%{INT:ids_sid}\:%{INT:ids_rev}\].%{GREEDYDATA:ids_alert}.\[Classification\: %{DATA:ids_classification}\].*\[Priority\: %{INT:ids_priority}].*{%{WORD:ids_proto}}.*%{IP:src_ip}:%{INT:src_port} \-\>.*%{IP:dest_ip}:%{INT:dest_port}", "\[%{INT:ids_gid}\:%{INT:ids_sid}\:%{INT:ids_rev}\].%{GREEDYDATA:ids_alert}.\[Classification\: %{DATA:ids_classification}\].*\[Priority\: %{INT:ids_priority}].*\{PROTO:%{WORD:ids_proto}.*%{IP:src_ip} \-\>.*%{IP:dest_ip}}" ] }		
-			id => "filter_grok_pfsense_snort"
-		}
-		translate {
-			field => "ids_priority"
-			destination => "ids_priority_full"
-			dictionary => [
-			"1", "High",
-			"2", "Medium",
-			"3", "Low"
-			]
-			id => "filter_translate_pfsense_snort"
-		}
-		geoip {
-			add_tag => [ "GeoIP_src" ]
-			source => "src_ip"
-			target => "geoip_src_ip"
-			id => "filter_geoip_pfsense_snort_src"
-		}
-		geoip {
-			add_tag => [ "GeoIP_dst" ]
-			source => "dest_ip"
-			target => "geoip_dest_ip"
-			id => "filter_geoip_pfsense_snort_dest"
-		}
-		dns {
-			action => "replace"
-			reverse => [ "src_host" ]
-			id => "filter_dns_pfsense_snort_src"
-		}
-		dns {
-			action => "replace"
-			reverse => [ "dest_host" ]
-			id => "filter_dns_pfsense_snort_dest"
-		}
-
-		if [ids_signature] {
-			if [ids_alert] =~ /^GPL/ {
-				mutate {
-					add_tag => [ "Snort-ET-sig" ]
-					add_field => { "ids_rule_type" => "Emerging Threats" }
-					id => "filter_mutate_pfsense_snort_ids_gpl"
-				}
-			}
-			if [ids_alert] =~ /^ET/ {
-				mutate {
-					add_tag => [ "Snort-ET-sig" ]
-					add_field => { "ids_rule_type" => "Emerging Threats" }
-					id => "filter_mutate_pfsense_snort_ids_et"
-				}
-			}
-			if "Snort-ET-sig" not in [tags] {
-				mutate {
-					add_tag => [ "Snort-sig" ]
-					add_field => { "ids_rule_type" => "Snort" }
-					id => "filter_mutate_pfsense_snort_ids_sig"
-				}
-			}
-		}
-		if "Snort-sig" in [tags] {
-			if [ids_gid] == "1" {
-				mutate {
-					add_field => { "Signature_Info" => "http://rootedyour.com/snortsid?sid=%{ids_sid}" }
-					id => "filter_mutate_pfsense_snort_ids_gid_1"
-				}
-			}
-			if [ids_gid] != "1" {
-				mutate {
-					add_field => { "Signature_Info" => "http://rootedyour.com/snortsid?sid=%{ids_gid}-%{ids_sid}" }
-					id => "filter_mutate_pfsense_snort_ids_gid_not_1"
-				}
-			}
-			if "Snort-ET-sig" in [tags] {
-				mutate {
-					add_field => { "Signature_Info" => "http://doc.emergingthreats.net/bin/view/Main/%{ids_sid}" }
-					id => "filter_mutate_pfsense_snort_ids_et_sig"
-				}
-			}
-		}
-	}
-}	
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/21-filter-syslog.conf b/logstash-core/src/test/resources/org/logstash/config/ir/21-filter-syslog.conf
deleted file mode 100644
index b71e2473722..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/21-filter-syslog.conf
+++ /dev/null
@@ -1,103 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-filter {
-	if [type] == "syslog"  {
-		if "_grokparsefailure_sysloginput" in [tags] {
-			drop { 
-				id => "filter_drop_syslogintput_syslog"
-			}
-		}  
-		date {
-		  match => [ "timestamp", "MMM d HH:mm:ss", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "MMMM d'th' yyyy',' HH:mm:ss.SSS" , "MMMM dd'th' yyyy',' HH:mm:ss.SSS" ]
-		  locale => "en_GB"
-		  timezone => "Europe/London"
-		  id => "filter_date_syslog"
-		}
-		syslog_pri { 
-			id => "filter_syslog_pri_syslog"
-		}
-		mutate {
-			add_field => [ "received_from", "%{host}" ]
-			replace => [ "host", "%{logsource}"]
-			replace => [ "timestamp", "%{@timestamp}" ]
-			id => "filter_mutate_syslog_add_fields"
-		}		
-		cidr {
-			add_tag => [ "host_is_ip" ]
-			address => [ "%{host}" ]
-			network => [ "0.0.0.0/0" ]
-			id => "filter_cidr_syslog_host"
-		}
-		if "host_is_ip" not in [tags] {
-			dns {
-				resolve => [ "host" ]
-				action => "replace"
-				remove_tag => [ "host_is_ip" ]
-				id => "filter_dns_syslog_host"
-			}
-		}
-		cidr {
-			add_tag => [ "logsource_is_ip" ]
-			address => [ "%{logsource}" ]
-			network => [ "0.0.0.0/0" ]
-			id => "filter_cidr_syslog_logsource"
-		}
-		if ("logsource_is_ip" in [tags]) {
-			dns {
-				reverse => [ "logsource" ]
-				action => "replace"
-				remove_tag => [ "host_is_ip" ]
-				id => "filter_dns_syslog_logsource"
-			}
-		}
-	}
-
-	if [type] == "local-syslog" {
-		grok {
-			match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
-			add_field => [ "received_at", "%{@timestamp}" ]
-			add_field => [ "received_from", "%{host}" ]
-			id => "filter_grok_syslog_local-syslog"
-		}	
-		if "_grokparsefailure" not in [tags] {
-			syslog_pri { 
-				id => "filter_syslog_pri_syslog_local-syslog"
-			}	
-			date {
-				match => [ "syslog_timestamp", "MMM d HH:mm:ss", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
-				locale => "en"
-				timezone => "Europe/London"
-				id => "filter_date_syslog_local-syslog"
-			}
-			mutate {
-				replace => [ "@source_host", "%{syslog_hostname}" ]		
-				replace => [ "@message", "%{syslog_message}" ]
-				id => "filter_mutate_syslog_local-syslog_add_fields"
-			}
-			mutate {
-				remove_field => [ "syslog_hostname", "syslog_message", "syslog_timestamp" ]
-				id => "filter_mutate_syslog_local-syslog_remove_fields"
-			}
-		}			
-	}
-
-	if [type] == "beats-syslog"  {
-		syslog_pri { 
-			id => "filter_syslog_pri_syslog_beats-syslog"
-		}
-		cidr {
-			add_tag => [ "host_is_ip" ]
-			address => [ "%{host}" ]
-			network => [ "0.0.0.0/0" ]
-			id => "filter_cidr_syslog_beats-syslog"
-		}
-		if "host_is_ip" not in [tags] {
-			dns {
-				resolve => [ "host" ]
-				action => "replace"
-				id => "filter_dns_syslog_beats-syslog_host"
-			}
-		}
-	}
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/22-filter-syslog-programs.conf b/logstash-core/src/test/resources/org/logstash/config/ir/22-filter-syslog-programs.conf
deleted file mode 100644
index c9578a2a690..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/22-filter-syslog-programs.conf
+++ /dev/null
@@ -1,22 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-filter {
-	if [type] == "syslog" and [program] == "fail2ban"  {		
-		date {
-		  match => [ "timestamp", "MMM d HH:mm:ss", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "MMMM d'th' yyyy',' HH:mm:ss.SSS" , "MMMM dd'th' yyyy',' HH:mm:ss.SSS", "ISO8601" ]
-		  locale => "en_GB"
-		  timezone => "Europe/London"
-		  id => "filter_date_syslog-programs"
-		}		
-		syslog_pri { 
-			id => "filter_syslog_pri_syslog-programs"
-		}		
-		geoip {
-			add_tag => [ "GeoIP_src" ]
-			source => "src_ip"
-			target => "geoip_src_ip"
-			id => "filter_geoip_src_syslog-programs"
-		}		
-	}
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-apache.conf b/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-apache.conf
deleted file mode 100644
index 477a31fd5d7..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-apache.conf
+++ /dev/null
@@ -1,11 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-filter {
-  if [type] == "apache-access" {
-    grok {
-      match => { "message" => "%{COMBINEDAPACHELOG}" }
-	  id => "filter_grok_apache-access"
-    }
-  }
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-iptables.conf b/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-iptables.conf
deleted file mode 100644
index f239537b2b9..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-iptables.conf
+++ /dev/null
@@ -1,49 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-filter {
-	if [type] == "iptables" {
-		grok {
-			patterns_dir => [ "/etc/logstash/patterns" ]
-			patterns_files_glob => "iptables*"
-			match => { "message" => "%{IPTABLES}" }
-			id => "filter_grok_iptables"
-		}	
-		date {
-			match => [ "syslog_timestamp", "MMM d HH:mm:ss", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
-			locale => "en"
-			timezone => "Europe/London"
-			id => "filter_date_iptables"
-		}	
-		mutate {
-			add_tag => [ "firewall", "iptables" ]
-			id => "filter_mutate_iptables_add_tag"
-		}
-		if "_grokparsefailure" not in [tags] {
-			mutate {
-				copy => { "host" => "host_ip" }
-				id => "filter_mutate_iptables_copy_host_ip"
-			}
-			dns {
-				resolve => [ "host_ip" ]
-				action => "replace"
-				add_tag => [ "dns_host_lookup" ]
-				id => "filter_dns_iptables_host_ip"
-			}
-			geoip {
-				add_tag => [ "geoip_src" ]
-				source => "src_ip"
-				target => "geoip_src_ip"
-				tag_on_failure => [ "_geoip_lookup_failure_src" ]
-				id => "filter_geoip_iptables_src"
-			}
-			geoip {
-				add_tag => [ "geoip_dst" ]
-				source => "dst_ip"
-				target => "geoip_dst_ip"
-				tag_on_failure => [ "_geoip_lookup_failure_dst" ]
-				id => "filter_geoip_iptables_dst"
-			}
-		}
-	}
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-nginx.conf b/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-nginx.conf
deleted file mode 100644
index 33636d358db..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-nginx.conf
+++ /dev/null
@@ -1,58 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-filter {
-	if [type] == "nginx-access" {  
-		mutate {
-			add_tag => ["nginx"]
-			id => "filter_mutate_nginx-access_add_tag"
-		}	  	  
-		grok {
-			match => { "message" => "%{NGINXACCESS}" }
-			patterns_dir => [ "/etc/logstash/patterns" ]
-			id => "filter_grok_nginx-access"
-		}
-		if "_grokparsefailure" not in [tags] {
-			date {
-				match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
-				locale => "en_GB"
-				timezone => "Europe/London"
-				id => "filter_date_nginx-access"
-			}	
-			geoip {
-				add_tag => [ "GeoIP_Client" ]
-				source => "clientip"
-				target => "geoip"
-				id => "filter_geoip_nginx-access_clientip"
-			}	
-			mutate {
-				add_field => { "clienthost" => "%{clientip}" }
-				remove_field => [ "timestamp" ]
-				id => "filter_mutate_nginx-access_add_clienthost"
-			}	
-			dns {
-				action => "replace"
-				reverse => [ "clienthost" ]
-				id => "filter_dns_nginx-access_clienthost"
-			}	
-			cidr {
-				add_tag => [ "host_is_ip" ]
-				address => [ "%{host}" ]
-				network => [ "0.0.0.0/0" ]
-				id => "filter_cidr_nginx-access_host_ip"
-			}
-			if "host_is_ip" not in [tags] {
-				dns {
-					resolve => [ "host" ]
-					action => "replace"
-					# remove_tag => [ "host_is_ip" ]
-					id => "filter_dns_nginx-access_host_ip"
-				}
-			}		
-			mutate {
-				add_field => [ "received_at", "%{@timestamp}" ]
-				id => "filter_mutate_nginx-access_add_receieved_at"
-			}
-		}
-	}
-}
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/26-filter-netflow.conf b/logstash-core/src/test/resources/org/logstash/config/ir/26-filter-netflow.conf
deleted file mode 100644
index 9200c79b43f..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/26-filter-netflow.conf
+++ /dev/null
@@ -1,42 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-# Netflow
-filter {
-	if [type] == "netflow" {
-		geoip {
-			add_tag => [ "GeoIP_src" ]
-			source => "[netflow][ipv4_src_addr]"
-			target => "[geoip][src_ip]"
-			id => "filter_geoip_netflow_src"
-		}
-		geoip {
-			add_tag => [ "GeoIP_dst" ]
-			source => "[netflow][ipv4_dst_addr]"
-			target => "[geoip][dest_ip]"
-			id => "filter_geoip_netflow_dest"
-		}
-		translate {
-			field => "[netflow][protocol]"
-			destination => "[netflow][protocol_name]"
-			override => "true"
-			dictionary => [ "1", "ICMP",
-							"2", "IGMP",
-							"6", "TCP",
-							"9", "IGMP",
-							"17", "UDP",
-							"41", "IPv6-Encap",
-							"43", "IPv6-Route",
-							"44", "IPv6-Frag",
-							"47", "GRE",
-							"50", "ESP",
-							"58", "IPv6-ICMP",
-							"88", "EIGRP",
-							"89", "OSPF-IGP",
-							"115", "L2TP",
-							"124", "ISIS" ]
-			fallback => "No protocol name found"
-			id => "filter_translate_netflow_protocol_name"
-		}
-	}
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/30-output-debug.conf b/logstash-core/src/test/resources/org/logstash/config/ir/30-output-debug.conf
deleted file mode 100644
index 4aa8e9eeb34..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/30-output-debug.conf
+++ /dev/null
@@ -1,29 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-# output {
-	# if [type] == "cisco-syslog" {
-		# file { 
-			# path => "/var/log/logstash/cisco_debug_events-%{+YYYY-MM-dd}" 
-			# id => "output_file_debug_cisco-syslog"
-		# }
-	# }
-# }
-
-output {
-	if [type] == "snmptrap" {
-		file { 
-			path => "/var/log/logstash/snmptrap_debug_events-%{+YYYY-MM-dd}" 
-			id => "output_file_debug_snmptrap"
-		}
-	}
-}
-
-output {
-	if [type] == "firewall" {
-		file { 
-			path => "/var/log/logstash/firewall_debug_events-%{+YYYY-MM-dd}" 
-			id => "output_file_debug_firewall"
-		}
-	}
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/30-output-elasticsearch.conf b/logstash-core/src/test/resources/org/logstash/config/ir/30-output-elasticsearch.conf
deleted file mode 100644
index a23792216ed..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/30-output-elasticsearch.conf
+++ /dev/null
@@ -1,87 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-output {
-	if [type] != "snmptrap" {
-		if [type] == "netflow" {
-			elasticsearch {
-				hosts => ["localhost:9200"]
-				index => "netflow-%{+YYYY.MM.dd}"
-				template => "/etc/logstash/templates/netflow-template-es6x.json"
-				template_name => "netflow"
-				template_overwrite => true
-				id => "output_elasticsearch_netflow"
-			}
-		} else if [@metadata][beat] == "winlogbeat" {
-			elasticsearch {
-				hosts => ["localhost:9200"]
-				index => "winlogbeat-%{+YYYY.MM.dd}"
-				template => "/etc/logstash/templates/winlogbeat-template-es6x.json"
-				template_name => "winlogbeat"
-				template_overwrite => true
-				id => "output_elasticsearch_winlogbeat"
-			}
-		} else if [@metadata][beat] == "metricbeat" {
-			elasticsearch {
-				hosts => ["localhost:9200"]
-				index => "metricbeat-%{+YYYY.MM.dd}"
-				template => "/etc/logstash/templates/metricbeat-template-es6x.json"
-				template_name => "metricbeat"
-				template_overwrite => true
-				id => "output_elasticsearch_metricbeat"
-			}
-		} else if [@metadata][beat] == "packetbeat" {
-			elasticsearch {
-				hosts => ["localhost:9200"]
-				index => "packetbeat-%{+YYYY.MM.dd}"
-				template => "/etc/logstash/templates/packetbeat-template-es6x.json"
-				template_name => "packetbeat"
-				template_overwrite => true
-				id => "output_elasticsearch_packetbeat"
-			}
-		} else if [type] == "iptables" {
-			elasticsearch {
-				hosts => ["localhost:9200"]
-				index => "iptables-%{+YYYY.MM.dd}"
-				template => "/etc/logstash/templates/iptables-template-es6x.json"
-				template_name => "iptables"
-				template_overwrite => true
-				id => "output_elasticsearch_iptables"
-			}
-		} else if [type] == "filterlog" {
-			elasticsearch {
-				hosts => ["localhost:9200"]
-				index => "filterlog-%{+YYYY.MM.dd}"
-				template => "/etc/logstash/templates/filterlog-template-es6x.json"
-				template_name => "filterlog"
-				template_overwrite => true
-				id => "output_elasticsearch_filterlog"
-			}
-		} else if [type] == "cisco-syslog" {
-			elasticsearch {
-				hosts => ["localhost:9200"]
-				index => "cisco-syslog-%{+YYYY.MM.dd}"
-				template => "/etc/logstash/templates/cisco-syslog-template-es6x.json"
-				template_name => "cisco-syslog"
-				template_overwrite => true
-				id => "output_elasticsearch_cisco-syslog"
-			}
-		} else if [type] == "nginx-access" {
-			elasticsearch {
-				hosts => ["localhost:9200"]
-				index => "nginx-access-%{+YYYY.MM.dd}"
-				template => "/etc/logstash/templates/nginx-access-template-es6x.json"
-				template_name => "nginx-access"
-				template_overwrite => true
-				id => "output_elasticsearch_nginx-access"
-			}
-		} else {
-			elasticsearch {
-				hosts => ["localhost:9200"]
-				template => "/etc/logstash/templates/elasticsearch-template-es6x.json"
-				template_overwrite => true
-				id => "output_elasticsearch_logstash"
-			}
-		}
-	}
-}
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/31-output-parsefailure.conf b/logstash-core/src/test/resources/org/logstash/config/ir/31-output-parsefailure.conf
deleted file mode 100644
index ffa8a90ec23..00000000000
--- a/logstash-core/src/test/resources/org/logstash/config/ir/31-output-parsefailure.conf
+++ /dev/null
@@ -1,23 +0,0 @@
-# Generated by Chef for REDACTED
-# Do NOT modify this file by hand.
-#
-output {
-	if [type] == "syslog" and "_grokparsefailure" in [tags] {
-		file { 
-			path => "/var/log/logstash/failed_syslog_events-%{+YYYY-MM-dd}" 
-			id => "output_file_syslog_failure"
-		}
-	}
-	if [type] == "cisco-syslog" and "_grokparsefailure" in [tags] {
-		file { 
-			path => "/var/log/logstash/failed_cisco_events-%{+YYYY-MM-dd}" 
-			id => "output_file_cisco-syslog_failure"
-		}
-	}
-	if [type] == "nginx-access" and "_grokparsefailure" in [tags] {
-		file { 
-			path => "/var/log/logstash/failed_nginx_events-%{+YYYY-MM-dd}" 
-			id => "output_file_nginx-access_failure"
-		}
-	}
-}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-cisco.conf b/logstash-core/src/test/resources/org/logstash/config/ir/complex.cfg
similarity index 77%
rename from logstash-core/src/test/resources/org/logstash/config/ir/25-filter-cisco.conf
rename to logstash-core/src/test/resources/org/logstash/config/ir/complex.cfg
index 00ecdcf8af9..216969520b8 100644
--- a/logstash-core/src/test/resources/org/logstash/config/ir/25-filter-cisco.conf
+++ b/logstash-core/src/test/resources/org/logstash/config/ir/complex.cfg
@@ -1,6 +1,417 @@
 # Generated by Chef for REDACTED
 # Do NOT modify this file by hand.
 #
+input {
+  beats {
+    port => 5044
+	tags => [ "beats" ]
+	id => "input_beats"
+  }
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+input {
+	udp {
+		port => 9995
+		type => "netflow"
+		codec => netflow {
+			versions => [5, 9]
+		}
+		id => "input_udp_netflow"
+	}	
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+input {
+	snmptrap {
+		tags => ["SNMP Trap", "Ready"]
+		type => snmptrap
+		community => "public"
+		id => "input_snmptrap"
+	}
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+input {
+	tcp {
+		port => 8514
+		type => "ciscosyslog"
+		id => "input_tcp_cisco-syslog"
+	}
+	udp {
+		port => 8514
+		type => "cisco-syslog"
+		id => "input_udp_cisco-syslog"
+	}
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+input {
+	syslog {
+		port => 5514
+		type => syslog
+		id => "input_syslog"
+	}
+}
+# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+filter {
+	if [type] == "syslog" {
+		mutate {
+			add_tag => "syslog"
+			id => "filter_mutate_add_syslog_tag"
+		}
+		if [logsource] =~ "pfsense.*" {
+		  mutate {
+			add_tag => ["pfsense", "firewall"]
+			id => "filter_mutate_add_pfsense_tag"
+		  }
+		}	
+		if [logsource] == "freenas.mds.home.local" {
+			if [program] == "snmpd" {
+				drop { 
+					id => "filter_drop_freenas_snmpd"
+				}
+			}
+		}
+	}	
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+filter {
+	if ("syslog" in [tags] or "pfsense" in [tags]) {
+		if [program] =~ /^dhcpd$/ {
+			mutate {
+				add_tag => [ "dhcp" ]
+				id => "filter_mutate_add_dhcp_tag"
+			}
+			if [message] =~ /^DHCPACK|^DHCPREQUEST|^DHCPOFFER/ {
+				grok {
+					patterns_dir => [ "/etc/logstash/patterns" ]
+					patterns_files_glob => "dhcpd"
+					match => { "message" => "%{DHCPACK}" }
+					id => "filter_grok_dhcpack"
+				}
+			}
+			if [message] =~ /^DHCPDISCOVER/ {
+				grok {
+					patterns_dir => [ "/etc/logstash/patterns" ]
+					patterns_files_glob => "dhcpd"
+					match => { "message" => "%{DHCPDISCOVER}" }
+					id => "filter_grok_dhcpdiscover"
+				}
+			}
+			if [message] =~ /^DHCPINFORM/ {
+				grok {
+					patterns_dir => [ "/etc/logstash/patterns" ]
+					patterns_files_glob => "dhcpd"
+					match => { "message" => "%{DHCPINFORM}" }
+					id => "filter_grok_dhcpinform"
+				}
+			}
+		}	
+	}
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+# pfSense
+filter {
+	if [type] == "syslog" and "pfsense" in [tags] {
+		grok {
+			match => { "message" => "(?<msg>.*)" }
+			id => "filter_grok_pfsense_message"
+		}
+		mutate {
+			gsub => [ "timestamp", "  ", " " ]
+			replace => { "message" => "%{msg}" }
+			replace => { "host" => "%{logsource}" }
+			remove_field => [ "msg" ]			
+			id => "filter_mutate_pfsense_tidy_message"
+		}
+		dns {
+			resolve => [ "host" ]
+			action => "replace"
+			id => "filter_dns_pfsense_host"
+		}		
+		if [program] == "filterlog" {
+			mutate {
+				remove_field => [ "msg" ]    
+				replace => { "type" => "filterlog" }
+				id => "filter_mutate_pfsense_filterlog_remove_fields"
+			}
+			grok {
+				patterns_dir => [ "/etc/logstash/patterns" ]
+				patterns_files_glob => "pfsense*"
+				match => { "message" => "%{LOG_DATA}%{IP_SPECIFIC_DATA}%{IP_DATA}(%{PROTOCOL_DATA})?" }
+				id => "filter_grok_pfsense_filterlog"
+			}
+			if "_grokparsefailure" not in [tags] {
+				geoip {
+					add_tag => [ "GeoIP_src" ]
+					source => "src_ip"
+					target => "geoip_src_ip"
+					id => "filter_geoip_pfsense_filterlog_src"
+				}
+				geoip {
+					add_tag => [ "GeoIP_dest" ]
+					source => "dest_ip"
+					target => "geoip_dest_ip"
+					id => "filter_geoip_pfsense_filterlog_dest"
+				}		
+				mutate {
+					add_field => { "src_host" => "%{src_ip}" }
+					add_field => { "dest_host" => "%{dest_ip}" }
+					lowercase => [ "%{proto}" ]
+					id => "filter_mutate_pfsense_filterlog_add_fields"					
+				}
+
+				dns {
+					action => "replace"
+					reverse => [ "src_host" ]
+					id => "filter_dns_pfsense_filterlog_src"
+				}
+				dns {
+					action => "replace"
+					reverse => [ "dest_host" ]
+					id => "filter_dns_pfsense_filterlog_dest"
+				}
+			}
+		}			
+		if [program] == "suricata" {
+			mutate {
+				add_tag => [ "suricata" ]
+				id => "filter_mutate_pfsense_suricata_tag"
+			}
+		}
+	}
+
+	# Snort
+	if [program] == "snort" {
+		mutate {
+			add_tag => [ "snort" ]
+			add_field => { "src_host" => "%{src_ip}" }
+			add_field => { "dest_host" => "%{dest_ip}" }
+			id => "filter_mutate_pfsense_snort_tags"
+		}
+		grok {
+			match => { "message" => ["\[%{INT:ids_gid}\:%{INT:ids_sid}\:%{INT:ids_rev}\].%{GREEDYDATA:ids_alert}.\[Classification\: %{DATA:ids_classification}\].*\[Priority\: %{INT:ids_priority}].*{%{WORD:ids_proto}}.*%{IP:src_ip}:%{INT:src_port} \-\>.*%{IP:dest_ip}:%{INT:dest_port}", "\[%{INT:ids_gid}\:%{INT:ids_sid}\:%{INT:ids_rev}\].%{GREEDYDATA:ids_alert}.\[Classification\: %{DATA:ids_classification}\].*\[Priority\: %{INT:ids_priority}].*\{PROTO:%{WORD:ids_proto}.*%{IP:src_ip} \-\>.*%{IP:dest_ip}}" ] }		
+			id => "filter_grok_pfsense_snort"
+		}
+		translate {
+			field => "ids_priority"
+			destination => "ids_priority_full"
+			dictionary => [
+			"1", "High",
+			"2", "Medium",
+			"3", "Low"
+			]
+			id => "filter_translate_pfsense_snort"
+		}
+		geoip {
+			add_tag => [ "GeoIP_src" ]
+			source => "src_ip"
+			target => "geoip_src_ip"
+			id => "filter_geoip_pfsense_snort_src"
+		}
+		geoip {
+			add_tag => [ "GeoIP_dst" ]
+			source => "dest_ip"
+			target => "geoip_dest_ip"
+			id => "filter_geoip_pfsense_snort_dest"
+		}
+		dns {
+			action => "replace"
+			reverse => [ "src_host" ]
+			id => "filter_dns_pfsense_snort_src"
+		}
+		dns {
+			action => "replace"
+			reverse => [ "dest_host" ]
+			id => "filter_dns_pfsense_snort_dest"
+		}
+
+		if [ids_signature] {
+			if [ids_alert] =~ /^GPL/ {
+				mutate {
+					add_tag => [ "Snort-ET-sig" ]
+					add_field => { "ids_rule_type" => "Emerging Threats" }
+					id => "filter_mutate_pfsense_snort_ids_gpl"
+				}
+			}
+			if [ids_alert] =~ /^ET/ {
+				mutate {
+					add_tag => [ "Snort-ET-sig" ]
+					add_field => { "ids_rule_type" => "Emerging Threats" }
+					id => "filter_mutate_pfsense_snort_ids_et"
+				}
+			}
+			if "Snort-ET-sig" not in [tags] {
+				mutate {
+					add_tag => [ "Snort-sig" ]
+					add_field => { "ids_rule_type" => "Snort" }
+					id => "filter_mutate_pfsense_snort_ids_sig"
+				}
+			}
+		}
+		if "Snort-sig" in [tags] {
+			if [ids_gid] == "1" {
+				mutate {
+					add_field => { "Signature_Info" => "http://rootedyour.com/snortsid?sid=%{ids_sid}" }
+					id => "filter_mutate_pfsense_snort_ids_gid_1"
+				}
+			}
+			if [ids_gid] != "1" {
+				mutate {
+					add_field => { "Signature_Info" => "http://rootedyour.com/snortsid?sid=%{ids_gid}-%{ids_sid}" }
+					id => "filter_mutate_pfsense_snort_ids_gid_not_1"
+				}
+			}
+			if "Snort-ET-sig" in [tags] {
+				mutate {
+					add_field => { "Signature_Info" => "http://doc.emergingthreats.net/bin/view/Main/%{ids_sid}" }
+					id => "filter_mutate_pfsense_snort_ids_et_sig"
+				}
+			}
+		}
+	}
+}	
+# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+filter {
+	if [type] == "syslog"  {
+		if "_grokparsefailure_sysloginput" in [tags] {
+			drop { 
+				id => "filter_drop_syslogintput_syslog"
+			}
+		}  
+		date {
+		  match => [ "timestamp", "MMM d HH:mm:ss", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "MMMM d'th' yyyy',' HH:mm:ss.SSS" , "MMMM dd'th' yyyy',' HH:mm:ss.SSS" ]
+		  locale => "en_GB"
+		  timezone => "Europe/London"
+		  id => "filter_date_syslog"
+		}
+		syslog_pri { 
+			id => "filter_syslog_pri_syslog"
+		}
+		mutate {
+			add_field => [ "received_from", "%{host}" ]
+			replace => [ "host", "%{logsource}"]
+			replace => [ "timestamp", "%{@timestamp}" ]
+			id => "filter_mutate_syslog_add_fields"
+		}		
+		cidr {
+			add_tag => [ "host_is_ip" ]
+			address => [ "%{host}" ]
+			network => [ "0.0.0.0/0" ]
+			id => "filter_cidr_syslog_host"
+		}
+		if "host_is_ip" not in [tags] {
+			dns {
+				resolve => [ "host" ]
+				action => "replace"
+				remove_tag => [ "host_is_ip" ]
+				id => "filter_dns_syslog_host"
+			}
+		}
+		cidr {
+			add_tag => [ "logsource_is_ip" ]
+			address => [ "%{logsource}" ]
+			network => [ "0.0.0.0/0" ]
+			id => "filter_cidr_syslog_logsource"
+		}
+		if ("logsource_is_ip" in [tags]) {
+			dns {
+				reverse => [ "logsource" ]
+				action => "replace"
+				remove_tag => [ "host_is_ip" ]
+				id => "filter_dns_syslog_logsource"
+			}
+		}
+	}
+
+	if [type] == "local-syslog" {
+		grok {
+			match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
+			add_field => [ "received_at", "%{@timestamp}" ]
+			add_field => [ "received_from", "%{host}" ]
+			id => "filter_grok_syslog_local-syslog"
+		}	
+		if "_grokparsefailure" not in [tags] {
+			syslog_pri { 
+				id => "filter_syslog_pri_syslog_local-syslog"
+			}	
+			date {
+				match => [ "syslog_timestamp", "MMM d HH:mm:ss", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
+				locale => "en"
+				timezone => "Europe/London"
+				id => "filter_date_syslog_local-syslog"
+			}
+			mutate {
+				replace => [ "@source_host", "%{syslog_hostname}" ]		
+				replace => [ "@message", "%{syslog_message}" ]
+				id => "filter_mutate_syslog_local-syslog_add_fields"
+			}
+			mutate {
+				remove_field => [ "syslog_hostname", "syslog_message", "syslog_timestamp" ]
+				id => "filter_mutate_syslog_local-syslog_remove_fields"
+			}
+		}			
+	}
+
+	if [type] == "beats-syslog"  {
+		syslog_pri { 
+			id => "filter_syslog_pri_syslog_beats-syslog"
+		}
+		cidr {
+			add_tag => [ "host_is_ip" ]
+			address => [ "%{host}" ]
+			network => [ "0.0.0.0/0" ]
+			id => "filter_cidr_syslog_beats-syslog"
+		}
+		if "host_is_ip" not in [tags] {
+			dns {
+				resolve => [ "host" ]
+				action => "replace"
+				id => "filter_dns_syslog_beats-syslog_host"
+			}
+		}
+	}
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+filter {
+	if [type] == "syslog" and [program] == "fail2ban"  {		
+		date {
+		  match => [ "timestamp", "MMM d HH:mm:ss", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "MMMM d'th' yyyy',' HH:mm:ss.SSS" , "MMMM dd'th' yyyy',' HH:mm:ss.SSS", "ISO8601" ]
+		  locale => "en_GB"
+		  timezone => "Europe/London"
+		  id => "filter_date_syslog-programs"
+		}		
+		syslog_pri { 
+			id => "filter_syslog_pri_syslog-programs"
+		}		
+		geoip {
+			add_tag => [ "GeoIP_src" ]
+			source => "src_ip"
+			target => "geoip_src_ip"
+			id => "filter_geoip_src_syslog-programs"
+		}		
+	}
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+filter {
+  if [type] == "apache-access" {
+    grok {
+      match => { "message" => "%{COMBINEDAPACHELOG}" }
+	  id => "filter_grok_apache-access"
+    }
+  }
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
 filter {
 	if [type] == "cisco-syslog" {
 		mutate {
@@ -1301,4 +1712,288 @@ filter {
 			}
 		}
 	}
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+filter {
+	if [type] == "iptables" {
+		grok {
+			patterns_dir => [ "/etc/logstash/patterns" ]
+			patterns_files_glob => "iptables*"
+			match => { "message" => "%{IPTABLES}" }
+			id => "filter_grok_iptables"
+		}	
+		date {
+			match => [ "syslog_timestamp", "MMM d HH:mm:ss", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
+			locale => "en"
+			timezone => "Europe/London"
+			id => "filter_date_iptables"
+		}	
+		mutate {
+			add_tag => [ "firewall", "iptables" ]
+			id => "filter_mutate_iptables_add_tag"
+		}
+		if "_grokparsefailure" not in [tags] {
+			mutate {
+				copy => { "host" => "host_ip" }
+				id => "filter_mutate_iptables_copy_host_ip"
+			}
+			dns {
+				resolve => [ "host_ip" ]
+				action => "replace"
+				add_tag => [ "dns_host_lookup" ]
+				id => "filter_dns_iptables_host_ip"
+			}
+			geoip {
+				add_tag => [ "geoip_src" ]
+				source => "src_ip"
+				target => "geoip_src_ip"
+				tag_on_failure => [ "_geoip_lookup_failure_src" ]
+				id => "filter_geoip_iptables_src"
+			}
+			geoip {
+				add_tag => [ "geoip_dst" ]
+				source => "dst_ip"
+				target => "geoip_dst_ip"
+				tag_on_failure => [ "_geoip_lookup_failure_dst" ]
+				id => "filter_geoip_iptables_dst"
+			}
+		}
+	}
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+filter {
+	if [type] == "nginx-access" {  
+		mutate {
+			add_tag => ["nginx"]
+			id => "filter_mutate_nginx-access_add_tag"
+		}	  	  
+		grok {
+			match => { "message" => "%{NGINXACCESS}" }
+			patterns_dir => [ "/etc/logstash/patterns" ]
+			id => "filter_grok_nginx-access"
+		}
+		if "_grokparsefailure" not in [tags] {
+			date {
+				match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
+				locale => "en_GB"
+				timezone => "Europe/London"
+				id => "filter_date_nginx-access"
+			}	
+			geoip {
+				add_tag => [ "GeoIP_Client" ]
+				source => "clientip"
+				target => "geoip"
+				id => "filter_geoip_nginx-access_clientip"
+			}	
+			mutate {
+				add_field => { "clienthost" => "%{clientip}" }
+				remove_field => [ "timestamp" ]
+				id => "filter_mutate_nginx-access_add_clienthost"
+			}	
+			dns {
+				action => "replace"
+				reverse => [ "clienthost" ]
+				id => "filter_dns_nginx-access_clienthost"
+			}	
+			cidr {
+				add_tag => [ "host_is_ip" ]
+				address => [ "%{host}" ]
+				network => [ "0.0.0.0/0" ]
+				id => "filter_cidr_nginx-access_host_ip"
+			}
+			if "host_is_ip" not in [tags] {
+				dns {
+					resolve => [ "host" ]
+					action => "replace"
+					# remove_tag => [ "host_is_ip" ]
+					id => "filter_dns_nginx-access_host_ip"
+				}
+			}		
+			mutate {
+				add_field => [ "received_at", "%{@timestamp}" ]
+				id => "filter_mutate_nginx-access_add_receieved_at"
+			}
+		}
+	}
+}
+# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+# Netflow
+filter {
+	if [type] == "netflow" {
+		geoip {
+			add_tag => [ "GeoIP_src" ]
+			source => "[netflow][ipv4_src_addr]"
+			target => "[geoip][src_ip]"
+			id => "filter_geoip_netflow_src"
+		}
+		geoip {
+			add_tag => [ "GeoIP_dst" ]
+			source => "[netflow][ipv4_dst_addr]"
+			target => "[geoip][dest_ip]"
+			id => "filter_geoip_netflow_dest"
+		}
+		translate {
+			field => "[netflow][protocol]"
+			destination => "[netflow][protocol_name]"
+			override => "true"
+			dictionary => [ "1", "ICMP",
+							"2", "IGMP",
+							"6", "TCP",
+							"9", "IGMP",
+							"17", "UDP",
+							"41", "IPv6-Encap",
+							"43", "IPv6-Route",
+							"44", "IPv6-Frag",
+							"47", "GRE",
+							"50", "ESP",
+							"58", "IPv6-ICMP",
+							"88", "EIGRP",
+							"89", "OSPF-IGP",
+							"115", "L2TP",
+							"124", "ISIS" ]
+			fallback => "No protocol name found"
+			id => "filter_translate_netflow_protocol_name"
+		}
+	}
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+# output {
+	# if [type] == "cisco-syslog" {
+		# file { 
+			# path => "/var/log/logstash/cisco_debug_events-%{+YYYY-MM-dd}" 
+			# id => "output_file_debug_cisco-syslog"
+		# }
+	# }
+# }
+
+output {
+	if [type] == "snmptrap" {
+		file { 
+			path => "/var/log/logstash/snmptrap_debug_events-%{+YYYY-MM-dd}" 
+			id => "output_file_debug_snmptrap"
+		}
+	}
+}
+
+output {
+	if [type] == "firewall" {
+		file { 
+			path => "/var/log/logstash/firewall_debug_events-%{+YYYY-MM-dd}" 
+			id => "output_file_debug_firewall"
+		}
+	}
+}# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+output {
+	if [type] != "snmptrap" {
+		if [type] == "netflow" {
+			elasticsearch {
+				hosts => ["localhost:9200"]
+				index => "netflow-%{+YYYY.MM.dd}"
+				template => "/etc/logstash/templates/netflow-template-es6x.json"
+				template_name => "netflow"
+				template_overwrite => true
+				id => "output_elasticsearch_netflow"
+			}
+		} else if [@metadata][beat] == "winlogbeat" {
+			elasticsearch {
+				hosts => ["localhost:9200"]
+				index => "winlogbeat-%{+YYYY.MM.dd}"
+				template => "/etc/logstash/templates/winlogbeat-template-es6x.json"
+				template_name => "winlogbeat"
+				template_overwrite => true
+				id => "output_elasticsearch_winlogbeat"
+			}
+		} else if [@metadata][beat] == "metricbeat" {
+			elasticsearch {
+				hosts => ["localhost:9200"]
+				index => "metricbeat-%{+YYYY.MM.dd}"
+				template => "/etc/logstash/templates/metricbeat-template-es6x.json"
+				template_name => "metricbeat"
+				template_overwrite => true
+				id => "output_elasticsearch_metricbeat"
+			}
+		} else if [@metadata][beat] == "packetbeat" {
+			elasticsearch {
+				hosts => ["localhost:9200"]
+				index => "packetbeat-%{+YYYY.MM.dd}"
+				template => "/etc/logstash/templates/packetbeat-template-es6x.json"
+				template_name => "packetbeat"
+				template_overwrite => true
+				id => "output_elasticsearch_packetbeat"
+			}
+		} else if [type] == "iptables" {
+			elasticsearch {
+				hosts => ["localhost:9200"]
+				index => "iptables-%{+YYYY.MM.dd}"
+				template => "/etc/logstash/templates/iptables-template-es6x.json"
+				template_name => "iptables"
+				template_overwrite => true
+				id => "output_elasticsearch_iptables"
+			}
+		} else if [type] == "filterlog" {
+			elasticsearch {
+				hosts => ["localhost:9200"]
+				index => "filterlog-%{+YYYY.MM.dd}"
+				template => "/etc/logstash/templates/filterlog-template-es6x.json"
+				template_name => "filterlog"
+				template_overwrite => true
+				id => "output_elasticsearch_filterlog"
+			}
+		} else if [type] == "cisco-syslog" {
+			elasticsearch {
+				hosts => ["localhost:9200"]
+				index => "cisco-syslog-%{+YYYY.MM.dd}"
+				template => "/etc/logstash/templates/cisco-syslog-template-es6x.json"
+				template_name => "cisco-syslog"
+				template_overwrite => true
+				id => "output_elasticsearch_cisco-syslog"
+			}
+		} else if [type] == "nginx-access" {
+			elasticsearch {
+				hosts => ["localhost:9200"]
+				index => "nginx-access-%{+YYYY.MM.dd}"
+				template => "/etc/logstash/templates/nginx-access-template-es6x.json"
+				template_name => "nginx-access"
+				template_overwrite => true
+				id => "output_elasticsearch_nginx-access"
+			}
+		} else {
+			elasticsearch {
+				hosts => ["localhost:9200"]
+				template => "/etc/logstash/templates/elasticsearch-template-es6x.json"
+				template_overwrite => true
+				id => "output_elasticsearch_logstash"
+			}
+		}
+	}
+}
+# Generated by Chef for REDACTED
+# Do NOT modify this file by hand.
+#
+output {
+	if [type] == "syslog" and "_grokparsefailure" in [tags] {
+		file { 
+			path => "/var/log/logstash/failed_syslog_events-%{+YYYY-MM-dd}" 
+			id => "output_file_syslog_failure"
+		}
+	}
+	if [type] == "cisco-syslog" and "_grokparsefailure" in [tags] {
+		file { 
+			path => "/var/log/logstash/failed_cisco_events-%{+YYYY-MM-dd}" 
+			id => "output_file_cisco-syslog_failure"
+		}
+	}
+	if [type] == "nginx-access" and "_grokparsefailure" in [tags] {
+		file { 
+			path => "/var/log/logstash/failed_nginx_events-%{+YYYY-MM-dd}" 
+			id => "output_file_nginx-access_failure"
+		}
+	}
 }
\ No newline at end of file
