diff --git a/lib/logstash/filters/advisor.rb b/lib/logstash/filters/advisor.rb
new file mode 100644
index 00000000000..902548530ef
--- /dev/null
+++ b/lib/logstash/filters/advisor.rb
@@ -0,0 +1,179 @@
+require "logstash/filters/base"
+require "logstash/namespace"
+
+# INFORMATION:
+# The filter Advisor is designed for capture and confrontation the events. 
+# The events must be grep by a filter first, then it can pull out a copy of it, like clone, whit tags "advisor_first",
+# this copy is the first occurrence of this event verified in time_adv.
+# After time_adv Advisor will pull out an event tagged "advisor_info" who will tell you the number of same events verified in time_adv.
+
+# INFORMATION ABOUT CLASS:
+ 
+# For do this job, i used a thread that will sleep time adv. I assume that events coming on advisor are tagged, then i use an array for storing different events.
+# If an events is not present on array, then is the first and if the option is activate then  advisor push out a copy of event.
+# Else if the event is present on array, then is another same event and not the first, let's count it.  
+
+# USAGE:
+
+# This is an example of logstash config:
+
+# filter{
+#  advisor {
+#     time_adv => 1                     #(optional)
+#     send_first => true                #(optional)
+#  }
+# }
+
+# We analize this:
+
+# time_adv => 1
+# Means the time when the events matched and collected are pushed on outputs with tag "advisor_info".
+
+# send_first => true
+# Means you can push out the first events different who came in advisor like clone copy and tagged with "advisor_first"
+
+class LogStash::Filters::Advisor < LogStash::Filters::Base
+
+ config_name "advisor"
+ plugin_status "experimental"
+
+ # If you do not set time_adv the plugin does nothing.
+ config :time_adv, :validate => :number, :default => 0
+ 
+ # If you want the first different event will be pushed out like a copy
+ config :send_first, :validate => :boolean, :default => true
+ 
+ public
+ def register
+
+  # Control the correct config
+  if (!(@time_adv == 0))
+    
+    @flag = false
+    @first = false
+    # Is used for store the different events.
+    @sarray = Array.new
+    # Is used for count the number of equals events.
+    @carray = Array.new
+
+    @thread = time_alert(@time_adv.to_i*60) do
+     # if collected any events then pushed out a new event after time_adv
+     if (@sarray.size !=0) 
+        @flag = true
+     end
+    end
+  
+  else
+   @logger.warn("Advisor: you have not specified Time_adv. This filter will do nothing!")
+  end
+
+ end
+ 
+ # This method is used to manage sleep and awaken threads (thanks StackOverflow for the support)
+  def time_alert(interval)
+     Thread.new do
+      loop do
+       start_time = Time.now
+       yield
+       elapsed = Time.now - start_time
+       sleep([interval - elapsed, 0].max)
+     end
+   end
+  end
+
+ public
+ def filter(event)
+  return unless filter?(event)
+  
+  # Control the correct config
+  if(!(@time_adv == 0))
+
+    new_event = true
+    @message = event.message
+    
+    # control if the events are new or they are came before
+    for i in (0..@sarray.size-1)
+      if (@message == @sarray[i].to_s)
+        @logger.debug("Avisor: Event match")
+        # if came before then count it
+        new_event = false
+        @carray[i] = @carray[i].to_i+1
+        @logger.debug("Advisor: "+@carray[i].to_s+" Events matched")
+        break
+      end
+    end
+     
+    if (new_event == true)
+       # else is a new event
+
+       @sarray << @message
+       @carray << 1
+       if (send_first == true)
+           @logger.debug("Advisor: is the first to send out")
+           @first = true
+       end
+    end
+     
+  else
+   @logger.warn("Advisor: you have not specified Time_adv. This filter will do nothing!")
+  end
+ end
+
+
+  # This method is used for generate events every 5 seconds (Thanks Jordan Sissel for explanation).
+  # In this case we generate an event when advisor thread trigger the flag or is the first different event. 
+
+  def flush
+      
+        if (@first == true)
+          event = LogStash::Event.new
+          event.source_host = Socket.gethostname
+          event.message = @message
+          event.tags << "advisor_first"
+          event.source = Socket.gethostname+" advisor_plugin"
+          filter_matched(event)
+         
+          @first = false
+          return [event]
+        end
+   
+         if (@flag == true)
+ 
+          if (@tags.size != 0)
+            @tag_path = ""
+            for i in (0..@tags.size-1)
+              @tag_path += @tags[i].to_s+"."
+            end
+          end
+            
+          # Prepare message 
+          message = "Advisor: Found events who match: "+@tag_path.to_s+"\n\n"
+
+          # See on messagge partial part of different events
+          for i in (0..@sarray.size-1)
+            message = message+@carray[i].to_s+" events like: "+(@sarray[i].to_s).slice(0, 300)+"\n\n"
+          end
+         
+          event = LogStash::Event.new
+          event.source_host = Socket.gethostname 
+          event.message = message  
+          event.tags << "advisor_info"
+          event.source = Socket.gethostname+" advisor_plugin"
+          filter_matched(event)
+   
+          # reset flag and counter 
+          @flag = false
+          @carray = nil
+          @sarray = nil
+          @carray = Array.new
+          @sarray = Array.new
+
+          # push the event
+          return [event]
+         end
+    return
+ 
+  end
+
+end
+# By Bistic:)
diff --git a/lib/logstash/outputs/s3.rb b/lib/logstash/outputs/s3.rb
new file mode 100644
index 00000000000..5e735e5c483
--- /dev/null
+++ b/lib/logstash/outputs/s3.rb
@@ -0,0 +1,349 @@
+require "logstash/outputs/base"
+require "logstash/namespace"
+require "aws-sdk"
+
+# TODO integrate aws_config in the future 
+#require "logstash/plugin_mixins/aws_config"
+
+# INFORMATION:
+
+# This plugin was created for store the logstash's events into Amazon Simple Storage Service (Amazon S3).
+# For use it you needs authentications and an s3 bucket. 
+# Be careful to have the permission to write file on S3's bucket and run logstash with super user for establish connection.
+
+# S3 plugin allows you to do something complex, let's explain:)
+
+# S3 outputs create temporary files into "/opt/logstash/S3_temp/". If you want, you can change the path at the start of register method.
+# This files have a special name, for example:
+
+# ls.s3.ip-10-228-27-95.2013-04-18T10.00.tag_hello.part0.txt
+
+# ls.s3 : indicate logstash plugin s3
+
+# "ip-10-228-27-95" : indicate you ip machine, if you have more logstash and writing on the same bucket for example.
+# "2013-04-18T10.00" : represents the time whenever you specify time_file.
+# "tag_hello" : this indicate the event's tag, you can collect events with the same tag. 
+# "part0" : this means if you indicate size_file then it will generate more parts if you file.size > size_file. 
+#           When a file is full it will pushed on bucket and will be deleted in temporary directory. 
+#           If a file is empty is not pushed, but deleted.
+
+# This plugin have a system to restore the previous temporary files if something crash.
+
+##[Note] :
+
+## If you specify size_file and time_file then it will create file for each tag (if specified), when time_file or
+## their size > size_file, it will be triggered then they will be pushed on s3's bucket and will delete from local disk.
+
+## If you don't specify size_file, but time_file then it will create only one file for each tag (if specified). 
+## When time_file it will be triggered then the files will be pushed on s3's bucket and delete from local disk.
+
+## If you don't specify time_file, but size_file  then it will create files for each tag (if specified),
+## that will be triggered when their size > size_file, then they will be pushed on s3's bucket and will delete from local disk.
+
+## If you don't specific size_file and time_file you have a curios mode. It will create only one file for each tag (if specified).
+## Then the file will be rest on temporary directory and don't will be pushed on bucket until we will restart logstash.
+
+# INFORMATION ABOUT CLASS:
+
+# I tried to comment the class at best i could do. 
+# I think there are much thing to improve, but if you want some points to develop here a list:
+
+# TODO Integrate aws_config in the future 
+# TODO Find a method to push them all files when logtstash close the session.
+# TODO Integrate @field on the path file
+# TODO Permanent connection or on demand? For now on demand, but isn't a good implementation. 
+#      Use a while or a thread to try the connection before break a time_out and signal an error.
+# TODO If you have bugs report or helpful advice contact me, but remember that this code is much mine as much as yours, 
+#      try to work on it if you want :)
+
+# The programmer's question is:  "Why you fuck you use name ls.s3....  you kidding me, motherfucker? 
+# The answer is simple, s3 not allow special characters like "/" "[,]", very useful in date format, 
+# because if you use them s3 dosen't know no more the key and send you to hell!
+# For example "/" in s3 means you can specify a subfolder on bucket. 
+
+# USAGE:
+
+# This is an example of logstash config:
+
+# output {
+#    s3{ 
+#      access_key_id => "crazy_key"             (required)
+#      secret_access_key => "monkey_access_key" (required)
+#      endpoint_region => "eu-west-1"           (required)
+#      bucket => "boss_please_open_your_bucket" (required)         
+#      size_file => 2048                        (optional)
+#      time_file => 5                           (optional)
+#      format => "plain"                        (optional) 
+#    }
+# }
+
+# We analize this:
+
+# access_key_id => "crazy_key" 
+# Amazon will give you the key for use their service if you buy it or try it. (not very much open source anyway)
+
+# secret_access_key => "monkey_access_key"
+# Amazon will give you the secret_access_key for use their service if you buy it or try it . (not very much open source anyway).
+
+# endpoint_region => "eu-west-1" 
+# When you make a contract with Amazon, you should know where the services you use.
+
+# bucket => "boss_please_open_your_bucket" 
+# Be careful you have the permission to write on bucket and know the name.
+
+# size_file => 2048
+# Means the size, in KB, of files who can store on temporary directory before you will be pushed on bucket.
+# Is useful if you have a little server with poor space on disk and you don't want blow up the server with unnecessary temporary log files.
+
+# time_file => 5
+# Means, in minutes, the time  before the files will be pushed on bucket. Is useful if you want to push the files every specific time.
+ 
+# format => "plain"
+# Means the format of events you want to store in the files
+
+# LET'S ROCK AND ROLL ON THE CODE!
+
+class LogStash::Outputs::S3 < LogStash::Outputs::Base
+ #TODO integrate aws_config in the future 
+ #  include LogStash::PluginMixins::AwsConfig
+
+ config_name "s3"
+ plugin_status "experimental"
+
+ # Aws access_key.
+ config :access_key_id, :validate => :string
+ 
+ # Aws secret_access_key
+ config :secret_access_key, :validate => :string
+
+ # S3 bucket
+ config :bucket, :validate => :string
+
+ # Aws endpoint_region
+ config :endpoint_region, :validate => ["us_east_1", "us-west-1", "us-west-2",
+                                        "eu-west-1", "ap-southeast-1", "ap-southeast-2",
+                                        "ap-northeast-1", "sa-east-1", "us-gov-west-1"], :default => "us_east_1"
+ 
+ # Set the size of file in KB, this means that files on bucket when have dimension > file_size, they are stored in two or more file. 
+ # If you have tags then it will generate a specific size file for every tags
+ ##NOTE: define size of file is the better thing, because generate a local temporary file on disk and then put it in bucket. 
+ config :size_file, :validate => :number, :default => 0
+
+ # Set the time, in minutes, to close the current sub_time_section of bucket. 
+ # If you define file_size you have a number of files in consideration of the section and the current tag.
+ # 0 stay all time on listerner, beware if you specific 0 and size_file 0, because you will not put the file on bucket,
+ # for now the only thing this plugin can do is to put the file when logstash restart.
+ config :time_file, :validate => :number, :default => 0 
+ 
+ # The event format you want to store in files. Defaults to plain text.
+ config :format, :validate => [ "json", "plain", "nil" ], :default => "plain"
+
+ ## IMPORTANT: if you use multiple instance of s3, you should specify on one of them the "restore=> true" and on the others "restore => false".
+ ## This is hack for not destroy the new files after restoring the initial files. 
+ ## If you do not specify "restore => true" when logstash crashes or is restarted, the files are not sent into the bucket,
+ ## for example if you have single Instance. 
+ config :restore, :validate => :boolean, :default => false
+
+ # Method to set up the aws configuration and establish connection
+ def aws_s3_config
+  
+  @logger.debug "S3: waiting for establishing connection..."
+  AWS.config(
+    :access_key_id => @access_key_id,
+    :secret_access_key => @secret_access_key,
+    :s3_endpoint => 's3-'+@endpoint_region+'.amazonaws.com'
+  )
+  @s3 = AWS::S3.new 
+
+ end
+
+ # This method is used to manage sleep and awaken thread.
+ def time_alert(interval)
+
+   Thread.new do
+    loop do
+      start_time = Time.now
+      yield
+      elapsed = Time.now - start_time
+      sleep([interval - elapsed, 0].max)
+    end
+   end
+
+ end
+
+ # this method is used for write files on bucket. It accept the file and the name of file.
+ def write_on_bucket (file_data, file_basename)
+ 
+  # if you lose connection with s3, bad control implementation.
+  if ( @s3 == nil) 
+    aws_s3_config
+  end
+
+  # find and use the bucket
+  bucket = @s3.buckets[@bucket]
+
+  @logger.debug "S3: ready to write "+file_basename+" in bucket "+@bucket+", Fire in the hole!"
+
+  # prepare for write the file
+  object = bucket.objects[file_basename]
+  object.write(:file => file_data, :acl => :public_read)
+ 
+  @logger.debug "S3: has written "+file_basename+" in bucket "+@bucket
+
+ end
+  
+ # this method is used for create new path for name the file
+ def getFinalPath
+   
+   @pass_time = Time.now 
+   return @temp_directory+"ls.s3."+Socket.gethostname+"."+(@pass_time).strftime("%Y-%m-%dT%H.%M")
+
+ end
+
+ # This method is used for restore the previous crash of logstash or to prepare the files to send in bucket. 
+ # Take two parameter: flag and name. Flag indicate if you want to restore or not, name is the name of file 
+ def upFile(flag, name)
+   
+   Dir[@temp_directory+name].each do |file|
+     name_file = File.basename(file)
+    
+     if (flag == true)
+      @logger.warn "S3: have found temporary file: "+name_file+", something has crashed before... Prepare for upload in bucket!"
+     end
+    
+     if (!File.zero?(file))  
+       write_on_bucket(file, name_file)
+
+       if (flag == true)
+          @logger.debug "S3: file: "+name_file+" restored on bucket "+@bucket
+       else
+          @logger.debug "S3: file: "+name_file+" was put on bucket "+@bucket
+       end
+     end
+
+     @logger.debug "S3: let's destroying the temporary shit file "+name_file
+     File.delete (file)
+
+   end
+ end
+
+ # This method is used for create new empty temporary files for use. Flag is needed for indicate new subsection time_file.
+ def newFile (flag)
+  
+   if (flag == true)
+     @current_final_path = getFinalPath
+     @sizeCounter = 0
+   end
+
+   if (@tags.size != 0)
+     @tempFile = File.new(@current_final_path+".tag_"+@tag_path+"part"+@sizeCounter.to_s+".txt", "w")
+   else
+     @tempFile = File.new(@current_final_path+".part"+@sizeCounter.to_s+".txt", "w")
+   end
+
+ end
+
+ public
+ def register
+   @temp_directory = "/opt/logstash/S3_temp/"
+
+   if (@tags.size != 0)
+       @tag_path = ""
+       for i in (0..@tags.size-1)
+          @tag_path += @tags[i].to_s+"." 
+       end
+   end
+
+   if !(File.directory? @temp_directory)
+    @logger.debug "S3: Directory "+@temp_directory+" doesn't exist, let's make it!"
+    Dir.mkdir(@temp_directory)
+   else
+    @logger.debug "S3: Directory "+@temp_directory+" exist, nothing to do"
+   end 
+   
+   if (@restore == true )
+     @logger.debug "S3: is attempting to verify previous crashes..."
+   
+     upFile(true, "*.txt")    
+   end
+   
+   newFile(true)
+   
+   if (time_file != 0)
+      first_time = true
+      @thread = time_alert(@time_file*60) do
+       if (first_time == false)
+         @logger.debug "S3: time_file triggered,  let's bucket the file if dosen't empty  and create new file "
+         upFile(false, File.basename(@tempFile))
+         newFile(true)
+       else
+         first_time = false
+       end
+     end
+   end
+ 
+ end
+ 
+ public
+ def receive(event)
+  return unless output?(event)
+   
+  # Prepare format of Events 
+  if (@format == "plain")
+     message = self.class.format_message(event)
+  elsif (@format == "json")
+     message = event.to_json
+  else
+     message = event.to_s
+  end
+  
+  if(time_file !=0)
+     @logger.debug "S3: trigger files after "+((@pass_time+60*time_file)-Time.now).to_s
+  end
+
+  # if specific the size
+  if(size_file !=0)
+    
+    if (@tempFile.size < @size_file )
+
+       @logger.debug "S3: File have size: "+@tempFile.size.to_s+" and size_file is: "+ @size_file.to_s
+       @logger.debug "S3: put event into: "+File.basename(@tempFile)
+
+       # Put the event in the file, now! 
+       File.open(@tempFile, 'a') do |file|
+         file.puts message
+         file.write "\n"
+       end
+
+     else
+
+       @logger.debug "S3: file: "+File.basename(@tempFile)+" is too large, let's bucket it and create new file"
+       upFile(false, File.basename(@tempFile))
+       @sizeCounter += 1
+       newFile(false)
+
+     end
+     
+  # else we put all in one file 
+  else
+
+    @logger.debug "S3: put event into "+File.basename(@tempFile)
+    File.open(@tempFile, 'a') do |file|
+      file.puts message
+      file.write "\n"
+    end
+  end
+    
+ end
+
+ def self.format_message(event)
+    message = "Date: #{event.timestamp}\n"
+    message << "Source: #{event.source}\n"
+    message << "Tags: #{event.tags.join(', ')}\n"
+    message << "Fields: #{event.fields.inspect}\n"
+    message << "Message: #{event.message}"
+ end
+
+end
+
+# Enjoy it, by Bistic:)
