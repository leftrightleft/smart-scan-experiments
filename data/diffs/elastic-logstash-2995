diff --git a/docs/asciidoc/static/command-line-flags.asciidoc b/docs/asciidoc/static/command-line-flags.asciidoc
index aca23fad631..c3d6793860d 100644
--- a/docs/asciidoc/static/command-line-flags.asciidoc
+++ b/docs/asciidoc/static/command-line-flags.asciidoc
@@ -3,15 +3,20 @@
 [float]
 === Agent
 
-The Logstash agent has the following flags. (You can use the '--help' flag to display this information.)
+The Logstash agent has the following flags. (You can use the '--help' flag to
+display this information.)
 
 [source,js]
 ----------------------------------
 -f, --config CONFIGFILE
- Load the Logstash config from a specific file, directory, or a wildcard. If given a directory or wildcard, config files will be read from the directory in alphabetical order.
+ Load the Logstash config from a specific file, directory, or a wildcard. If
+ given a directory or wildcard, config files will be read from the directory in
+ alphabetical order.
 
 -e CONFIGSTRING
- Use the given string as the configuration data. Same syntax as the config file. If not input is specified, 'stdin { type => stdin }' is default. If no output is specified, 'stdout { codec => rubydebug }}' is default.
+ Use the given string as the configuration data. Same syntax as the config file.
+ If not input is specified, 'stdin { type => stdin }' is default. If no output
+ is specified, 'stdout { codec => rubydebug }}' is default.
 
 -w, --filterworkers COUNT
  Run COUNT filter workers (default: 1)
@@ -29,9 +34,21 @@ The Logstash agent has the following flags. (You can use the '--help' flag to di
  Increase verbosity to the last level, more verbose.
 
 -v
- *DEPRECATED: see --verbose/debug* Increase verbosity. There are multiple levels of verbosity available with
-'-vv' currently being the highest
+ *DEPRECATED: see --verbose/debug* Increase verbosity. There are multiple levels
+ of verbosity available with '-vv' currently being the highest
 
 --pluginpath PLUGIN_PATH
  A colon-delimited path to find other Logstash plugins in
 ----------------------------------
+
+[float]
+=== Web
+
+[source,js]
+----------------------------------
+-a, --address ADDRESS
+ Address on which to start webserver. Default is 0.0.0.0.
+
+-p, --port PORT
+ Port on which to start webserver. Default is 9292.
+----------------------------------
diff --git a/docs/asciidoc/static/contributing-to-logstash.asciidoc b/docs/asciidoc/static/contributing-to-logstash.asciidoc
index 99b25e7e09d..8f4cc11ae46 100644
--- a/docs/asciidoc/static/contributing-to-logstash.asciidoc
+++ b/docs/asciidoc/static/contributing-to-logstash.asciidoc
@@ -1,5 +1,4 @@
 [[contributing-to-logstash]]
-
 == Contributing to Logstash
 
 Before version 1.5, Logstash included all plugins in each release.  This made it
@@ -25,6 +24,8 @@ deploying your own plugins:
 
 We also welcome contributions and bug fixes to the Logstash core feature set.
 
-Please read through our https://github.com/elasticsearch/logstash/blob/master/CONTRIBUTING.md[contribution]
-guide, and the Logstash https://github.com/elasticsearch/logstash/blob/master/README.md[readme]
+Please read through our
+https://github.com/elastic/logstash/blob/master/CONTRIBUTING.md[contribution]
+guide, and the Logstash
+https://github.com/elastic/logstash/blob/master/README.md[readme]
 document.
diff --git a/docs/asciidoc/static/getting-started-with-logstash.asciidoc b/docs/asciidoc/static/getting-started-with-logstash.asciidoc
index a7fd2b62eb7..e7ca0deb73e 100644
--- a/docs/asciidoc/static/getting-started-with-logstash.asciidoc
+++ b/docs/asciidoc/static/getting-started-with-logstash.asciidoc
@@ -1,14 +1,16 @@
+[[getting-started-with-logstash]]
 == Getting Started with Logstash
 
-Logstash is a tool for receiving, processing and outputting logs. All kinds of logs. System logs, webserver logs, error logs, application logs, and just about anything you can throw at it. Sounds great, eh?
-
-Logstash provides a powerful pipeline for storing, querying, and analyzing your logs. When using Elasticsearch as a backend data store and Kibana as a frontend reporting tool, Logstash acts as the workhorse.  It includes an arsenal of built-in inputs, filters, codecs, and outputs, enabling you to harness some powerful functionality with a small amount of effort. So, let's get started!
-
 [float]
 ==== Prerequisite: Java
-A Java runtime is required to run Logstash. We recommend running the latest version of Java. At a minimum, you need Java 7. You can use the http://www.oracle.com/technetwork/java/javase/downloads/index.html[official Oracle distribution], or an open-source distribution such as http://openjdk.java.net/[OpenJDK].
+A Java runtime is required to run Logstash. We recommend running the latest
+version of Java. At a minimum, you need Java 7. You can use the
+http://www.oracle.com/technetwork/java/javase/downloads/index.html[official Oracle distribution],
+or an open-source distribution such as http://openjdk.java.net/[OpenJDK].
+
+You can verify that you have Java installed by running the  command
+`java -version` in your shell. Here's something similar to what you might see:
 
-You can verify that you have Java installed by running the  command `java -version` in your shell. Here's something similar to what you might see:
 [source,java]
 ----------------------------------
 > java -version
@@ -21,8 +23,7 @@ Once you have verified the existence of Java on your system, we can move on!
 
 [float]
 === Up and Running!
-
-To get started, download and extract the 'logstash' binary and run 
+To get started, download and extract the 'logstash' binary and run
 it with a very simple configuration.
 
 First, download the Logstash tar file.
@@ -31,7 +32,7 @@ First, download the Logstash tar file.
 ----------------------------------
 curl -O https://download.elasticsearch.org/logstash/logstash/logstash-{logstash_version}.tar.gz
 ----------------------------------
-Then, unpack 'logstash-{logstash_version}.tar.gz' on your local filesystem. 
+Then, unpack 'logstash-{logstash_version}.tar.gz' on your local filesystem.
 
 ["source","sh",subs="attributes,callouts"]
 ----------------------------------
@@ -44,7 +45,7 @@ cd logstash-{logstash_version}
 bin/logstash -e 'input { stdin { } } output { stdout {} }'
 ----------------------------------
 
-This simply takes input from stdin and outputs it to stdout.  
+This simply takes input from stdin and outputs it to stdout.
 Type something at the command prompt, and you will see it output by Logstash:
 [source,js]
 ----------------------------------
@@ -52,9 +53,16 @@ hello world
 2013-11-21T01:22:14.405+0000 0.0.0.0 hello world
 ----------------------------------
 
-OK, that's interesting... By running Logstash with the input called `stdin` and the output named `stdout`, Logstash echoes whatever you type in a structured format. The `-e` flag enables you to specify a configuration directly from the command line. This is especially useful for quickly testing configurations without having to edit a file between iterations.
+OK, that's interesting... By running Logstash with the input called `stdin` and
+the output named `stdout`, Logstash echoes whatever you type in a structured
+format. The `-e` flag enables you to specify a configuration directly from the
+command line. This is especially useful for quickly testing configurations
+without having to edit a file between iterations.
+
+Let's try a slightly fancier example. First, exit Logstash by issuing a `CTRL-C`
+command in the shell in which it is running. Then, start Logstash again with the
+following command:
 
-Let's try a slightly fancier example. First, exit Logstash by issuing a `CTRL-C` command in the shell in which it is running. Then, start Logstash again with the following command:
 [source,ruby]
 ----------------------------------
 bin/logstash -e 'input { stdin { } } output { stdout { codec => rubydebug } }'
@@ -72,11 +80,21 @@ goodnight moon
 }
 ----------------------------------
 
-Re-configuring the `stdout` output by adding a "codec" enables you to change what Logstash outputs. By adding inputs, outputs, and filters to your configuration, you can massage the log data and maximize the flexibility of the stored data when you query it.
+Re-configuring the `stdout` output by adding a "codec" enables you to change
+what Logstash outputs. By adding inputs, outputs, and filters to your
+configuration, you can massage the log data and maximize the flexibility of the
+stored data when you query it.
 
 [float]
 === Storing logs with Elasticsearch
-Now, you're probably saying, "that's all fine and dandy, but typing all my logs into Logstash isn't really an option, and merely seeing them spit to STDOUT isn't very useful." Good point. First, let's set up Elasticsearch to store the messages we send into Logstash. If you don't have Elasticearch already installed, you can http://www.elasticsearch.org/download/[download the RPM or DEB package], or install manually by downloading the current release tarball, by issuing the following four commands:
+Now, you're probably saying, "that's all fine and dandy, but typing all my logs
+into Logstash isn't really an option, and merely seeing them spit to STDOUT
+isn't very useful." Good point. First, let's set up Elasticsearch to store the
+messages we send into Logstash. If you don't have Elasticearch already
+installed, you can
+http://www.elastic.co/download/[download the RPM or DEB package], or install
+manually by downloading the current release tarball, by issuing the following
+four commands:
 
 ["source","sh",subs="attributes,callouts"]
 ----------------------------------
@@ -86,25 +104,37 @@ cd elasticsearch-{elasticsearch_version}/
 ./bin/elasticsearch
 ----------------------------------
 
-NOTE: This tutorial runs Logstash {logstash_version} with Elasticsearch {elasticsearch_version}, although you can use it with a cluster running 1.0.0 or later. Each release of Logstash has a *recommended* version of Elasticsearch you should use. Make sure they match based on the http://www.elasticsearch.org/overview/logstash[Logstash version] you're running!
+NOTE: This tutorial runs Logstash {logstash_version} with Elasticsearch
+{elasticsearch_version}, although you can use it with a cluster running 1.0.0 or
+later. Each release of Logstash has a *recommended* version of Elasticsearch you
+should use. Make sure they match based on the
+http://www.elastic.co/overview/logstash[Logstash version] you're running!
 
-You can get started with Logstash using the default Elasticsearch installation and configuration. See the http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index.html[Elasticsearch Reference] for more  information about installing and running Elasticsearch. 
+You can get started with Logstash using the default Elasticsearch installation
+and configuration. See the
+http://www.elastic.co/guide/en/elasticsearch/reference/current/index.html[Elasticsearch Reference]
+for more  information about installing and running Elasticsearch.
 
-Now that you have Elasticsearch running on port 9200 (you do, right?), you can easily configure Logstash to use Elasticsearch as its backend. The defaults for both Logstash and Elasticsearch are fairly sane and well thought out, so you can omit the optional configurations within the elasticsearch output:
+Now that you have Elasticsearch running on port 9200 (you do, right?), you can
+easily configure Logstash to use Elasticsearch as its backend. The defaults for
+both Logstash and Elasticsearch are fairly sane and well thought out, so you can
+omit the optional configurations within the elasticsearch output:
 
 [source,js]
 ----------------------------------
 bin/logstash -e 'input { stdin { } } output { elasticsearch { host => localhost } }'
 ----------------------------------
 
-Type something and Logstash processes it as before. However, this time you won't see any output, since the stdout output isn't configured.
+Type something and Logstash processes it as before. However, this time you won't
+see any output, since the stdout output isn't configured.
 
 [source,js]
 ----------------------------------
 you know, for logs
 ----------------------------------
 
-You can confirm that Elasticsearch actually received the data by submitting a curl request:
+You can confirm that Elasticsearch actually received the data by submitting a
+curl request:
 
 [source,js]
 ----------------------------------
@@ -129,7 +159,7 @@ This should return something like the following:
     "hits" : [ {
       "_index" : "logstash-2013.11.21",
       "_type" : "logs",
-      "_id" : "2ijaoKqARqGvbMgP3BspJA",
+      "_id" : "2ijaoKqARGHvbMgP3BspJB",
       "_score" : 1.0, "_source" : {"message":"you know, for logs","@timestamp":"2013-11-21T18:45:09.862Z","@version":"1","host":"my-laptop"}
     } ]
   }
@@ -140,29 +170,53 @@ Congratulations! You've successfully stashed logs in Elasticsearch via Logstash.
 
 [float]
 ==== Elasticsearch Plugins (an aside)
-Another very useful tool for querying your Logstash data (and Elasticsearch in general) is the Elasticearch-kopf plugin. (For more information about Elasticsearch plugins, see http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/modules-plugins.html[Elasticsearch plugins].) To install elasticsearch-kopf,  issue the following command from your Elasticsearch directory (the same one from which you started Elasticsearch):
+Another very useful tool for querying your Logstash data (and Elasticsearch in
+general) is the Elasticearch-kopf plugin. (For more information about
+Elasticsearch plugins, see
+http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-plugins.html[Elasticsearch plugins].)
+To install elasticsearch-kopf,  issue the following command from your
+Elasticsearch directory (the same one from which you started Elasticsearch):
 
 [source,js]
 ----------------------------------
 bin/plugin -install lmenezes/elasticsearch-kopf
 ----------------------------------
-Now you can go to http://localhost:9200/_plugin/kopf/[http://localhost:9200/_plugin/kopf/] to browse your Elasticsearch data, settings, and mappings!
+Now you can go to
+http://localhost:9200/_plugin/kopf/[http://localhost:9200/_plugin/kopf/]
+to browse your Elasticsearch data, settings, and mappings!
 
 [float]
 ==== Multiple Outputs
-As a quick exercise in configuring multiple Logstash outputs, let's invoke Logstash again, using both  'stdout' and 'elasticsearch' as outputs:
+
+As a quick exercise in configuring multiple Logstash outputs, let's invoke
+Logstash again, using both  'stdout' and 'elasticsearch' as outputs:
 
 [source,js]
 ----------------------------------
 bin/logstash -e 'input { stdin { } } output { elasticsearch { host => localhost } stdout { } }'
 ----------------------------------
-Now when you enter a phrase, it is echoed to the terminal and saved in Elasticsearch! (You can verify this using curl or elasticsearch-kopf).
+Now when you enter a phrase, it is echoed to the terminal and saved in
+Elasticsearch! (You can verify this using curl or elasticsearch-kopf).
 
 [float]
 ==== Default - Daily Indices
-You might have noticed that Logstash is smart enough to create a new index in Elasticsearch. The default index name is in the form of `logstash-YYYY.MM.DD`, which essentially creates one index per day. At midnight (UTC), Logstash automagically rotates the index to a fresh one, with the new current day's timestamp. This allows you to keep windows of data, based on how far retroactively you'd like to query your log data. Of course, you can always archive (or re-index) your data to an alternate location so you can query further into the past. If you want to delete old indices after a certain time period, you can use the https://github.com/elasticsearch/curator[Elasticsearch Curator tool].
+You might have noticed that Logstash is smart enough to create a new index in
+Elasticsearch. The default index name is in the form of `logstash-YYYY.MM.DD`,
+which essentially creates one index per day. At midnight (UTC), Logstash
+automagically rotates the index to a fresh one, with the new current day's
+timestamp. This allows you to keep windows of data, based on how far
+retroactively you'd like to query your log data. Of course, you can always
+archive (or re-index) your data to an alternate location so you can query
+further into the past. If you want to delete old indices after a certain time
+period, you can use the
+http://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html[Elasticsearch Curator tool].
 
 [float]
 === Moving On
-Configuring inputs and outputs from the command line is convenient for getting started and doing quick testing. To move beyond
-these simple examples, however, you need to know a bit more about the Logstash event processing pipeline and how to specify pipeline options in a config file. To learn about the event processing pipeline, see <<pipeline,Logstash Processing Pipeline>>. To see how to configure more complex pipelines using config files, see <<configuration, Configuring Logstash>>.
+Configuring inputs and outputs from the command line is convenient for getting
+started and doing quick testing. To move beyond these simple examples, however,
+you need to know a bit more about the Logstash event processing pipeline and how
+to specify pipeline options in a config file. To learn about the event
+processing pipeline, see <<pipeline,Logstash Processing Pipeline>>. To see how
+to configure more complex pipelines using config files, see
+<<configuration, Configuring Logstash>>.
diff --git a/docs/asciidoc/static/include/pluginbody.asciidoc b/docs/asciidoc/static/include/pluginbody.asciidoc
index 9b3a0b7cbcc..3b948fcff99 100644
--- a/docs/asciidoc/static/include/pluginbody.asciidoc
+++ b/docs/asciidoc/static/include/pluginbody.asciidoc
@@ -1,6 +1,3 @@
-:branch:          1.5
-:ls_version:		  1.5.0.beta1
-
 == How to write a Logstash {plugintype} plugin
 
 To develop a new {plugintype} for Logstash, you build a self-contained Ruby gem
@@ -1023,9 +1020,9 @@ http://www.elasticsearch.org/overview/logstash/download/[Logstash downloads page
 [source,sh]
 [subs="attributes"]
 ----------------------------------
-curl -O http://download.elasticsearch.org/logstash/logstash/logstash-{ls_version}.tar.gz
-tar xzvf logstash-{ls_version}.tar.gz
-cd logstash-{ls_version}
+curl -O http://download.elasticsearch.org/logstash/logstash/logstash-{logstash_version}.tar.gz
+tar xzvf logstash-{logstash_version}.tar.gz
+cd logstash-{logstash_version}
 ----------------------------------
 . Using the plugin tool, we can install the gem we just built.
 +
diff --git a/docs/asciidoc/static/life-of-an-event.asciidoc b/docs/asciidoc/static/life-of-an-event.asciidoc
index a5d683b3bb6..4d25295ecdc 100644
--- a/docs/asciidoc/static/life-of-an-event.asciidoc
+++ b/docs/asciidoc/static/life-of-an-event.asciidoc
@@ -1,69 +1,123 @@
 [[pipeline]]
 == Logstash Processing Pipeline
 
-The Logstash event processing pipeline has three stages: inputs -> filters -> outputs. Inputs generate events, filters modify them, and outputs ship them elsewhere. Inputs and outputs support codecs that enable you to encode or decode the data as it enters or exits the pipeline without having to use a separate filter.
+The Logstash event processing pipeline has three stages: inputs -> filters ->
+outputs. Inputs generate events, filters modify them, and outputs ship them
+elsewhere. Inputs and outputs support codecs that enable you to encode or decode
+the data as it enters or exits the pipeline without having to use a separate
+filter.
 
 [float]
 ==== Inputs
-You use inputs to get data into Logstash. Some of the more commonly-used inputs are:
-
-* *file*: reads from a file on the filesystem, much like the UNIX command `tail -0a`
-* *syslog*: listens on the well-known port 514 for syslog messages and parses according to the RFC3164 format
-* *redis*: reads from a redis server, using both redis channels and redis lists. Redis is often used as a "broker" in a centralized Logstash installation, which queues Logstash events from remote Logstash "shippers".
-* *lumberjack*: processes events sent in the lumberjack protocol. Now called https://github.com/elasticsearch/logstash-forwarder[logstash-forwarder].
-
-For more information about the available inputs, see <<input-plugins,Input Plugins>>.
+You use inputs to get data into Logstash. Some of the more commonly-used inputs
+are:
+
+* *file*: reads from a file on the filesystem, much like the UNIX command
+`tail -0a`
+* *syslog*: listens on the well-known port 514 for syslog messages and parses
+according to the RFC3164 format
+* *redis*: reads from a redis server, using both redis channels and redis lists.
+Redis is often used as a "broker" in a centralized Logstash installation, which
+queues Logstash events from remote Logstash "shippers".
+* *lumberjack*: processes events sent in the lumberjack protocol. Now called
+https://github.com/elastic/logstash-forwarder[logstash-forwarder].
+
+For more information about the available inputs, see
+<<input-plugins,Input Plugins>>.
 
 [float]
 ==== Filters
-Filters are intermediary processing devices in the Logstash pipeline. You can combine filters with conditionals to perform an action on an event if it meets certain criteria. Some useful filters include:
-
-* *grok*: parse and structure arbitrary text. Grok is currently the best way in Logstash to parse unstructured log data into something structured and queryable. With 120 patterns built-in to Logstash, it's more than likely you'll find one that meets your needs!
-* *mutate*: perform general transformations on event fields. You can rename, remove, replace, and modify fields in your events.
+Filters are intermediary processing devices in the Logstash pipeline. You can
+combine filters with conditionals to perform an action on an event if it meets
+certain criteria. Some useful filters include:
+
+* *grok*: parse and structure arbitrary text. Grok is currently the best way in
+Logstash to parse unstructured log data into something structured and queryable.
+With 120 patterns built-in to Logstash, it's more than likely you'll find one
+that meets your needs!
+* *mutate*: perform general transformations on event fields. You can rename,
+remove, replace, and modify fields in your events.
 * *drop*: drop an event completely, for example, 'debug' events.
 * *clone*: make a copy of an event, possibly adding or removing fields.
-* *geoip*: add information about geographical location of IP addresses (also displays amazing charts in Kibana!)
+* *geoip*: add information about geographical location of IP addresses (also
+displays amazing charts in Kibana!)
 
-For more information about the available filters, see <<filter-plugins,Filter Plugins>>.
+For more information about the available filters, see
+<<filter-plugins,Filter Plugins>>.
 
 [float]
 ==== Outputs
-Outputs are the final phase of the Logstash pipeline. An event can pass through multiple outputs, but once all output processing is complete, the event has finished its execution. Some commonly used outputs include:
+Outputs are the final phase of the Logstash pipeline. An event can pass through
+multiple outputs, but once all output processing is complete, the event has
+finished its execution. Some commonly used outputs include:
 
-* *elasticsearch*: send event data to Elasticsearch. If you're planning to save your data in an efficient, convenient, and easily queryable format... Elasticsearch is the way to go. Period. Yes, we're biased :)
+* *elasticsearch*: send event data to Elasticsearch. If you're planning to save
+your data in an efficient, convenient, and easily queryable format...
+Elasticsearch is the way to go. Period. Yes, we're biased :)
 * *file*: write event data to a file on disk.
-* *graphite*: send event data to graphite, a popular open source tool for storing and graphing metrics. http://graphite.wikidot.com/
-* *statsd*: send event data to statsd, a service that "listens for statistics, like counters and timers, sent over UDP and sends aggregates to one or more pluggable backend services". If you're already using statsd, this could be useful for you!
+* *graphite*: send event data to graphite, a popular open source tool for
+storing and graphing metrics. http://graphite.wikidot.com/
+* *statsd*: send event data to statsd, a service that "listens for statistics,
+like counters and timers, sent over UDP and sends aggregates to one or more
+pluggable backend services". If you're already using statsd, this could be
+useful for you!
 
-For more information about the available outputs, see <<output-plugins,Output Plugins>>.
+For more information about the available outputs, see
+<<output-plugins,Output Plugins>>.
 
 [float]
 ==== Codecs
-Codecs are basically stream filters that can operate as part of an input or output. Codecs enable you to easily separate the transport of your messages from the serialization process. Popular codecs include `json`, `msgpack`, and `plain` (text).
+Codecs are basically stream filters that can operate as part of an input or
+output. Codecs enable you to easily separate the transport of your messages from
+the serialization process. Popular codecs include `json`, `msgpack`, and `plain`
+(text).
 
 * *json*: encode or decode data in the JSON format.
-* *multiline*: merge multiple-line text events such as java exception and stacktrace messages into a single event.  
+* *multiline*: merge multiple-line text events such as java exception and
+stacktrace messages into a single event.
 
-For more information about the available codecs, see <<codec-plugins,Codec Plugins>>.
+For more information about the available codecs, see
+<<codec-plugins,Codec Plugins>>.
 
 [float]
 === Fault Tolerance
 
-Events are passed from stage to stage using internal queues implemented with a Ruby `SizedQueue`. A `SizedQueue` has a maximum number of items it can contain.  When the queue is at maximum capacity, all writes to the queue are blocked.
+Events are passed from stage to stage using internal queues implemented with a
+Ruby `SizedQueue`. A `SizedQueue` has a maximum number of items it can contain.
+When the queue is at maximum capacity, all writes to the queue are blocked.
 
-Logstash sets the size of each queue to 20. This means a maximum of 20 events can be pending for the next stage, which helps prevent data loss and keeps Logstash from acting as a data storage system. These internal queues are not intended for storing messages long-term.
+Logstash sets the size of each queue to 20. This means a maximum of 20 events
+can be pending for the next stage, which helps prevent data loss and keeps
+Logstash from acting as a data storage system. These internal queues are not
+intended for storing messages long-term.
 
-The small queue sizes mean that Logstash simply blocks and stalls safely when there's a heavy load or temporary pipeline problems. The alternatives would be to either have an unlimited queue or drop messages when there's a problem. An unlimited queue can grow unbounded and eventually exceed memory, causing a crash that loses all of the queued messages. In most cases, dropping messages outright is equally undesirable.
+The small queue sizes mean that Logstash simply blocks and stalls safely when
+there's a heavy load or temporary pipeline problems. The alternatives would be
+to either have an unlimited queue or drop messages when there's a problem. An
+unlimited queue can grow unbounded and eventually exceed memory, causing a crash
+that loses all of the queued messages. In most cases, dropping messages outright
+is equally undesirable.
 
-An output can fail or have problems due to downstream issues, such as a full disk, permissions problems, temporary network failures, or service outages. Most outputs keep retrying to ship events affected by the failure.
+An output can fail or have problems due to downstream issues, such as a full
+disk, permissions problems, temporary network failures, or service outages. Most
+outputs keep retrying to ship events affected by the failure.
 
-If an output is failing, the output thread waits until the output is able to successfully send the message. The output stops reading from the output queue, which means the queue can fill up with events. 
+If an output is failing, the output thread waits until the output is able to
+successfully send the message. The output stops reading from the output queue,
+which means the queue can fill up with events.
 
-When the output queue is full, filters are blocked because they cannot write new events to the output queue. While they are blocked from writing to the output queue, filters stop reading from the filter queue. Eventually, this can cause the filter queue (input -> filter) to fill up.
+When the output queue is full, filters are blocked because they cannot write new
+events to the output queue. While they are blocked from writing to the output
+queue, filters stop reading from the filter queue. Eventually, this can cause
+the filter queue (input -> filter) to fill up.
 
-A full filter queue blocks inputs from writing to the filters. This causes all inputs to stop processing data from wherever they're getting new events.
+A full filter queue blocks inputs from writing to the filters. This causes all
+inputs to stop processing data from wherever they're getting new events.
 
-In ideal circumstances, this behaves similarly to when the tcp window closes to 0. No new data is sent because the receiver hasn't finished processing the current queue of data, but as soon as the downstream (output) problem is resolved, messages start flowing again.
+In ideal circumstances, this behaves similarly to when the tcp window closes to
+0. No new data is sent because the receiver hasn't finished processing the
+current queue of data, but as soon as the downstream (output) problem is
+resolved, messages start flowing again.
 
 [float]
 === Thread Model
@@ -82,20 +136,41 @@ Filters are optional, so if you have no filters defined it is simply:
 input threads | output worker
 ----------------------------------
 
-Each input runs in a thread by itself. This prevents busier inputs from being blocked by slower ones. It also allows for easier containment of scope because each input has a thread.
+Each input runs in a thread by itself. This prevents busier inputs from being
+blocked by slower ones. It also allows for easier containment of scope because
+each input has a thread.
 
-The filter thread model is a 'worker' model where each worker receives an event and applies all filters, in order, before sending it on to the output queue. This allows scalability across CPUs because many filters are CPU intensive (permitting that we have thread safety). 
+The filter thread model is a 'worker' model where each worker receives an event
+and applies all filters, in order, before sending it on to the output queue.
+This allows scalability across CPUs because many filters are CPU intensive
+(permitting that we have thread safety).
 
-The default number of filter workers is 1, but you can increase this number by specifying the '-w' flag when you run the Logstash agent.
+The default number of filter workers is 1, but you can increase this number by
+specifying the '-w' flag when you run the Logstash agent.
 
-The output worker model is currently a single thread. Outputs receive events in the order the outputs are defined in the config file. 
+The output worker model is currently a single thread. Outputs receive events in
+the order the outputs are defined in the config file.
 
-Outputs might decide to temporarily buffer events before publishing them. One example of this is the `elasticsearch` output, which buffers events and flushes them all at once using a separate thread. This mechanism (buffering many events and writing in a separate thread) can improve performance because it prevents the Logstash pipeline from being stalled waiting for a response from elasticsearch.
+Outputs might decide to temporarily buffer events before publishing them. One
+example of this is the `elasticsearch` output, which buffers events and flushes
+them all at once using a separate thread. This mechanism (buffering many events
+and writing in a separate thread) can improve performance because it prevents
+the Logstash pipeline from being stalled waiting for a response from
+elasticsearch.
 
 [float]
 === Resource Usage
 
-Logstash typically has at least 3 threads (2 if you have no filters). One input thread, one filter worker thread, and one output thread. If you see Logstash using multiple CPUs, this is likely why. If you want to know more about what each thread is doing, you should read this article: http://www.semicomplete.com/blog/geekery/debugging-java-performance.html[Debugging Java Performance]. Threads in Java have names and you can use `jstack` and `top` to figure out who is using what resources. 
-
-On Linux platforms, Logstash labels all the threads it can with something descriptive. For example, inputs show up as `<inputname`, filter workers show up as `|worker`, and outputs show up as `>outputworker`.  Where possible, other threads are also labeled to help you identify their purpose should you wonder why they are consuming resources!
-
+Logstash typically has at least 3 threads (2 if you have no filters). One input
+thread, one filter worker thread, and one output thread. If you see Logstash
+using multiple CPUs, this is likely why. If you want to know more about what
+each thread is doing, you should read this article:
+http://www.semicomplete.com/blog/geekery/debugging-java-performance.html[Debugging Java Performance].
+Threads in Java have names and you can use `jstack` and `top` to figure out who
+is using what resources.
+
+On Linux platforms, Logstash labels all the threads it can with something
+descriptive. For example, inputs show up as `<inputname`, filter workers show up
+as `|worker`, and outputs show up as `>outputworker`.  Where possible, other
+threads are also labeled to help you identify their purpose should you wonder
+why they are consuming resources!
diff --git a/docs/asciidoc/static/roadmap/index.asciidoc b/docs/asciidoc/static/roadmap/index.asciidoc
index 88d8c4c09dd..c94cba77b92 100644
--- a/docs/asciidoc/static/roadmap/index.asciidoc
+++ b/docs/asciidoc/static/roadmap/index.asciidoc
@@ -1,81 +1,219 @@
 = Logstash Roadmap
 
-:ISSUES:  https://github.com/elasticsearch/logstash/issues/
-:LABELS:  https://github.com/elasticsearch/logstash/labels/
+:ISSUES:  https://github.com/elastic/logstash/issues/
+:LABELS:  https://github.com/elastic/logstash/labels/
 
 == Overview
 
-Welcome to the Logstash roadmap page! 
+Welcome to the Logstash roadmap page!
 
-While GitHub is great for sharing our work, it can be difficult to get an overview of the current state of affairs from an issues list. This page outlines major themes for our future plans, with pointers to additional resources if you want to contribute to the Logstash project.
+While GitHub is great for sharing our work, it can be difficult to get an
+overview of the current state of affairs from an issues list. This page outlines
+major themes for our future plans, with pointers to additional resources if you
+want to contribute to the Logstash project.
 
-We will not track concrete milestones on this page, because we often make adjustments to our timelines based on community feedback. For the latest release status information, please search for the {LABELS}roadmap[roadmap] tag in GitHub. 
+We will not track concrete milestones on this page, because we often make
+adjustments to our timelines based on community feedback. For the latest release
+status information, please search for the {LABELS}roadmap[roadmap] tag in
+GitHub.
 
 == Logstash 1.5-GA status
 
-We recently released http://www.elasticsearch.org/blog/logstash-1-5-0-beta1-released/[Logstash 1.5 beta1], http://www.elasticsearch.org/blog/announcing-logstash-1-5-0-release-candidate/[Logstash 1.5 RC1], and http://www.elasticsearch.org/blog/logstash-1-5-0-rc2-released/[Logstash 1.5 RC2]! The main themes of this release are improved plugin management, increased performance, and Apache Kafka integration (see more details in the Logstash 1.5 beta1 announcement). We are currently working to incorporate community feedback and to release Logstash 1.5 GA. You can track our progress on GitHub by looking at issues with the milestone https://github.com/elasticsearch/logstash/issues?q=is%3Aopen+is%3Aissue+milestone%3Av1.5.0[v1.5.0]. 
-
-== Plugin Framework 
+We recently released
+http://www.elasticsearch.org/blog/logstash-1-5-0-beta1-released/[Logstash 1.5 beta1],
+http://www.elasticsearch.org/blog/announcing-logstash-1-5-0-release-candidate/[Logstash 1.5 RC1],
+and http://www.elasticsearch.org/blog/logstash-1-5-0-rc2-released/[Logstash 1.5 RC2]!
+The main themes of this release are improved plugin management, increased
+performance, and Apache Kafka integration (see more details in the Logstash 1.5
+beta1 announcement). We are currently working to incorporate community feedback
+and to release Logstash 1.5 GA. You can track our progress on GitHub by looking
+at issues with the milestone
+https://github.com/elastic/logstash/issues?q=is%3Aopen+is%3Aissue+milestone%3Av1.5.0[v1.5.0].
+
+== Plugin Framework
 [float]
 === status: ongoing; v1.5
 
-Logstash has a rich collection of 165+ plugins, which are developed by Elasticsearch and contributed by the community. Previously, most commonly-used plugins were bundled with Logstash to make the getting started experience easier. However, there was no way to update plugins outside of the Logstash release cycle. In Logstash 1.5, we created a powerful plugin framework based on https://rubygems.org/[RubyGems.org] to facilitate per-plugin installation and updates. We will continue to distribute commonly-used plugins with Logstash, but now users will be able to install new plugins and receive plugin updates at any time. Read more about these changes in the http://www.elasticsearch.org/blog/plugin-ecosystem-changes/[Logstash Plugin Ecosystem Changes] announcement.
+Logstash has a rich collection of 165+ plugins, which are developed by
+Elasticsearch and contributed by the community. Previously, most commonly-used
+plugins were bundled with Logstash to make the getting started experience
+easier. However, there was no way to update plugins outside of the Logstash
+release cycle. In Logstash 1.5, we created a powerful plugin framework based on
+https://rubygems.org/[RubyGems.org] to facilitate per-plugin installation and
+updates. We will continue to distribute commonly-used plugins with Logstash, but
+now users will be able to install new plugins and receive plugin updates at any
+time. Read more about these changes in the
+http://www.elastic.co/blog/plugin-ecosystem-changes/[Logstash Plugin Ecosystem Changes]
+announcement.
 
 == Windows Support
 [float]
 === status: ongoing; v1.5, v2.x
 
-Leading up to the 1.5 release, we greatly improved automated Windows testing of Logstash. As a result of this testing, we identified and https://github.com/elasticsearch/logstash/issues?q=is%3Aissue+label%3Awindows+is%3Aclosed[resolved] a number of critical issues affecting the Windows platform, pertaining to initial setup, upgrade, and file input plugin. You can follow the outstanding issues we are still working on using the GitHub https://github.com/elasticsearch/logstash/issues?q=is%3Aissue+label%3Awindows+is%3Aopen[windows] label.
+Leading up to the 1.5 release, we greatly improved automated Windows testing of
+Logstash. As a result of this testing, we identified and
+https://github.com/elastic/logstash/issues?q=is%3Aissue+label%3Awindows+is%3Aclosed[resolved]
+a number of critical issues affecting the Windows platform, pertaining to
+initial setup, upgrade, and file input plugin. You can follow the outstanding
+issues we are still working on using the GitHub
+https://github.com/elastic/logstash/issues?q=is%3Aissue+label%3Awindows+is%3Aopen[windows]
+label.
 
 
 == Performance
 [float]
 === status: ongoing; v1.5, v2.x
 
-In the 1.5 release, we significantly improved the performance of the Grok filter, which is used to parse text via regular expressions. Based on our internal benchmarks, parsing common log formats, such as Apache logs, was 2x faster in Logstash 1.5 compared to previous versions. We also sped up JSON serialization and deserialization. In future releases of Logstash, we plan to incorporate additional JRuby optimizations to make the code even more efficient. We also plan to seek community feedback in terms of prioritizing other aspects of performance, such as startup time, resource utilization, and pipeline latency. 
+In the 1.5 release, we significantly improved the performance of the Grok
+filter, which is used to parse text via regular expressions. Based on our
+internal benchmarks, parsing common log formats, such as Apache logs, was 2x
+faster in Logstash 1.5 compared to previous versions. We also sped up JSON
+serialization and deserialization. In future releases of Logstash, we plan to
+incorporate additional JRuby optimizations to make the code even more efficient.
+We also plan to seek community feedback in terms of prioritizing other aspects
+of performance, such as startup time, resource utilization, and pipeline
+latency.
 
 == Resiliency
 [float]
 === status: ongoing; v2.x
 
-The Logstash team is committed to continuously improving the resiliency of Logstash. As with any modular system, Logstash has many moving parts and a multitude of deployment architectures, all of which need to be considered in the context of resiliency. Our resiliency project is an ongoing effort to identify and enhance areas where Logstash can provide additional resiliency guarantees. You can follow this effort on GitHub by searching for issues that have the {LABELS}resiliency[resiliency] tag.
-
-*Event persistence ({ISSUES}2605[#2605]).* Logstash relies on bounded in-memory queues between pipeline stages to buffer events (see the http://www.elasticsearch.org/guide/en/logstash/current/pipeline.html#_fault_tolerance[documentation] for more information). Currently, these queues are not persisted to disk. To prevent loss in the event of a plugin crash or a restart, we plan to persist these queues to disk.
-
-*Variable internal queues ({ISSUES}2606[#2606]).* Logstash currently uses fixed-sized queues between pipeline stages. When the processing rates differ widely between stages (such as parsing and indexing), users typically deploy a message broker, such as Redis or RabbitMQ, to provide an external queueing mechanism. We plan to offer a built-in alternative to using an external message broker by adding a variable queueing option to Logstash. 
-
-*Dead letter queue (https://github.com/elasticsearch/logstash/issues/2607[#2607]).* Today, when Logstash cannot process an event due to an error, it has two choices: drop or retry. If the condition is temporary (for example,  the next stage in the pipeline is temporarily overloaded), retry is a good approach. However, if the failure is permanent (such as  bad encoding or a mapping error) retrying could cause an indefinite stall in processing. In this case, dropping the event is preferred. As a third option, we plan to introduce a dead letter queue (DLQ), which will store events that could stall the pipeline. Users can then examine these events and resolve problems as needed. The DLQ could also receive events that abuse the grok filter (e.g. runaway regular expressions which cause expensive backtracking), failures in grok patterns, date filters, and so on.
-
-*End-to-end acknowledgement of message delivery ({ISSUES}2609[#2609]).* Logstash currently does not provide end-to-end delivery guarantees. When a plugin fails to process an event, it does not signal to an earlier stage in the pipeline that an error has occurred. In the longer term, we plan to introduce an optional notification mechanism to give operators an easier way to track and replay failed events. 
-
-*Known issues affecting resiliency.* There are certain categories of defects that affect resiliency, such as plugin crashes, failures in retry logic, and exhausting system resources. We respond to critical bug requests in real-time and perform weekly triaging of less urgent requests. All known issues are flagged with the https://github.com/elasticsearch/logstash/labels/resiliency[resiliency] tag.
-
-*Known unknowns.* If we don’t know it’s happening, it’s hard for us to fix it! Please report your issues in GitHub, under the https://github.com/elasticsearch/logstash/issues[Logstash], https://github.com/elasticsearch/logstash-forwarder/issues[Logstash Forwarder], or individual https://github.com/logstash-plugins/[Logstash plugin] repositories. 
+The Logstash team is committed to continuously improving the resiliency of
+Logstash. As with any modular system, Logstash has many moving parts and a
+multitude of deployment architectures, all of which need to be considered in the
+context of resiliency. Our resiliency project is an ongoing effort to identify
+and enhance areas where Logstash can provide additional resiliency guarantees.
+You can follow this effort on GitHub by searching for issues that have the
+{LABELS}resiliency[resiliency] tag.
+
+*Event persistence ({ISSUES}2605[#2605]).* Logstash relies on bounded in-memory
+queues between pipeline stages to buffer events (see the
+http://www.elastic.co/guide/en/logstash/current/pipeline.html#_fault_tolerance[documentation]
+for more information). Currently, these queues are not persisted to disk.
+To prevent loss in the event of a plugin crash or a restart, we plan to persist
+these queues to disk.
+
+*Variable internal queues ({ISSUES}2606[#2606]).* Logstash currently uses
+fixed-sized queues between pipeline stages. When the processing rates differ
+widely between stages (such as parsing and indexing), users typically deploy a
+message broker, such as Redis or RabbitMQ, to provide an external queueing
+mechanism. We plan to offer a built-in alternative to using an external message
+broker by adding a variable queueing option to Logstash.
+
+*Dead letter queue (https://github.com/elastic/logstash/issues/2607[#2607]).*
+Today, when Logstash cannot process an event due to an error, it has two
+choices: drop or retry. If the condition is temporary (for example,  the next
+stage in the pipeline is temporarily overloaded), retry is a good approach.
+However, if the failure is permanent (such as  bad encoding or a mapping error)
+retrying could cause an indefinite stall in processing. In this case, dropping
+the event is preferred. As a third option, we plan to introduce a dead letter
+queue (DLQ), which will store events that could stall the pipeline. Users can
+then examine these events and resolve problems as needed. The DLQ could also
+receive events that abuse the grok filter (e.g. runaway regular expressions
+which cause expensive backtracking), failures in grok patterns, date filters,
+and so on.
+
+*End-to-end acknowledgement of message delivery ({ISSUES}2609[#2609]).* Logstash
+currently does not provide end-to-end delivery guarantees. When a plugin fails
+to process an event, it does not signal to an earlier stage in the pipeline that
+an error has occurred. In the longer term, we plan to introduce an optional
+notification mechanism to give operators an easier way to track and replay
+failed events.
+
+*Known issues affecting resiliency.* There are certain categories of defects
+that affect resiliency, such as plugin crashes, failures in retry logic, and
+exhausting system resources. We respond to critical bug requests in real-time
+and perform weekly triaging of less urgent requests. All known issues are
+flagged with the
+https://github.com/elastic/logstash/labels/resiliency[resiliency] tag.
+
+*Known unknowns.* If we don’t know it’s happening, it’s hard for us to fix it!
+Please report your issues in GitHub, under the
+https://github.com/elastic/logstash/issues[Logstash],
+https://github.com/elastic/logstash-forwarder/issues[Logstash Forwarder], or
+individual https://github.com/logstash-plugins/[Logstash plugin] repositories.
 
 == Manageability
 [float]
 === status: ongoing; v2.x
 
-As Logstash deployments scale up, managing and monitoring multiple Logstash instances using configuration and log files can become challenging. Our manageability project aims to improve this experience by adding functionality that makes administration of Logstash more efficient and less error-prone. You can follow this effort on GitHub by searching for issues that have the {LABELS}manageability[manageability] tag.
-
-*Logstash Monitoring API ({ISSUES}2611[#2611]).* Today, most Logstash monitoring functions are accomplished by tailing logs or outputting debug messages. As a result, it is hard to monitor the Logstash health and track success or failure of events passing through the pipeline. We plan to introduce a Logstash monitoring API to improve visibility into pipeline activity and provide performance metrics such as number of events processed, success/failure rates, and time spent in each plugin.
-
-*Logstash Management API ({ISSUES}2612[#2612]).* Currently, updating the Logstash configuration requires editing a configuration file and restarting the Logstash process. This means you either have to temporarily halt the pipeline or accept an interruption in processing. While file-based configuration management will continue to be supported, we plan to add a robust Logstash management API that enables you to update the configuration dynamically without restarting the Logstash process. As the API matures, it will provide us with a strong foundation for building a user interface for monitoring and managing Logstash. 
-
-*Clustering ({ISSUES}2632[#2632]).* In large-scale Logstash deployments, users run multiple instances of Logstash to horizontally scale event processing. Currently, this requires manual management of individual configuration files, or custom/3rd party configuration automation tools, some of which are maintained and supported by us (e.g. puppet-logstash). We plan to introduce an option to centrally store and manage Logstash configuration options to provide an alternative for scaling out your deployment that doesn’t rely on manual configuration file management or or 3rd party configuration management tools. 
-
-*High availability and load balancing ({ISSUES}2633[#2633]).* Currently, if a specific instance of Logstash becomes overloaded or unavailable, it can result in a performance degradation or outage until the problem is resolved, unless you use a dedicated load balancer to distribute traffic over the available instances. In a clustered deployment, we have the option of automatically distributing the load between instances based on the latest cluster state. This is a complex use case that will require input from the community on current approaches to implementing HA and load balancing of Logstash instances. 
+As Logstash deployments scale up, managing and monitoring multiple Logstash
+instances using configuration and log files can become challenging. Our
+manageability project aims to improve this experience by adding functionality
+that makes administration of Logstash more efficient and less error-prone. You
+can follow this effort on GitHub by searching for issues that have the
+{LABELS}manageability[manageability] tag.
+
+*Logstash Monitoring API ({ISSUES}2611[#2611]).* Today, most Logstash monitoring
+functions are accomplished by tailing logs or outputting debug messages. As a
+result, it is hard to monitor the Logstash health and track success or failure
+of events passing through the pipeline. We plan to introduce a Logstash
+monitoring API to improve visibility into pipeline activity and provide
+performance metrics such as number of events processed, success/failure rates,
+and time spent in each plugin.
+
+*Logstash Management API ({ISSUES}2612[#2612]).* Currently, updating the
+Logstash configuration requires editing a configuration file and restarting
+the Logstash process. This means you either have to temporarily halt the
+pipeline or accept an interruption in processing. While file-based configuration
+management will continue to be supported, we plan to add a robust Logstash
+management API that enables you to update the configuration dynamically without
+restarting the Logstash process. As the API matures, it will provide us with a
+strong foundation for building a user interface for monitoring and managing
+Logstash.
+
+*Clustering ({ISSUES}2632[#2632]).* In large-scale Logstash deployments, users
+run multiple instances of Logstash to horizontally scale event processing.
+Currently, this requires manual management of individual configuration files, or
+custom/3rd party configuration automation tools, some of which are maintained
+and supported by us (e.g. puppet-logstash). We plan to introduce an option to
+centrally store and manage Logstash configuration options to provide an
+alternative for scaling out your deployment that doesn’t rely on manual
+configuration file management or or 3rd party configuration management tools.
+
+*High availability and load balancing ({ISSUES}2633[#2633]).* Currently, if a
+specific instance of Logstash becomes overloaded or unavailable, it can result
+in a performance degradation or outage until the problem is resolved, unless you
+use a dedicated load balancer to distribute traffic over the available
+instances. In a clustered deployment, we have the option of automatically
+distributing the load between instances based on the latest cluster state. This
+is a complex use case that will require input from the community on current
+approaches to implementing HA and load balancing of Logstash instances.
 
 == Logstash Forwarder
 [float]
 === status: ongoing; v2.x
 
-Logstash Forwarder uses a different code base from Logstash, and as a result it has been a challenge for us to keep feature parity between the two projects. We are experimenting with unifying the two code bases to improve ongoing maintenance of the Logstash Forwarder. Currently, Logstash Forwarder is written in Go and Logstash is written in Ruby and runs on JRuby. We are investigating the feasibility of replacing Logstash Forwarder with Logstash Ruby code executed on Matz Ruby Interpreter (http://en.wikipedia.org/wiki/Ruby_MRI[MRI]). Important criteria for success in this POC is to keep Logstash Forwarder lightweight and still distribute it as a binary so it doesn’t introduce language dependencies on the servers where it is deployed. You can follow this effort on GitHub through the Logstash Forwarder https://github.com/elasticsearch/logstash-forwarder/issues[issues list].
-
-While we are working on these enhancements, we are committed to maintaining the Logstash Forwarder. We recently delivered http://www.elasticsearch.org/blog/logstash-forwarder-0-4-0-released/[Logstash Forwarder 0.4.0], which addressed many existing issues our users have been reporting. 
+Logstash Forwarder uses a different code base from Logstash, and as a result it
+has been a challenge for us to keep feature parity between the two projects. We
+are experimenting with unifying the two code bases to improve ongoing
+maintenance of the Logstash Forwarder. Currently, Logstash Forwarder is written
+in Go and Logstash is written in Ruby and runs on JRuby. We are investigating
+the feasibility of replacing Logstash Forwarder with Logstash Ruby code executed
+on Matz Ruby Interpreter (http://en.wikipedia.org/wiki/Ruby_MRI[MRI]). Important
+criteria for success in this POC is to keep Logstash Forwarder lightweight and
+still distribute it as a binary so it doesn’t introduce language dependencies on
+the servers where it is deployed. You can follow this effort on GitHub through
+the Logstash Forwarder
+https://github.com/elastic/logstash-forwarder/issues[issues list].
+
+While we are working on these enhancements, we are committed to maintaining the
+Logstash Forwarder. We recently delivered
+http://www.elasticsearch.org/blog/logstash-forwarder-0-4-0-released/[Logstash Forwarder 0.4.0],
+which addressed many existing issues our users have been reporting.
 
 == New Plugins
 [float]
 === status: ongoing
 
-Logstash plugins are continuously added to the Logstash plugin ecosystem, both by us and by our wonderful community of plugin contributors. Recent additions include https://github.com/logstash-plugins?query=kafka[Kafka], https://github.com/logstash-plugins?query=couchdb[CouchDB], and https://github.com/logstash-plugins/logstash-input-rss[RSS], just to name a few. In Logstash 1.5, we made it easier than ever to add and maintain plugins by putting each plugin into its own repository (read more about that in http://www.elasticsearch.org/blog/plugin-ecosystem-changes/[Logstash Plugin Ecosystem Changes]). We also greatly improved the S3, Twitter, RabbitMQ plugins. To follow requests for new Logstash plugins or contribute to the discussion, look for issues that have the {LABELS}new-plugin[new-plugin] tag in Github. 
+Logstash plugins are continuously added to the Logstash plugin ecosystem, both
+by us and by our wonderful community of plugin contributors. Recent additions
+include https://github.com/logstash-plugins?query=kafka[Kafka],
+https://github.com/logstash-plugins?query=couchdb[CouchDB], and
+https://github.com/logstash-plugins/logstash-input-rss[RSS], just to name a few.
+In Logstash 1.5, we made it easier than ever to add and maintain plugins by
+putting each plugin into its own repository (read more about that in
+http://www.elasticsearch.org/blog/plugin-ecosystem-changes/[Logstash Plugin Ecosystem Changes]).
+We also greatly improved the S3, Twitter, RabbitMQ plugins. To follow requests
+for new Logstash plugins or contribute to the discussion, look for issues that
+have the {LABELS}new-plugin[new-plugin] tag in Github.
