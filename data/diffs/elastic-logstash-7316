diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/io/AbstractByteBufferPageIO.java b/logstash-core/src/main/java/org/logstash/ackedqueue/io/AbstractByteBufferPageIO.java
index 4c97da20d98..64dc16dd5b7 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/io/AbstractByteBufferPageIO.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/io/AbstractByteBufferPageIO.java
@@ -42,7 +42,7 @@ public static class PageIOInvalidVersionException extends IOException {
     protected int head; // head is the write position and is an int per ByteBuffer class position
     protected byte version;
     private CRC32 checkSummer;
-    private final List<Integer> offsetMap; // has to be extendable
+    protected final List<Integer> offsetMap; // has to be extendable
 
     public AbstractByteBufferPageIO(int pageNum, int capacity) {
         this.minSeqNum = 0;
@@ -189,7 +189,7 @@ public void write(byte[] bytes, long seqNum) throws IOException {
         write(bytes, seqNum, bytes.length, checksum(bytes));
     }
 
-    protected int write(byte[] bytes, long seqNum, int length, int checksum) {
+    protected int write(byte[] bytes, long seqNum, int length, int checksum) throws IOException {
         // since writes always happen at head, we can just append head to the offsetMap
         assert this.offsetMap.size() == this.elementCount :
                 String.format("offsetMap size=%d != elementCount=%d", this.offsetMap.size(), this.elementCount);
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/io/MmapPageIO.java b/logstash-core/src/main/java/org/logstash/ackedqueue/io/MmapPageIO.java
index 46bd79f358a..123cd2a43cf 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/io/MmapPageIO.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/io/MmapPageIO.java
@@ -1,35 +1,35 @@
 package org.logstash.ackedqueue.io;
 
-import sun.misc.Cleaner;
-import sun.nio.ch.DirectBuffer;
-
 import java.io.File;
 import java.io.IOException;
 import java.io.RandomAccessFile;
+import java.nio.ByteBuffer;
 import java.nio.MappedByteBuffer;
 import java.nio.channels.FileChannel;
 import java.nio.file.Files;
 import java.nio.file.Paths;
+import sun.misc.Cleaner;
+import sun.nio.ch.DirectBuffer;
 
 // TODO: this essentially a copy of ByteBufferPageIO and should be DRY'ed - temp impl to test file based stress test
 
 @SuppressWarnings("sunapi")
 public class MmapPageIO extends AbstractByteBufferPageIO {
 
-    private File file;
+    private final File file;
 
     private FileChannel channel;
     protected MappedByteBuffer buffer;
 
+    private final ByteBuffer writeBuffer = ByteBuffer.allocateDirect(256 * 256);
+
     public MmapPageIO(int pageNum, int capacity, String dirPath) {
         super(pageNum, capacity);
-
         this.file = Paths.get(dirPath, "page." + pageNum).toFile();
     }
 
     @Override
     public void open(long minSeqNum, int elementCount) throws IOException {
-        mapFile(STRICT_CAPACITY);
         super.open(minSeqNum, elementCount);
     }
 
@@ -37,43 +37,46 @@ public void open(long minSeqNum, int elementCount) throws IOException {
     // to reflect what it recovered from the page
     @Override
     public void recover() throws IOException {
-        mapFile(!STRICT_CAPACITY);
         super.recover();
     }
 
-    // memory map data file to this.buffer and read initial version byte
-    // @param strictCapacity if true verify that data file size is same as configured page capacity, if false update page capacity to actual file size
-    private void mapFile(boolean strictCapacity) throws IOException {
-        RandomAccessFile raf = new RandomAccessFile(this.file, "rw");
-
-        if (raf.length() > Integer.MAX_VALUE) {
-            throw new IOException("Page file too large " + this.file);
-        }
-        int pageFileCapacity = (int)raf.length();
+    @Override
+    public void write(byte[] bytes, long seqNum) throws IOException {
+        write(bytes, seqNum, bytes.length, checksum(bytes));
+    }
 
-        if (strictCapacity && this.capacity != pageFileCapacity) {
-            throw new IOException("Page file size " + pageFileCapacity + " different to configured page capacity " + this.capacity + " for " + this.file);
+    protected int write(byte[] bytes, long seqNum, int length, int checksum) throws IOException {
+        // since writes always happen at head, we can just append head to the offsetMap
+        assert this.offsetMap.size() == this.elementCount :
+            String.format("offsetMap size=%d != elementCount=%d", this.offsetMap.size(),
+                this.elementCount
+            );
+        this.writeBuffer.clear();
+        this.writeBuffer.putLong(seqNum);
+        this.writeBuffer.putInt(length);
+        this.writeBuffer.put(bytes);
+        this.writeBuffer.putInt(checksum);
+        this.head += persistedByteCount(bytes.length);
+        if (this.elementCount <= 0) {
+            this.minSeqNum = seqNum;
         }
-
-        // update capacity to actual raf length
-        this.capacity = pageFileCapacity;
-
-        if (this.capacity < MIN_CAPACITY) { throw new IOException(String.format("Page file size is too small to hold elements")); }
-
-        this.channel = raf.getChannel();
-        this.buffer = this.channel.map(FileChannel.MapMode.READ_WRITE, 0, this.capacity);
-        raf.close();
-        this.buffer.load();
+        final int initialHead = this.head - writeBuffer.position();
+        this.offsetMap.add(initialHead);
+        this.elementCount++;
+        this.writeBuffer.flip();
+        this.channel.write(this.writeBuffer);
+        return initialHead;
     }
 
     @Override
     public void create() throws IOException {
         RandomAccessFile raf = new RandomAccessFile(this.file, "rw");
         this.channel = raf.getChannel();
-        this.buffer = this.channel.map(FileChannel.MapMode.READ_WRITE, 0, this.capacity);
-        raf.close();
-
-        super.create();
+        writeBuffer.put(VERSION_ONE).flip();
+        channel.write(writeBuffer);
+        this.head = 1;
+        this.minSeqNum = 0L;
+        this.elementCount = 0;
     }
 
     @Override
@@ -84,18 +87,19 @@ public void deactivate() throws IOException {
     @Override
     public void activate() throws IOException {
         if (this.channel == null) {
-            RandomAccessFile raf = new RandomAccessFile(this.file, "rw");
-            this.channel = raf.getChannel();
-            this.buffer = this.channel.map(FileChannel.MapMode.READ_WRITE, 0, this.capacity);
-            raf.close();
-            this.buffer.load();
+            this.channel = FileChannel.open(this.file.toPath());
         }
         // TODO: do we need to check is the channel is still open? not sure how it could be closed
     }
 
     @Override
     public void ensurePersisted() {
-        this.buffer.force();
+        try {
+            this.activate();
+            this.channel.force(false);
+        } catch (final IOException ex) {
+            throw new IllegalStateException(ex);
+        }
     }
 
     @Override
@@ -108,15 +112,18 @@ public void purge() throws IOException {
     public void close() throws IOException {
         if (this.buffer != null) {
             this.buffer.force();
-
             // calling the cleaner() method releases resources held by this direct buffer which would be held until GC otherwise.
             // see https://github.com/elastic/logstash/pull/6740
             Cleaner cleaner = ((DirectBuffer) this.buffer).cleaner();
-            if (cleaner != null) { cleaner.clean(); }
+            if (cleaner != null) {
+                cleaner.clean();
+            }
 
         }
         if (this.channel != null) {
-            if (this.channel.isOpen()) { this.channel.force(false); }
+            if (this.channel.isOpen()) {
+                this.channel.force(false);
+            }
             this.channel.close(); // close can be called multiple times
         }
         this.channel = null;
@@ -125,6 +132,17 @@ public void close() throws IOException {
 
     @Override
     protected MappedByteBuffer getBuffer() {
+        if(this.buffer == null) {
+            try {
+                try(final RandomAccessFile raf = new RandomAccessFile(this.file, "rw")) {
+                    this.buffer = raf.getChannel()
+                        .map(FileChannel.MapMode.READ_ONLY, 0L, this.capacity);
+                    this.buffer.position(1);
+                }
+            } catch (final IOException ex) {
+                throw new IllegalStateException(ex);
+            }
+        }
         return this.buffer;
     }
 }
