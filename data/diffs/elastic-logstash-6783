diff --git a/logstash-core-event/lib/logstash-core-event.rb b/logstash-core-event/lib/logstash-core-event.rb
deleted file mode 100644
index b2979326dac..00000000000
--- a/logstash-core-event/lib/logstash-core-event.rb
+++ /dev/null
@@ -1 +0,0 @@
-require "logstash-core-event/logstash-core-event"
\ No newline at end of file
diff --git a/logstash-core-event/lib/logstash-core-event/logstash-core-event.rb b/logstash-core-event/lib/logstash-core-event/logstash-core-event.rb
deleted file mode 100644
index b0f773e203c..00000000000
--- a/logstash-core-event/lib/logstash-core-event/logstash-core-event.rb
+++ /dev/null
@@ -1,5 +0,0 @@
-# encoding: utf-8
-module LogStash
-end
-
-require "logstash/event"
\ No newline at end of file
diff --git a/logstash-core-event/lib/logstash-core-event/version.rb b/logstash-core-event/lib/logstash-core-event/version.rb
deleted file mode 100644
index 74914785722..00000000000
--- a/logstash-core-event/lib/logstash-core-event/version.rb
+++ /dev/null
@@ -1,8 +0,0 @@
-# encoding: utf-8
-
-# The version of logstash core event gem.
-#
-# Note to authors: this should not include dashes because 'gem' barfs if
-# you include a dash in the version string.
-
-LOGSTASH_CORE_EVENT_VERSION = "6.0.0-alpha1"
diff --git a/logstash-core-event/lib/logstash/event.rb b/logstash-core-event/lib/logstash/event.rb
deleted file mode 100644
index de0cf5fc00d..00000000000
--- a/logstash-core-event/lib/logstash/event.rb
+++ /dev/null
@@ -1,292 +0,0 @@
-# encoding: utf-8
-require "time"
-require "date"
-require "cabin"
-require "logstash/namespace"
-require "logstash/util/accessors"
-require "logstash/timestamp"
-require "logstash/json"
-require "logstash/string_interpolation"
-
-# transcient pipeline events for normal in-flow signaling as opposed to
-# flow altering exceptions. for now having base classes is adequate and
-# in the future it might be necessary to refactor using like a BaseEvent
-# class to have a common interface for all pileline events to support
-# eventual queueing persistence for example, TBD.
-
-module LogStash
-  class SignalEvent
-    def flush?; raise "abstract method"; end;
-    def shutdown?; raise "abstract method"; end;
-  end
-
-  class ShutdownEvent < SignalEvent
-    def flush?; false; end;
-    def shutdown?; true; end;
-  end
-
-  class FlushEvent < SignalEvent
-    def flush?; true; end;
-    def shutdown?; false; end;
-  end
-
-  FLUSH = FlushEvent.new
-
-  # LogStash::SHUTDOWN is used by plugins
-  SHUTDOWN = ShutdownEvent.new
-end
-
-# the logstash event object.
-#
-# An event is simply a tuple of (timestamp, data).
-# The 'timestamp' is an ISO8601 timestamp. Data is anything - any message,
-# context, references, etc that are relevant to this event.
-#
-# Internally, this is represented as a hash with only two guaranteed fields.
-#
-# * "@timestamp" - an ISO8601 timestamp representing the time the event
-#   occurred at.
-# * "@version" - the version of the schema. Currently "1"
-#
-# They are prefixed with an "@" symbol to avoid clashing with your
-# own custom fields.
-#
-# When serialized, this is represented in JSON. For example:
-#
-#     {
-#       "@timestamp": "2013-02-09T20:39:26.234Z",
-#       "@version": "1",
-#       message: "hello world"
-#     }
-class LogStash::Event
-  class DeprecatedMethod < StandardError; end
-
-  CHAR_PLUS = "+"
-  TIMESTAMP = "@timestamp"
-  VERSION = "@version"
-  VERSION_ONE = "1"
-  TIMESTAMP_FAILURE_TAG = "_timestampparsefailure"
-  TIMESTAMP_FAILURE_FIELD = "_@timestamp"
-  TAGS = "tags".freeze
-
-  METADATA = "@metadata".freeze
-  METADATA_BRACKETS = "[#{METADATA}]".freeze
-
-  # Floats outside of these upper and lower bounds are forcibly converted
-  # to scientific notation by Float#to_s
-  MIN_FLOAT_BEFORE_SCI_NOT = 0.0001
-  MAX_FLOAT_BEFORE_SCI_NOT = 1000000000000000.0
-
-  DEFAULT_LOGGER = Cabin::Channel.get(LogStash)
-  @@logger = DEFAULT_LOGGER
-
-  def initialize(data = {})
-    @cancelled = false
-    @data = data
-    @accessors = LogStash::Util::Accessors.new(data)
-    @data[VERSION] ||= VERSION_ONE
-    ts = @data[TIMESTAMP]
-    @data[TIMESTAMP] = ts ? init_timestamp(ts) : LogStash::Timestamp.now
-
-    @metadata = @data.delete(METADATA) || {}
-    @metadata_accessors = LogStash::Util::Accessors.new(@metadata)
-  end
-
-  def cancel
-    @cancelled = true
-  end
-
-  def uncancel
-    @cancelled = false
-  end
-
-  def cancelled?
-    @cancelled
-  end
-
-  # Create a deep-ish copy of this event.
-  def clone
-    copy = {}
-    @data.each do |k,v|
-      # TODO(sissel): Recurse if this is a hash/array?
-      copy[k] = begin v.clone rescue v end
-    end
-
-    self.class.new(copy)
-  end
-
-  def to_s
-    "#{timestamp.to_iso8601} #{self.sprintf("%{host} %{message}")}"
-  end
-
-  def timestamp
-    @data[TIMESTAMP]
-  end
-
-  def timestamp=(val)
-    @data[TIMESTAMP] = val
-  end
-
-  def get(fieldref)
-    if fieldref.start_with?(METADATA_BRACKETS)
-      @metadata_accessors.get(fieldref[METADATA_BRACKETS.length .. -1])
-    elsif fieldref == METADATA
-      @metadata
-    else
-      @accessors.get(fieldref)
-    end
-  end
-
-  def set(fieldref, value)
-    if fieldref == TIMESTAMP && !value.is_a?(LogStash::Timestamp)
-      raise TypeError, "The field '@timestamp' must be a (LogStash::Timestamp, not a #{value.class} (#{value})"
-    end
-    if fieldref.start_with?(METADATA_BRACKETS)
-      @metadata_accessors.set(fieldref[METADATA_BRACKETS.length .. -1], value)
-    elsif fieldref == METADATA
-      @metadata = value
-      @metadata_accessors = LogStash::Util::Accessors.new(@metadata)
-    else
-      @accessors.set(fieldref, value)
-    end
-  end
-
-  def to_json(*args)
-    # ignore arguments to respect accepted to_json method signature
-    LogStash::Json.dump(@data)
-  end
-
-  def to_hash
-    @data
-  end
-
-  def overwrite(event)
-    # pickup new event @data and also pickup @accessors
-    # otherwise it will be pointing on previous data
-    @data = event.instance_variable_get(:@data)
-    @accessors = event.instance_variable_get(:@accessors)
-
-    #convert timestamp if it is a String
-    if @data[TIMESTAMP].is_a?(String)
-      @data[TIMESTAMP] = LogStash::Timestamp.parse_iso8601(@data[TIMESTAMP])
-    end
-  end
-
-  def include?(fieldref)
-    if fieldref.start_with?(METADATA_BRACKETS)
-      @metadata_accessors.include?(fieldref[METADATA_BRACKETS.length .. -1])
-    elsif fieldref == METADATA
-      true
-    else
-      @accessors.include?(fieldref)
-    end
-  end
-
-  # Append an event to this one.
-  def append(event)
-    # non-destructively merge that event with ourselves.
-
-    # no need to reset @accessors here because merging will not disrupt any existing field paths
-    # and if new ones are created they will be picked up.
-    LogStash::Util.hash_merge(@data, event.to_hash)
-  end
-
-  # Remove a field or field reference. Returns the value of that field when deleted
-  def remove(fieldref)
-    @accessors.del(fieldref)
-  end
-
-  # sprintf. This could use a better method name.
-  # The idea is to take an event and convert it to a string based on
-  # any format values, delimited by %{foo} where 'foo' is a field or
-  # metadata member.
-  #
-  # For example, if the event has type == "foo" and host == "bar"
-  # then this string:
-  #   "type is %{type} and source is %{host}"
-  # will return
-  #   "type is foo and source is bar"
-  #
-  # If a %{name} value is an array, then we will join by ','
-  # If a %{name} value does not exist, then no substitution occurs.
-  def sprintf(format)
-    LogStash::StringInterpolation.evaluate(self, format)
-  end
-
-  def tag(value)
-    # Generalize this method for more usability
-    tags = @accessors.get(TAGS) || []
-    tags << value unless tags.include?(value)
-    @accessors.set(TAGS, tags)
-  end
-
-  def to_hash_with_metadata
-    @metadata.empty? ? to_hash : to_hash.merge(METADATA => @metadata)
-  end
-
-  def to_json_with_metadata(*args)
-    # ignore arguments to respect accepted to_json method signature
-    LogStash::Json.dump(to_hash_with_metadata)
-  end
-
-  # this is used by logstash-devutils spec_helper.rb to monkey patch the Event field setter []=
-  # and add systematic encoding validation on every field set in specs.
-  # TODO: (colin) this should be moved, probably in logstash-devutils ?
-  def self.validate_value(value)
-    case value
-    when String
-      raise("expected UTF-8 encoding for value=#{value}, encoding=#{value.encoding.inspect}") unless value.encoding == Encoding::UTF_8
-      raise("invalid UTF-8 encoding for value=#{value}, encoding=#{value.encoding.inspect}") unless value.valid_encoding?
-      value
-    when Array
-      value.each{|v| validate_value(v)} # don't map, return original object
-      value
-    else
-      value
-    end
-  end
-
-  # depracated public methods
-  # TODO: (colin) since these depracated mothods are still exposed in 2.x we should remove them in 3.0
-
-  def unix_timestamp
-    raise DeprecatedMethod
-  end
-
-  def ruby_timestamp
-    raise DeprecatedMethod
-  end
-
-  def fields
-    raise DeprecatedMethod
-  end
-
-  # set a new logger for all Event instances
-  # there is no point in changing it at runtime for other reasons than in tests/specs.
-  # @param logger [Cabin::Channel] logger instance that will be used by all Event instances
-  def self.logger=(logger)
-    @@logger = logger
-  end
-
-  private
-
-  def logger
-    @@logger
-  end
-
-  def init_timestamp(o)
-    begin
-      timestamp = LogStash::Timestamp.coerce(o)
-      return timestamp if timestamp
-
-      logger.warn("Unrecognized #{TIMESTAMP} value, setting current time to #{TIMESTAMP}, original in #{TIMESTAMP_FAILURE_FIELD}field", :value => o.inspect)
-    rescue LogStash::TimestampParserError => e
-      logger.warn("Error parsing #{TIMESTAMP} string, setting current time to #{TIMESTAMP}, original in #{TIMESTAMP_FAILURE_FIELD} field", :value => o.inspect, :exception => e.message)
-    end
-
-    tag(TIMESTAMP_FAILURE_TAG)
-    @accessors.set(TIMESTAMP_FAILURE_FIELD, o)
-
-    LogStash::Timestamp.now
-  end
-end
diff --git a/logstash-core-event/lib/logstash/string_interpolation.rb b/logstash-core-event/lib/logstash/string_interpolation.rb
deleted file mode 100644
index aaa54981165..00000000000
--- a/logstash-core-event/lib/logstash/string_interpolation.rb
+++ /dev/null
@@ -1,152 +0,0 @@
-# encoding: utf-8
-require "thread_safe"
-require "forwardable"
-
-module LogStash
-  module StringInterpolation
-    extend self
-
-    # Floats outside of these upper and lower bounds are forcibly converted
-    # to scientific notation by Float#to_s
-    MIN_FLOAT_BEFORE_SCI_NOT = 0.0001
-    MAX_FLOAT_BEFORE_SCI_NOT = 1000000000000000.0
-
-    CACHE = ThreadSafe::Cache.new
-    TEMPLATE_TAG_REGEXP = /%\{[^}]+\}/
-
-    def evaluate(event, template)
-      if template.is_a?(Float) && (template < MIN_FLOAT_BEFORE_SCI_NOT || template >= MAX_FLOAT_BEFORE_SCI_NOT)
-        return ("%.15f" % template).sub(/0*$/,"")
-      end
-
-      template = template.to_s
-
-      return template if not_cachable?(template)
-
-      compiled = CACHE.get_or_default(template, nil) || CACHE.put(template, compile_template(template))
-      compiled.evaluate(event)
-    end
-
-    # clear the global compiled templates cache
-    def clear_cache
-      CACHE.clear
-    end
-
-    # @return [Fixnum] the compiled templates cache size
-    def cache_size
-      CACHE.size
-    end
-
-    private
-    def not_cachable?(template)
-      template.index("%").nil?
-    end
-
-    def compile_template(template)
-      nodes = Template.new
-
-      position = 0
-      matches = template.to_enum(:scan, TEMPLATE_TAG_REGEXP).map { |m| $~ }
-
-      matches.each do |match|
-        tag = match[0][2..-2]
-        start = match.offset(0).first
-        nodes << StaticNode.new(template[position..(start-1)]) if start > 0
-        nodes << identify(tag)
-        position = match.offset(0).last
-      end
-
-      if position < template.size
-        nodes << StaticNode.new(template[position..-1])
-      end
-
-      optimize(nodes)
-    end
-
-    def optimize(nodes)
-      nodes.size == 1 ?  nodes.first : nodes
-    end
-
-    def identify(tag)
-      if tag == "+%s"
-        EpocNode.new
-      elsif tag[0, 1] == "+"
-        DateNode.new(tag[1..-1])
-      else
-        KeyNode.new(tag)
-      end
-    end
-  end
-
-  class Template
-    extend Forwardable
-    def_delegators :@nodes, :<<, :push, :size, :first
-
-    def initialize
-      @nodes = []
-    end
-
-    def evaluate(event)
-      @nodes.collect { |node| node.evaluate(event) }.join
-    end
-  end
-
-  class EpocNode
-    def evaluate(event)
-      t = event.timestamp
-      raise LogStash::Error, "Unable to format in string \"#{@format}\", #{LogStash::Event::TIMESTAMP} field not found" unless t
-      t.to_i.to_s
-    end
-  end
-
-  class StaticNode
-    def initialize(content)
-      @content = content
-    end
-
-    def evaluate(event)
-      @content
-    end
-  end
-
-  class KeyNode
-    def initialize(key)
-      @key = key
-    end
-
-    def evaluate(event)
-      value = event.get(@key)
-
-      case value
-      when nil
-        "%{#{@key}}"
-      when Array
-        value.join(",")
-      when Hash
-        LogStash::Json.dump(value)
-      else
-        # Make sure we dont work on the refence of the value
-        # The Java Event implementation was always returning a string.
-        "#{value}"
-      end
-    end
-  end
-
-  class DateNode
-    def initialize(format)
-      @format = format
-      @formatter = org.joda.time.format.DateTimeFormat.forPattern(@format)
-          .withZone(org.joda.time.DateTimeZone::UTC)
-    end
-
-    def evaluate(event)
-      t = event.timestamp
-
-      raise LogStash::Error, "Unable to format in string \"#{@format}\", #{LogStash::Event::TIMESTAMP} field not found" unless t
-
-      org.joda.time.Instant.java_class.constructor(Java::long).new_instance(
-        t.tv_sec * 1000 + t.tv_usec / 1000
-      ).to_java.toDateTime.toString(@formatter)
-    end
-  end
-end
diff --git a/logstash-core-event/lib/logstash/timestamp.rb b/logstash-core-event/lib/logstash/timestamp.rb
deleted file mode 100644
index ab6b6edb3bc..00000000000
--- a/logstash-core-event/lib/logstash/timestamp.rb
+++ /dev/null
@@ -1,103 +0,0 @@
-# encoding: utf-8
-require "logstash/environment"
-require "logstash/json"
-require "forwardable"
-require "date"
-require "time"
-
-module LogStash
-  class TimestampParserError < StandardError; end
-
-  class Timestamp
-    extend Forwardable
-    include Comparable
-
-    def_delegators :@time, :tv_usec, :usec, :year, :iso8601, :to_i, :tv_sec, :to_f, :to_edn, :<=>, :+
-
-    attr_reader :time
-
-    ISO8601_STRFTIME = "%04d-%02d-%02dT%02d:%02d:%02d.%06d%+03d:00".freeze
-    ISO8601_PRECISION = 3
-
-    def initialize(time = Time.new)
-      @time = time.utc
-    end
-
-    def self.at(*args)
-      epoch = args.first
-      if epoch.is_a?(BigDecimal)
-        # bug in JRuby prevents correcly parsing a BigDecimal fractional part, see https://github.com/elastic/logstash/issues/4565
-        Timestamp.new(::Time.at(epoch.to_i, epoch.frac.to_f * 1000000))
-      else
-        Timestamp.new(::Time.at(*args))
-      end
-    end
-
-    def self.parse(*args)
-      Timestamp.new(::Time.parse(*args))
-    end
-
-    def self.now
-      Timestamp.new(::Time.now)
-    end
-
-    # coerce tries different strategies based on the time object class to convert into a Timestamp.
-    # @param [String, Time, Timestamp] time the time object to try coerce
-    # @return [Timestamp, nil] Timestamp will be returned if successful otherwise nil
-    # @raise [TimestampParserError] on String with invalid format
-    def self.coerce(time)
-      case time
-      when String
-        LogStash::Timestamp.parse_iso8601(time)
-      when LogStash::Timestamp
-        time
-      when Time
-        LogStash::Timestamp.new(time)
-      else
-        nil
-      end
-    end
-
-    if LogStash::Environment.jruby?
-      JODA_ISO8601_PARSER = org.joda.time.format.ISODateTimeFormat.dateTimeParser
-      UTC = org.joda.time.DateTimeZone.forID("UTC")
-
-      def self.parse_iso8601(t)
-        millis = JODA_ISO8601_PARSER.parseMillis(t)
-        LogStash::Timestamp.at(millis / 1000, (millis % 1000) * 1000)
-      rescue => e
-        raise(TimestampParserError, "invalid timestamp string #{t.inspect}, error=#{e.inspect}")
-      end
-
-    else
-
-      def self.parse_iso8601(t)
-        # warning, ruby's Time.parse is *really* terrible and slow.
-        LogStash::Timestamp.new(::Time.parse(t))
-      rescue => e
-        raise(TimestampParserError, "invalid timestamp string #{t.inspect}, error=#{e.inspect}")
-      end
-    end
-
-    def utc
-      @time.utc # modifies the receiver
-      self
-    end
-    alias_method :gmtime, :utc
-
-    def to_json(*args)
-      # ignore arguments to respect accepted to_json method signature
-      "\"" + to_iso8601 + "\""
-    end
-    alias_method :inspect, :to_json
-
-    def to_iso8601
-      @iso8601 ||= @time.iso8601(ISO8601_PRECISION)
-    end
-    alias_method :to_s, :to_iso8601
-
-    def -(value)
-      @time - (value.is_a?(Timestamp) ? value.time : value)
-    end
-  end
-end
diff --git a/logstash-core-event/lib/logstash/util/accessors.rb b/logstash-core-event/lib/logstash/util/accessors.rb
deleted file mode 100644
index 23248f2c3ea..00000000000
--- a/logstash-core-event/lib/logstash/util/accessors.rb
+++ /dev/null
@@ -1,130 +0,0 @@
-# encoding: utf-8
-require "logstash/namespace"
-require "logstash/util"
-require "thread_safe"
-
-module LogStash::Util
-
-  # PathCache is a singleton which globally caches the relation between a field reference and its
-  # decomposition into a [key, path array] tuple. For example the field reference [foo][bar][baz]
-  # is decomposed into ["baz", ["foo", "bar"]].
-  module PathCache
-    extend self
-
-    # requiring libraries and defining constants is thread safe in JRuby so
-    # PathCache::CACHE will be corretly initialized, once, when accessors.rb
-    # will be first required
-    CACHE = ThreadSafe::Cache.new
-
-    def get(field_reference)
-      # the "get_or_default(x, nil) || put(x, parse(x))" is ~2x faster than "get || put" because the get call is
-      # proxied through the JRuby JavaProxy op_aref method. the correct idiom here would be to use
-      # "compute_if_absent(x){parse(x)}" but because of the closure creation, it is ~1.5x slower than
-      # "get_or_default || put".
-      # this "get_or_default || put" is obviously non-atomic which is not really important here
-      # since all threads will set the same value and this cache will stabilize very quickly after the first
-      # few events.
-      CACHE.get_or_default(field_reference, nil) || CACHE.put(field_reference, parse(field_reference))
-    end
-
-    def parse(field_reference)
-      path = field_reference.split(/[\[\]]/).select{|s| !s.empty?}
-      [path.pop, path]
-    end
-  end
-
-  # Accessors uses a lookup table to speedup access of a field reference of the form
-  # "[hello][world]" to the underlying store hash into {"hello" => {"world" => "foo"}}
-  class Accessors
-
-    # @param store [Hash] the backing data store field refereces point to
-    def initialize(store)
-      @store = store
-
-      # @lut is a lookup table between a field reference and a [target, key] tuple
-      # where target is the containing Hash or Array for key in @store.
-      # this allows us to directly access the containing object for key instead of
-      # walking the field reference path into the inner @store objects
-      @lut = {}
-    end
-
-    # @param field_reference [String] the field reference
-    # @return [Object] the value in @store for this field reference
-    def get(field_reference)
-      target, key = lookup(field_reference)
-      return nil unless target
-      target.is_a?(Array) ? target[key.to_i] : target[key]
-    end
-
-    # @param field_reference [String] the field reference
-    # @param value [Object] the value to set in @store for this field reference
-    # @return [Object] the value set
-    def set(field_reference, value)
-      target, key = lookup_or_create(field_reference)
-      target[target.is_a?(Array) ? key.to_i : key] = value
-    end
-
-    # @param field_reference [String] the field reference to remove
-    # @return [Object] the removed value in @store for this field reference
-    def del(field_reference)
-      target, key = lookup(field_reference)
-      return nil unless target
-      target.is_a?(Array) ? target.delete_at(key.to_i) : target.delete(key)
-    end
-
-    # @param field_reference [String] the field reference to test for inclusion in the store
-    # @return [Boolean] true if the store contains a value for this field reference
-    def include?(field_reference)
-      target, key = lookup(field_reference)
-      return false unless target
-
-      target.is_a?(Array) ? !target[key.to_i].nil? : target.include?(key)
-    end
-
-    private
-
-    # retrieve the [target, key] tuple associated with this field reference
-    # @param field_reference [String] the field referece
-    # @return [[Object, String]] the  [target, key] tuple associated with this field reference
-    def lookup(field_reference)
-      @lut[field_reference] ||= find_target(field_reference)
-    end
-
-    # retrieve the [target, key] tuple associated with this field reference and create inner
-    # container objects if they do not exists
-    # @param field_reference [String] the field referece
-    # @return [[Object, String]] the  [target, key] tuple associated with this field reference
-    def lookup_or_create(field_reference)
-      # flush the @lut to prevent stale cached fieldref which may point to an old target
-      # which was overwritten with a new value. for example, if "[a][b]" is cached and we
-      # set a new value for "[a]" then reading again "[a][b]" would point in a stale target.
-      # flushing the complete @lut is suboptimal, but a hierarchical lut would be required
-      # to be able to invalidate fieldrefs from a common root.
-      # see https://github.com/elastic/logstash/pull/5132
-      @lut.clear
-      @lut[field_reference] = find_or_create_target(field_reference)
-    end
-
-    # find the target container object in store for this field reference
-    # @param field_reference [String] the field referece
-    # @return [Object] the target container object in store associated with this field reference
-    def find_target(field_reference)
-      key, path = PathCache.get(field_reference)
-      target = path.inject(@store) do |r, k|
-        return nil unless r
-        r[r.is_a?(Array) ? k.to_i : k]
-      end
-      target ? [target, key] : nil
-    end
-
-    # find the target container object in store for this field reference and create inner
-    # container objects if they do not exists
-    # @param field_reference [String] the field referece
-    # @return [Object] the target container object in store associated with this field reference
-    def find_or_create_target(accessor)
-      key, path = PathCache.get(accessor)
-      target = path.inject(@store) {|r, k| r[r.is_a?(Array) ? k.to_i : k] ||= {}}
-      [target, key]
-    end
-  end # class Accessors
-end # module LogStash::Util
diff --git a/logstash-core-event/logstash-core-event.gemspec b/logstash-core-event/logstash-core-event.gemspec
deleted file mode 100644
index 9e0a757a870..00000000000
--- a/logstash-core-event/logstash-core-event.gemspec
+++ /dev/null
@@ -1,23 +0,0 @@
-# -*- encoding: utf-8 -*-
-lib = File.expand_path('../lib', __FILE__)
-$LOAD_PATH.unshift(lib) unless $LOAD_PATH.include?(lib)
-require 'logstash-core-event/version'
-
-Gem::Specification.new do |gem|
-  gem.authors       = ["Elastic"]
-  gem.email         = ["info@elastic.co"]
-  gem.description   = %q{The core event component of logstash, the scalable log and event management tool}
-  gem.summary       = %q{logstash-core-event - The core event component of logstash}
-  gem.homepage      = "http://www.elastic.co/guide/en/logstash/current/index.html"
-  gem.license       = "Apache License (2.0)"
-
-  gem.files         = Dir.glob(["logstash-core-event.gemspec", "lib/**/*.rb", "spec/**/*.rb"])
-  gem.test_files    = gem.files.grep(%r{^(test|spec|features)/})
-  gem.name          = "logstash-core-event"
-  gem.require_paths = ["lib"]
-  gem.version       = LOGSTASH_CORE_EVENT_VERSION
-
-  if RUBY_PLATFORM == 'java'
-    gem.platform = RUBY_PLATFORM
-  end
-end
diff --git a/logstash-core-event/spec/logstash/event_spec.rb b/logstash-core/spec/logstash/legacy_ruby_event_spec.rb
similarity index 100%
rename from logstash-core-event/spec/logstash/event_spec.rb
rename to logstash-core/spec/logstash/legacy_ruby_event_spec.rb
diff --git a/logstash-core-event/spec/logstash/timestamp_spec.rb b/logstash-core/spec/logstash/legacy_ruby_timestamp_spec.rb
similarity index 100%
rename from logstash-core-event/spec/logstash/timestamp_spec.rb
rename to logstash-core/spec/logstash/legacy_ruby_timestamp_spec.rb
diff --git a/logstash-core-event/spec/logstash/util/accessors_spec.rb b/logstash-core/spec/logstash/util/accessors_spec.rb
similarity index 100%
rename from logstash-core-event/spec/logstash/util/accessors_spec.rb
rename to logstash-core/spec/logstash/util/accessors_spec.rb
diff --git a/rakelib/artifacts.rake b/rakelib/artifacts.rake
index c517157892b..f518449740b 100644
--- a/rakelib/artifacts.rake
+++ b/rakelib/artifacts.rake
@@ -103,7 +103,6 @@ namespace "artifact" do
   desc "Generate logstash core gems"
   task "gems" => ["prepare"] do
     Rake::Task["artifact:build-logstash-core"].invoke
-    Rake::Task["artifact:build-logstash-core-event"].invoke
     Rake::Task["artifact:build-logstash-core-plugin-api"].invoke
   end
 
@@ -172,27 +171,6 @@ namespace "artifact" do
     end
   end
 
-  # # locate the "gem "logstash-core-event*" ..." line in Gemfile, and if the :path => "." option if specified
-  # # build the local logstash-core-event* gem otherwise just do nothing, bundler will deal with it.
-  task "build-logstash-core-event" do
-    # regex which matches a Gemfile gem definition for the logstash-core-event* gem and captures the gem name and :path option
-    gem_line_regex = /^\s*gem\s+["'](logstash-core-event[^"^']*)["'](?:\s*,\s*["'][^"^']+["'])?(?:\s*,\s*:path\s*=>\s*["']([^"^']+)["'])?/i
-
-    lines = File.readlines("Gemfile")
-    matches = lines.select{|line| line[gem_line_regex]}
-    abort("ERROR: Gemfile format error, need a single logstash-core-event gem specification") if matches.size != 1
-
-    name = matches.first[gem_line_regex, 1]
-    path = matches.first[gem_line_regex, 2]
-
-    if path
-      Rake::Task["plugin:build-local-core-gem"].invoke(name, path)
-    else
-      puts "The Gemfile should reference \"logstash-core-event\" gem locally through :path, but found instead: #{matches}"
-      exit(1)
-    end
-  end
-
   # locate the "gem "logstash-core-plugin-api" ..." line in Gemfile, and if the :path => "..." option if specified
   # build the local logstash-core-plugin-api gem otherwise just do nothing, bundler will deal with it.
   task "build-logstash-core-plugin-api" do
diff --git a/rakelib/test.rake b/rakelib/test.rake
index 28cddcdd082..8cf7c0d1559 100644
--- a/rakelib/test.rake
+++ b/rakelib/test.rake
@@ -27,11 +27,7 @@ namespace "test" do
   end
 
   def core_specs
-    # note that regardless if which logstash-core-event-* gem is live, we will always run the
-    # logstash-core-event specs since currently this is the most complete Event and Timestamp specs
-    # which actually defines the Event contract and should pass regardless of the actuall underlying
-    # implementation.
-    specs = ["spec/unit/**/*_spec.rb", "logstash-core/spec/**/*_spec.rb", "logstash-core-event/spec/**/*_spec.rb"]
+    specs = ["spec/unit/**/*_spec.rb", "logstash-core/spec/**/*_spec.rb"]
 
     Rake::FileList[*specs]
   end
diff --git a/rakelib/version.rake b/rakelib/version.rake
index 4ec7ea67f63..d9ddb7dedcb 100644
--- a/rakelib/version.rake
+++ b/rakelib/version.rake
@@ -58,7 +58,6 @@ namespace :version do
       IO.write(metadata["location"], text.gsub(metadata["current_version"], metadata["yaml_version"]))
     end
 
-    # logstash-core-event-java depends on logstash-code
     # ./logstash-core-plugin-api/logstash-core-plugin-api.gemspec:  gem.add_runtime_dependency "logstash-core", "5.0.0.dev"
     logstash_core_plugin_api_gemspec = File.join("logstash-core-plugin-api", "logstash-core-plugin-api.gemspec")
     logstash_core_version = versions['logstash-core']['yaml_version']
@@ -76,7 +75,7 @@ namespace :version do
     end
   end
 
-  desc "set version of logstash, logstash-core, logstash-core-event"
+  desc "set version of logstash, logstash-core"
   task :set, [:version] => [:validate] do |t, args|
     hash = {}
     get_versions.each do |component, metadata|
diff --git a/spec/unit/license_spec.rb b/spec/unit/license_spec.rb
index fdc5ea80065..f04e1365fe1 100644
--- a/spec/unit/license_spec.rb
+++ b/spec/unit/license_spec.rb
@@ -1,5 +1,5 @@
 # encoding: utf-8
-require 'spec_helper'
+require_relative '../spec_helper'
 require 'rakelib/default_plugins'
 
 describe "Project licenses" do
diff --git a/versions.yml b/versions.yml
index 2c59dc0832a..a86e36b628e 100644
--- a/versions.yml
+++ b/versions.yml
@@ -1,5 +1,4 @@
 ---
 logstash: 6.0.0-alpha1
 logstash-core: 6.0.0-alpha1
-logstash-core-event: 6.0.0-alpha1
 logstash-core-plugin-api: 2.1.16
