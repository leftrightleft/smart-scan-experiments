diff --git a/docs/static/advanced-pipeline.asciidoc b/docs/static/advanced-pipeline.asciidoc
index c5e209c5b4e..7687e67ef7d 100644
--- a/docs/static/advanced-pipeline.asciidoc
+++ b/docs/static/advanced-pipeline.asciidoc
@@ -47,7 +47,6 @@ filebeat.inputs:
 output.logstash:
   hosts: ["localhost:5044"]
 --------------------------------------------------------------------------------
-
 <1> Absolute path to the file or files that Filebeat processes.
 
 Save your changes.
@@ -732,7 +731,6 @@ filebeat.inputs:
 output.logstash:
   hosts: ["localhost:5044"]
 --------------------------------------------------------------------------------
-
 <1> Absolute path to the file or files that Filebeat processes.
 <2> Adds a field called `type` with the value `syslog` to the event.
 
diff --git a/docs/static/azure-module.asciidoc b/docs/static/azure-module.asciidoc
index 96ac77970a8..1f202877105 100644
--- a/docs/static/azure-module.asciidoc
+++ b/docs/static/azure-module.asciidoc
@@ -125,7 +125,6 @@ modules:
       - "Endpoint=sb://...EntityPath=insights-logs-querystorewaitstatistics"
       - "Endpoint=sb://...EntityPath=insights-logs-timeouts"
 -----
-
 <1> The `consumer_group` (optional) is highly recommended. See <<azure_best_practices>>.
 <2> The `storage_connection` (optional) sets the Azure Blob Storage connection for tracking processing state for Event Hubs when scaling out a deployment with multiple Logstash instances. See <<scaling-blob>> for additional details.
 <3> See <<azure_best_practices>> for guidelines on choosing an appropriate number of threads.
@@ -168,7 +167,7 @@ modules:
     var.input.azure_event_hubs.event_hubs:
       - ["name",                                    "initial_position",  "storage_container",  "decorate_events",  "event_hub_connection"]                                   <3>
       - ["insights-operational-logs",                 "TAIL",              "activity-logs1",    "true",             "Endpoint=sb://...EntityPath=insights-operational-logs"]
-      - ["insights-operational-logs",                 "TAIL",              "activity_logs2",<4>   "true",             "Endpoint=sb://...EntityPath=insights-operational-logs"] 
+      - ["insights-operational-logs",                 "TAIL",              "activity_logs2",  "true",             "Endpoint=sb://...EntityPath=insights-operational-logs"]   <4>  
       - ["insights-metrics-pt1m",                     "TAIL",              "dbmetrics",         "true",             "Endpoint=sb://...EntityPath=insights-metrics-pt1m"]
       - ["insights-logs-blocks",                      "TAIL",              "dbblocks",          "true",             "Endpoint=sb://...EntityPath=insights-logs-blocks"]
       - ["insights-logs-databasewaitstatistics",      "TAIL",              "dbwaitstats",       "false",            "Endpoint=sb://...EntityPath=insights-logs-databasewaitstatistics"]
@@ -177,7 +176,6 @@ modules:
       - ["insights-logs-querystorewaitstatistics",    "TAIL",              "dbstorewaitstats",  "true",             "Endpoint=sb://...EntityPath=insights-logs-querystorewaitstatistics"]
       - ["insights-logs-timeouts",                    "TAIL",              "dbtimeouts",        "true",             "Endpoint=sb://...EntityPath=insights-logs-timeouts"]
 -----
-
 <1> You can specify global Event Hub options. They will be overridden by any configurations specified in the event_hubs option.
 <2> See <<azure_best_practices>> for guidelines on choosing an appropriate number of threads.
 <3> The header array must be defined with name in the first position. Other options can be defined in any order. The per Event Hub configuration takes precedence. Any values not defined per Event Hub use the global config value.
diff --git a/docs/static/dead-letter-queues.asciidoc b/docs/static/dead-letter-queues.asciidoc
index 5b63cd7c500..9bb3b7936e2 100644
--- a/docs/static/dead-letter-queues.asciidoc
+++ b/docs/static/dead-letter-queues.asciidoc
@@ -103,7 +103,6 @@ output {
   }
 }
 --------------------------------------------------------------------------------
-
 <1> The path to the top-level directory containing the dead letter queue. This
 directory contains a separate folder for each pipeline that writes to the dead
 letter queue. To find the path to this directory, look at the `logstash.yml`
@@ -212,7 +211,6 @@ output {
   } 
 }
 --------------------------------------------------------------------------------
-
 <1> The <<plugins-inputs-dead_letter_queue,`dead_letter_queue` input>> reads from the dead letter queue.
 <2> The `mutate` filter removes the problem field called `location`.
 <3> The clean event is sent to Elasticsearch, where it can be indexed because
diff --git a/docs/static/maintainer-guide.asciidoc b/docs/static/maintainer-guide.asciidoc
index 7d3e0c9a029..ea4272a0089 100644
--- a/docs/static/maintainer-guide.asciidoc
+++ b/docs/static/maintainer-guide.asciidoc
@@ -110,27 +110,27 @@ Please see following annotated example and see a concrete example in https://raw
 
 [source,markdown]
 ----
-## 1.0.x                              // <1> <2>
- - change description                 // <3>
- - tag: change description            // <3> <4>
- - tag1,tag2: change description      // <3> <5>
- - tag: Multi-line description        // <3> <6>
+## 1.0.x                              // <1>
+ - change description                 // <2>
+ - tag: change description            // <3>
+ - tag1,tag2: change description      // <4>
+ - tag: Multi-line description        // <5>
    must be indented and can use
    additional markdown syntax
-                                      // <7>
-## 1.0.0                              // <8>
+                                      // <6>
+## 1.0.0                              // <7>
 [...]
 
 ----
-<1> Latest version is the first line of CHANGELOG.md
-<2> Each version identifier should be a level-2 header using `##`
-<3> One change description is described as a list item using a dash `-` aligned under the version identifier
-<4> One change can be tagged by a word and suffixed by `:`. +
+<1> Latest version is the first line of CHANGELOG.md.
+Each version identifier should be a level-2 header using `##`
+<2> One change description is described as a list item using a dash `-` aligned under the version identifier
+<3> One change can be tagged by a word and suffixed by `:`. +
     Common tags are `bugfix`, `feature`, `doc`, `test` or `internal`.
-<5> One change can have multiple tags separated by a comma and suffixed by `:`
-<6> A multi-line change description must be properly indented
-<7> Please take care to *separate versions with an empty line*
-<8> Previous version identifier
+<4> One change can have multiple tags separated by a comma and suffixed by `:`
+<5> A multi-line change description must be properly indented
+<6> Please take care to *separate versions with an empty line*
+<7> Previous version identifier
 
 [float]
 ==== Continuous Integration
diff --git a/docs/static/monitoring-apis.asciidoc b/docs/static/monitoring-apis.asciidoc
index 33e301da237..9209131f98a 100644
--- a/docs/static/monitoring-apis.asciidoc
+++ b/docs/static/monitoring-apis.asciidoc
@@ -134,7 +134,7 @@ curl -XGET 'localhost:9600/_node/pipelines/test?pretty'
 Example response:
 
 [source,json]
---------------------------------------------------
+----------
 {
   "pipelines" : {
     "test" : {
@@ -145,7 +145,7 @@ Example response:
       "config_reload_interval" : 3
     }
   }
-------------------------------------------------
+----------
 
 If you specify an invalid pipeline ID, the request returns a 404 Not Found error.
 
diff --git a/docs/static/plugin-generator.asciidoc b/docs/static/plugin-generator.asciidoc
index cd18d1d6713..8b30bf31bf7 100644
--- a/docs/static/plugin-generator.asciidoc
+++ b/docs/static/plugin-generator.asciidoc
@@ -8,7 +8,7 @@ can start adding custom code to process data with Logstash.
 **Example Usage**
 
 [source,sh]
---------------------------------------------
+-------------------------------------------
 bin/logstash-plugin generate --type input --name xkcd --path ~/ws/elastic/plugins
 -------------------------------------------
 
diff --git a/docs/static/running-logstash.asciidoc b/docs/static/running-logstash.asciidoc
index a7a1e70d81c..cdda6db0aa4 100644
--- a/docs/static/running-logstash.asciidoc
+++ b/docs/static/running-logstash.asciidoc
@@ -24,7 +24,7 @@ Distributions like Debian Jessie, Ubuntu 15.10+, and many of the SUSE derivative
 `systemctl` command to start and stop services. Logstash places the systemd unit files in `/etc/systemd/system` for both deb and rpm. After installing the package, you can start up Logstash with:
 
 [source,sh]
---------------------------------------------
+-------------------------------------------
 sudo systemctl start logstash.service
 -------------------------------------------
 
@@ -34,7 +34,7 @@ sudo systemctl start logstash.service
 For systems that use upstart, you can start Logstash with:
 
 [source,sh]
---------------------------------------------
+-------------------------------------------
 sudo initctl start logstash
 -------------------------------------------
 
@@ -46,7 +46,7 @@ The auto-generated configuration file for upstart systems is `/etc/init/logstash
 For systems that use SysV, you can start Logstash with:
 
 [source,sh]
---------------------------------------------
+-------------------------------------------
 sudo /etc/init.d/logstash start
 -------------------------------------------
 
diff --git a/docs/static/security/logstash.asciidoc b/docs/static/security/logstash.asciidoc
index 2d7bdca993c..c5491089412 100644
--- a/docs/static/security/logstash.asciidoc
+++ b/docs/static/security/logstash.asciidoc
@@ -54,14 +54,11 @@ POST _xpack/security/role/logstash_writer
   ]
 }
 ---------------------------------------------------------------
-
 <1> The cluster needs the `manage_ilm` privilege if 
 {ref}/getting-started-index-lifecycle-management.html[index lifecycle management]
 is enabled.
-
 <2> If you use a custom Logstash index pattern, specify your custom pattern
 instead of the default `logstash-*` pattern.
-
 <3> If {ref}/getting-started-index-lifecycle-management.html[index lifecycle
 management] is enabled, the role requires the `manage` and `manage_ilm`
 privileges to load index lifecycle policies, create rollover aliases, and create
@@ -133,7 +130,6 @@ POST _xpack/security/role/logstash_reader
   ]
 }
 ---------------------------------------------------------------
-
 <1> If you use a custom Logstash index pattern, specify that pattern
 instead of the default `logstash-*` pattern.
 
@@ -152,7 +148,6 @@ POST _xpack/security/user/logstash_user
   "full_name" : "Kibana User for Logstash"
 }
 ---------------------------------------------------------------
-
 <1> `logstash_admin` is a built-in role that provides access to `.logstash-*`
 indices for managing configurations.
 
@@ -260,6 +255,5 @@ You configure the user and password in the `logstash.yml` configuration file:
 xpack.management.elasticsearch.username: logstash_admin_user <1>
 xpack.management.elasticsearch.password: t0p.s3cr3t
 ----------------------------------------------------------
-
 <1> The user you specify here must have the built-in `logstash_admin` role as
 well as the `logstash_writer` role that you created earlier.
diff --git a/docs/static/transforming-data.asciidoc b/docs/static/transforming-data.asciidoc
index 769578ab736..9c2e8125e7d 100644
--- a/docs/static/transforming-data.asciidoc
+++ b/docs/static/transforming-data.asciidoc
@@ -535,7 +535,7 @@ filter {
     # using add_field here to add & rename values to the event root
     add_field => { server_name => "%{[server][0][description]}" }
     add_field => { user_firstname => "%{[user][0][firstname]}" } <5>
-    add_field => { user_lastname => "%{[user][0][lastname]}" } <5>
+    add_field => { user_lastname => "%{[user][0][lastname]}" }
     remove_field => ["server", "user"]
     jdbc_user => "logstash"
     jdbc_password => "example"
