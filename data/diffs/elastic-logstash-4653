diff --git a/Gemfile b/Gemfile
index 060844f1798..92cc9a5533a 100644
--- a/Gemfile
+++ b/Gemfile
@@ -21,4 +21,5 @@ gem "stud", "~> 0.0.21", :group => :build
 gem "fpm", "~> 1.3.3", :group => :build
 gem "rubyzip", "~> 1.1.7", :group => :build
 gem "gems", "~> 0.8.3", :group => :build
+gem "rack-test", :require => "rack/test", :group => :development
 gem "flores", "~> 0.0.6", :group => :development
diff --git a/Gemfile.jruby-1.9.lock b/Gemfile.jruby-1.9.lock
index 88eecdc7059..69163d4626a 100644
--- a/Gemfile.jruby-1.9.lock
+++ b/Gemfile.jruby-1.9.lock
@@ -3,25 +3,31 @@ PATH
   specs:
     logstash-core (3.0.0.dev-java)
       cabin (~> 0.8.0)
+      chronic_duration (= 0.10.6)
       clamp (~> 0.6.5)
-      concurrent-ruby (= 0.9.2)
+      concurrent-ruby (= 1.0.0)
       filesize (= 0.0.4)
       gems (~> 0.8.3)
       i18n (= 0.6.9)
       jrjackson (~> 0.3.7)
+      jruby-monitoring (~> 0.1)
       jruby-openssl (= 0.9.13)
-      logstash-core-event (~> 3.0.0.dev)
+      logstash-core-event-java (~> 3.0.0.dev)
       minitar (~> 0.5.4)
       pry (~> 0.10.1)
+      puma (~> 2.15, >= 2.15.3)
       rubyzip (~> 1.1.7)
+      sinatra (~> 1.4, >= 1.4.6)
       stud (~> 0.0.19)
       thread_safe (~> 0.3.5)
       treetop (< 1.5.0)
 
 PATH
-  remote: ./logstash-core-event
+  remote: ./logstash-core-event-java
   specs:
-    logstash-core-event (3.0.0.dev-java)
+    logstash-core-event-java (3.0.0.dev-java)
+      jar-dependencies
+      ruby-maven (~> 3.3.9)
 
 GEM
   remote: https://rubygems.org/
@@ -35,6 +41,8 @@ GEM
     cabin (0.8.1)
     childprocess (0.5.9)
       ffi (~> 1.0, >= 1.0.11)
+    chronic_duration (0.10.6)
+      numerizer (~> 0.1.1)
     ci_reporter (2.0.0)
       builder (>= 2.1.2)
     ci_reporter_rspec (1.0.0)
@@ -42,7 +50,7 @@ GEM
       rspec (>= 2.14, < 4)
     clamp (0.6.5)
     coderay (1.1.0)
-    concurrent-ruby (0.9.2-java)
+    concurrent-ruby (1.0.0-java)
     coveralls (0.8.10)
       json (~> 1.8)
       rest-client (>= 1.6.8, < 2)
@@ -52,7 +60,7 @@ GEM
       tins (~> 1.6.0)
     diff-lcs (1.2.5)
     docile (1.1.5)
-    domain_name (0.5.25)
+    domain_name (0.5.20160128)
       unf (>= 0.0.5, < 1.0.0)
     faraday (0.9.2)
       multipart-post (>= 1.2, < 3)
@@ -75,7 +83,9 @@ GEM
       domain_name (~> 0.5)
     i18n (0.6.9)
     insist (1.0.0)
+    jar-dependencies (0.3.2)
     jrjackson (0.3.8)
+    jruby-monitoring (0.3.0)
     jruby-openssl (0.9.13-java)
     json (1.8.3-java)
     kramdown (1.9.0)
@@ -93,6 +103,7 @@ GEM
     minitar (0.5.4)
     multipart-post (2.0.0)
     netrc (0.11.0)
+    numerizer (0.1.1)
     octokit (3.8.0)
       sawyer (~> 0.6.0, >= 0.5.3)
     polyglot (0.3.5)
@@ -101,7 +112,13 @@ GEM
       method_source (~> 0.8.1)
       slop (~> 3.4)
       spoon (~> 0.0)
-    rake (10.4.2)
+    puma (2.16.0-java)
+    rack (1.6.4)
+    rack-protection (1.5.3)
+      rack
+    rack-test (0.6.3)
+      rack (>= 1.0)
+    rake (10.5.0)
     rest-client (1.8.0)
       http-cookie (>= 1.0.2, < 2.0)
       mime-types (>= 1.16, < 3.0)
@@ -120,15 +137,22 @@ GEM
     rspec-support (3.1.2)
     rspec-wait (0.0.8)
       rspec (>= 2.11, < 3.5)
+    ruby-maven (3.3.9)
+      ruby-maven-libs (~> 3.3.1)
+    ruby-maven-libs (3.3.3)
     rubyzip (1.1.7)
     sawyer (0.6.0)
       addressable (~> 2.3.5)
       faraday (~> 0.8, < 0.10)
-    simplecov (0.11.1)
+    simplecov (0.11.2)
       docile (~> 1.1.0)
       json (~> 1.8)
       simplecov-html (~> 0.10.0)
     simplecov-html (0.10.0)
+    sinatra (1.4.7)
+      rack (~> 1.5)
+      rack-protection (~> 1.4)
+      tilt (>= 1.3, < 3)
     slop (3.6.0)
     spoon (0.0.4)
       ffi
@@ -137,6 +161,7 @@ GEM
       tins (~> 1.0)
     thor (0.19.1)
     thread_safe (0.3.5-java)
+    tilt (2.0.2)
     tins (1.6.0)
     treetop (1.4.15)
       polyglot
@@ -155,9 +180,10 @@ DEPENDENCIES
   fpm (~> 1.3.3)
   gems (~> 0.8.3)
   logstash-core (= 3.0.0.dev)!
-  logstash-core-event (= 3.0.0.dev)!
+  logstash-core-event-java (= 3.0.0.dev)!
   logstash-devutils (~> 0.0.15)
   octokit (= 3.8.0)
+  rack-test
   rspec (~> 3.1.0)
   rubyzip (~> 1.1.7)
   simplecov
diff --git a/benchmark/collector.rb b/benchmark/collector.rb
new file mode 100644
index 00000000000..b8bbdeb1090
--- /dev/null
+++ b/benchmark/collector.rb
@@ -0,0 +1,3 @@
+# encoding: utf-8
+require "benchmark/ips"
+require "logstash/instrument/collector"
diff --git a/benchmark/event_sprintf.rb b/benchmark/event_sprintf.rb
index 718d1fd6149..9bce01d6b2f 100644
--- a/benchmark/event_sprintf.rb
+++ b/benchmark/event_sprintf.rb
@@ -1,3 +1,4 @@
+# encoding: utf-8
 require "benchmark/ips"
 require "lib/logstash/event"
 
diff --git a/logstash-core/lib/logstash/agent.rb b/logstash-core/lib/logstash/agent.rb
index 89dd0c8e9c5..a036d2fb18e 100644
--- a/logstash-core/lib/logstash/agent.rb
+++ b/logstash-core/lib/logstash/agent.rb
@@ -2,7 +2,13 @@
 require "logstash/environment"
 require "logstash/errors"
 require "logstash/config/cpu_core_strategy"
+require "logstash/instrument/collector"
+require "logstash/instrument/metric"
+require "logstash/instrument/periodic_pollers"
+require "logstash/instrument/collector"
+require "logstash/instrument/metric"
 require "logstash/pipeline"
+require "logstash/webserver"
 require "stud/trap"
 require "logstash/config/loader"
 require "uri"
@@ -12,7 +18,9 @@
 LogStash::Environment.load_locale!
 
 class LogStash::Agent
-  attr_reader :logger, :pipelines
+  STARTED_AT = Time.now.freeze
+
+  attr_reader :metric, :node_name, :pipelines, :logger
 
   # initialize method for LogStash::Agent
   # @param params [Hash] potential parameters are:
@@ -23,19 +31,27 @@ class LogStash::Agent
   def initialize(params)
     @logger = params[:logger]
     @auto_reload = params[:auto_reload]
-    @pipelines = {}
 
+    @pipelines = {}
     @node_name = params[:node_name] || Socket.gethostname
+    @web_api_http_host = params[:web_api_http_host]
+    @web_api_http_port = params[:web_api_http_port]
+
     @config_loader = LogStash::Config::Loader.new(@logger)
     @reload_interval = params[:reload_interval] || 3 # seconds
     @upgrade_mutex = Mutex.new
+
+    @collect_metric = params.fetch(:collect_metric, false)
+    setup_metric_collection
   end
 
   def execute
     @thread = Thread.current # this var is implicilty used by Stud.stop?
     @logger.info("starting agent")
 
+    start_background_services
     start_pipelines
+    start_webserver
 
     return 1 if clean_state?
 
@@ -59,7 +75,7 @@ def execute
   # @param settings [Hash] settings that will be passed when creating the pipeline.
   #   keys should be symbols such as :pipeline_workers and :pipeline_batch_delay
   def register_pipeline(pipeline_id, settings)
-    pipeline = create_pipeline(settings.merge(:pipeline_id => pipeline_id))
+    pipeline = create_pipeline(settings.merge(:pipeline_id => pipeline_id, :metric => metric))
     return unless pipeline.is_a?(LogStash::Pipeline)
     @pipelines[pipeline_id] = pipeline
   end
@@ -76,15 +92,67 @@ def reload_state!
     end
   end
 
+  # Calculate the Logstash uptime in milliseconds
+  #
+  # @return [Fixnum] Uptime in milliseconds
+  def uptime
+    ((Time.now.to_f - STARTED_AT.to_f) * 1000.0).to_i
+  end
+
   def shutdown
+    stop_background_services
+    stop_webserver
     shutdown_pipelines
   end
 
-  private
   def node_uuid
     @node_uuid ||= SecureRandom.uuid
   end
 
+  private
+  def start_webserver
+    options = {:http_host => @web_api_http_host, :http_port => @web_api_http_port }
+    @webserver = LogStash::WebServer.new(@logger, options)
+    Thread.new(@webserver) do |webserver|
+      LogStash::Util.set_thread_name("Api Webserver")
+      webserver.run
+    end
+  end
+
+  def stop_webserver
+    @webserver.stop if @webserver
+  end
+
+  def start_background_services
+    if collect_metrics?
+      @logger.debug("Agent: Starting metric periodic pollers")
+      @periodic_pollers.start
+    end
+  end
+
+  def stop_background_services
+    if collect_metrics?
+      @logger.debug("Agent: Stopping metric periodic pollers")
+      @periodic_pollers.stop
+    end
+  end
+
+  def setup_metric_collection
+    if collect_metrics?
+      @logger.debug("Agent: Configuring metric collection")
+      LogStash::Instrument::Collector.instance.agent = self
+      @metric = LogStash::Instrument::Metric.new
+    else
+      @metric = LogStash::Instrument::NullMetric.new
+    end
+
+    @periodic_pollers = LogStash::Instrument::PeriodicPollers.new(metric)
+  end
+
+  def collect_metrics?
+    @collect_metric
+  end
+
   def create_pipeline(settings)
     begin
       config = fetch_config(settings)
@@ -174,5 +242,4 @@ def upgrade_pipeline(pipeline_id, new_pipeline)
   def clean_state?
     @pipelines.empty?
   end
-
 end # class LogStash::Agent
diff --git a/logstash-core/lib/logstash/api/init.ru b/logstash-core/lib/logstash/api/init.ru
new file mode 100644
index 00000000000..550092f1d0e
--- /dev/null
+++ b/logstash-core/lib/logstash/api/init.ru
@@ -0,0 +1,29 @@
+ROOT = File.expand_path(File.dirname(__FILE__))
+$LOAD_PATH.unshift File.join(ROOT, 'lib')
+Dir.glob('lib/**').each{ |d| $LOAD_PATH.unshift(File.join(ROOT, d)) }
+
+require 'sinatra'
+require 'app/root'
+require 'app/modules/stats'
+require 'app/modules/node'
+require 'app/modules/node_stats'
+
+env = ENV["RACK_ENV"].to_sym
+set :environment, env
+
+set :service, LogStash::Api::Service.instance
+
+configure do
+  enable :logging
+end
+run LogStash::Api::Root
+
+namespaces = { "/_node" => LogStash::Api::Node,
+               "/_node/stats" => LogStash::Api::NodeStats,
+               "/_stats" => LogStash::Api::Stats }
+
+namespaces.each_pair do |namespace, app|
+  map(namespace) do
+    run app
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app.rb b/logstash-core/lib/logstash/api/lib/app.rb
new file mode 100644
index 00000000000..72946ec6707
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app.rb
@@ -0,0 +1,40 @@
+# encoding: utf-8
+require "cabin"
+require "logstash/json"
+require "helpers/app_helpers"
+require "app/service"
+require "app/command_factory"
+require "logstash/util/loggable"
+
+module LogStash::Api
+  class BaseApp < ::Sinatra::Application
+
+    attr_reader :factory
+
+    if settings.environment != :production
+      set :raise_errors, true
+      set :show_exceptions, :after_handler
+    end
+
+    include LogStash::Util::Loggable
+
+    helpers AppHelpers
+
+    def initialize(app=nil)
+      super(app)
+      @factory = CommandFactory.new(settings.service)
+    end
+
+    not_found do
+      status 404
+      as   = params.has_key?("human") ? :string : :json
+      text = as == :string ? "" : {}
+      respond_with(text, :as => as)
+    end
+
+    error do
+      logger.error(env['sinatra.error'].message, :url => request.url, :ip => request.ip, :params => request.params)
+    end
+
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/command.rb b/logstash-core/lib/logstash/api/lib/app/command.rb
new file mode 100644
index 00000000000..75d8f958c6b
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/command.rb
@@ -0,0 +1,29 @@
+# encoding: utf-8
+require "app/service"
+
+module LogStash::Api
+  class Command
+
+    attr_reader :service
+
+    def initialize(service = LogStash::Api::Service.instance)
+      @service = service
+    end
+
+    def run
+      raise "Not implemented"
+    end
+
+    def hostname
+      service.agent.node_name
+    end
+
+    def uptime
+      service.agent.uptime
+    end
+
+    def started_at
+      (LogStash::Agent::STARTED_AT.to_f * 1000.0).to_i
+    end
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/command_factory.rb b/logstash-core/lib/logstash/api/lib/app/command_factory.rb
new file mode 100644
index 00000000000..7de93384649
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/command_factory.rb
@@ -0,0 +1,27 @@
+# encoding: utf-8
+require "app/service"
+require "app/commands/system/basicinfo_command"
+require "app/commands/stats/events_command"
+require "app/commands/stats/hotthreads_command"
+require "app/commands/stats/memory_command"
+
+module LogStash::Api
+  class CommandFactory
+
+    attr_reader :factory, :service
+
+    def initialize(service)
+      @service = service
+      @factory = {}.merge(
+        :system_basic_info => SystemBasicInfoCommand,
+        :events_command => StatsEventsCommand,
+        :hot_threads_command => HotThreadsCommand,
+        :memory_command => JvmMemoryCommand
+      )
+    end
+
+    def build(klass)
+      factory[klass].new(service)
+    end
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/commands/stats/events_command.rb b/logstash-core/lib/logstash/api/lib/app/commands/stats/events_command.rb
new file mode 100644
index 00000000000..78337364548
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/commands/stats/events_command.rb
@@ -0,0 +1,13 @@
+# encoding: utf-8
+require "app/command"
+
+class LogStash::Api::StatsEventsCommand < LogStash::Api::Command
+
+  def run
+    #return whatever is comming out of the snapshot event, this obvoiusly
+    #need to be tailored to the right metrics for this command.
+    stats =  LogStash::Json.load(service.get(:events_stats))
+    stats["stats"]["events"]
+  end
+
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/commands/stats/hotthreads_command.rb b/logstash-core/lib/logstash/api/lib/app/commands/stats/hotthreads_command.rb
new file mode 100644
index 00000000000..0c3f4ee2ef7
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/commands/stats/hotthreads_command.rb
@@ -0,0 +1,120 @@
+# encoding: utf-8
+require "app/command"
+require 'monitoring'
+require "socket"
+
+class LogStash::Api::HotThreadsCommand < LogStash::Api::Command
+
+  STACK_TRACES_SIZE_DEFAULT = 10.freeze
+
+  def run(options={})
+    filter = { :stacktrace_size => options.fetch(:stacktrace_size, STACK_TRACES_SIZE_DEFAULT) }
+    hash   = JRMonitor.threads.generate(filter)
+    ThreadDump.new(hash, self, options)
+  end
+
+  private
+
+  class ThreadDump
+
+    SKIPPED_THREADS             = [ "Finalizer", "Reference Handler", "Signal Dispatcher" ].freeze
+    THREADS_COUNT_DEFAULT       = 3.freeze
+    IGNORE_IDLE_THREADS_DEFAULT = true.freeze
+
+    attr_reader :top_count, :ignore, :dump
+
+    def initialize(dump, cmd, options={})
+      @dump      = dump
+      @options   = options
+      @top_count = options.fetch(:threads, THREADS_COUNT_DEFAULT)
+      @ignore    = options.fetch(:ignore_idle_threads, IGNORE_IDLE_THREADS_DEFAULT)
+      @cmd       = cmd
+    end
+
+    def to_s
+      hash = to_hash
+      report =  "#{I18n.t("logstash.web_api.hot_threads.title", :hostname => hash[:hostname], :time => hash[:time], :top_count => top_count )} \n"
+      hash[:threads].each do |thread|
+        thread_report = ""
+        thread_report = "\t #{I18n.t("logstash.web_api.hot_threads.thread_title", :percent_of_cpu_time => thread[:percent_of_cpu_time], :thread_state => thread[:state], :thread_name => thread[:name])} \n"
+        thread_report = "\t #{thread[:percent_of_cpu_time]} % of of cpu usage by #{thread[:state]} thread named '#{thread[:name]}'\n"
+        thread_report << "\t\t #{thread[:path]}\n" if thread[:path]
+        thread[:traces].split("\n").each do |trace|
+          thread_report << "#{trace}\n"
+        end
+        report << thread_report
+      end
+      report
+    end
+
+    def to_hash
+      hash = { :hostname => hostname, :time => Time.now.iso8601, :busiest_threads => top_count, :threads => [] }
+      each do |thread_name, _hash|
+        thread_name, thread_path = _hash["thread.name"].split(": ")
+        thread = { :name => thread_name,
+                   :percent_of_cpu_time => cpu_time_as_percent(_hash),
+                   :state => _hash["thread.state"]
+        }
+        thread[:path] = thread_path if thread_path
+        traces = ""
+        _hash["thread.stacktrace"].each do |trace|
+          traces << "\t\t#{trace}\n"
+        end
+        thread[:traces] = traces unless traces.empty?
+        hash[:threads] << thread
+      end
+      hash
+    end
+
+    private
+
+    def each(&block)
+      i=0
+      dump.each_pair do |thread_name, _hash|
+        break if i >= top_count
+        if ignore
+          next if idle_thread?(thread_name, _hash)
+        end
+        block.call(thread_name, _hash)
+        i += 1
+      end
+    end
+
+    def idle_thread?(thread_name, data)
+      idle = false
+      if SKIPPED_THREADS.include?(thread_name)
+        # these are likely JVM dependent
+        idle = true
+      elsif thread_name.match(/Ruby-\d+-JIT-\d+/)
+        # This are internal JRuby JIT threads, 
+        # see java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor for details.
+        idle = true
+      elsif thread_name.match(/pool-\d+-thread-\d+/)
+        # This are threads used by the internal JRuby implementation to dispatch
+        # calls and tasks, see prg.jruby.internal.runtime.methods.DynamicMethod.call
+        idle = true
+      else
+        data["thread.stacktrace"].each do |trace|
+          if trace.start_with?("java.util.concurrent.ThreadPoolExecutor.getTask")
+            idle = true
+            break
+          end
+        end
+      end
+      idle
+    end
+
+    def hostname
+      @cmd.hostname
+    end
+
+    def cpu_time_as_percent(hash)
+      (((cpu_time(hash) / @cmd.uptime * 1.0)*10000).to_i)/100.0
+    end
+
+    def cpu_time(hash)
+      hash["cpu.time"] / 1000000.0
+    end
+  end
+
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/commands/stats/memory_command.rb b/logstash-core/lib/logstash/api/lib/app/commands/stats/memory_command.rb
new file mode 100644
index 00000000000..b6aa34f5d42
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/commands/stats/memory_command.rb
@@ -0,0 +1,25 @@
+# encoding: utf-8
+require "app/command"
+require 'monitoring'
+
+class LogStash::Api::JvmMemoryCommand < LogStash::Api::Command
+
+  def run
+    memory = LogStash::Json.load(service.get(:jvm_memory_stats))
+    {
+      :heap_used_in_bytes => memory["heap"]["used_in_bytes"],
+      :heap_used_percent => memory["heap"]["used_percent"],
+      :heap_committed_in_bytes => memory["heap"]["committed_in_bytes"],
+      :heap_max_in_bytes => memory["heap"]["max_in_bytes"],
+      :heap_used_in_bytes => memory["heap"]["used_in_bytes"],
+      :non_heap_used_in_bytes => memory["non_heap"]["used_in_bytes"],
+      :non_heap_committed_in_bytes => memory["non_heap"]["committed_in_bytes"],
+      :pools => memory["pools"].inject({}) do |acc, (type, hash)|
+          hash.delete("committed_in_bytes")
+          acc[type] = hash
+          acc
+    end
+    }
+  end
+
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/commands/system/basicinfo_command.rb b/logstash-core/lib/logstash/api/lib/app/commands/system/basicinfo_command.rb
new file mode 100644
index 00000000000..0822f54fb6a
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/commands/system/basicinfo_command.rb
@@ -0,0 +1,15 @@
+# encoding: utf-8
+require "app/command"
+require "logstash/util/duration_formatter"
+
+class LogStash::Api::SystemBasicInfoCommand < LogStash::Api::Command
+
+  def run
+    {
+      "hostname" => hostname,
+      "version" => {
+        "number" => LOGSTASH_VERSION
+      }
+    }
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/modules/node.rb b/logstash-core/lib/logstash/api/lib/app/modules/node.rb
new file mode 100644
index 00000000000..3edfb0de5a1
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/modules/node.rb
@@ -0,0 +1,25 @@
+# encoding: utf-8
+require "app"
+
+module LogStash::Api
+  class Node < BaseApp
+
+    helpers AppHelpers
+
+    # return hot threads information
+    get "/hot_threads" do
+      ignore_idle_threads = params["ignore_idle_threads"] || true
+
+      options = {
+        :ignore_idle_threads => as_boolean(ignore_idle_threads),
+        :human => params.has_key?("human")
+      }
+      options[:threads] = params["threads"].to_i if params.has_key?("threads")
+
+      command = factory.build(:hot_threads_command)
+      as    = options[:human] ? :string : :json
+      respond_with(command.run(options), {:as => as})
+    end
+
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/modules/node_stats.rb b/logstash-core/lib/logstash/api/lib/app/modules/node_stats.rb
new file mode 100644
index 00000000000..8f9e7392485
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/modules/node_stats.rb
@@ -0,0 +1,43 @@
+# encoding: utf-8
+require "app"
+
+module LogStash::Api
+  class NodeStats < BaseApp
+
+    helpers AppHelpers
+
+
+    # Global _stats resource where all information is 
+    # retrieved and show
+    get "/" do
+      events_command = factory.build(:events_command)
+      memory_command = factory.build(:memory_command)
+      payload = {
+        :events => events_command.run,
+        :start_time_in_millis => events_command.started_at,
+        :jvm => { :memory => memory_command.run }
+      }
+      respond_with payload
+    end
+
+    # Show all events stats information
+    # (for ingested, emitted, dropped)
+    # - #events since startup
+    # - #data (bytes) since startup
+    # - events/s
+    # - bytes/s
+    # - dropped events/s
+    # - events in the pipeline
+    get "/events" do
+      command = factory.build(:events_command)
+      respond_with({ :events => command.run })
+    end
+
+    # return hot threads information
+    get "/jvm" do
+      command = factory.build(:memory_command)
+      respond_with({ :memory => command.run })
+    end
+
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/modules/stats.rb b/logstash-core/lib/logstash/api/lib/app/modules/stats.rb
new file mode 100644
index 00000000000..ed3aa54f789
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/modules/stats.rb
@@ -0,0 +1,21 @@
+# encoding: utf-8
+require "app"
+
+module LogStash::Api
+  class Stats < BaseApp
+
+    helpers AppHelpers
+
+    # return hot threads information
+    get "/jvm" do
+      command = factory.build(:memory_command)
+      jvm_payload = {
+        :timestamp => command.started_at,
+        :uptime_in_millis => command.uptime,
+        :mem => command.run
+      }
+      respond_with({:jvm => jvm_payload})
+    end
+
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/root.rb b/logstash-core/lib/logstash/api/lib/app/root.rb
new file mode 100644
index 00000000000..75a0ba6be67
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/root.rb
@@ -0,0 +1,13 @@
+# encoding: utf-8
+require "app"
+
+module LogStash::Api
+  class Root < BaseApp
+
+    get "/" do
+      command = factory.build(:system_basic_info)
+      respond_with command.run
+    end
+
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/service.rb b/logstash-core/lib/logstash/api/lib/app/service.rb
new file mode 100644
index 00000000000..b8396e07577
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/service.rb
@@ -0,0 +1,43 @@
+# encoding: utf-8
+require "logstash/instrument/collector"
+require "logstash/util/loggable"
+
+class LogStash::Api::Service
+
+  include Singleton
+  include LogStash::Util::Loggable
+
+  def initialize
+    @snapshot_rotation_mutex = Mutex.new
+    @snapshot = nil
+    logger.debug("[api-service] start") if logger.debug?
+    LogStash::Instrument::Collector.instance.add_observer(self)
+  end
+
+  def stop
+    logger.debug("[api-service] stop") if logger.debug?
+    LogStash::Instrument::Collector.instance.delete_observer(self)
+  end
+
+  def agent
+    LogStash::Instrument::Collector.instance.agent
+  end
+
+  def update(snapshot)
+    logger.debug("[api-service] snapshot received", :snapshot => snapshot) if logger.debug?
+    if @snapshot_rotation_mutex.try_lock
+      @snapshot = snapshot
+      @snapshot_rotation_mutex.unlock
+    end
+  end
+
+  def get(key)
+    metric_store = @snapshot.metric_store
+    if key == :jvm_memory_stats
+      data = metric_store.get_with_path("jvm/memory")[:jvm][:memory]
+    else
+      data = metric_store.get_with_path("stats/events")
+    end
+    LogStash::Json.dump(data)
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/stats.rb b/logstash-core/lib/logstash/api/lib/app/stats.rb
new file mode 100644
index 00000000000..2d3f9a4f08b
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/stats.rb
@@ -0,0 +1,56 @@
+# encoding: utf-8
+require "app"
+require "app/stats/events_command"
+require "app/stats/hotthreads_command"
+
+module LogStash::Api
+  class Stats < BaseApp
+
+    helpers AppHelpers
+
+
+    # Global _stats resource where all information is 
+    # retrieved and show
+    get "/" do
+      events_command = factory.build(:events_command)
+      memory_command = factory.build(:memory_command)
+      payload = {
+        :events => events_command.run,
+        :jvm => { :memory => memory_command.run }
+      }
+      respond_with payload
+    end
+
+    # Show all events stats information
+    # (for ingested, emitted, dropped)
+    # - #events since startup
+    # - #data (bytes) since startup
+    # - events/s
+    # - bytes/s
+    # - dropped events/s
+    # - events in the pipeline
+    get "/events" do
+      command = factory.build(:events_command)
+      respond_with({ :events => command.run })
+    end
+
+    # return hot threads information
+    get "/jvm/hot_threads" do
+      top_threads_count = params["threads"] || 3
+      ignore_idle_threads = params["ignore_idle_threads"] || true
+      options = {
+        :threads => top_threads_count.to_i,
+        :ignore_idle_threads => as_boolean(ignore_idle_threads)
+      }
+      command = factory.build(:hot_threads_command)
+      respond_with(command.run(options), :string)
+    end
+
+    # return hot threads information
+    get "/jvm/memory" do
+      command = factory.build(:memory_command)
+      respond_with({ :memory => command.run })
+    end
+
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/helpers/app_helpers.rb b/logstash-core/lib/logstash/api/lib/helpers/app_helpers.rb
new file mode 100644
index 00000000000..cd872edc51d
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/helpers/app_helpers.rb
@@ -0,0 +1,23 @@
+# encoding: utf-8
+require "logstash/json"
+
+module LogStash::Api::AppHelpers
+
+  def respond_with(data, options={})
+    as     = options.fetch(:as, :json)
+    pretty = params.has_key?("pretty")
+    if as == :json
+      content_type "application/json"
+      LogStash::Json.dump(data, {:pretty => pretty})
+    else
+      content_type "text/plain"
+      data.to_s
+    end
+  end
+
+  def as_boolean(string)
+    return true   if string == true   || string =~ (/(true|t|yes|y|1)$/i)
+    return false  if string == false  || string.blank? || string =~ (/(false|f|no|n|0)$/i)
+    raise ArgumentError.new("invalid value for Boolean: \"#{string}\"")
+  end
+end
diff --git a/logstash-core/lib/logstash/filter_delegator.rb b/logstash-core/lib/logstash/filter_delegator.rb
new file mode 100644
index 00000000000..ce2c71d6644
--- /dev/null
+++ b/logstash-core/lib/logstash/filter_delegator.rb
@@ -0,0 +1,63 @@
+# encoding: utf-8
+#
+module LogStash
+  class FilterDelegator
+    extend Forwardable
+
+    def_delegators :@filter,
+      :register,
+      :close,
+      :threadsafe?,
+      :do_close,
+      :do_stop,
+      :periodic_flush
+
+    def initialize(logger, klass, metric, *args)
+      options = args.reduce({}, :merge)
+
+      @logger = logger
+      @klass = klass
+      @filter = klass.new(options)
+
+      # Scope the metrics to the plugin
+      namespaced_metric = metric.namespace(@filter.id.to_sym)
+      @filter.metric = metric
+
+      @metric_events = namespaced_metric.namespace(:events)
+
+      # Not all the filters will do bufferings
+      define_flush_method if @filter.respond_to?(:flush)
+    end
+
+    def config_name
+      @klass.config_name
+    end
+
+    def multi_filter(events)
+      @metric_events.increment(:in, events.size)
+
+      new_events = @filter.multi_filter(events)
+
+      # There is no garantee in the context of filter
+      # that EVENTS_INT == EVENTS_OUT, see the aggregates and
+      # the split filter
+      @metric_events.increment(:out, new_events.size) unless new_events.nil?
+
+      return new_events
+    end
+
+    private
+    def define_flush_method
+      define_singleton_method(:flush) do |options = {}|
+        # we also need to trace the number of events
+        # coming from a specific filters.
+        new_events = @filter.flush(options)
+
+        # Filter plugins that does buffering or spooling of events like the
+        # `Logstash-filter-aggregates` can return `NIL` and will flush on the next flush ticks.
+        @metric_events.increment(:out, new_events.size) unless new_events.nil?
+        new_events
+      end
+    end
+  end
+end
diff --git a/logstash-core/lib/logstash/inputs/metrics.rb b/logstash-core/lib/logstash/inputs/metrics.rb
new file mode 100644
index 00000000000..8a8ce92dcf0
--- /dev/null
+++ b/logstash-core/lib/logstash/inputs/metrics.rb
@@ -0,0 +1,47 @@
+# encoding: utf-8
+require "logstash/event"
+require "logstash/inputs/base"
+require "logstash/instrument/collector"
+
+module LogStash module Inputs
+  # The Metrics inputs is responable of registring itself to the collector.
+  # The collector class will periodically emits new snapshot of the system,
+  # The metrics need to take that information and transform it into
+  # a `Logstash::Event`, which can be consumed by the shipper and send to
+  # Elasticsearch
+  class Metrics < LogStash::Inputs::Base
+    config_name "metrics"
+    milestone 3
+
+    def register
+    end
+
+    def run(queue)
+      @logger.debug("Metric: input started")
+      @queue = queue
+
+      # we register to the collector after receiving the pipeline queue
+      LogStash::Instrument::Collector.instance.add_observer(self)
+
+      # Keep this plugin thread alive,
+      # until we shutdown the metric pipeline
+      sleep(1) while !stop?
+    end
+
+    def stop
+      @logger.debug("Metrics input: stopped")
+      LogStash::Instrument::Collector.instance.delete_observer(self)
+    end
+
+    def update(snapshot)
+      @logger.debug("Metrics input: received a new snapshot", :created_at => snapshot.created_at, :snapshot => snapshot, :event => snapshot.metric_store.to_event) if @logger.debug?
+
+      # The back pressure is handled in the collector's
+      # scheduled task (running into his own thread) if something append to one of the listener it will
+      # will timeout. In a sane pipeline, with a low traffic of events it shouldn't be a problems.
+      snapshot.metric_store.each do |metric|
+        @queue << LogStash::Event.new({ "@timestamp" => snapshot.created_at }.merge(metric.to_hash))
+      end
+    end
+  end
+end;end
diff --git a/logstash-core/lib/logstash/instrument/collector.rb b/logstash-core/lib/logstash/instrument/collector.rb
new file mode 100644
index 00000000000..1666810bf95
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/collector.rb
@@ -0,0 +1,111 @@
+# encoding: utf-8
+require "logstash/instrument/snapshot"
+require "logstash/instrument/metric_store"
+require "logstash/util/loggable"
+require "concurrent/timer_task"
+require "observer"
+require "singleton"
+require "thread"
+
+module LogStash module Instrument
+  # The Collector singleton is the single point of reference for all
+  # the metrics collection inside logstash, the metrics library will make
+  # direct calls to this class.
+  #
+  # This class is an observable responsable of periodically emitting view of the system
+  # to other components like the internal metrics pipelines.
+  class Collector
+    include LogStash::Util::Loggable
+    include Observable
+    include Singleton
+
+    SNAPSHOT_ROTATION_TIME_SECS = 1 # seconds
+    SNAPSHOT_ROTATION_TIMEOUT_INTERVAL_SECS = 10 * 60 # seconds
+
+    attr_accessor :agent
+
+    def initialize
+      @metric_store = MetricStore.new
+      @agent = nil
+      start_periodic_snapshotting
+
+      @async_worker_pool
+    end
+
+    # The metric library will call this unique interface
+    # its the job of the collector to update the store with new metric
+    # of update the metric
+    #
+    # If there is a problem with the key or the type of metric we will record an error
+    # but we wont stop processing events, theses errors are not considered fatal.
+    #
+    def push(namespaces_path, key, type, *metric_type_params)
+      begin
+        metric = @metric_store.fetch_or_store(namespaces_path, key) do
+          LogStash::Instrument::MetricType.create(type, namespaces_path, key)
+        end
+
+        metric.execute(*metric_type_params)
+
+        changed # we had changes coming in so we can notify the observers
+      rescue MetricStore::NamespacesExpectedError => e
+        logger.error("Collector: Cannot record metric", :exception => e)
+      rescue NameError => e
+        logger.error("Collector: Cannot create concrete class for this metric type",
+                     :type => type,
+                     :namespaces_path => namespaces_path,
+                     :key => key,
+                     :metrics_params => metric_type_params,
+                     :exception => e,
+                     :stacktrace => e.backtrace)
+      end
+    end
+
+    def clear
+      @metric_store = MetricStore.new
+    end
+
+    # Monitor the `Concurrent::TimerTask` this update is triggered on every successful or not
+    # run of the task, TimerTask implement Observable and the collector acts as
+    # the observer and will keep track if something went wrong in the execution.
+    #
+    # @param [Time] Time of execution
+    # @param [result] Result of the execution
+    # @param [Exception] Exception
+    def update(time_of_execution, result, exception)
+      return true if exception.nil?
+      logger.error("Collector: Something went wrong went sending data to the observers",
+                   :execution_time => time_of_execution,
+                   :result => result,
+                   :exception => exception)
+    end
+
+    # Snapshot the current Metric Store and return it immediately,
+    # This is useful if you want to get access to the current metric store without
+    # waiting for a periodic call.
+    #
+    # @return [LogStash::Instrument::MetricStore]
+    def snapshot_metric
+      Snapshot.new(@metric_store)
+    end
+
+    # Configure and start the periodic task for snapshotting the `MetricStore`
+    def start_periodic_snapshotting
+      @snapshot_task = Concurrent::TimerTask.new { publish_snapshot }
+      @snapshot_task.execution_interval = SNAPSHOT_ROTATION_TIME_SECS
+      @snapshot_task.timeout_interval = SNAPSHOT_ROTATION_TIMEOUT_INTERVAL_SECS
+      @snapshot_task.add_observer(self)
+      @snapshot_task.execute
+    end
+
+    # Create a snapshot of the MetricStore and send it to to the registered observers
+    # The observer will receive the following signature in the update methode.
+    #
+    # `#update(created_at, metric_store)`
+    def publish_snapshot
+      created_at = Time.now
+      logger.debug("Collector: Sending snapshot to observers", :created_at => created_at) if logger.debug?
+      notify_observers(snapshot_metric)
+    end
+  end
+end; end
diff --git a/logstash-core/lib/logstash/instrument/metric.rb b/logstash-core/lib/logstash/instrument/metric.rb
new file mode 100644
index 00000000000..601c7b0ed4b
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/metric.rb
@@ -0,0 +1,102 @@
+# encoding: utf-8
+require "logstash/instrument/collector"
+require "concurrent"
+
+module LogStash module Instrument
+  class MetricException < Exception; end
+  class MetricNoKeyProvided < MetricException; end
+  class MetricNoBlockProvided < MetricException; end
+  class MetricNoNamespaceProvided < MetricException; end
+
+  # This class provide the interface between the code, the collector and the format
+  # of the recorded metric.
+  class Metric
+    attr_reader :collector
+
+    def initialize(collector = LogStash::Instrument::Collector.instance)
+      @collector = collector
+    end
+
+    def increment(namespace, key, value = 1)
+      validate_key!(key)
+      collector.push(namespace, key, :counter, :increment, value)
+    end
+
+    def decrement(namespace, key, value = 1)
+      validate_key!(key)
+      collector.push(namespace, key, :counter, :decrement, value)
+    end
+
+    def gauge(namespace, key, value)
+      validate_key!(key)
+      collector.push(namespace, key, :gauge, :set, value)
+    end
+
+    def time(namespace, key)
+      validate_key!(key)
+
+      if block_given?
+        timer = TimedExecution.new(self, namespace, key)
+        content = yield
+        timer.stop
+        return content
+      else
+        TimedExecution.new(self, namespace, key)
+      end
+    end
+
+    def report_time(namespace, key, duration)
+      collector.push(namespace, key, :mean, :increment, duration)
+    end
+
+    # This method return a metric instance tied to a specific namespace
+    # so instead of specifying the namespace on every call.
+    #
+    # Example:
+    #   metric.increment(:namespace, :mykey, 200)
+    #   metric.increment(:namespace, :mykey_2, 200)
+    #
+    #   namespaced_metric = metric.namespace(:namespace)
+    #   namespaced_metric.increment(:mykey, 200)
+    #   namespaced_metric.increment(:mykey_2, 200)
+    # ```
+    #
+    # @param name [Array<String>] Name of the namespace
+    # @param name [String] Name of the namespace
+    def namespace(name)
+      raise MetricNoNamespaceProvided if name.nil? || name.empty?
+
+      NamespacedMetric.new(self, name)
+    end
+
+    private
+    def validate_key!(key)
+      raise MetricNoKeyProvided if key.nil? || key.empty?
+    end
+
+    # Allow to calculate the execution of a block of code.
+    # This class support 2 differents syntax a block or the return of
+    # the object itself, but in the later case the metric wont be recorded
+    # Until we call `#stop`.
+    #
+    # @see LogStash::Instrument::Metric#time
+    class TimedExecution
+      MILLISECONDS = 1_000_000.0.freeze
+
+      def initialize(metric, namespace, key)
+        @metric = metric
+        @namespace = namespace
+        @key = key
+        start
+      end
+
+      def start
+        @start_time = Time.now
+      end
+
+      def stop
+        @metric.report_time(@namespace, @key, (MILLISECONDS * (Time.now - @start_time)).to_i)
+      end
+    end
+  end
+end; end
diff --git a/logstash-core/lib/logstash/instrument/metric_store.rb b/logstash-core/lib/logstash/instrument/metric_store.rb
new file mode 100644
index 00000000000..53ff0cd6668
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/metric_store.rb
@@ -0,0 +1,228 @@
+# encoding: utf-8
+require "concurrent"
+require "logstash/event"
+require "logstash/instrument/metric_type"
+
+module LogStash module Instrument
+  # The Metric store the data structure that make sure the data is
+  # saved in a retrievable way, this is a wrapper around multiples ConcurrentHashMap
+  # acting as a tree like structure.
+  class MetricStore
+    class NamespacesExpectedError < StandardError; end
+    class MetricNotFound < StandardError; end
+
+    KEY_PATH_SEPARATOR = "/".freeze
+
+    # Lets me a bit flexible on the coma usage in the path
+    # definition
+    FILTER_KEYS_SEPARATOR = /\s?*,\s*/.freeze
+
+    def initialize
+      # We keep the structured cache to allow
+      # the api to search the content of the differents nodes
+      @store = Concurrent::Map.new
+
+      # This hash has only one dimension
+      # and allow fast retrieval of the metrics
+      @fast_lookup = Concurrent::Map.new
+    end
+
+    # This method use the namespace and key to search the corresponding value of
+    # the hash, if it doesn't exist it will create the appropriate namespaces
+    # path in the hash and return `new_value`
+    #
+    # @param [Array] The path where the values should be located
+    # @param [Symbol] The metric key
+    # @return [Object] Return the new_value of the retrieve object in the tree
+    def fetch_or_store(namespaces, key, default_value = nil)
+      provided_value =  block_given? ? yield(key) : default_value
+
+      # We first check in the `@fast_lookup` store to see if we have already see that metrics before,
+      # This give us a `o(1)` access, which is faster than searching through the structured
+      # data store (Which is a `o(n)` operation where `n` is the number of element in the namespace and
+      # the value of the key). If the metric is already present in the `@fast_lookup`, the call to
+      # `#put_if_absent` will return the value. This value is send back directly to the caller.
+      #
+      # BUT. If the value is not present in the `@fast_lookup` the value will be inserted and
+      # `#puf_if_absent` will return nil. With this returned value of nil we assume that we don't
+      # have it in the `@metric_store` for structured search so we add it there too.
+      #
+      # The problem with only using the `@metric_store` directly all the time would require us
+      # to use the mutex around the structure since its a multi-level hash, without that it wont
+      # return a consistent value of the metric and this would slow down the code and would
+      # complixity the code.
+      if found_value = @fast_lookup.put_if_absent([namespaces, key], provided_value)
+        return found_value
+      else
+        # If we cannot find the value this mean we need to save it in the store.
+        fetch_or_store_namespaces(namespaces).fetch_or_store(key, provided_value)
+        return provided_value
+      end
+    end
+
+    # This method allow to retrieve values for a specific path,
+    # This method support the following queries
+    #
+    # stats/pipelines/pipeline_X
+    # stats/pipelines/pipeline_X,pipeline_2
+    # stats/os,jvm
+    #
+    # If you use the `,` on a key the metric store will return the both values at that level
+    #
+    # The returned hash will keep the same structure as it had in the `Concurrent::Map`
+    # but will be a normal ruby hash. This will allow the api to easily seriliaze the content
+    # of the map
+    #
+    # @param [Array] The path where values should be located
+    # @return [Hash]
+    def get_with_path(path)
+      key_paths = path.gsub(/^#{KEY_PATH_SEPARATOR}+/, "").split(KEY_PATH_SEPARATOR)
+      get(*key_paths)
+    end
+
+    # Similar to `get_with_path` but use symbols instead of string
+    #
+    # @param [Array<Symbol>
+    # @return [Hash]
+    def get(*key_paths)
+      # Normalize the symbols access
+      key_paths.map(&:to_sym)
+      new_hash = Hash.new
+
+      get_recursively(key_paths, @store, new_hash)
+
+      new_hash
+    end
+
+    # Return all the individuals Metric,
+    # This call mimic a Enum's each if a block is provided
+    #
+    # @param path [String] The search path for metrics
+    # @param [Array] The metric for the specific path
+    def each(path = nil, &block)
+      metrics = if path.nil?
+        get_all
+      else
+        transform_to_array(get_with_path(path))
+      end
+
+      block_given? ? metrics.each(&block) : metrics
+    end
+    alias_method :all, :each
+
+    private
+    def get_all
+      @fast_lookup.values
+    end
+
+    # This method take an array of keys and recursively search the metric store structure
+    # and return a filtered hash of the structure. This method also take into consideration
+    # getting two different branchs.
+    #
+    #
+    # If one part of the `key_paths` contains a filter key with the following format.
+    # "pipeline01, pipeline_02", It know that need to fetch the branch `pipeline01` and `pipeline02`
+    #
+    # Look at the rspec test for more usage.
+    #
+    # @param key_paths [Array<Symbol>] The list of keys part to filter
+    # @param map [Concurrent::Map] The the part of map to search in
+    # @param new_hash [Hash] The hash to populate with the results.
+    # @return Hash
+    def get_recursively(key_paths, map, new_hash)
+      key_candidates = extract_filter_keys(key_paths.shift)
+
+      key_candidates.each do |key_candidate|
+        raise MetricNotFound, "For path: #{key_candidate}" if map[key_candidate].nil?
+
+        if key_paths.empty? # End of the user requested path
+          if map[key_candidate].is_a?(Concurrent::Map)
+            new_hash[key_candidate] = transform_to_hash(map[key_candidate])
+          else
+            new_hash[key_candidate] = map[key_candidate]
+          end
+        else
+          if map[key_candidate].is_a?(Concurrent::Map)
+            new_hash[key_candidate] = get_recursively(key_paths, map[key_candidate], {})
+          else
+            new_hash[key_candidate] = map[key_candidate]
+          end
+        end
+      end
+      return new_hash
+    end
+
+    def extract_filter_keys(key)
+      key.to_s.strip.split(FILTER_KEYS_SEPARATOR).map(&:to_sym)
+    end
+
+    # Take a hash and recursively flatten it into an array.
+    # This is useful if you are only interested in the leaf of the tree.
+    # Mostly used with `each` to get all the metrics from a specific namespaces
+    #
+    # This could be moved to `LogStash::Util` once this api stabilize
+    #
+    # @return [Array] One dimension array
+     def transform_to_array(map)
+      map.values.collect do |value|
+        value.is_a?(Hash) ? transform_to_array(value) : value
+      end.flatten
+    end
+
+    # Transform the Concurrent::Map hash into a ruby hash format,
+    # This is used to be serialize at the web api layer.
+    #
+    # This could be moved to `LogStash::Util` once this api stabilize
+    #
+    # @return [Hash]
+    def transform_to_hash(map, new_hash = Hash.new)
+      map.each_pair do |key, value|
+        if value.is_a?(Concurrent::Map)
+          new_hash[key] = {}
+          transform_to_hash(value, new_hash[key])
+        else
+          new_hash[key] = value
+        end
+      end
+
+      return new_hash
+    end
+
+    # This method iterate through the namespace path and try to find the corresponding
+    # value for the path, if any part of the path is not found it will
+    # create it.
+    #
+    # @param [Array] The path where values should be located
+    # @raise [ConcurrentMapExpected] Raise if the retrieved object isn't a `Concurrent::Map`
+    # @return [Concurrent::Map] Map where the metrics should be saved
+    def fetch_or_store_namespaces(namespaces_path)
+      path_map = fetch_or_store_namespace_recursively(@store, namespaces_path)
+
+      # This mean one of the namespace and key are colliding
+      # and we have to deal it upstream.
+      unless path_map.is_a?(Concurrent::Map)
+        raise NamespacesExpectedError, "Expecting a `Namespaces` but found class:  #{path_map.class.name} for namespaces_path: #{namespaces_path}"
+      end
+
+      return path_map
+    end
+
+    # Recursively fetch or create the namespace paths through the `MetricStove`
+    # This algorithm use an index to known which keys to search in the map.
+    # This doesn't cloning the array if we want to give a better feedback to the user
+    #
+    # @param [Concurrent::Map] Map to search for the key
+    # @param [Array] List of path to create
+    # @param [Fixnum] Which part from the list to create
+    #
+    def fetch_or_store_namespace_recursively(map, namespaces_path, idx = 0)
+      current = namespaces_path[idx]
+
+      # we are at the end of the namespace path, break out of the recursion
+      return map if current.nil?
+
+      new_map = map.fetch_or_store(current) { Concurrent::Map.new }
+      return fetch_or_store_namespace_recursively(new_map, namespaces_path, idx + 1)
+    end
+  end
+end; end
diff --git a/logstash-core/lib/logstash/instrument/metric_type.rb b/logstash-core/lib/logstash/instrument/metric_type.rb
new file mode 100644
index 00000000000..127d43ce3b0
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/metric_type.rb
@@ -0,0 +1,24 @@
+# encoding: utf-8
+require "logstash/instrument/metric_type/counter"
+require "logstash/instrument/metric_type/mean"
+require "logstash/instrument/metric_type/gauge"
+
+module LogStash module Instrument
+  module MetricType
+    METRIC_TYPE_LIST = {
+      :counter => LogStash::Instrument::MetricType::Counter,
+      :mean => LogStash::Instrument::MetricType::Mean,
+      :gauge => LogStash::Instrument::MetricType::Gauge
+    }.freeze
+
+    # Use the string to generate a concrete class for this metrics
+    #
+    # @param [String] The name of the class
+    # @param [Array] Namespaces list
+    # @param [String] The metric key
+    # @raise [NameError] If the class is not found
+    def self.create(type, namespaces, key)
+      METRIC_TYPE_LIST[type].new(namespaces, key)
+    end
+  end
+end; end
diff --git a/logstash-core/lib/logstash/instrument/metric_type/base.rb b/logstash-core/lib/logstash/instrument/metric_type/base.rb
new file mode 100644
index 00000000000..5711c3f83b6
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/metric_type/base.rb
@@ -0,0 +1,35 @@
+# encoding: utf-8
+require "logstash/event"
+require "logstash/util"
+
+module LogStash module Instrument module MetricType
+  class Base
+    attr_reader :namespaces, :key
+
+    def initialize(namespaces, key)
+      @namespaces = namespaces
+      @key = key
+    end
+
+    def inspect
+      "#{self.class.name} - namespaces: #{namespaces} key: #{key} value: #{value}"
+    end
+
+    def to_hash
+      {
+        "namespaces" => namespaces,
+        "key" => key,
+        "type" => type,
+        "value" => value
+      }
+    end
+
+    def to_json_data
+      value
+    end
+
+    def type
+      @type ||= LogStash::Util.class_name(self).downcase
+    end
+  end
+end; end; end
diff --git a/logstash-core/lib/logstash/instrument/metric_type/counter.rb b/logstash-core/lib/logstash/instrument/metric_type/counter.rb
new file mode 100644
index 00000000000..e99bca57939
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/metric_type/counter.rb
@@ -0,0 +1,29 @@
+# encoding: utf-8
+require "logstash/instrument/metric_type/base"
+require "concurrent"
+
+module LogStash module Instrument module MetricType
+  class Counter < Base
+    def initialize(namespaces, key, value = 0)
+      super(namespaces, key)
+
+      @counter = Concurrent::AtomicFixnum.new(value)
+    end
+
+    def increment(value = 1)
+      @counter.increment(value)
+    end
+
+    def decrement(value = 1)
+      @counter.decrement(value)
+    end
+
+    def execute(action, value = 1)
+      @counter.send(action, value)
+    end
+
+    def value
+      @counter.value
+    end
+  end
+end; end; end
diff --git a/logstash-core/lib/logstash/instrument/metric_type/gauge.rb b/logstash-core/lib/logstash/instrument/metric_type/gauge.rb
new file mode 100644
index 00000000000..7981bc877a5
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/metric_type/gauge.rb
@@ -0,0 +1,22 @@
+# encoding: utf-8
+require "logstash/instrument/metric_type/base"
+require "concurrent/atomic_reference/mutex_atomic"
+require "logstash/json"
+
+module LogStash module Instrument module MetricType
+  class Gauge < Base
+    def initialize(namespaces, key)
+      super(namespaces, key)
+
+      @gauge = Concurrent::MutexAtomicReference.new()
+    end
+
+    def execute(action, value = nil)
+      @gauge.set(value)
+    end
+
+    def value
+      @gauge.get
+    end
+  end
+end; end; end
diff --git a/logstash-core/lib/logstash/instrument/metric_type/mean.rb b/logstash-core/lib/logstash/instrument/metric_type/mean.rb
new file mode 100644
index 00000000000..f2cf7c5bc46
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/metric_type/mean.rb
@@ -0,0 +1,33 @@
+# encoding: utf-8
+require "logstash/instrument/metric_type/base"
+require "concurrent"
+
+module LogStash module Instrument module MetricType
+  class Mean < Base
+    def initialize(namespaces, key)
+      super(namespaces, key)
+
+      @counter = Concurrent::AtomicFixnum.new
+      @sum = Concurrent::AtomicFixnum.new
+    end
+
+    def increment(value = 1)
+      @counter.increment
+      @sum.increment(value)
+    end
+
+    def decrement(value = 1)
+      @counter.decrement
+      @sum.decrement(value)
+    end
+
+    def mean
+      if @counter > 0
+        @sum.value / @counter.value
+      else
+        0
+      end
+    end
+    alias_method :value, :mean
+  end
+end; end; end
diff --git a/logstash-core/lib/logstash/instrument/namespaced_metric.rb b/logstash-core/lib/logstash/instrument/namespaced_metric.rb
new file mode 100644
index 00000000000..6b0ad020e60
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/namespaced_metric.rb
@@ -0,0 +1,54 @@
+# encoding: utf-8
+require "logstash/instrument/metric"
+
+module LogStash module Instrument
+  # This class acts a a proxy between the metric library and the user calls.
+  #
+  # This is the class that plugins authors will use to interact with the `MetricStore`
+  # It has the same public interface as `Metric` class but doesnt require to send
+  # the namespace on every call.
+  #
+  # @see Logstash::Instrument::Metric
+  class NamespacedMetric
+    attr_reader :namespace_name
+    # Create metric with a specific namespace
+    #
+    # @param metric [LogStash::Instrument::Metric] The metric instance to proxy
+    # @param namespace [Array] The namespace to use
+    def initialize(metric, namespace_name)
+      @metric = metric
+      @namespace_name = Array(namespace_name)
+    end
+
+    def increment(key, value = 1)
+      @metric.increment(namespace_name, key, value)
+    end
+
+    def decrement(namespace, key, value = 1)
+      @metric.decrement(namespace_name, key, value)
+    end
+
+    def gauge(key, value)
+      @metric.gauge(namespace_name, key, value)
+    end
+
+    def report_time(key, duration)
+      @metric.report_time(namespace_name, key, duration)
+    end
+
+    def time(key, &block)
+      @metric.time(namespace_name, key, &block)
+    end
+
+    def collector
+      @metric.collector
+    end
+
+    def namespace(name)
+      NamespacedMetric.new(metric, namespace_name.concat(Array(name)))
+    end
+
+    private
+    attr_reader :metric
+  end
+end; end
diff --git a/logstash-core/lib/logstash/instrument/null_metric.rb b/logstash-core/lib/logstash/instrument/null_metric.rb
new file mode 100644
index 00000000000..b8054b766dc
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/null_metric.rb
@@ -0,0 +1,46 @@
+# encoding: utf-8
+require "logstash/instrument/metric"
+
+module LogStash module Instrument
+ # This class is used in the context when we disable the metric collection
+ # for specific plugin to replace the `NamespacedMetric` class with this one
+ # which doesn't produce any metric to the collector.
+ class NullMetric
+   attr_reader :namespace_name, :collector
+
+   def increment(key, value = 1)
+   end
+
+   def decrement(namespace, key, value = 1)
+   end
+
+   def gauge(key, value)
+   end
+
+   def report_time(key, duration)
+   end
+
+   # We have to manually redefine this method since it can return an
+   # object this object also has to be implemented as a NullObject
+   def time(key)
+     if block_given?
+       yield
+     else
+       NullTimedExecution
+     end
+   end
+
+   def namespace(key)
+     self.class.new
+   end
+
+   private
+   # Null implementation of the internal timer class
+   #
+   # @see LogStash::Instrument::TimedExecution`
+   class NullTimedExecution
+     def self.stop
+     end
+   end
+ end
+end; end
diff --git a/logstash-core/lib/logstash/instrument/periodic_poller/base.rb b/logstash-core/lib/logstash/instrument/periodic_poller/base.rb
new file mode 100644
index 00000000000..32bfd931a9a
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/periodic_poller/base.rb
@@ -0,0 +1,57 @@
+# encoding: utf-8
+require "logstash/util/loggable"
+require "logstash/util"
+require "concurrent"
+
+module LogStash module Instrument module PeriodicPoller
+  class Base
+    include LogStash::Util::Loggable
+
+    DEFAULT_OPTIONS = {
+      :polling_interval => 1,
+      :polling_timeout => 60
+    }
+
+    public
+    def initialize(metric, options = {})
+      @metric = metric
+      @options = DEFAULT_OPTIONS.merge(options)
+      configure_task
+    end
+
+    def update(time, result, exception)
+      return unless exception
+
+      logger.error("PeriodicPoller: exception",
+                   :poller => self,
+                   :result => result,
+                   :exception => exception,
+                   :executed_at => time)
+    end
+
+    def collect
+      raise NotImplementedError, "#{self.class.name} need to implement `#collect`"
+    end
+
+    def start
+      logger.debug("PeriodicPoller: Starting", :poller => self,
+                   :polling_interval => @options[:polling_interval],
+                   :polling_timeout => @options[:polling_timeout]) if logger.debug?
+      @task.execute
+    end
+
+    def stop
+      logger.debug("PeriodicPoller: Stopping", :poller => self)
+      @task.shutdown
+    end
+
+    protected
+    def configure_task
+      @task = Concurrent::TimerTask.new { collect }
+      @task.execution_interval = @options[:polling_interval]
+      @task.timeout_interval = @options[:polling_timeout]
+      @task.add_observer(self)
+    end
+  end
+end
+end; end
diff --git a/logstash-core/lib/logstash/instrument/periodic_poller/jvm.rb b/logstash-core/lib/logstash/instrument/periodic_poller/jvm.rb
new file mode 100644
index 00000000000..b4dd0086067
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/periodic_poller/jvm.rb
@@ -0,0 +1,82 @@
+# encoding: utf-8
+require "logstash/instrument/periodic_poller/base"
+require 'monitoring'
+
+module LogStash module Instrument module PeriodicPoller
+  class JVM < Base
+
+    attr_reader :metric
+
+    def initialize(metric, options = {})
+      super(metric, options)
+      @metric = metric
+    end
+
+    def collect
+      raw = JRMonitor.memory.generate
+      collect_heap_metrics(raw)
+      collect_non_heap_metrics(raw)
+      collect_pools_metrics(raw)
+    end
+
+    private
+
+    def collect_heap_metrics(data)
+      heap = aggregate_information_for(data["heap"].values)
+      heap[:used_percent] = (heap[:used_in_bytes] / heap[:max_in_bytes].to_f)*100.0
+
+      heap.each_pair do |key, value|
+        metric.gauge([:jvm, :memory, :heap], key, value.to_i)
+      end
+    end
+
+    def collect_non_heap_metrics(data)
+      non_heap = aggregate_information_for(data["non_heap"].values)
+      non_heap.each_pair do |key, value|
+        metric.gauge([:jvm, :memory, :non_heap],key, value.to_i)
+      end
+    end
+
+    def collect_pools_metrics(data)
+      metrics = build_pools_metrics(data)
+      metrics.each_pair do |key, hash|
+        hash.each_pair do |p,v|
+          metric.gauge([:jvm, :memory, :pools, key.to_sym], p, v)
+        end
+      end
+    end
+
+    def build_pools_metrics(data)
+      {
+        "young"    => aggregate_information_for(data["heap"]["Par Eden Space"]),
+        "old"      => aggregate_information_for(data["heap"]["CMS Old Gen"]),
+        "survivor" => aggregate_information_for(data["heap"]["Par Survivor Space"]),
+      }
+    end
+
+    def aggregate_information_for(collection)
+      collection.reduce(default_information_accumulator) do |m,e|
+        e = { e[0] => e[1] } if e.is_a?(Array)
+        e.each_pair do |k,v|
+          m[:used_in_bytes] += v       if k.include?("used")
+          m[:committed_in_bytes] += v  if k.include?("committed")
+          m[:max_in_bytes] += v        if k.include?("max")
+          m[:peak_max_in_bytes] += v   if k.include?("peak.max")
+          m[:peak_used_in_bytes] += v  if k.include?("peak.used")
+        end
+        m
+      end
+    end
+
+    def default_information_accumulator
+      {
+        :used_in_bytes => 0,
+        :committed_in_bytes => 0,
+        :max_in_bytes => 0,
+        :peak_used_in_bytes => 0,
+        :peak_max_in_bytes  => 0
+      }
+    end
+
+  end
+end; end; end
diff --git a/logstash-core/lib/logstash/instrument/periodic_poller/os.rb b/logstash-core/lib/logstash/instrument/periodic_poller/os.rb
new file mode 100644
index 00000000000..8ad09dfc7d7
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/periodic_poller/os.rb
@@ -0,0 +1,13 @@
+# encoding: utf-8
+require "logstash/instrument/periodic_poller/base"
+
+module LogStash module Instrument module PeriodicPoller
+  class Os < Base
+    def initialize(metric, options = {})
+      super(metric, options)
+    end
+
+    def collect
+    end
+  end
+end; end; end
diff --git a/logstash-core/lib/logstash/instrument/periodic_poller/periodic_poller_observer.rb b/logstash-core/lib/logstash/instrument/periodic_poller/periodic_poller_observer.rb
new file mode 100644
index 00000000000..382b350968d
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/periodic_poller/periodic_poller_observer.rb
@@ -0,0 +1,19 @@
+# encoding: utf-8
+module LogStash module Instrument module PeriodicPoller
+  class PeriodicPollerObserver
+    include LogStash::Util::Loggable
+    
+    def initialize(poller)
+      @poller = poller
+    end
+
+    def update(time, result, exception)
+      if exception
+        logger.error("PeriodicPoller exception", :poller => @poller,
+                     :result => result,
+                     :exception => exception,
+                     :executed_at => time)
+      end
+    end
+  end
+end; end; end
diff --git a/logstash-core/lib/logstash/instrument/periodic_pollers.rb b/logstash-core/lib/logstash/instrument/periodic_pollers.rb
new file mode 100644
index 00000000000..09c4feebd57
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/periodic_pollers.rb
@@ -0,0 +1,26 @@
+# encoding: utf-8
+require "logstash/instrument/periodic_poller/os"
+require "logstash/instrument/periodic_poller/jvm"
+
+module LogStash module Instrument
+  # Each PeriodPoller manager his own thread to do the poller
+  # of the stats, this class encapsulate the starting and stopping of the poller
+  # if the unique timer uses too much resource we can refactor this behavior here.
+  class PeriodicPollers
+    attr_reader :metric
+
+    def initialize(metric)
+      @metric = metric
+      @periodic_pollers = [PeriodicPoller::Os.new(metric),
+                          PeriodicPoller::JVM.new(metric)]
+    end
+
+    def start
+      @periodic_pollers.map(&:start)
+    end
+
+    def stop
+      @periodic_pollers.map(&:stop)
+    end
+  end
+end; end
diff --git a/logstash-core/lib/logstash/instrument/snapshot.rb b/logstash-core/lib/logstash/instrument/snapshot.rb
new file mode 100644
index 00000000000..f46068439ad
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/snapshot.rb
@@ -0,0 +1,16 @@
+# encoding: utf-8
+require "logstash/util/loggable"
+require "logstash/event"
+
+module LogStash module Instrument
+  class Snapshot
+    include LogStash::Util::Loggable
+
+    attr_reader :metric_store, :created_at
+
+    def initialize(metric_store, created_at = Time.now)
+      @metric_store = metric_store
+      @created_at = created_at
+    end
+  end
+end; end
diff --git a/logstash-core/lib/logstash/json.rb b/logstash-core/lib/logstash/json.rb
index adbabff18c5..7380b630463 100644
--- a/logstash-core/lib/logstash/json.rb
+++ b/logstash-core/lib/logstash/json.rb
@@ -41,13 +41,12 @@ def jruby_load(data, options = {})
       raise LogStash::Json::ParserError.new(e.message)
     end
 
-    def jruby_dump(o)
+    def jruby_dump(o, options={})
       # TODO [guyboertje] remove these comments in 5.0
       # test for enumerable here to work around an omission in JrJackson::Json.dump to
       # also look for Java::JavaUtil::ArrayList, see TODO submit issue
       # o.is_a?(Enumerable) ? JrJackson::Raw.generate(o) : JrJackson::Json.dump(o)
-
-      JrJackson::Base.generate(o, {})
+      JrJackson::Base.generate(o, options)
 
     rescue => e
       raise LogStash::Json::GeneratorError.new(e.message)
diff --git a/logstash-core/lib/logstash/namespace.rb b/logstash-core/lib/logstash/namespace.rb
index 44701c38450..355f0ac25fa 100644
--- a/logstash-core/lib/logstash/namespace.rb
+++ b/logstash-core/lib/logstash/namespace.rb
@@ -10,4 +10,5 @@ module Web; end
   module Util; end
   module PluginMixins; end
   module PluginManager; end
+  module Api; end
 end # module LogStash
diff --git a/logstash-core/lib/logstash/output_delegator.rb b/logstash-core/lib/logstash/output_delegator.rb
index 260e6b15797..7ac962dfeb7 100644
--- a/logstash-core/lib/logstash/output_delegator.rb
+++ b/logstash-core/lib/logstash/output_delegator.rb
@@ -12,12 +12,18 @@ module LogStash class OutputDelegator
 
   # The *args this takes are the same format that a Outputs::Base takes. A list of hashes with parameters in them
   # Internally these just get merged together into a single hash
-  def initialize(logger, klass, default_worker_count, *args)
+  def initialize(logger, klass, default_worker_count, metric, *args)
     @logger = logger
     @threadsafe = klass.threadsafe?
     @config = args.reduce({}, :merge)
     @klass = klass
 
+    # Create an instance of the input so we can fetch the identifier
+    output = @klass.new(*args)
+
+    # Scope the metrics to the plugin
+    @metric = metric.namespace(output.id.to_sym)
+
     # We define this as an array regardless of threadsafety
     # to make reporting simpler, even though a threadsafe plugin will just have
     # a single instance
@@ -39,6 +45,7 @@ def initialize(logger, klass, default_worker_count, *args)
 
     @workers += (@worker_count - 1).times.map do
       inst = @klass.new(*args)
+      inst.metric = @metric
       inst.register
       inst
     end
@@ -107,6 +114,7 @@ def register
 
   def threadsafe_multi_receive(events)
     @events_received.increment(events.length)
+    @metric.increment(:events_in, events.length)
 
     @threadsafe_worker.multi_receive(events)
   end
@@ -147,4 +155,4 @@ def busy_workers
   private
   # Needed for testing, so private
   attr_reader :threadsafe_worker, :worker_queue
-end end
\ No newline at end of file
+end end
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 29a8e27aee1..0eef3bdb501 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -14,10 +14,28 @@
 require "logstash/shutdown_watcher"
 require "logstash/util/wrapped_synchronous_queue"
 require "logstash/pipeline_reporter"
+require "logstash/instrument/metric"
+require "logstash/instrument/namespaced_metric"
+require "logstash/instrument/null_metric"
+require "logstash/instrument/collector"
 require "logstash/output_delegator"
+require "logstash/filter_delegator"
 
 module LogStash; class Pipeline
-  attr_reader :inputs, :filters, :outputs, :worker_threads, :events_consumed, :events_filtered, :reporter, :pipeline_id, :logger, :thread, :config_str, :original_settings
+ attr_reader :inputs,
+    :filters,
+    :outputs,
+    :worker_threads,
+    :events_consumed,
+    :events_filtered,
+    :reporter,
+    :pipeline_id,
+    :metric,
+    :logger,
+    :started_at,
+    :thread,
+    :config_str,
+    :original_settings
 
   DEFAULT_SETTINGS = {
     :default_pipeline_workers => LogStash::Config::CpuCoreStrategy.maximum,
@@ -52,6 +70,16 @@ def initialize(config_str, settings = {})
 
     @worker_threads = []
 
+    # Metric object should be passed upstream, multiple pipeline share the same metric
+    # and collector only the namespace will changes.
+    # If no metric is given, we use a `NullMetric` for all internal calls.
+    # We also do this to make the changes backward compatible with previous testing of the
+    # pipeline.
+    #
+    # This need to be configured before we evaluate the code to make
+    # sure the metric instance is correctly send to the plugin.
+    @metric = settings.fetch(:metric, Instrument::NullMetric.new)
+
     grammar = LogStashConfigParser.new
     @config = grammar.parse(config_str)
     if @config.nil?
@@ -61,9 +89,12 @@ def initialize(config_str, settings = {})
     # The code will initialize all the plugins and define the
     # filter and output methods.
     code = @config.compile
+    @code = code
+
     # The config code is hard to represent as a log message...
     # So just print it.
     @logger.debug? && @logger.debug("Compiled pipeline code:\n#{code}")
+
     begin
       eval(code)
     rescue => e
@@ -99,7 +130,7 @@ def safe_pipeline_worker_count
     safe_filters, unsafe_filters = @filters.partition(&:threadsafe?)
 
     if unsafe_filters.any?
-      plugins = unsafe_filters.collect { |f| f.class.config_name }
+      plugins = unsafe_filters.collect { |f| f.config_name }
       case thread_count
       when nil
         # user did not specify a worker thread count
@@ -128,6 +159,9 @@ def filters?
   end
 
   def run
+    @started_at = Time.now
+
+    LogStash::Util.set_thread_name("[#{pipeline_id}]-pipeline-manager")
     @logger.terminal(LogStash::Util::DefaultsPrinter.print(@settings))
     @thread = Thread.current
 
@@ -179,7 +213,7 @@ def start_workers
     begin
       start_inputs
       @outputs.each {|o| o.register }
-      @filters.each {|f| f.register}
+      @filters.each {|f| f.register }
 
       pipeline_workers = safe_pipeline_worker_count
       batch_size = @settings[:pipeline_batch_size]
@@ -209,16 +243,21 @@ def start_workers
   end
 
   # Main body of what a worker thread does
-  # Repeatedly takes batches off the queu, filters, then outputs them
+  # Repeatedly takes batches off the queue, filters, then outputs them
   def worker_loop(batch_size, batch_delay)
     running = true
 
+    namespace_events = metric.namespace([:stats, :events])
+    namespace_pipeline = metric.namespace([:stats, :pipelines, pipeline_id.to_s.to_sym, :events])
+
     while running
       # To understand the purpose behind this synchronize please read the body of take_batch
       input_batch, signal = @input_queue_pop_mutex.synchronize { take_batch(batch_size, batch_delay) }
       running = false if signal == LogStash::SHUTDOWN
 
       @events_consumed.increment(input_batch.size)
+      namespace_events.increment(:in, input_batch.size)
+      namespace_pipeline.increment(:in, input_batch.size)
 
       filtered_batch = filter_batch(input_batch)
 
@@ -229,8 +268,14 @@ def worker_loop(batch_size, batch_delay)
 
       @events_filtered.increment(filtered_batch.size)
 
+      namespace_events.increment(:filtered, filtered_batch.size)
+      namespace_pipeline.increment(:filtered, filtered_batch.size)
+
       output_batch(filtered_batch)
 
+      namespace_events.increment(:out, filtered_batch.size)
+      namespace_pipeline.increment(:out, filtered_batch.size)
+
       inflight_batches_synchronize { set_current_thread_inflight_batch(nil) }
     end
   end
@@ -408,10 +453,14 @@ def shutdown_workers
   def plugin(plugin_type, name, *args)
     args << {} if args.empty?
 
+    pipeline_scoped_metric = metric.namespace([:stats, :pipelines, pipeline_id.to_s.to_sym, :plugins])
+
     klass = LogStash::Plugin.lookup(plugin_type, name)
 
     if plugin_type == "output"
-      LogStash::OutputDelegator.new(@logger, klass, default_output_workers, *args)
+      LogStash::OutputDelegator.new(@logger, klass, default_output_workers, pipeline_scoped_metric.namespace(:outputs), *args)
+    elsif plugin_type == "filter"
+      LogStash::FilterDelegator.new(@logger, klass, pipeline_scoped_metric.namespace(:filters), *args)
     else
       klass.new(*args)
     end
@@ -463,6 +512,15 @@ def flush
     end
   end
 
+
+  # Calculate the uptime in milliseconds
+  #
+  # @return [Fixnum] Uptime in milliseconds, 0 if the pipeline is not started
+  def uptime
+    return 0 if started_at.nil?
+    ((Time.now.to_f - started_at.to_f) * 1000.0).to_i
+  end
+
   # perform filters flush into the output queue
   # @param options [Hash]
   # @option options [Boolean] :final => true to signal a final shutdown flush
diff --git a/logstash-core/lib/logstash/plugin.rb b/logstash-core/lib/logstash/plugin.rb
index 1f9d471b087..0ac1fc78ce5 100644
--- a/logstash-core/lib/logstash/plugin.rb
+++ b/logstash-core/lib/logstash/plugin.rb
@@ -2,8 +2,10 @@
 require "logstash/namespace"
 require "logstash/logging"
 require "logstash/config/mixin"
+require "logstash/instrument/null_metric"
 require "cabin"
 require "concurrent"
+require "securerandom"
 
 class LogStash::Plugin
   attr_accessor :params
@@ -11,26 +13,54 @@ class LogStash::Plugin
 
   NL = "\n"
 
-  public
+  include LogStash::Config::Mixin
+
+  # Disable or enable metric logging for this specific plugin instance
+  # by default we record all the metrics we can, but you can disable metrics collection
+  # for a specific plugin.
+  config :enable_metric, :validate => :boolean, :default => true
+
+  # Add a unique `ID` to the plugin instance, this `ID` is used for tracking
+  # information for a specific configuration of the plugin.
+  #
+  # ```
+  # output {
+  #  stdout {
+  #    id => "ABC"
+  #  }
+  # }
+  # ```
+  #
+  # If you don't explicitely set this variable Logstash will generate a unique name.
+  config :id, :validate => :string
+
   def hash
     params.hash ^
     self.class.name.hash
   end
 
-  public
+
   def eql?(other)
     self.class.name == other.class.name && @params == other.params
   end
 
-  public
   def initialize(params=nil)
     @params = LogStash::Util.deep_clone(params)
     @logger = Cabin::Channel.get(LogStash)
   end
 
+  # Return a uniq ID for this plugin configuration, by default
+  # we will generate a UUID
+  #
+  # If the user defines a `id => 'ABC'` in the configuration we will return
+  #
+  # @return [String] A plugin ID
+  def id
+    (@params["id"].nil? || @params["id"].empty?) ? SecureRandom.uuid : @params["id"]
+  end
+
   # close is called during shutdown, after the plugin worker
   # main task terminates
-  public
   def do_close
     @logger.debug("closing", :plugin => self)
     close
@@ -38,7 +68,6 @@ def do_close
 
   # Subclasses should implement this close method if you need to perform any
   # special tasks during shutdown (like flushing, etc.)
-  public
   def close
     # ..
   end
@@ -47,7 +76,6 @@ def to_s
     return "#{self.class.name}: #{@params}"
   end
 
-  public
   def inspect
     if !@params.nil?
       description = @params
@@ -59,13 +87,19 @@ def inspect
     end
   end
 
-  public
   def debug_info
     [self.class.to_s, original_params]
   end
 
+  def metric=(new_metric)
+    @metric = new_metric
+  end
+
+  def metric
+    @metric_plugin ||= enable_metric ? @metric : LogStash::Instrument::NullMetric.new
+  end
+
   # Look up a plugin by type and name.
-  public
   def self.lookup(type, name)
     path = "logstash/#{type}s/#{name}"
 
@@ -86,7 +120,6 @@ def self.lookup(type, name)
   end
 
   private
-
   # lookup a plugin by type and name in the existing LogStash module namespace
   # ex.: namespace_lookup("filter", "grok") looks for LogStash::Filters::Grok
   # @param type [String] plugin type, "input", "ouput", "filter"
diff --git a/logstash-core/lib/logstash/runner.rb b/logstash-core/lib/logstash/runner.rb
index a9e56a3507a..a355fba4d42 100644
--- a/logstash-core/lib/logstash/runner.rb
+++ b/logstash-core/lib/logstash/runner.rb
@@ -82,6 +82,14 @@ class LogStash::Runner < Clamp::Command
     I18n.t("logstash.runner.flag.auto_reload"),
     :attribute_name => :auto_reload, :default => false
 
+  option ["--http-host"], "WEB_API_HTTP_HOST",
+    I18n.t("logstash.web_api.flag.http_host"),
+    :attribute_name => :web_api_http_host, :default => "127.0.0.1"
+
+  option ["--http-port"], "WEB_API_HTTP_PORT",
+    I18n.t("logstash.web_api.flag.http_port"),
+    :attribute_name => :web_api_http_port, :default => 9600
+
   def pipeline_workers=(pipeline_workers_value)
     @pipeline_settings[:pipeline_workers] = validate_positive_integer(pipeline_workers_value)
   end
@@ -117,6 +125,11 @@ def execute
     require "stud/task"
     require "cabin" # gem 'cabin'
 
+
+    # Configure Logstash logging facility, this need to be done before everything else to
+    # make sure the logger has the correct settings and the log level is correctly defined.
+    configure_logging(log_file)
+
     LogStash::Util::set_thread_name(self.class.name)
 
     if RUBY_VERSION < "1.9.2"
@@ -162,7 +175,12 @@ def execute
     end
 
     @agent = create_agent(:logger => @logger,
-                          :auto_reload => @auto_reload)
+                          :auto_reload => @auto_reload,
+                          :collect_metric => true,
+                          :debug => debug?,
+                          :node_name => node_name,
+                          :web_api_http_host => @web_api_http_host,
+                          :web_api_http_port => @web_api_http_port)
 
     @agent.register_pipeline("main", @pipeline_settings.merge({
                           :config_string => config_string,
@@ -235,7 +253,6 @@ def show_gems
   #
   # Log file stuff, plugin path checking, etc.
   def configure
-    configure_logging(log_file)
     configure_plugin_paths(plugin_paths)
   end # def configure
 
@@ -254,6 +271,7 @@ def create_agent(*args)
 
   # Point logging at a specific path.
   def configure_logging(path)
+    @logger = Cabin::Channel.get(LogStash)
     # Set with the -v (or -vv...) flag
     if quiet?
       @logger.level = :error
diff --git a/logstash-core/lib/logstash/util.rb b/logstash-core/lib/logstash/util.rb
index fc0ba6c9eeb..88f8b999200 100644
--- a/logstash-core/lib/logstash/util.rb
+++ b/logstash-core/lib/logstash/util.rb
@@ -184,6 +184,15 @@ def self.stringify_symbols(o)
     end
   end
 
+  # Take a instance reference and return the name of the class
+  # stripping all the modules.
+  #
+  # @param [Object] The object to return the class)
+  # @return [String] The name of the class
+  def self.class_name(instance)
+    instance.class.name.split("::").last
+  end
+
   def self.deep_clone(o)
     case o
     when Hash
diff --git a/logstash-core/lib/logstash/util/duration_formatter.rb b/logstash-core/lib/logstash/util/duration_formatter.rb
new file mode 100644
index 00000000000..42cf6ff66f1
--- /dev/null
+++ b/logstash-core/lib/logstash/util/duration_formatter.rb
@@ -0,0 +1,15 @@
+# encoding: utf-8
+require "chronic_duration"
+module LogStash::Util::DurationFormatter
+  CHRONIC_OPTIONS = { :format => :short }
+
+  # Take a duration in milliseconds and transform it into
+  # a format that a human can understand. This is currently used by
+  # the API.
+  #
+  # @param [Fixnum] Duration in milliseconds
+  # @return [String] Duration in human format
+  def self.human_format(duration)
+    ChronicDuration.output(duration / 1000, CHRONIC_OPTIONS)
+  end
+end
diff --git a/logstash-core/lib/logstash/util/loggable.rb b/logstash-core/lib/logstash/util/loggable.rb
new file mode 100644
index 00000000000..0add9f3e2b0
--- /dev/null
+++ b/logstash-core/lib/logstash/util/loggable.rb
@@ -0,0 +1,29 @@
+# encoding: utf-8
+require "logstash/namespace"
+require "cabin"
+
+module LogStash module Util
+  module Loggable
+    class << self
+      def logger=(new_logger)
+        @logger = new_logger
+      end
+
+      def logger
+        @logger ||= Cabin::Channel.get(LogStash)
+      end
+    end
+
+    def self.included(base)
+      class << base
+        def logger
+          Loggable.logger
+        end
+      end
+    end
+
+    def logger
+      Loggable.logger
+    end
+  end
+end; end
diff --git a/logstash-core/lib/logstash/webserver.rb b/logstash-core/lib/logstash/webserver.rb
new file mode 100644
index 00000000000..45587d11f15
--- /dev/null
+++ b/logstash-core/lib/logstash/webserver.rb
@@ -0,0 +1,93 @@
+# encoding: utf-8
+require "puma"
+require "puma/single"
+require "puma/binder"
+require "puma/configuration"
+require "puma/commonlogger"
+
+module LogStash 
+  class WebServer
+
+    extend Forwardable
+
+    attr_reader :logger, :status, :config, :options, :cli_options, :runner, :binder, :events
+
+    def_delegator :@runner, :stats
+
+    DEFAULT_HOST = "127.0.0.1".freeze
+    DEFAULT_PORT = 9600.freeze
+
+    def initialize(logger, options={})
+      @logger      = logger
+      http_host    = options[:http_host] || DEFAULT_HOST
+      http_port    = options[:http_port] || DEFAULT_PORT
+      @options     = {}
+      @cli_options = options.merge({ :rackup => ::File.join(::File.dirname(__FILE__), "api", "init.ru"),
+                                     :binds => ["tcp://#{http_host}:#{http_port}"],
+                                     :debug => logger.debug? })
+      @status      = nil
+
+      parse_options
+
+      @runner  = nil
+      @events  = ::Puma::Events.strings
+      @binder  = ::Puma::Binder.new(@events)
+      @binder.import_from_env
+
+      set_environment
+    end
+
+    def run
+      log "=== puma start: #{Time.now} ==="
+
+      @runner = Puma::Single.new(self)
+      @status = :run
+      @runner.run
+      stop(:graceful => true)
+    end
+
+    def log(str)
+      logger.debug(str)
+    end
+
+    def error(str)
+      logger.error(str)
+    end
+
+    # Empty method, this method is required because of the puma usage we make through
+    # the Single interface, https://github.com/puma/puma/blob/master/lib/puma/single.rb#L82
+    # for more details. This can always be implemented when we want to keep track of this
+    # bit of data.
+    def write_state; end
+
+    def stop(options={})
+      graceful = options.fetch(:graceful, true)
+
+      if graceful
+        @runner.stop_blocked
+      else
+        @runner.stop
+      end rescue nil
+
+      @status = :stop
+      log "=== puma shutdown: #{Time.now} ==="
+    end
+
+    private
+
+    def env
+      @options[:debug] ? "development" : "production"
+    end
+
+    def set_environment
+      @options[:environment] = env
+      ENV['RACK_ENV']        = env
+    end
+
+    def parse_options
+      @config  = ::Puma::Configuration.new(cli_options)
+      @config.load
+      @options = @config.options
+    end
+  end
+end
diff --git a/logstash-core/locales/en.yml b/logstash-core/locales/en.yml
index 163f7ea7ef2..1d33f28d534 100644
--- a/logstash-core/locales/en.yml
+++ b/logstash-core/locales/en.yml
@@ -69,6 +69,16 @@ en:
         data loss.
       forced_sigint: >-
         SIGINT received. Terminating immediately..
+    web_api:
+      flag:
+        http_host: Web API binding host
+        http_port: Web API http port
+      hot_threads:
+        title: |-
+          ::: {%{hostname}}
+            Hot threads at %{time}, busiestThreads=%{top_count}:
+        thread_title: |-
+            %{percent_of_cpu_time} % of cpu usage by %{thread_state} thread named '%{thread_name}'
     runner:
       short-help: |-
         usage:
diff --git a/logstash-core/logstash-core.gemspec b/logstash-core/logstash-core.gemspec
index 8deeee9a175..d92f28c491f 100644
--- a/logstash-core/logstash-core.gemspec
+++ b/logstash-core/logstash-core.gemspec
@@ -11,7 +11,7 @@ Gem::Specification.new do |gem|
   gem.homepage      = "http://www.elastic.co/guide/en/logstash/current/index.html"
   gem.license       = "Apache License (2.0)"
 
-  gem.files         = Dir.glob(["logstash-core.gemspec", "lib/**/*.rb", "spec/**/*.rb", "locales/*"])
+  gem.files         = Dir.glob(["logstash-core.gemspec", "lib/**/*.rb", "spec/**/*.rb", "locales/*", "lib/logstash/api/init.ru"])
   gem.test_files    = gem.files.grep(%r{^(test|spec|features)/})
   gem.name          = "logstash-core"
   gem.require_paths = ["lib"]
@@ -25,8 +25,12 @@ Gem::Specification.new do |gem|
   gem.add_runtime_dependency "clamp", "~> 0.6.5" #(MIT license) for command line args/flags
   gem.add_runtime_dependency "filesize", "0.0.4" #(MIT license) for :bytes config validator
   gem.add_runtime_dependency "gems", "~> 0.8.3"  #(MIT license)
-  gem.add_runtime_dependency "concurrent-ruby", "0.9.2"
+  gem.add_runtime_dependency "concurrent-ruby", "1.0.0"
+  gem.add_runtime_dependency "sinatra", '~> 1.4', '>= 1.4.6'
+  gem.add_runtime_dependency 'puma', '~> 2.16', '>= 2.16.0'
   gem.add_runtime_dependency "jruby-openssl", "0.9.13" # Required to support TLSv1.2
+  gem.add_runtime_dependency "chronic_duration", "0.10.6"
+  gem.add_runtime_dependency "jruby-monitoring", '~> 0.1'
 
   # TODO(sissel): Treetop 1.5.x doesn't seem to work well, but I haven't
   # investigated what the cause might be. -Jordan
diff --git a/logstash-core/spec/api/fixtures/memory.json b/logstash-core/spec/api/fixtures/memory.json
new file mode 100644
index 00000000000..2cd94aef053
--- /dev/null
+++ b/logstash-core/spec/api/fixtures/memory.json
@@ -0,0 +1,42 @@
+{
+	"heap": {
+		"used_in_bytes": 1,
+		"committed_in_bytes": 2,
+		"max_in_bytes": 3,
+		"peak_used_in_bytes": 4,
+		"peak_max_in_bytes": 5,
+		"used_percent": 7
+
+	},
+	"non_heap": {
+		"used_in_bytes": 1,
+		"committed_in_bytes": 2,
+		"max_in_bytes": 3,
+		"peak_used_in_bytes": 4,
+		"peak_max_in_bytes": 5
+
+	},
+	"pools": {
+		"young": {
+			"used_in_bytes": 1,
+			"committed_in_bytes": 2,
+			"max_in_bytes": 3,
+			"peak_used_in_bytes": 4,
+			"peak_max_in_bytes": 5
+		},
+		"old": {
+			"used_in_bytes": 1,
+			"committed_in_bytes": 2,
+			"max_in_bytes": 3,
+			"peak_used_in_bytes": 4,
+			"peak_max_in_bytes": 5
+		},
+		"survivor": {
+			"used_in_bytes": 1,
+			"committed_in_bytes": 2,
+			"max_in_bytes": 3,
+			"peak_used_in_bytes": 4,
+			"peak_max_in_bytes": 5
+		}
+	}
+}
diff --git a/logstash-core/spec/api/lib/api/node_stats_spec.rb b/logstash-core/spec/api/lib/api/node_stats_spec.rb
new file mode 100644
index 00000000000..809ab40e12b
--- /dev/null
+++ b/logstash-core/spec/api/lib/api/node_stats_spec.rb
@@ -0,0 +1,34 @@
+# encoding: utf-8
+require_relative "../../spec_helper"
+require "sinatra"
+require "app/modules/node_stats"
+
+describe LogStash::Api::NodeStats do
+
+  include Rack::Test::Methods
+
+  def app()
+    described_class
+  end
+
+  let(:mem) do
+    { :heap_used_in_bytes => 10,
+      :pools => { :used_in_bytes => 20 }}
+  end
+
+  let(:events) do
+    { :in => 10, :out => 20 }
+  end
+
+  it "respond to the events resource" do
+    expect_any_instance_of(LogStash::Api::StatsEventsCommand).to receive(:run).and_return(events)
+    get "/events"
+    expect(last_response).to be_ok
+  end
+
+  it "respond to the jvm resource" do
+    expect_any_instance_of(LogStash::Api::JvmMemoryCommand).to receive(:run).and_return(mem)
+    get "jvm"
+    expect(last_response).to be_ok
+  end
+end
diff --git a/logstash-core/spec/api/lib/api/root_spec.rb b/logstash-core/spec/api/lib/api/root_spec.rb
new file mode 100644
index 00000000000..83abb232957
--- /dev/null
+++ b/logstash-core/spec/api/lib/api/root_spec.rb
@@ -0,0 +1,27 @@
+# encoding: utf-8
+require_relative "../../spec_helper"
+require "sinatra"
+require "app/root"
+require "logstash/json"
+
+describe LogStash::Api::Root do
+
+  include Rack::Test::Methods
+
+  def app()
+    described_class
+  end
+
+  let(:agent) { double("agent") }
+
+  before(:each) do
+    allow(agent).to receive(:node_name).and_return("foo")
+    expect_any_instance_of(LogStash::Api::Service).to receive(:agent).and_return(agent)
+  end
+
+  it "should respond to root resource" do
+    get "/"
+    expect(last_response).to be_ok
+  end
+
+end
diff --git a/logstash-core/spec/api/lib/api/stats_spec.rb b/logstash-core/spec/api/lib/api/stats_spec.rb
new file mode 100644
index 00000000000..2f140e05c95
--- /dev/null
+++ b/logstash-core/spec/api/lib/api/stats_spec.rb
@@ -0,0 +1,30 @@
+# encoding: utf-8
+require_relative "../../spec_helper"
+require "sinatra"
+require "app/modules/stats"
+
+describe LogStash::Api::Stats do
+
+  include Rack::Test::Methods
+
+  def app()
+    described_class
+  end
+
+  let(:mem) do
+    { :heap_used_in_bytes => 10,
+      :pools => { :used_in_bytes => 20 }}
+  end
+
+  before(:each) do
+    expect_any_instance_of(LogStash::Api::JvmMemoryCommand).to receive(:started_at).and_return(1234567890)
+    expect_any_instance_of(LogStash::Api::JvmMemoryCommand).to receive(:uptime).and_return(10)
+    expect_any_instance_of(LogStash::Api::JvmMemoryCommand).to receive(:run).and_return(mem)
+  end
+
+  it "respond to the jvm resource" do
+    get "/jvm"
+    expect(last_response).to be_ok
+  end
+
+end
diff --git a/logstash-core/spec/api/lib/commands/events_spec.rb b/logstash-core/spec/api/lib/commands/events_spec.rb
new file mode 100644
index 00000000000..54c4dc86459
--- /dev/null
+++ b/logstash-core/spec/api/lib/commands/events_spec.rb
@@ -0,0 +1,29 @@
+# encoding: utf-8
+require_relative "../../spec_helper"
+require "app/commands/stats/events_command"
+
+describe LogStash::Api::StatsEventsCommand do
+
+  let(:service) { double("snapshot-service") }
+
+  subject { described_class.new(service) }
+
+  let(:stats) do
+    { "stats" => { "events" => { "in" => 100,
+                                 "out" => 0,
+                                 "filtered" => 200 }}}
+  end
+
+  before(:each) do
+    allow(service).to receive(:get).with(:events_stats).and_return(LogStash::Json.dump(stats))
+  end
+
+  context "#schema" do
+    let(:report) { subject.run }
+
+    it "return events information" do
+      expect(report).to include({"in" => 100, "filtered" => 200 })
+    end
+
+  end
+end
diff --git a/logstash-core/spec/api/lib/commands/jvm_spec.rb b/logstash-core/spec/api/lib/commands/jvm_spec.rb
new file mode 100644
index 00000000000..5cf1651b221
--- /dev/null
+++ b/logstash-core/spec/api/lib/commands/jvm_spec.rb
@@ -0,0 +1,64 @@
+# encoding: utf-8
+require_relative "../../spec_helper"
+require "app/commands/stats/hotthreads_command"
+require "app/commands/stats/memory_command"
+
+describe "JVM stats" do
+
+  let(:agent) { double("agent") }
+
+  describe LogStash::Api::HotThreadsCommand do
+
+    before(:each) do
+      allow(agent).to receive(:node_name).and_return("foo")
+      expect_any_instance_of(LogStash::Api::Service).to receive(:agent).and_return(agent)
+      allow(subject).to receive(:uptime).and_return(10)
+    end
+
+    context "#schema" do
+      let(:report) { subject.run }
+
+      it "return hot threads information" do
+        expect(report.to_s).not_to be_empty
+      end
+
+    end
+  end
+
+  describe LogStash::Api::JvmMemoryCommand do
+
+    context "#schema" do
+
+      let(:service) { double("snapshot-service") }
+
+      subject { described_class.new(service) }
+
+      let(:stats) do
+        read_fixture("memory.json")
+      end
+
+      before(:each) do
+        allow(service).to receive(:agent).and_return(agent)
+        allow(service).to receive(:get).with(:jvm_memory_stats).and_return(stats)
+      end
+
+
+      let(:report) do
+        subject.run
+      end
+
+      it "return hot threads information" do
+        expect(report).not_to be_empty
+      end
+
+      it "return heap information" do
+        expect(report.keys).to include(:heap_used_in_bytes)
+      end
+
+      it "return non heap information" do
+        expect(report.keys).to include(:non_heap_used_in_bytes)
+      end
+
+    end
+  end
+end
diff --git a/logstash-core/spec/api/spec_helper.rb b/logstash-core/spec/api/spec_helper.rb
new file mode 100644
index 00000000000..f6f9ac70ca9
--- /dev/null
+++ b/logstash-core/spec/api/spec_helper.rb
@@ -0,0 +1,19 @@
+# encoding: utf-8
+ROOT = File.expand_path(File.join(File.dirname(__FILE__), "..", "..", "lib", "logstash", "api"))
+$LOAD_PATH.unshift File.join(ROOT, 'lib')
+Dir.glob(File.join(ROOT, "lib" "**")).each{ |d| $LOAD_PATH.unshift(d) }
+
+require "logstash/devutils/rspec/spec_helper"
+
+require 'rack/test'
+require 'rspec'
+require "json"
+
+ENV['RACK_ENV'] = 'test'
+
+Rack::Builder.parse_file(File.join(ROOT, 'init.ru'))
+
+def read_fixture(name)
+  path = File.join(File.dirname(__FILE__), "fixtures", name)
+  File.read(path)
+end
diff --git a/logstash-core/spec/logstash/agent_spec.rb b/logstash-core/spec/logstash/agent_spec.rb
index 1fae820b32a..b7ad9065e04 100644
--- a/logstash-core/spec/logstash/agent_spec.rb
+++ b/logstash-core/spec/logstash/agent_spec.rb
@@ -41,7 +41,9 @@
     let(:config_file) { Stud::Temporary.pathname }
 
     before :each do
-      File.open(config_file, "w") {|f| f.puts sample_config }
+      allow(subject).to receive(:start_webserver).and_return(false)
+      allow(subject).to receive(:stop_webserver).and_return(false)
+      File.open(config_file, "w") { |f| f.puts sample_config }
     end
 
     after :each do
@@ -182,6 +184,17 @@
       fetched_config = subject.send(:fetch_config, settings)
       expect(fetched_config.strip).to eq(cli_config + IO.read(tmp_config_path))
     end
+  end
 
+  context "#started_at" do
+    it "return the start time when the agent is started" do
+      expect(described_class::STARTED_AT).to be_kind_of(Time)
+    end
+  end
+
+  context "#uptime" do
+    it "return the number of milliseconds since start time" do
+      expect(subject.uptime).to be >= 0
+    end
   end
 end
diff --git a/logstash-core/spec/logstash/inputs/metrics_spec.rb b/logstash-core/spec/logstash/inputs/metrics_spec.rb
new file mode 100644
index 00000000000..5a214924b39
--- /dev/null
+++ b/logstash-core/spec/logstash/inputs/metrics_spec.rb
@@ -0,0 +1,48 @@
+# encoding: utf-8
+require "logstash/inputs/metrics"
+require "spec_helper"
+
+describe LogStash::Inputs::Metrics do
+  let(:queue) { [] }
+
+  describe "#run" do
+    it "should register itself to the collector observer" do
+      expect(LogStash::Instrument::Collector.instance).to receive(:add_observer).with(subject)
+      t = Thread.new { subject.run(queue) }
+      sleep(0.1) # give a bit of time to the thread to start
+      subject.stop
+    end
+  end
+
+  describe "#update" do
+    let(:namespaces)  { [:root, :base] }
+    let(:key)        { :foo }
+    let(:metric_store) { LogStash::Instrument::MetricStore.new }
+
+    it "should fill up the queue with received events" do
+      Thread.new { subject.run(queue) }
+      sleep(0.1)
+      subject.stop
+
+      metric_store.fetch_or_store(namespaces, key, LogStash::Instrument::MetricType::Counter.new(namespaces, key))
+      subject.update(LogStash::Instrument::Snapshot.new(metric_store))
+      expect(queue.count).to eq(1)
+    end
+  end
+
+  describe "#stop" do
+    it "should remove itself from the the collector observer" do
+      expect(LogStash::Instrument::Collector.instance).to receive(:delete_observer).with(subject)
+      t = Thread.new { subject.run(queue) }
+      sleep(0.1) # give a bit of time to the thread to start
+      subject.stop
+    end
+
+    it "should unblock the input" do
+      t = Thread.new { subject.run(queue) }
+      sleep(0.1) # give a bit of time to the thread to start
+      subject.do_stop
+      wait_for { t.status }.to be_falsey
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/instrument/collector_spec.rb b/logstash-core/spec/logstash/instrument/collector_spec.rb
new file mode 100644
index 00000000000..b96be4a5ede
--- /dev/null
+++ b/logstash-core/spec/logstash/instrument/collector_spec.rb
@@ -0,0 +1,49 @@
+# encoding: utf-8
+require "logstash/instrument/collector"
+require "spec_helper"
+
+describe LogStash::Instrument::Collector do
+  subject { LogStash::Instrument::Collector.instance }
+  describe "#push" do
+    let(:namespaces_path) { [:root, :pipelines, :pipelines01] }
+    let(:key) { :my_key }
+
+    context "when the `MetricType` exist" do
+      it "store the metric of type `counter`" do
+        subject.push(namespaces_path, key, :counter, :increment)
+      end
+    end
+
+    context "when the `MetricType` doesn't exist" do
+      let(:wrong_type) { :donotexist }
+
+      it "logs an error but dont crash" do
+        expect(subject.logger).to receive(:error)
+          .with("Collector: Cannot create concrete class for this metric type",
+        hash_including({ :type => wrong_type, :namespaces_path => namespaces_path }))
+
+          subject.push(namespaces_path, key, wrong_type, :increment)
+      end
+    end
+
+    context "when there is a conflict with the metric key" do
+      let(:conflicting_namespaces) { [namespaces_path, key].flatten }
+
+      it "logs an error but dont crash" do
+        subject.push(namespaces_path, key, :counter, :increment)
+
+        expect(subject.logger).to receive(:error)
+          .with("Collector: Cannot record metric",
+          hash_including({ :exception => instance_of(LogStash::Instrument::MetricStore::NamespacesExpectedError) }))
+
+          subject.push(conflicting_namespaces, :random_key, :counter, :increment)
+      end
+    end
+  end
+
+  describe "#snapshot_metric" do
+    it "return a `LogStash::Instrument::MetricStore`" do
+      expect(subject.snapshot_metric).to be_kind_of(LogStash::Instrument::Snapshot)
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/instrument/metric_spec.rb b/logstash-core/spec/logstash/instrument/metric_spec.rb
new file mode 100644
index 00000000000..0a8a65d4338
--- /dev/null
+++ b/logstash-core/spec/logstash/instrument/metric_spec.rb
@@ -0,0 +1,110 @@
+# encoding: utf-8
+require "logstash/instrument/metric"
+require "logstash/instrument/collector"
+require_relative "../../support/matchers"
+require "spec_helper"
+
+describe LogStash::Instrument::Metric do
+  let(:collector) { [] }
+  let(:namespace) { :root }
+
+  subject { LogStash::Instrument::Metric.new(collector) }
+
+  context "#increment" do
+    it "a counter by 1" do
+      metric = subject.increment(:root, :error_rate)
+      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :increment, 1)
+    end
+
+    it "a counter by a provided value" do
+      metric = subject.increment(:root, :error_rate, 20)
+      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :increment, 20)
+    end
+
+    it "raises an exception if the key is an empty string" do
+      expect { subject.increment(:root, "", 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
+    end
+
+    it "raise an exception if the key is nil" do
+      expect { subject.increment(:root, nil, 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
+    end
+  end
+
+  context "#decrement" do
+    it "a counter by 1" do
+      metric = subject.decrement(:root, :error_rate)
+      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :decrement, 1)
+    end
+
+    it "a counter by a provided value" do
+      metric = subject.decrement(:root, :error_rate, 20)
+      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :decrement, 20)
+    end
+
+    it "raises an exception if the key is an empty string" do
+      expect { subject.decrement(:root, "", 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
+    end
+
+    it "raise an exception if the key is nil" do
+      expect { subject.decrement(:root, nil, 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
+    end
+  end
+
+  context "#gauge" do
+    it "set the value of a key" do
+      metric = subject.gauge(:root, :size_queue, 20)
+      expect(collector).to be_a_metric_event([:root, :size_queue], :gauge, :set, 20)
+    end
+
+    it "raises an exception if the key is an empty string" do
+      expect { subject.gauge(:root, "", 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
+    end
+
+    it "raise an exception if the key is nil" do
+      expect { subject.gauge(:root, nil, 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
+    end
+  end
+
+  context "#time" do
+    let(:sleep_time) { 2 }
+    let(:sleep_time_ms) { sleep_time * 1_000_000 }
+
+    it "records the duration" do
+      subject.time(:root, :duration_ms) { sleep(sleep_time) }
+
+      expect(collector.last).to be_within(sleep_time_ms).of(sleep_time_ms + 5000)
+      expect(collector[0]).to match(:root)
+      expect(collector[1]).to be(:duration_ms)
+      expect(collector[2]).to be(:mean)
+    end
+
+    it "returns the value of the executed block" do
+      expect(subject.time(:root, :testing) { "hello" }).to eq("hello")
+    end
+
+    it "return a TimedExecution" do
+      execution = subject.time(:root, :duration_ms)
+      sleep(sleep_time)
+      execution.stop
+
+      expect(collector.last).to be_within(sleep_time_ms).of(sleep_time_ms + 0.1)
+      expect(collector[0]).to match(:root)
+      expect(collector[1]).to be(:duration_ms)
+      expect(collector[2]).to be(:mean)
+    end
+  end
+
+  context "#namespace" do
+    let(:sub_key) { :my_sub_key }
+
+    it "creates a new metric object and append the `sub_key` to the `base_key`" do
+      expect(subject.namespace(sub_key).namespace_name).to eq([sub_key])
+    end
+
+    it "uses the same collector as the creator class" do
+      child = subject.namespace(sub_key)
+      metric = child.increment(:error_rate)
+      expect(collector).to be_a_metric_event([sub_key, :error_rate], :counter, :increment, 1)
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/instrument/metric_store_spec.rb b/logstash-core/spec/logstash/instrument/metric_store_spec.rb
new file mode 100644
index 00000000000..4371977355b
--- /dev/null
+++ b/logstash-core/spec/logstash/instrument/metric_store_spec.rb
@@ -0,0 +1,163 @@
+# encoding: utf-8
+require "logstash/instrument/metric_store"
+require "logstash/instrument/metric_type/base"
+
+describe LogStash::Instrument::MetricStore do
+  let(:namespaces) { [ :root, :pipelines, :pipeline_01 ] }
+  let(:key) { :events_in }
+  let(:counter) { LogStash::Instrument::MetricType::Counter.new(namespaces, key) }
+
+  context "when the metric object doesn't exist" do
+    it "store the object" do
+      expect(subject.fetch_or_store(namespaces, key, counter)).to eq(counter)
+    end
+
+    it "support a block as argument" do
+      expect(subject.fetch_or_store(namespaces, key) { counter }).to eq(counter)
+    end
+  end
+
+  context "when the metric object exist in the namespace"  do
+    let(:new_counter) { LogStash::Instrument::MetricType::Counter.new(namespaces, key) }
+
+    it "return the object" do
+      subject.fetch_or_store(namespaces, key, counter)
+      expect(subject.fetch_or_store(namespaces, key, new_counter)).to eq(counter)
+    end
+  end
+
+  context "when the namespace end node isn't a map" do
+    let(:conflicting_namespaces) { [:root, :pipelines, :pipeline_01, :events_in] }
+
+    it "raise an exception" do
+      subject.fetch_or_store(namespaces, key, counter)
+      expect { subject.fetch_or_store(conflicting_namespaces, :new_key, counter) }.to raise_error(LogStash::Instrument::MetricStore::NamespacesExpectedError)
+    end
+  end
+
+  context "retrieving events" do
+    let(:metric_events) {
+      [
+        [[:node, :sashimi, :pipelines, :pipeline01, :plugins, :"logstash-output-elasticsearch"], :event_in, :increment],
+        [[:node, :sashimi, :pipelines, :pipeline01], :processed_events_in, :increment],
+        [[:node, :sashimi, :pipelines, :pipeline01], :processed_events_out, :increment],
+        [[:node, :sashimi, :pipelines, :pipeline02], :processed_events_out, :increment],
+      ]
+    }
+
+    before :each do
+      # Lets add a few metrics in the store before trying to find them
+      metric_events.each do |namespaces, metric_key, action|
+        metric = subject.fetch_or_store(namespaces, metric_key, LogStash::Instrument::MetricType::Counter.new(namespaces, metric_key))
+        metric.execute(action)
+      end
+    end
+
+    describe "#get" do
+      context "when the path exist" do
+        it "retrieves end of of a branch" do
+          metrics = subject.get(:node, :sashimi, :pipelines, :pipeline01, :plugins, :"logstash-output-elasticsearch")
+          expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => a_hash_including(:plugins => a_hash_including(:"logstash-output-elasticsearch" => anything)))))))
+        end
+
+        it "retrieves branch" do
+          metrics = subject.get(:node, :sashimi, :pipelines, :pipeline01)
+          expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything)))))
+        end
+
+        it "allow to retrieve a specific metrics" do
+          metrics = subject.get(:node, :sashimi, :pipelines, :pipeline01, :plugins, :"logstash-output-elasticsearch", :event_in)
+          expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => a_hash_including(:plugins => a_hash_including(:"logstash-output-elasticsearch" => a_hash_including(:event_in => be_kind_of(LogStash::Instrument::MetricType::Base)))))))))
+        end
+
+        context "with filtered keys" do
+          it "allows to retrieve multiple keys on the same level" do
+            metrics = subject.get(:node, :sashimi, :pipelines, :"pipeline01,pipeline02")
+            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything, :pipeline02 => anything)))))
+          end
+
+          it "supports space in the keys" do
+            metrics = subject.get(:node, :sashimi, :pipelines, :"pipeline01, pipeline02 ")
+            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything, :pipeline02 => anything)))))
+          end
+
+          it "retrieves only the requested keys" do
+            metrics = subject.get(:node, :sashimi, :pipelines, :"pipeline01,pipeline02", :processed_events_in)
+            expect(metrics[:node][:sashimi][:pipelines].keys).to include(:pipeline01, :pipeline02)
+          end
+        end
+
+        context "when the path doesnt exist" do
+          it "raise an exception" do
+            expect { subject.get(:node, :sashimi, :dontexist) }.to raise_error(LogStash::Instrument::MetricStore::MetricNotFound, /dontexist/)
+          end
+        end
+      end
+
+      describe "#get_with_path" do
+        context "when the path exist" do
+          it "removes the first `/`" do
+            metrics = subject.get_with_path("/node/sashimi/")
+            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => anything)))
+          end
+
+          it "retrieves end of of a branch" do
+            metrics = subject.get_with_path("node/sashimi/pipelines/pipeline01/plugins/logstash-output-elasticsearch")
+            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => a_hash_including(:plugins => a_hash_including(:"logstash-output-elasticsearch" => anything)))))))
+          end
+
+          it "retrieves branch" do
+            metrics = subject.get_with_path("node/sashimi/pipelines/pipeline01")
+            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything)))))
+          end
+
+          it "allow to retrieve a specific metrics" do
+            metrics = subject.get_with_path("node/sashimi/pipelines/pipeline01/plugins/logstash-output-elasticsearch/event_in")
+            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => a_hash_including(:plugins => a_hash_including(:"logstash-output-elasticsearch" => a_hash_including(:event_in => be_kind_of(LogStash::Instrument::MetricType::Base)))))))))
+          end
+
+          context "with filtered keys" do
+            it "allows to retrieve multiple keys on the same level" do
+              metrics = subject.get_with_path("node/sashimi/pipelines/pipeline01,pipeline02/plugins/logstash-output-elasticsearch/event_in")
+              expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything, :pipeline02 => anything)))))
+            end
+
+            it "supports space in the keys" do
+              metrics = subject.get_with_path("node/sashimi/pipelines/pipeline01, pipeline02 /plugins/logstash-output-elasticsearch/event_in")
+              expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything, :pipeline02 => anything)))))
+            end
+
+            it "retrieves only the requested keys" do
+              metrics = subject.get(:node, :sashimi, :pipelines, :"pipeline01,pipeline02", :processed_events_in)
+              expect(metrics[:node][:sashimi][:pipelines].keys).to include(:pipeline01, :pipeline02)
+            end
+          end
+        end
+      end
+
+      context "when the path doesnt exist" do
+        it "raise an exception" do
+          expect { subject.get_with_path("node/sashimi/dontexist, pipeline02 /plugins/logstash-output-elasticsearch/event_in") }.to raise_error(LogStash::Instrument::MetricStore::MetricNotFound, /dontexist/)
+        end
+      end
+    end
+
+    describe "#each" do
+      it "retrieves all the metric" do
+        expect(subject.each.size).to eq(metric_events.size)
+      end
+
+      it "returns metric types" do
+        metrics = []
+        subject.each { |i| metrics << i }
+        expect(metrics.size).to eq(metric_events.size)
+      end
+
+      it "retrieves all the metrics from a specific branch" do
+        metrics = []
+        subject.each("node/sashimi/pipelines/pipeline01") { |i| metrics << i }
+        expect(metrics.size).to eq(3)
+      end
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/instrument/metric_type/counter_spec.rb b/logstash-core/spec/logstash/instrument/metric_type/counter_spec.rb
new file mode 100644
index 00000000000..b51aebc792d
--- /dev/null
+++ b/logstash-core/spec/logstash/instrument/metric_type/counter_spec.rb
@@ -0,0 +1,40 @@
+# encoding: utf-8
+require "logstash/instrument/metric_type/counter"
+require "spec_helper"
+
+describe LogStash::Instrument::MetricType::Counter do
+  let(:namespaces) { [:root, :pipelines, :pipeline_01] }
+  let(:key) { :mykey }
+
+  subject { LogStash::Instrument::MetricType::Counter.new(namespaces, key) }
+
+  describe "#increment" do
+    it "increment the counter" do
+      expect{ subject.increment }.to change { subject.value }.by(1)
+    end
+  end
+
+  describe "#decrement" do
+    it "decrement the counter" do
+      expect{ subject.decrement }.to change { subject.value }.by(-1)
+    end
+  end
+
+  context "When serializing to JSON" do
+    it "serializes the value" do
+      expect(LogStash::Json.dump(subject)).to eq("0")
+    end
+  end
+
+  context "When creating a hash " do
+    it "creates the hash from all the values" do
+      metric_hash = {
+        "key" => key,
+        "namespaces" => namespaces,
+        "value" => 0,
+        "type" => "counter"
+      }
+      expect(subject.to_hash).to match(metric_hash)
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/instrument/metric_type/gauge_spec.rb b/logstash-core/spec/logstash/instrument/metric_type/gauge_spec.rb
new file mode 100644
index 00000000000..0481f6d283b
--- /dev/null
+++ b/logstash-core/spec/logstash/instrument/metric_type/gauge_spec.rb
@@ -0,0 +1,40 @@
+# encoding: utf-8
+require "logstash/instrument/metric_type/gauge"
+require "logstash/json"
+require "spec_helper"
+
+describe LogStash::Instrument::MetricType::Gauge do
+  let(:namespaces) { [:root, :pipelines, :pipeline_01] }
+  let(:key) { :mykey }
+  let(:value) { "hello" }
+
+  subject { described_class.new(namespaces, key) }
+
+  before :each do
+    subject.execute(:set, value)
+  end
+
+  describe "#execute" do
+    it "set the value of the gauge" do
+      expect(subject.value).to eq(value)
+    end
+  end
+
+  context "When serializing to JSON" do
+    it "serializes the value" do
+      expect(LogStash::Json.dump(subject)).to eq("\"#{value}\"")
+    end
+  end
+
+  context "When creating a hash " do
+    it "creates the hash from all the values" do
+      metric_hash = {
+        "key" => key,
+        "namespaces" => namespaces,
+        "value" => value,
+        "type" => "gauge"
+      }
+      expect(subject.to_hash).to match(metric_hash)
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/instrument/namespaced_metric_spec.rb b/logstash-core/spec/logstash/instrument/namespaced_metric_spec.rb
new file mode 100644
index 00000000000..6ba84168df9
--- /dev/null
+++ b/logstash-core/spec/logstash/instrument/namespaced_metric_spec.rb
@@ -0,0 +1,25 @@
+# encoding: utf-8
+require "logstash/instrument/namespaced_metric"
+require "logstash/instrument/metric"
+require_relative "../../support/matchers"
+require "spec_helper"
+
+describe LogStash::Instrument::NamespacedMetric do
+  let(:namespace) { :stats }
+  let(:collector) { [] }
+  let(:metric) { LogStash::Instrument::Metric.new(collector) }
+
+  subject { described_class.new(metric, namespace) }
+
+  it "defines the same interface as `Metric`" do
+    expect(described_class).to implement_interface_of(LogStash::Instrument::Metric)
+  end
+
+  it "returns a TimedException when we call without a block" do
+    expect(subject.time(:duration_ms)).to be_kind_of(LogStash::Instrument::Metric::TimedExecution)
+  end
+
+  it "returns the value of the block" do
+    expect(subject.time(:duration_ms) { "hello" }).to eq("hello")
+  end
+end
diff --git a/logstash-core/spec/logstash/instrument/null_metric_spec.rb b/logstash-core/spec/logstash/instrument/null_metric_spec.rb
new file mode 100644
index 00000000000..ec55d341be4
--- /dev/null
+++ b/logstash-core/spec/logstash/instrument/null_metric_spec.rb
@@ -0,0 +1,21 @@
+# encoding: utf-8
+require "logstash/instrument/null_metric"
+require "logstash/instrument/namespaced_metric"
+require_relative "../../support/matchers"
+
+describe LogStash::Instrument::NullMetric do
+  it "defines the same interface as `Metric`" do
+    expect(described_class).to implement_interface_of(LogStash::Instrument::NamespacedMetric)
+  end
+
+  describe "#time" do
+    it "returns the value of the block without recording any metrics" do
+      expect(subject.time(:execution_time) { "hello" }).to eq("hello")
+    end
+
+    it "return a TimedExecution" do
+      execution = subject.time(:do_something)
+      expect { execution.stop }.not_to raise_error
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/json_spec.rb b/logstash-core/spec/logstash/json_spec.rb
index 68a1a6811eb..056325ac91b 100644
--- a/logstash-core/spec/logstash/json_spec.rb
+++ b/logstash-core/spec/logstash/json_spec.rb
@@ -59,6 +59,20 @@
         expect(LogStash::Json.dump(array)).to eql(json_array)
       end
 
+      context "pretty print" do
+
+        let(:hash) { { "foo" => "bar", :zoo => 2 } }
+
+        it "should serialize with pretty print" do
+          pprint_json = LogStash::Json.dump(hash, :pretty => true)
+          expect(pprint_json).to include("\n")
+        end
+
+        it "should by default do no pretty print" do
+          pprint_json = LogStash::Json.dump(hash)
+          expect(pprint_json).not_to include("\n")
+        end
+      end
     end
 
   else
diff --git a/logstash-core/spec/logstash/output_delegator_spec.rb b/logstash-core/spec/logstash/output_delegator_spec.rb
index dee26d95bc0..c3683a9526a 100644
--- a/logstash-core/spec/logstash/output_delegator_spec.rb
+++ b/logstash-core/spec/logstash/output_delegator_spec.rb
@@ -1,4 +1,5 @@
 # encoding: utf-8
+require "logstash/output_delegator"
 require 'spec_helper'
 
 describe LogStash::OutputDelegator do
@@ -6,18 +7,20 @@
   let(:events) { 7.times.map { LogStash::Event.new }}
   let(:default_worker_count) { 1 }
 
-  subject { described_class.new(logger, out_klass, default_worker_count) }
+  subject { described_class.new(logger, out_klass, default_worker_count, LogStash::Instrument::NullMetric.new) }
 
   context "with a plain output plugin" do
     let(:out_klass) { double("output klass") }
     let(:out_inst) { double("output instance") }
 
-    before do
+    before(:each) do
       allow(out_klass).to receive(:new).with(any_args).and_return(out_inst)
       allow(out_klass).to receive(:threadsafe?).and_return(false)
       allow(out_klass).to receive(:workers_not_supported?).and_return(false)
       allow(out_inst).to receive(:register)
       allow(out_inst).to receive(:multi_receive)
+      allow(out_inst).to receive(:metric=).with(any_args)
+      allow(out_inst).to receive(:id).and_return("a-simple-plugin")
       allow(logger).to receive(:debug).with(any_args)
     end
 
@@ -56,6 +59,8 @@
         before do
           allow(out_klass).to receive(:threadsafe?).and_return(false)
           allow(out_klass).to receive(:workers_not_supported?).and_return(false)
+          allow(out_inst).to receive(:metric=).with(any_args)
+          allow(out_inst).to receive(:id).and_return("a-simple-plugin")
         end
 
         it "should instantiate multiple workers" do
@@ -71,6 +76,8 @@
       describe "threadsafe outputs" do
         before do
           allow(out_klass).to receive(:threadsafe?).and_return(true)
+          allow(out_inst).to receive(:metric=).with(any_args)
+          allow(out_inst).to receive(:id).and_return("a-simple-plugin")
           allow(out_klass).to receive(:workers_not_supported?).and_return(false)
         end
 
diff --git a/logstash-core/spec/logstash/pipeline_spec.rb b/logstash-core/spec/logstash/pipeline_spec.rb
index 5b8000cb390..d594a84592a 100644
--- a/logstash-core/spec/logstash/pipeline_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_spec.rb
@@ -17,6 +17,21 @@ def close
   end
 end
 
+class DummyInputGenerator < LogStash::Inputs::Base
+  config_name "dummyinputgenerator"
+  milestone 2
+
+  def register
+  end
+
+  def run(queue)
+    queue << Logstash::Event.new while !stop?
+  end
+
+  def close
+  end
+end
+
 class DummyCodec < LogStash::Codecs::Base
   config_name "dummycodec"
   milestone 2
@@ -47,16 +62,20 @@ def initialize(params={})
 
   def register
   end
-  
+
   def receive(event)
     @events << event
   end
 
   def close
-    @num_closes += 1
+    @num_closes = 1
   end
 end
 
+class DummyOutputMore < DummyOutput
+  config_name "dummyoutputmore"
+end
+
 class DummyFilter < LogStash::Filters::Base
   config_name "dummyfilter"
   milestone 2
@@ -120,8 +139,7 @@ class TestPipeline < LogStash::Pipeline
 
       context "when there is no command line -w N set" do
         it "starts one filter thread" do
-          msg = "Defaulting pipeline worker threads to 1 because there are some" +
-                " filters that might not work with multiple worker threads"
+          msg = "Defaulting pipeline worker threads to 1 because there are some filters that might not work with multiple worker threads"
           pipeline = TestPipeline.new(test_config_with_filters)
           expect(pipeline.logger).to receive(:warn).with(msg,
             {:count_was=>worker_thread_count, :filters=>["dummyfilter"]})
@@ -132,8 +150,7 @@ class TestPipeline < LogStash::Pipeline
 
       context "when there is command line -w N set" do
         it "starts multiple filter thread" do
-          msg = "Warning: Manual override - there are filters that might" +
-                " not work with multiple worker threads"
+          msg = "Warning: Manual override - there are filters that might not work with multiple worker threads"
           pipeline = TestPipeline.new(test_config_with_filters)
           expect(pipeline.logger).to receive(:warn).with(msg,
             {:worker_threads=> override_thread_count, :filters=>["dummyfilter"]})
@@ -356,6 +373,39 @@ class TestPipeline < LogStash::Pipeline
     end
   end
 
+  context "metrics" do
+    config <<-CONFIG
+    input { }
+    filter { }
+    output { }
+    CONFIG
+
+    it "uses a `NullMetric` object if no metric is given" do
+      pipeline = LogStash::Pipeline.new(config)
+      expect(pipeline.metric).to be_kind_of(LogStash::Instrument::NullMetric)
+    end
+  end
+
+  context "Multiples pipelines" do
+    before do
+      allow(LogStash::Plugin).to receive(:lookup).with("input", "dummyinputgenerator").and_return(DummyInputGenerator)
+      allow(LogStash::Plugin).to receive(:lookup).with("codec", "plain").and_return(DummyCodec)
+      allow(LogStash::Plugin).to receive(:lookup).with("filter", "dummyfilter").and_return(DummyFilter)
+      allow(LogStash::Plugin).to receive(:lookup).with("output", "dummyoutput").and_return(DummyOutput)
+      allow(LogStash::Plugin).to receive(:lookup).with("output", "dummyoutputmore").and_return(DummyOutputMore)
+    end
+
+    let(:pipeline1) { LogStash::Pipeline.new("input { dummyinputgenerator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
+    let(:pipeline2) { LogStash::Pipeline.new("input { dummyinputgenerator {} } filter { dummyfilter {} } output { dummyoutputmore {}}") }
+
+    it "should handle evaluating different config" do
+      expect(pipeline1.output_func(LogStash::Event.new)).not_to include(nil)
+      expect(pipeline1.filter_func(LogStash::Event.new)).not_to include(nil)
+      expect(pipeline2.output_func(LogStash::Event.new)).not_to include(nil)
+      expect(pipeline1.filter_func(LogStash::Event.new)).not_to include(nil)
+    end
+  end
+
   context "Periodic Flush" do
     let(:number_of_events) { 100 }
     let(:config) do
@@ -366,7 +416,7 @@ class TestPipeline < LogStash::Pipeline
         }
       }
       filter {
-        multiline { 
+        multiline {
           pattern => "^NeverMatch"
           negate => true
           what => "previous"
@@ -378,7 +428,7 @@ class TestPipeline < LogStash::Pipeline
       EOS
     end
     let(:output) { DummyOutput.new }
-    
+
     before do
       allow(DummyOutput).to receive(:new).with(any_args).and_return(output)
       allow(LogStash::Plugin).to receive(:lookup).with("input", "generator").and_return(LogStash::Inputs::Generator)
@@ -414,8 +464,8 @@ class TestPipeline < LogStash::Pipeline
 
     it "should handle evaluating different config" do
       # When the functions are compiled from the AST it will generate instance
-      # variables that are unique to the actual config, the intance are pointing
-      # to conditionals/plugins.
+      # variables that are unique to the actual config, the intances are pointing
+      # to conditionals and/or plugins.
       #
       # Before the `defined_singleton_method`, the definition of the method was
       # not unique per class, but the `instance variables` were unique per class.
@@ -429,4 +479,108 @@ class TestPipeline < LogStash::Pipeline
       expect(pipeline1.filter_func(LogStash::Event.new)).not_to include(nil)
     end
   end
+
+  context "#started_at" do
+    let(:config) do
+      <<-EOS
+      input {
+        generator {}
+      }
+      EOS
+    end
+
+    subject { described_class.new(config) }
+
+    it "returns nil when the pipeline isnt started" do
+      expect(subject.started_at).to be_nil
+    end
+
+    it "return when the pipeline started working" do
+      t = Thread.new { subject.run }
+      sleep(0.1)
+      expect(subject.started_at).to be < Time.now
+      t.kill rescue nil
+    end
+  end
+
+  context "#uptime" do
+    let(:config) do
+      <<-EOS
+      input {
+        generator {}
+      }
+      EOS
+    end
+    subject { described_class.new(config) }
+
+    context "when the pipeline is not started" do
+      it "returns 0" do
+        expect(subject.uptime).to eq(0)
+      end
+    end
+
+    context "when the pipeline is started" do
+      it "return the duration in milliseconds" do
+        t = Thread.new { subject.run }
+        sleep(0.1)
+        expect(subject.uptime).to be > 0
+        t.kill rescue nil
+      end
+    end
+  end
+
+  context "when collecting metric in the pipeline" do
+    subject { described_class.new(config, { :metric => metric, :pipeline_id => pipeline_id }) }
+    let(:pipeline_id) { :main }
+    let(:metric) { LogStash::Instrument::Metric.new }
+    let(:number_of_events) { 1000 }
+    let(:config) do
+      <<-EOS
+      input { generator { count => #{number_of_events}} }
+      filter {
+         multiline {
+              pattern => "hello"
+              what => next
+          }
+      }
+      output { dummyoutput {} }
+      EOS
+    end
+    let(:dummyoutput) { DummyOutput.new }
+
+    before do
+      allow(DummyOutput).to receive(:new).with(any_args).and_return(dummyoutput)
+      allow(LogStash::Plugin).to receive(:lookup).with("input", "generator").and_return(LogStash::Inputs::Generator)
+      allow(LogStash::Plugin).to receive(:lookup).with("codec", "plain").and_return(LogStash::Codecs::Plain)
+      allow(LogStash::Plugin).to receive(:lookup).with("filter", "multiline").and_return(LogStash::Filters::Multiline)
+      allow(LogStash::Plugin).to receive(:lookup).with("output", "dummyoutput").and_return(DummyOutput)
+
+      # Reset the metric store
+      LogStash::Instrument::Collector.instance.clear
+    end
+
+    it "populates the differents core metrics" do
+      t = Thread.new { subject.run }
+      # make sure we have received all the generated events
+      sleep 0.01 while dummyoutput.events.size < number_of_events
+
+      collected_metric = LogStash::Instrument::Collector.instance.snapshot_metric.metric_store.get_with_path("stats/events")
+
+      expect(collected_metric[:stats][:events][:in].value).to eq(number_of_events)
+      expect(collected_metric[:stats][:events][:filtered].value).to eq(number_of_events)
+      expect(collected_metric[:stats][:events][:out].value).to eq(number_of_events)
+    end
+
+    it "populates the pipelines core metrics" do
+      t = Thread.new { subject.run }
+      # make sure we have received all the generated events
+      sleep 0.01 while dummyoutput.events.size < number_of_events
+
+      collected_metric = LogStash::Instrument::Collector.instance.snapshot_metric.metric_store.get_with_path("stats/pipelines/")
+
+      expect(collected_metric[:stats][:pipelines][:main][:events][:in].value).to eq(number_of_events)
+      expect(collected_metric[:stats][:pipelines][:main][:events][:filtered].value).to eq(number_of_events)
+      expect(collected_metric[:stats][:pipelines][:main][:events][:out].value).to eq(number_of_events)
+    end
+  end
 end
diff --git a/logstash-core/spec/logstash/plugin_spec.rb b/logstash-core/spec/logstash/plugin_spec.rb
index 16d1485e180..fa94ca7350d 100644
--- a/logstash-core/spec/logstash/plugin_spec.rb
+++ b/logstash-core/spec/logstash/plugin_spec.rb
@@ -1,6 +1,10 @@
 # encoding: utf-8
 require "spec_helper"
 require "logstash/plugin"
+require "logstash/outputs/base"
+require "logstash/codecs/base"
+require "logstash/inputs/base"
+require "logstash/filters/base"
 
 describe LogStash::Plugin do
   it "should fail lookup on inexisting type" do
@@ -166,4 +170,56 @@ def register; end
 
     end
   end
+
+  describe "#id" do
+    plugin_types = [
+      LogStash::Filters::Base,
+      LogStash::Codecs::Base,
+      LogStash::Outputs::Base,
+      LogStash::Inputs::Base
+    ]
+
+    plugin_types.each do |plugin_type|
+      let(:plugin) do
+        Class.new(plugin_type) do
+          config_name "simple_plugin"
+
+          config :host, :validate => :string
+          config :export, :validte => :boolean
+
+          def register; end
+        end
+      end
+
+      let(:config) do
+        {
+          "host" => "127.0.0.1",
+          "export" => true
+        }
+      end
+
+      subject { plugin.new(config) }
+
+      context "plugin type is #{plugin_type}" do
+        context "when there is not ID configured for the output" do
+          it "it uses a UUID to identify this plugins" do
+            expect(subject.id).not_to eq(nil)
+          end
+
+          it "will be different between instance of plugins" do
+            expect(subject.id).not_to eq(plugin.new(config).id)
+          end
+        end
+
+        context "When a user provide an ID for the plugin" do
+          let(:id) { "ABC" }
+          let(:config) { super.merge("id" => id) }
+
+          it "uses the user provided ID" do
+            expect(subject.id).to eq(id)
+          end
+        end
+      end
+    end
+  end
 end
diff --git a/logstash-core/spec/logstash/runner_spec.rb b/logstash-core/spec/logstash/runner_spec.rb
index a2faefe7a5c..f8bcd9a6f35 100644
--- a/logstash-core/spec/logstash/runner_spec.rb
+++ b/logstash-core/spec/logstash/runner_spec.rb
@@ -3,6 +3,7 @@
 require "logstash/runner"
 require "stud/task"
 require "stud/trap"
+require "logstash/util/java_version"
 
 class NullRunner
   def run(args); end
@@ -40,6 +41,13 @@ def run(args); end
 
     context "with no arguments" do
       let(:args) { [] }
+      let(:agent) { double("agent") }
+
+      before(:each) do
+        allow(LogStash::Agent).to receive(:new).and_return(agent)
+        allow(LogStash::Util::JavaVersion).to receive(:warn_on_bad_java_version)
+      end
+
       it "should show help" do
         expect($stderr).to receive(:puts).once
         expect(subject).to receive(:signal_usage_error).once.and_call_original
@@ -93,6 +101,7 @@ def run(args); end
     let(:pipeline) { double("pipeline") }
 
     before(:each) do
+      allow_any_instance_of(LogStash::Agent).to receive(:execute).and_return(true)
       task = Stud::Task.new { 1 }
       allow(pipeline).to receive(:run).and_return(task)
       allow(pipeline).to receive(:shutdown)
@@ -101,6 +110,7 @@ def run(args); end
     context "when :pipeline_workers is not defined by the user" do
       it "should not pass the value to the pipeline" do
         expect(LogStash::Pipeline).to receive(:new).once.with(pipeline_string, hash_excluding(:pipeline_workers)).and_return(pipeline)
+
         args = ["-e", pipeline_string]
         subject.run("bin/logstash", args)
       end
@@ -110,6 +120,7 @@ def run(args); end
       it "should pass the value to the pipeline" do
         main_pipeline_settings[:pipeline_workers] = 2
         expect(LogStash::Pipeline).to receive(:new).with(pipeline_string, hash_including(main_pipeline_settings)).and_return(pipeline)
+
         args = ["-w", "2", "-e", pipeline_string]
         subject.run("bin/logstash", args)
       end
diff --git a/logstash-core/spec/logstash/util/duration_formatter_spec.rb b/logstash-core/spec/logstash/util/duration_formatter_spec.rb
new file mode 100644
index 00000000000..44c0eb64632
--- /dev/null
+++ b/logstash-core/spec/logstash/util/duration_formatter_spec.rb
@@ -0,0 +1,11 @@
+# encoding: utf-8
+require "logstash/util/duration_formatter"
+require "spec_helper"
+
+describe LogStash::Util::DurationFormatter do
+  let(:duration) { 3600 * 1000 } # in milliseconds
+
+  it "returns a human format" do
+    expect(subject.human_format(duration)).to eq("1h")
+  end
+end
diff --git a/logstash-core/spec/logstash/util_spec.rb b/logstash-core/spec/logstash/util_spec.rb
index 82e75092675..4cd56139fbf 100644
--- a/logstash-core/spec/logstash/util_spec.rb
+++ b/logstash-core/spec/logstash/util_spec.rb
@@ -3,8 +3,18 @@
 
 require "logstash/util"
 
+class ClassNameTest
+end
+
+module TestingClassName
+  class TestKlass
+  end
+end
+
 describe LogStash::Util do
 
+  subject { described_class }
+
   context "stringify_keys" do
     it "should convert hash symbol keys to strings" do
       expect(LogStash::Util.stringify_symbols({:a => 1, "b" => 2})).to eq({"a" => 1, "b" => 2})
@@ -32,4 +42,22 @@
       expect(LogStash::Util.stringify_symbols([:a, [1, :b]])).to eq(["a", [1, "b"]])
     end
   end
+
+  describe ".class_name" do
+    context "when the class is a top level class" do
+      let(:klass) { ClassNameTest.new }
+
+      it "returns the name of the class" do
+        expect(subject.class_name(klass)).to eq("ClassNameTest")
+      end
+    end
+
+    context "when the class is nested inside modules" do
+      let(:klass) { TestingClassName::TestKlass.new }
+
+      it "returns the name of the class" do
+        expect(subject.class_name(klass)).to eq("TestKlass")
+      end
+    end
+  end
 end
diff --git a/logstash-core/spec/support/matchers.rb b/logstash-core/spec/support/matchers.rb
new file mode 100644
index 00000000000..88ea508b02d
--- /dev/null
+++ b/logstash-core/spec/support/matchers.rb
@@ -0,0 +1,30 @@
+# encoding: utf-8
+require "rspec"
+require "rspec/expectations"
+
+RSpec::Matchers.define :be_a_metric_event do |namespace, type, *args|
+  match do
+    namespace == Array(actual[0]).concat(Array(actual[1])) &&
+      type == actual[2] &&
+      args == actual[3..-1]
+  end
+end
+
+# Match to test `NullObject` pattern
+RSpec::Matchers.define :implement_interface_of do |type, key, value|
+  match do |actual|
+    all_instance_methods_implemented?
+  end
+
+  def missing_methods
+    expected.instance_methods.select { |method| !actual.instance_methods.include?(method) }
+  end
+
+  def all_instance_methods_implemented?
+    expected.instance_methods.all? { |method| actual.instance_methods.include?(method) }
+  end
+
+  failure_message do
+    "Expecting `#{expected}` to implements instance methods of `#{actual}`, missing methods: #{missing_methods.join(",")}"
+  end
+end
