diff --git a/logstash-core/lib/logstash/agent.rb b/logstash-core/lib/logstash/agent.rb
index 15d8e5d9c42..45345e30d08 100644
--- a/logstash-core/lib/logstash/agent.rb
+++ b/logstash-core/lib/logstash/agent.rb
@@ -12,43 +12,78 @@
 LogStash::Environment.load_locale!
 
 class LogStash::Agent
-  attr_reader :logger
+  attr_reader :logger, :state
 
-  attr_writer :logger
-  attr_reader :node_name
-
-  def initialize(logger, options = {})
-    @logger = logger
+  def initialize(params)
+    @logger = params[:logger]
     @pipelines = {}
      
-    @node_name = options[:node_name] || Socket.gethostname
+    @node_name = params[:node_name] || Socket.gethostname
+    @pipeline_threads = {}
+    @config_loader = LogStash::Config::Loader.new(@logger, false)
+    @config_string = params[:config_string]
+    @config_path = params[:config_path]
+    @auto_reload = params[:auto_reload]
+    @pipeline_settings = params[:pipeline_settings]
+    @reload_interval = params[:reload_interval] || 5 # seconds
+    @upgrade_mutex = Mutex.new
+    # @state represents the necessary information for the agent's lifecycle.
+    # this base implementation uses the configuration string itself as state.
+    # if fetch_state returns a different string, it is regarded as new state
+    # and upgrade_state will take care of stopping the previous pipeline and
+    # starting a new one
+    # a subclass of this base Agent could use more complex state objects such
+    # as a hash map containing versioning, update_at timestamp, etc.
+    @state = clean_state
   end
 
-  def config_valid?(config_str)
-    begin
-      # There should be a better way to test this ideally
-      LogStash::Pipeline.new(config_str)
-    rescue Exception => e
-      e
+  def execute
+    @thread = Thread.current
+    @logger.info("starting agent", :state => @state)
+
+    if @auto_reload
+      Stud.interval(@reload_interval) do
+        if clean_state? || running_pipelines?
+          reload_state!
+        else
+          break
+        end
+      end
+    else
+      reload_state!
+      while !Stud.stop?
+        if clean_state? || running_pipelines?
+          sleep 0.5
+        else
+          break
+        end
+      end
     end
   end
 
-  def execute
-    # Make SIGINT/SIGTERM shutdown the pipeline.
-    sigint_id = trap_sigint()
-    sigterm_id = trap_sigterm()
+  def shutdown
+    shutdown_pipelines
+  end
 
-    @pipelines.each {|_, p| p.run } # blocking operation. works now because size <= 1
-    return 0
+  def reload_state!
+    new_state = fetch_state
+    if valid_state?(new_state)
+      if new_state?(@state, new_state)
+        @logger.warn("fetched new state. upgrading..", :state => new_state)
+        @upgrade_mutex.synchronize { upgrade_state(new_state) }
+      else
+        @logger.debug("same state, ignoring..")
+      end
+    else
+      @logger.error("invalid state", :state => new_state)
+    end
   rescue => e
     @logger.fatal I18n.t("oops", :error => e)
     @logger.fatal e.backtrace if @logger.debug? || $DEBUGLIST.include?("stacktrace")
     return 1
-  ensure
-    Stud::untrap("INT", sigint_id) unless sigint_id.nil?
-    Stud::untrap("TERM", sigterm_id) unless sigterm_id.nil?
-  end # def execute
+  end
 
+  private
   def add_pipeline(pipeline_id, config_str, settings = {})
     @pipelines[pipeline_id] = LogStash::Pipeline.new(config_str, settings.merge(:pipeline_id => pipeline_id))
   end
@@ -57,44 +92,67 @@ def node_uuid
     @node_uuid ||= SecureRandom.uuid
   end
 
-  private
-  # Emit a warning message.
-  def warn(message)
-    # For now, all warnings are fatal.
-    raise LogStash::ConfigurationError, message
-  end # def warn
+  def start_pipeline(id)
+    return unless @pipelines[id]
+    @logger.info("starting pipeline", :id => id)
+    @pipeline_threads[id] = Thread.new do
+      LogStash::Util.set_thread_name("pipeline.#{id}")
+      @pipelines[id].run
+    end
+  end
 
-  # Emit a failure message and abort.
-  def fail(message)
-    raise LogStash::ConfigurationError, message
-  end # def fail
+  def stop_pipeline(id)
+    return unless @pipelines[id]
+    @logger.warn("stopping pipeline", :id => id)
+    @pipelines[id].shutdown do
+      LogStash::ShutdownController.start(@pipelines[id], @pipeline_threads[id])
+    end
+    @pipeline_threads[id].join
+  end
 
   def shutdown_pipelines
-    @pipelines.each do |_, pipeline|
-      pipeline.shutdown do
-        ::LogStash::ShutdownController.start(pipeline)
-      end
-    end
+    @pipelines.each { |id, _| stop_pipeline(id) }
   end
 
-  def trap_sigterm
-    Stud::trap("TERM") do
-      @logger.warn(I18n.t("logstash.agent.sigterm"))
-      shutdown_pipelines
+  def running_pipelines?
+    @upgrade_mutex.synchronize do
+      @pipeline_threads.select {|_, pipeline| pipeline.alive? }.any?
     end
   end
 
-  def trap_sigint
-    Stud::trap("INT") do
-      if @interrupted_once
-        @logger.fatal(I18n.t("logstash.agent.forced_sigint"))
-        exit
-      else
-        @logger.warn(I18n.t("logstash.agent.sigint"))
-        Thread.new(@logger) {|logger| sleep 5; logger.warn(I18n.t("logstash.agent.slow_shutdown")) }
-        @interrupted_once = true
-        shutdown_pipelines
-      end
-    end
+  # Override the methods below if you're implementing your own agent
+  def upgrade_state(new_state)
+    stop_pipeline("base")
+    add_pipeline("base", new_state, @pipeline_settings)
+  rescue => e
+    @logger.error("failed to update state", :new_state => new_state, :message => e.message, :backtrace => e.backtrace)
+    @logger.warn("reverting to previous state", :state => @state)
+    add_pipeline("base", @state, @pipeline_settings) unless clean_state?
+    @state
+  else
+    @state = new_state
+  ensure
+    start_pipeline("base") unless clean_state?
+  end
+
+  def fetch_state
+    @config_loader.format_config(@config_path, @config_string)
   end
+
+  def valid_state?(new_state)
+    new_state.is_a?(String)
+  end
+
+  def new_state?(old_state, new_state)
+    old_state != new_state
+  end
+
+  def clean_state
+    ""
+  end
+
+  def clean_state?
+    @state == clean_state
+  end
+
 end # class LogStash::Agent
diff --git a/logstash-core/lib/logstash/agent.rb.orig b/logstash-core/lib/logstash/agent.rb.orig
new file mode 100644
index 00000000000..9aaf5ab1ea7
--- /dev/null
+++ b/logstash-core/lib/logstash/agent.rb.orig
@@ -0,0 +1,153 @@
+# encoding: utf-8
+require "logstash/environment"
+require "logstash/errors"
+require "logstash/config/cpu_core_strategy"
+require "logstash/pipeline"
+require "stud/trap"
+require "logstash/config/loader"
+require "uri"
+require "socket"
+require "securerandom"
+
+LogStash::Environment.load_locale!
+
+class LogStash::Agent
+  attr_reader :logger, :state
+
+  def initialize(params)
+    @logger = params[:logger]
+    @pipelines = {}
+     
+    @node_name = options[:node_name] || Socket.gethostname
+    @pipeline_threads = {}
+    @state = clean_state
+    @config_loader = LogStash::Config::Loader.new(@logger, false)
+    @config_string = params[:config_string]
+    @config_path = params[:config_path]
+    @auto_reload = params[:auto_reload]
+    @reload_interval = params[:reload_interval] || 5 # seconds
+  end
+
+  def execute
+    @thread = Thread.current
+    @logger.info("starting agent", :state => @state)
+<<<<<<< HEAD
+    reload_state
+    if @auto_reload
+      Stud.interval(5) { reload_state }
+=======
+
+    if @auto_reload
+      Stud.interval(@reload_interval) do
+        break unless clean_state? || running_pipelines?
+        reload_state!
+      end
+>>>>>>> d1c7f1a... add tests to agent. stop agent if pipeline terminates
+    else
+      reload_state!
+      while !Stud.stop?
+        break unless clean_state? || running_pipelines?
+        sleep 0.5
+      end
+    end
+  end
+
+  def shutdown
+    shutdown_pipelines
+  end
+
+  def reload_state
+    new_state = fetch_state
+    if valid_state?(new_state)
+      if new_state?(@state, new_state)
+        @logger.warn("fetched new state. upgrading..", :state => new_state)
+        upgrade_state(new_state)
+      else
+        @logger.debug("same state, ignoring..")
+      end
+    else
+      @logger.error("invalid state", :state => new_state)
+    end
+  rescue => e
+    @logger.fatal I18n.t("oops", :error => e)
+    @logger.fatal e.backtrace if @logger.debug? || $DEBUGLIST.include?("stacktrace")
+    return 1
+  end
+
+  private
+  def add_pipeline(pipeline_id, config_str, settings = {})
+    @pipelines[pipeline_id] = LogStash::Pipeline.new(config_str, settings.merge(:pipeline_id => pipeline_id))
+  end
+
+  def node_uuid
+    @node_uuid ||= SecureRandom.uuid
+  end
+
+  def start_pipeline(id)
+    return unless @pipelines[id]
+    @logger.info("starting pipeline", :id => id)
+    @pipeline_threads[id] = Thread.new do
+      LogStash::Util.set_thread_name("pipeline.#{id}")
+      @pipelines[id].run
+    end
+  end
+
+  def stop_pipeline(id)
+    return unless @pipelines[id]
+    @logger.warn("stopping pipeline", :id => id)
+    @pipelines[id].shutdown do
+      # TODO uncomment once shutdown controller can be stopped
+      #LogStash::ShutdownController.start(@pipelines[id])
+    end
+    @pipeline_threads[id].join
+  end
+
+  def shutdown_pipelines
+    @pipelines.each do |id, pipeline|
+      stop_pipeline(id)
+      #pipeline.shutdown do
+      #  ::LogStash::ShutdownController.start(pipeline)
+      #end
+    end
+  end
+
+  def running_pipelines?
+    @pipeline_threads.select {|_, pipeline| pipeline.alive? }.any?
+  end
+
+  # Override the methods below if you're implementing your own agent
+  def upgrade_state(new_state)
+    stop_pipeline("base")
+    add_pipeline("base", new_state)
+  rescue => e
+    @logger.error("failed to update state", :new_state => new_state, :message => e.message, :backtrace => e.backtrace)
+    @logger.warn("reverting to previous state", :state => @state)
+    add_pipeline("base", @state) unless clean_state?
+    @state
+  else
+    @state = new_state
+  ensure
+    start_pipeline("base") unless clean_state?
+  end
+
+  def fetch_state
+    @config_loader.format_config(@config_path, @config_string)
+  end
+
+  def valid_state?(new_state)
+    new_state.is_a?(String)
+  end
+
+  def new_state?(old_state, new_state)
+    old_state != new_state
+  end
+
+  def clean_state
+    ""
+  end
+
+  def clean_state?
+    @state == clean_state
+  end
+
+end # class LogStash::Agent
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 635f4d5b853..c5d77ec67c7 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -27,6 +27,16 @@ module LogStash; class Pipeline
     :flush_timeout_interval => 60 # in seconds
   }
 
+  def self.config_valid?(config_str)
+    begin
+      # There should be a better way to test this ideally
+      self.new(config_str)
+      true
+    rescue Exception => e
+      e
+    end
+  end
+
   def initialize(config_str, settings = {})
     @pipeline_id = settings[:pipeline_id] || self.object_id
     @logger = Cabin::Channel.get(LogStash)
@@ -118,7 +128,6 @@ def filters?
   end
 
   def run
-    LogStash::Util.set_thread_name("[#{pipeline_id}]-pipeline-manager")
     @logger.terminal(LogStash::Util::DefaultsPrinter.print(@settings))
 
     start_workers
diff --git a/logstash-core/lib/logstash/pipeline.rb.orig b/logstash-core/lib/logstash/pipeline.rb.orig
new file mode 100644
index 00000000000..7e20fd1a5ca
--- /dev/null
+++ b/logstash-core/lib/logstash/pipeline.rb.orig
@@ -0,0 +1,458 @@
+# encoding: utf-8
+require "thread"
+require "stud/interval"
+require "concurrent"
+require "logstash/namespace"
+require "logstash/errors"
+require "logstash/event"
+require "logstash/config/file"
+require "logstash/filters/base"
+require "logstash/inputs/base"
+require "logstash/outputs/base"
+require "logstash/config/cpu_core_strategy"
+require "logstash/util/defaults_printer"
+require "logstash/shutdown_controller"
+require "logstash/util/wrapped_synchronous_queue"
+require "logstash/pipeline_reporter"
+require "logstash/output_delegator"
+
+module LogStash; class Pipeline
+  attr_reader :inputs, :filters, :outputs, :worker_threads, :events_consumed, :events_filtered, :reporter, :pipeline_id
+
+  DEFAULT_SETTINGS = {
+    :default_pipeline_workers => LogStash::Config::CpuCoreStrategy.fifty_percent,
+    :pipeline_batch_size => 125,
+    :pipeline_batch_delay => 5, # in milliseconds
+    :flush_interval => 5, # in seconds
+    :flush_timeout_interval => 60 # in seconds
+  }
+
+  def self.config_valid?(config_str)
+    begin
+      # There should be a better way to test this ideally
+      self.new(config_str)
+      true
+    rescue Exception => e
+      e
+    end
+  end
+
+  def initialize(config_str, settings = {})
+    @pipeline_id = settings[:pipeline_id] || self.object_id
+    @logger = Cabin::Channel.get(LogStash)
+    @reporter = LogStash::PipelineReporter.new(@logger, self)
+
+    @inputs = nil
+    @filters = nil
+    @outputs = nil
+
+    @worker_threads = []
+
+    grammar = LogStashConfigParser.new
+    @config = grammar.parse(config_str)
+    if @config.nil?
+      raise LogStash::ConfigurationError, grammar.failure_reason
+    end
+    # This will compile the config to ruby and evaluate the resulting code.
+    # The code will initialize all the plugins and define the
+    # filter and output methods.
+    code = @config.compile
+    # The config code is hard to represent as a log message...
+    # So just print it.
+    @logger.debug? && @logger.debug("Compiled pipeline code:\n#{code}")
+    begin
+      eval(code)
+    rescue => e
+      raise
+    end
+
+    @input_queue = LogStash::Util::WrappedSynchronousQueue.new
+    @events_filtered = Concurrent::AtomicFixnum.new(0)
+    @events_consumed = Concurrent::AtomicFixnum.new(0)
+
+    # We generally only want one thread at a time able to access pop/take/poll operations
+    # from this queue. We also depend on this to be able to block consumers while we snapshot
+    # in-flight buffers
+    @input_queue_pop_mutex = Mutex.new
+    @input_threads = []
+    @settings = DEFAULT_SETTINGS.clone
+    # @ready requires thread safety since it is typically polled from outside the pipeline thread
+    @ready = Concurrent::AtomicBoolean.new(false)
+    @running = Concurrent::AtomicBoolean.new(false)
+    @flushing = Concurrent::AtomicReference.new(false)
+    settings.each {|setting, value| configure(setting, value) }
+
+    start_flusher
+  end # def initialize
+
+  def ready?
+    @ready.value
+  end
+
+  def configure(setting, value)
+    @settings[setting] = value
+  end
+
+  def safe_pipeline_worker_count
+    default = DEFAULT_SETTINGS[:default_pipeline_workers]
+    thread_count = @settings[:pipeline_workers] #override from args "-w 8" or config
+    safe_filters, unsafe_filters = @filters.partition(&:threadsafe?)
+
+    if unsafe_filters.any?
+      plugins = unsafe_filters.collect { |f| f.class.config_name }
+      case thread_count
+      when nil
+        # user did not specify a worker thread count
+        # warn if the default is multiple
+
+        if default > 1
+          @logger.warn("Defaulting pipeline worker threads to 1 because there are some filters that might not work with multiple worker threads",
+                       :count_was => default, :filters => plugins)
+        end
+
+        1 # can't allow the default value to propagate if there are unsafe filters
+      when 0, 1
+        1
+      else
+        @logger.warn("Warning: Manual override - there are filters that might not work with multiple worker threads",
+                     :worker_threads => thread_count, :filters => plugins)
+        thread_count # allow user to force this even if there are unsafe filters
+      end
+    else
+      thread_count || default
+    end
+  end
+
+  def filters?
+    return @filters.any?
+  end
+
+  def run
+<<<<<<< HEAD
+    LogStash::Util.set_thread_name("[#{pipeline_id}]-pipeline-manager")
+=======
+    @thread = Thread.current
+>>>>>>> 6213e77... Temp work on stoppable shutdown controller
+    @logger.terminal(LogStash::Util::DefaultsPrinter.print(@settings))
+
+    start_workers
+
+    @logger.info("Pipeline started")
+    @logger.terminal("Logstash startup completed")
+
+    # Block until all inputs have stopped
+    # Generally this happens if SIGINT is sent and `shutdown` is called from an external thread
+
+    @running.make_true
+    wait_inputs
+    @running.make_false
+
+    @logger.info("Input plugins stopped! Will shutdown filter/output workers.")
+
+    shutdown_flusher
+    shutdown_workers
+
+    @logger.info("Pipeline shutdown complete.")
+    @logger.terminal("Logstash shutdown completed")
+
+    # exit code
+    return 0
+  end # def run
+
+  def start_workers
+    @inflight_batches = {}
+
+    @worker_threads.clear # In case we're restarting the pipeline
+    begin
+      start_inputs
+      @outputs.each {|o| o.register }
+      @filters.each {|f| f.register}
+
+      pipeline_workers = safe_pipeline_worker_count
+      batch_size = @settings[:pipeline_batch_size]
+      batch_delay = @settings[:pipeline_batch_delay]
+      @logger.info("Starting pipeline",
+                   :id => self.pipeline_id,
+                   :pipeline_workers => pipeline_workers,
+                   :batch_size => batch_size,
+                   :batch_delay => batch_delay)
+
+      pipeline_workers.times do |t|
+        @worker_threads << Thread.new do
+          LogStash::Util.set_thread_name("[#{pipeline_id}]>worker#{t}")
+          worker_loop(batch_size, batch_delay)
+        end
+      end
+    ensure
+      # it is important to garantee @ready to be true after the startup sequence has been completed
+      # to potentially unblock the shutdown method which may be waiting on @ready to proceed
+      @ready.make_true
+    end
+  end
+
+  # Main body of what a worker thread does
+  # Repeatedly takes batches off the queu, filters, then outputs them
+  def worker_loop(batch_size, batch_delay)
+    running = true
+
+    while running
+      # To understand the purpose behind this synchronize please read the body of take_batch
+      input_batch, signal = @input_queue_pop_mutex.synchronize { take_batch(batch_size, batch_delay) }
+      running = false if signal == LogStash::SHUTDOWN
+
+      @events_consumed.increment(input_batch.size)
+
+      filtered_batch = filter_batch(input_batch)
+
+      if signal # Flush on SHUTDOWN or FLUSH
+        flush_options = (signal == LogStash::SHUTDOWN) ? {:final => true} : {}
+        flush_filters_to_batch(filtered_batch, flush_options)
+      end
+
+      @events_filtered.increment(filtered_batch.size)
+
+      output_batch(filtered_batch)
+
+      inflight_batches_synchronize { set_current_thread_inflight_batch(nil) }
+    end
+  end
+
+  def take_batch(batch_size, batch_delay)
+    batch = []
+    # Since this is externally synchronized in `worker_look` wec can guarantee that the visibility of an insight batch
+    # guaranteed to be a full batch not a partial batch
+    set_current_thread_inflight_batch(batch)
+
+    signal = false
+    batch_size.times do |t|
+      event = (t == 0) ? @input_queue.take : @input_queue.poll(batch_delay)
+      
+      if event.nil?
+        next
+      elsif event == LogStash::SHUTDOWN || event == LogStash::FLUSH
+        # We MUST break here. If a batch consumes two SHUTDOWN events
+        # then another worker may have its SHUTDOWN 'stolen', thus blocking
+        # the pipeline. We should stop doing work after flush as well.
+        signal = event
+        break
+      else
+        batch << event
+      end
+    end
+
+    [batch, signal]
+  end
+
+  def filter_batch(batch)
+    batch.reduce([]) do |acc,e|
+      if e.is_a?(LogStash::Event)
+        filtered = filter_func(e)
+        filtered.each {|fe| acc << fe unless fe.cancelled?}
+      end
+      acc
+    end
+  rescue Exception => e
+    # Plugins authors should manage their own exceptions in the plugin code
+    # but if an exception is raised up to the worker thread they are considered
+    # fatal and logstash will not recover from this situation.
+    #
+    # Users need to check their configuration or see if there is a bug in the
+    # plugin.
+    @logger.error("Exception in pipelineworker, the pipeline stopped processing new events, please check your filter configuration and restart Logstash.",
+                  "exception" => e, "backtrace" => e.backtrace)
+    raise
+  end
+
+  # Take an array of events and send them to the correct output
+  def output_batch(batch)
+    # Build a mapping of { output_plugin => [events...]}
+    outputs_events = batch.reduce(Hash.new { |h, k| h[k] = [] }) do |acc, event|
+      # We ask the AST to tell us which outputs to send each event to
+      # Then, we stick it in the correct bin
+      output_func(event).each do |output|
+        acc[output] << event
+      end
+      acc
+    end
+    # Now that we have our output to event mapping we can just invoke each output
+    # once with its list of events
+    outputs_events.each do |output, events|
+      output.multi_receive(events)
+    end
+  end
+
+  def set_current_thread_inflight_batch(batch)
+    @inflight_batches[Thread.current] = batch
+  end
+
+  def inflight_batches_synchronize
+    @input_queue_pop_mutex.synchronize do
+      yield(@inflight_batches)
+    end
+  end
+
+  def wait_inputs
+    @input_threads.each(&:join)
+  end
+
+  def start_inputs
+    moreinputs = []
+    @inputs.each do |input|
+      if input.threadable && input.threads > 1
+        (input.threads - 1).times do |i|
+          moreinputs << input.clone
+        end
+      end
+    end
+    @inputs += moreinputs
+
+    @inputs.each do |input|
+      input.register
+      start_input(input)
+    end
+  end
+
+  def start_input(plugin)
+    @input_threads << Thread.new { inputworker(plugin) }
+  end
+
+  def inputworker(plugin)
+    LogStash::Util::set_thread_name("[#{pipeline_id}]<#{plugin.class.config_name}")
+    begin
+      plugin.run(@input_queue)
+    rescue => e
+      if plugin.stop?
+        @logger.debug("Input plugin raised exception during shutdown, ignoring it.",
+                      :plugin => plugin.class.config_name, :exception => e,
+                      :backtrace => e.backtrace)
+        return
+      end
+
+      # otherwise, report error and restart
+      if @logger.debug?
+        @logger.error(I18n.t("logstash.pipeline.worker-error-debug",
+                             :plugin => plugin.inspect, :error => e.to_s,
+                             :exception => e.class,
+                             :stacktrace => e.backtrace.join("\n")))
+      else
+        @logger.error(I18n.t("logstash.pipeline.worker-error",
+                             :plugin => plugin.inspect, :error => e))
+      end
+
+      # Assuming the failure that caused this exception is transient,
+      # let's sleep for a bit and execute #run again
+      sleep(1)
+      retry
+    ensure
+      plugin.do_close
+    end
+  end # def inputworker
+
+  # initiate the pipeline shutdown sequence
+  # this method is intended to be called from outside the pipeline thread
+  def shutdown(&before_stop)
+    before_stop.call if block_given?
+
+    @logger.info "Closing inputs"
+    @inputs.each(&:do_stop)
+    @logger.info "Closed inputs"
+  end # def shutdown
+
+  # After `shutdown` is called from an external thread this is called from the main thread to
+  # tell the worker threads to stop and then block until they've fully stopped
+  # This also stops all filter and output plugins
+  def shutdown_workers
+    # Each worker thread will receive this exactly once!
+    @worker_threads.each do |t|
+      @logger.debug("Pushing shutdown", :thread => t)
+      @input_queue.push(LogStash::SHUTDOWN)
+    end
+
+    @worker_threads.each do |t|
+      @logger.debug("Shutdown waiting for worker thread #{t}")
+      t.join
+    end
+
+    @filters.each(&:do_close)
+    @outputs.each(&:do_close)
+  end
+
+  def plugin(plugin_type, name, *args)
+    args << {} if args.empty?
+
+    klass = LogStash::Plugin.lookup(plugin_type, name)
+
+    if plugin_type == "output"
+      LogStash::OutputDelegator.new(@logger, klass, *args)
+    else
+      klass.new(*args)
+    end
+  end
+
+  # for backward compatibility in devutils for the rspec helpers, this method is not used
+  # in the pipeline anymore.
+  def filter(event, &block)
+    # filter_func returns all filtered events, including cancelled ones
+    filter_func(event).each { |e| block.call(e) }
+  end
+
+
+  # perform filters flush and yeild flushed event to the passed block
+  # @param options [Hash]
+  # @option options [Boolean] :final => true to signal a final shutdown flush
+  def flush_filters(options = {}, &block)
+    flushers = options[:final] ? @shutdown_flushers : @periodic_flushers
+
+    flushers.each do |flusher|
+      flusher.call(options, &block)
+    end
+  end
+
+  def start_flusher
+    @flusher_thread = Thread.new do
+      while Stud.stoppable_sleep(5, 0.1) { @running.false? }
+        flush
+        break if @running.false?
+      end
+    end
+  end
+
+  def shutdown_flusher
+    @flusher_thread.join
+  end
+
+  def flush
+    if @flushing.compare_and_set(false, true)
+      @logger.debug? && @logger.debug("Pushing flush onto pipeline")
+      @input_queue.push(LogStash::FLUSH)
+    end
+  end
+
+  # perform filters flush into the output queue
+  # @param options [Hash]
+  # @option options [Boolean] :final => true to signal a final shutdown flush
+  def flush_filters_to_batch(batch, options = {})
+    flush_filters(options) do |event|
+      unless event.cancelled?
+        @logger.debug? and @logger.debug("Pushing flushed events", :event => event)
+        batch << event
+      end
+    end
+
+    @flushing.set(false)
+  end # flush_filters_to_output!
+
+  def plugin_threads_info
+    input_threads = @input_threads.select {|t| t.alive? }
+    worker_threads = @worker_threads.select {|t| t.alive? }
+    (input_threads + worker_threads).map {|t| LogStash::Util.thread_info(t) }
+  end
+
+  def stalling_threads_info
+    plugin_threads_info
+      .reject {|t| t["blocked_on"] } # known benign blocking statuses
+      .each {|t| t.delete("backtrace") }
+      .each {|t| t.delete("blocked_on") }
+      .each {|t| t.delete("status") }
+  end
+end end
\ No newline at end of file
diff --git a/logstash-core/lib/logstash/runner.rb b/logstash-core/lib/logstash/runner.rb
index 502a161acc5..f89795a05b1 100644
--- a/logstash-core/lib/logstash/runner.rb
+++ b/logstash-core/lib/logstash/runner.rb
@@ -25,7 +25,7 @@ class MissingAgentError < StandardError; end # Raised when the user asks for an
     I18n.t("logstash.runner.flag.config-string",
            :default_input => LogStash::Config::Defaults.input,
            :default_output => LogStash::Config::Defaults.output),
-    :default => "", :attribute_name => :config_string
+    :default => nil, :attribute_name => :config_string
 
   option ["-w", "--pipeline-workers"], "COUNT",
     I18n.t("logstash.runner.flag.pipeline-workers"),
@@ -84,6 +84,10 @@ class MissingAgentError < StandardError; end # Raised when the user asks for an
     I18n.t("logstash.runner.flag.agent"),
     :attribute_name => :agent_name, :default => LogStash::AgentPluginRegistry::DEFAULT_AGENT_NAME
 
+  option ["-r", "--[no-]auto-reload"], :flag,
+    I18n.t("logstash.runner.flag.auto_reload"),
+    :attribute_name => :auto_reload, :default => false
+
   attr_reader :agent
 
   def initialize(*args)
@@ -120,41 +124,49 @@ def execute
 
     return start_shell(@ruby_shell, binding) if @ruby_shell
 
-    @agent = create_agent
-    if !@agent
-      @logger.fatal("Could not load specified agent",
-                    :agent_name => agent_name,
-                    :valid_agent_names => LogStash::AgentPluginRegistry.available.map(&:to_s))
-      return 1
-    end
-
-    config_loader = LogStash::Config::Loader.new(@logger, config_test?)
-    loaded_config_str = config_loader.format_config(config_path, config_string)
-
-    if !config_path && (!config_string || config_string.empty?)
+    if config_string.nil? && config_path.nil?
       fail(I18n.t("logstash.runner.missing-configuration"))
     end
 
-
     if config_test?
-      config_error = @agent.config_valid?(loaded_config_str)
-      if config_error
+      config_loader = LogStash::Config::Loader.new(@logger, config_test?)
+      config_str = config_loader.format_config(config_path, config_string)
+      config_error = LogStash::Pipeline.config_valid?(config_str)
+      if config_error == true
+        @logger.terminal "Configuration OK"
+        return 0
+      else
         @logger.fatal I18n.t("logstash.error", :error => config_error)
         return 1
-      else
-        @logger.terminal "Configuration OK"
       end
-    else
-      pipeline_settings = {
-        :pipeline_workers => pipeline_workers,
-        :pipeline_batch_size => pipeline_batch_size,
-        :pipeline_batch_delay => pipeline_batch_delay
-      }
-      @agent.add_pipeline("base", loaded_config_str, pipeline_settings)
-      task = Stud::Task.new { @agent.execute }
-      return task.wait
     end
 
+    pipeline_settings = {
+      :pipeline_workers => pipeline_workers,
+      :pipeline_batch_size => pipeline_batch_size,
+      :pipeline_batch_delay => pipeline_batch_delay
+    }
+
+    @agent = create_agent(:logger => @logger,
+                          :config_string => config_string,
+                          :config_path => config_path,
+                          :auto_reload => @auto_reload,
+                          :pipeline_settings => pipeline_settings)
+
+    # enable sigint/sigterm before starting the agent
+    # to properly handle a stalled agent
+    sigint_id = trap_sigint()
+    sigterm_id = trap_sigterm()
+
+    @agent_task = Stud::Task.new { @agent.execute }
+
+    # no point in enabling config reloading before the agent starts
+    sighup_id = trap_sighup()
+
+    @agent_task.wait
+
+    @agent.shutdown
+
   rescue LoadError => e
     fail("Configuration problem.")
   rescue LogStash::ConfigurationError => e
@@ -162,10 +174,18 @@ def execute
     @logger.fatal I18n.t("logstash.error", :error => e)
     show_short_help
     return 1
+  rescue MissingAgentError => e
+    @logger.fatal("Could not load specified agent",
+                  :agent_name => agent_name,
+                  :valid_agent_names => LogStash::AgentPluginRegistry.available.map(&:to_s))
+    return 1
   rescue => e
     @logger.fatal I18n.t("oops", :error => e)
     @logger.debug e.backtrace if $DEBUGLIST.include?("stacktrace")
   ensure
+    Stud::untrap("INT", sigint_id) unless sigint_id.nil?
+    Stud::untrap("TERM", sigterm_id) unless sigterm_id.nil?
+    Stud::untrap("HUP", sighup_id) unless sighup_id.nil?
     @log_fd.close if @log_fd
   end # def self.main
 
@@ -218,12 +238,10 @@ def configure_plugin_paths(paths)
     end
   end
 
-  def create_agent
+  def create_agent(*args)
     agent_class = LogStash::AgentPluginRegistry.lookup(agent_name)
-
-
     @logger.info("Creating new agent", :class => agent_class)
-    agent_class ? agent_class.new(@logger, :node_name => node_name) : nil
+    agent_class.new(*args)
   end
 
   # Point logging at a specific path.
@@ -297,4 +315,33 @@ def start_shell(shell, start_binding)
       fail(I18n.t("logstash.runner.invalid-shell"))
     end
   end
+
+  def trap_sighup
+    Stud::trap("HUP") do
+      @logger.warn(I18n.t("logstash.agent.sighup"))
+      @agent.reload_state
+    end
+  end
+
+  def trap_sigterm
+    Stud::trap("TERM") do
+      @logger.warn(I18n.t("logstash.agent.sigterm"))
+      @agent_task.stop!
+    end
+  end
+
+  def trap_sigint
+    Stud::trap("INT") do
+      if @interrupted_once
+        @logger.fatal(I18n.t("logstash.agent.forced_sigint"))
+        exit
+      else
+        @logger.warn(I18n.t("logstash.agent.sigint"))
+        Thread.new(@logger) {|logger| sleep 5; logger.warn(I18n.t("logstash.agent.slow_shutdown")) }
+        @interrupted_once = true
+        @agent_task.stop!
+      end
+    end
+  end
+
 end # class LogStash::Runner
diff --git a/logstash-core/lib/logstash/runner.rb.orig b/logstash-core/lib/logstash/runner.rb.orig
new file mode 100644
index 00000000000..82110ed4a35
--- /dev/null
+++ b/logstash-core/lib/logstash/runner.rb.orig
@@ -0,0 +1,327 @@
+# encoding: utf-8
+Thread.abort_on_exception = true
+Encoding.default_external = Encoding::UTF_8
+$DEBUGLIST = (ENV["DEBUG"] || "").split(",")
+
+require "clamp" # gem 'clamp'
+require "net/http"
+require "logstash/environment"
+
+LogStash::Environment.load_locale!
+
+require "logstash/namespace"
+require "logstash/agent_plugin_registry"
+require "logstash/agent"
+require "logstash/config/defaults"
+
+class LogStash::Runner < Clamp::Command
+  class MissingAgentError < StandardError; end # Raised when the user asks for an agent plugin that doesn't exist
+
+  option ["-f", "--config"], "CONFIG_PATH",
+    I18n.t("logstash.runner.flag.config"),
+    :attribute_name => :config_path
+
+  option "-e", "CONFIG_STRING",
+    I18n.t("logstash.runner.flag.config-string",
+           :default_input => LogStash::Config::Defaults.input,
+           :default_output => LogStash::Config::Defaults.output),
+    :default => nil, :attribute_name => :config_string
+
+  option ["-w", "--pipeline-workers"], "COUNT",
+    I18n.t("logstash.runner.flag.pipeline-workers"),
+    :attribute_name => :pipeline_workers,
+    :default => LogStash::Pipeline::DEFAULT_SETTINGS[:default_pipeline_workers], &:to_i
+
+  option ["-b", "--pipeline-batch-size"], "SIZE",
+         I18n.t("logstash.runner.flag.pipeline-batch-size"),
+         :attribute_name => :pipeline_batch_size,
+         :default => LogStash::Pipeline::DEFAULT_SETTINGS[:pipeline_batch_size], &:to_i
+
+  option ["-u", "--pipeline-batch-delay"], "DELAY_IN_MS",
+         I18n.t("logstash.runner.flag.pipeline-batch-delay"),
+         :attribute_name => :pipeline_batch_delay,
+         :default => LogStash::Pipeline::DEFAULT_SETTINGS[:pipeline_batch_delay], &:to_i
+
+  option ["-l", "--log"], "FILE",
+    I18n.t("logstash.runner.flag.log"),
+    :attribute_name => :log_file
+
+  # Old support for the '-v' flag'
+  option "-v", :flag,
+    I18n.t("logstash.runner.flag.verbosity"),
+    :attribute_name => :verbosity, :multivalued => true
+
+  option "--quiet", :flag, I18n.t("logstash.runner.flag.quiet")
+  option "--verbose", :flag, I18n.t("logstash.runner.flag.verbose")
+  option "--debug", :flag, I18n.t("logstash.runner.flag.debug")
+
+  option ["-V", "--version"], :flag,
+    I18n.t("logstash.runner.flag.version")
+
+  option ["-p", "--pluginpath"] , "PATH",
+    I18n.t("logstash.runner.flag.pluginpath"),
+    :multivalued => true,
+    :attribute_name => :plugin_paths
+
+  option ["-t", "--configtest"], :flag,
+    I18n.t("logstash.runner.flag.configtest"),
+    :attribute_name => :config_test
+
+  option "--[no-]allow-unsafe-shutdown", :flag,
+    I18n.t("logstash.runner.flag.unsafe_shutdown"),
+    :attribute_name => :unsafe_shutdown,
+    :default => false
+
+  option ["-i", "--interactive"], "SHELL",
+    I18n.t("logstash.runner.flag.rubyshell"),
+    :attribute_name => :ruby_shell
+
+  option ["-n", "--node-name"], "NAME", 
+    I18n.t("logstash.runner.flag.node_name"),
+    :attribute_name => :node_name
+
+  option ["-a", "--agent"], "AGENT",
+    I18n.t("logstash.runner.flag.agent"),
+    :attribute_name => :agent_name, :default => LogStash::AgentPluginRegistry::DEFAULT_AGENT_NAME
+
+  attr_reader :agent
+
+  def initialize(*args)
+    LogStash::AgentPluginRegistry.load_all
+    @logger = Cabin::Channel.get(LogStash)
+    super(*args)
+  end
+
+  def execute
+    require "logstash/util"
+    require "logstash/util/java_version"
+    require "stud/task"
+    require "cabin" # gem 'cabin'
+
+    LogStash::Util::set_thread_name(self.class.name)
+
+    if RUBY_VERSION < "1.9.2"
+      $stderr.puts "Ruby 1.9.2 or later is required. (You are running: " + RUBY_VERSION + ")"
+      return 1
+    end
+
+    # Print a warning to STDERR for bad java versions
+    LogStash::Util::JavaVersion.warn_on_bad_java_version
+
+    LogStash::ShutdownController.unsafe_shutdown = unsafe_shutdown?
+    LogStash::ShutdownController.logger = @logger
+
+    configure
+
+    if version?
+      show_version
+      return 0
+    end
+
+    return start_shell(@ruby_shell, binding) if @ruby_shell
+
+<<<<<<< HEAD
+    @agent = create_agent
+    if !@agent
+      @logger.fatal("Could not load specified agent",
+                    :agent_name => agent_name,
+                    :valid_agent_names => LogStash::AgentPluginRegistry.available.map(&:to_s))
+      return 1
+    end
+
+    config_loader = LogStash::Config::Loader.new(@logger, config_test?)
+    loaded_config_str = config_loader.format_config(config_path, config_string)
+
+    if !config_path && (!config_string || config_string.empty?)
+      fail(I18n.t("logstash.runner.missing-configuration"))
+    end
+
+
+    if config_test?
+      config_error = @agent.config_valid?(loaded_config_str)
+      if config_error
+=======
+    if config_string.nil? && config_path.nil?
+      fail(I18n.t("logstash.runner.missing-configuration"))
+    end
+
+    if config_test?
+      config_loader = LogStash::Config::Loader.new(@logger, config_test?)
+      config_str = config_loader.format_config(config_path, config_string)
+      config_error = LogStash::Pipeline.config_valid?(config_str)
+      if config_error == true
+        @logger.terminal "Configuration OK"
+        return 0
+      else
+>>>>>>> 5cf00e4... reload config from files
+        @logger.fatal I18n.t("logstash.error", :error => config_error)
+        return 1
+      end
+<<<<<<< HEAD
+    else
+      pipeline_settings = {
+        :pipeline_workers => pipeline_workers,
+        :pipeline_batch_size => pipeline_batch_size,
+        :pipeline_batch_delay => pipeline_batch_delay
+      }
+      @agent.add_pipeline("base", loaded_config_str, pipeline_settings)
+      task = Stud::Task.new { @agent.execute }
+      return task.wait
+=======
+>>>>>>> 5cf00e4... reload config from files
+    end
+
+    @agent = create_agent(@logger, config_string, config_path)
+    task = Stud::Task.new { @agent.execute }
+    return task.wait
+
+  rescue LoadError => e
+    fail("Configuration problem.")
+  rescue LogStash::ConfigurationError => e
+    @logger.warn I18n.t("logstash.runner.configtest-flag-information")
+    @logger.fatal I18n.t("logstash.error", :error => e)
+    show_short_help
+    return 1
+  rescue MissingAgentError => e
+    @logger.fatal("Could not load specified agent",
+                  :agent_name => agent_name,
+                  :valid_agent_names => LogStash::AgentPluginRegistry.available.map(&:to_s))
+    return 1
+  rescue => e
+    @logger.fatal I18n.t("oops", :error => e)
+    @logger.debug e.backtrace if $DEBUGLIST.include?("stacktrace")
+  ensure
+    @log_fd.close if @log_fd
+  end # def self.main
+
+  def show_version
+    show_version_logstash
+
+    if [:info, :debug].include?(verbosity?) || debug? || verbose?
+      show_version_ruby
+      show_version_java if LogStash::Environment.jruby?
+      show_gems if [:debug].include?(verbosity?) || debug?
+    end
+  end # def show_version
+
+  def show_version_logstash
+    require "logstash/version"
+    puts "logstash #{LOGSTASH_VERSION}"
+  end # def show_version_logstash
+
+  def show_version_ruby
+    puts RUBY_DESCRIPTION
+  end # def show_version_ruby
+
+  def show_version_java
+    properties = java.lang.System.getProperties
+    puts "java #{properties["java.version"]} (#{properties["java.vendor"]})"
+    puts "jvm #{properties["java.vm.name"]} / #{properties["java.vm.version"]}"
+  end # def show_version_java
+
+  def show_gems
+    require "rubygems"
+    Gem::Specification.each do |spec|
+      puts "gem #{spec.name} #{spec.version}"
+    end
+  end # def show_gems
+
+  # Do any start-time configuration.
+  #
+  # Log file stuff, plugin path checking, etc.
+  def configure
+    configure_logging(log_file)
+    configure_plugin_paths(plugin_paths)
+  end # def configure
+
+  # add the given paths for ungemified/bare plugins lookups
+  # @param paths [String, Array<String>] plugins path string or list of path strings to add
+  def configure_plugin_paths(paths)
+    Array(paths).each do |path|
+      fail(I18n.t("logstash.runner.configuration.plugin_path_missing", :path => path)) unless File.directory?(path)
+      LogStash::Environment.add_plugin_path(path)
+    end
+  end
+
+  def create_agent(*args)
+    agent_class = LogStash::AgentPluginRegistry.lookup(agent_name)
+    @logger.info("Creating new agent", :class => agent_class)
+<<<<<<< HEAD
+    agent_class ? agent_class.new(@logger, :node_name => node_name) : nil
+=======
+    agent_class.new(*args)
+>>>>>>> 5cf00e4... reload config from files
+  end
+
+  # Point logging at a specific path.
+  def configure_logging(path)
+    # Set with the -v (or -vv...) flag
+    if quiet?
+      @logger.level = :error
+    elsif verbose?
+      @logger.level = :info
+    elsif debug?
+      @logger.level = :debug
+    else
+      # Old support for the -v and -vv stuff.
+      if verbosity? && verbosity?.any?
+        # this is an array with length of how many times the flag is given
+        if verbosity?.length == 1
+          @logger.warn("The -v flag is deprecated and will be removed in a future release. You should use --verbose instead.")
+          @logger.level = :info
+        else
+          @logger.warn("The -vv flag is deprecated and will be removed in a future release. You should use --debug instead.")
+          @logger.level = :debug
+        end
+      else
+        @logger.level = :warn
+      end
+    end
+
+    if log_file
+      # TODO(sissel): Implement file output/rotation in Cabin.
+      # TODO(sissel): Catch exceptions, report sane errors.
+      begin
+        @log_fd.close if @log_fd
+        @log_fd = File.new(path, "a")
+      rescue => e
+        fail(I18n.t("logstash.runner.configuration.log_file_failed",
+                    :path => path, :error => e))
+      end
+
+      @logger.subscribe(STDOUT, :level => :fatal)
+      @logger.subscribe(@log_fd)
+      @logger.terminal "Sending logstash logs to #{path}."
+    else
+      @logger.subscribe(STDOUT)
+    end
+
+    # TODO(sissel): redirect stdout/stderr to the log as well
+    # http://jira.codehaus.org/browse/JRUBY-7003
+  end # def configure_logging
+
+  # Emit a failure message and abort.
+  def fail(message)
+    raise LogStash::ConfigurationError, message
+  end # def fail
+
+  def show_short_help
+    puts I18n.t("logstash.runner.short-help")
+  end
+
+  def start_shell(shell, start_binding)
+    case shell
+    when "pry"
+      require 'pry'
+      start_binding.pry
+    when "irb"
+      require 'irb'
+      ARGV.clear
+      # TODO: set binding to this instance of Runner
+      # currently bugged as per https://github.com/jruby/jruby/issues/384
+      IRB.start(__FILE__)
+    else
+      fail(I18n.t("logstash.runner.invalid-shell"))
+    end
+  end
+end # class LogStash::Runner
diff --git a/logstash-core/lib/logstash/shutdown_controller.rb b/logstash-core/lib/logstash/shutdown_controller.rb
index dd12246ef9f..ca2a578d8be 100644
--- a/logstash-core/lib/logstash/shutdown_controller.rb
+++ b/logstash-core/lib/logstash/shutdown_controller.rb
@@ -9,8 +9,9 @@ class ShutdownController
 
     attr_reader :cycle_period, :report_every, :abort_threshold
 
-    def initialize(pipeline, cycle_period=CHECK_EVERY, report_every=REPORT_EVERY, abort_threshold=ABORT_AFTER)
+    def initialize(pipeline, pipeline_thread, cycle_period=CHECK_EVERY, report_every=REPORT_EVERY, abort_threshold=ABORT_AFTER)
       @pipeline = pipeline
+      @pipeline_thread = pipeline_thread
       @cycle_period = cycle_period
       @report_every = report_every
       @abort_threshold = abort_threshold
@@ -33,8 +34,8 @@ def self.logger
       @logger ||= Cabin::Channel.get(LogStash)
     end
 
-    def self.start(pipeline, cycle_period=CHECK_EVERY, report_every=REPORT_EVERY, abort_threshold=ABORT_AFTER)
-      controller = self.new(pipeline, cycle_period, report_every, abort_threshold)
+    def self.start(pipeline, pipeline_thread, cycle_period=CHECK_EVERY, report_every=REPORT_EVERY, abort_threshold=ABORT_AFTER)
+      controller = self.new(pipeline, pipeline_thread, cycle_period, report_every, abort_threshold)
       Thread.new(controller) { |controller| controller.start }
     end
 
@@ -47,6 +48,7 @@ def start
       cycle_number = 0
       stalled_count = 0
       Stud.interval(@cycle_period) do
+        break unless @pipeline_thread.alive?
         @reports << pipeline_report_snapshot
         @reports.delete_at(0) if @reports.size > @report_every # expire old report
         if cycle_number == (@report_every - 1) # it's report time!
diff --git a/logstash-core/lib/logstash/shutdown_controller.rb.orig b/logstash-core/lib/logstash/shutdown_controller.rb.orig
new file mode 100644
index 00000000000..6d30e9ddf66
--- /dev/null
+++ b/logstash-core/lib/logstash/shutdown_controller.rb.orig
@@ -0,0 +1,108 @@
+# encoding: utf-8
+
+module LogStash
+  class ShutdownController
+
+    CHECK_EVERY = 1 # second
+    REPORT_EVERY = 5 # checks
+    ABORT_AFTER = 3 # stalled reports
+
+    attr_reader :cycle_period, :report_every, :abort_threshold
+
+    def initialize(pipeline, pipeline_thread, cycle_period=CHECK_EVERY, report_every=REPORT_EVERY, abort_threshold=ABORT_AFTER)
+      @pipeline = pipeline
+      @pipeline_thread = pipeline_thread
+      @cycle_period = cycle_period
+      @report_every = report_every
+      @abort_threshold = abort_threshold
+      @reports = []
+    end
+
+    def self.unsafe_shutdown=(boolean)
+      @unsafe_shutdown = boolean
+    end
+
+    def self.unsafe_shutdown?
+      @unsafe_shutdown
+    end
+
+    def self.logger=(logger)
+      @logger = logger
+    end
+
+    def self.logger
+      @logger ||= Cabin::Channel.get(LogStash)
+    end
+
+    def self.start(pipeline, pipeline_thread, cycle_period=CHECK_EVERY, report_every=REPORT_EVERY, abort_threshold=ABORT_AFTER)
+      controller = self.new(pipeline, pipeline_thread, cycle_period, report_every, abort_threshold)
+      Thread.new(controller) { |controller| controller.start }
+    end
+
+    def logger
+      self.class.logger
+    end
+
+    def start
+      sleep 0.1 while !@pipeline.ready?
+
+      sleep(@cycle_period)
+      cycle_number = 0
+      stalled_count = 0
+      Stud.interval(@cycle_period) do
+<<<<<<< HEAD
+        @reports << pipeline_report_snapshot
+=======
+        break unless @pipeline_thread.alive?
+        @reports << Report.from_pipeline(@pipeline)
+>>>>>>> 6213e77... Temp work on stoppable shutdown controller
+        @reports.delete_at(0) if @reports.size > @report_every # expire old report
+        if cycle_number == (@report_every - 1) # it's report time!
+          logger.warn(@reports.last)
+
+          if shutdown_stalled?
+            logger.error("The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.") if stalled_count == 0
+            stalled_count += 1
+
+            if self.class.unsafe_shutdown? && @abort_threshold == stalled_count
+              logger.fatal("Forcefully quitting logstash..")
+              force_exit()
+              break
+            end
+          else
+            stalled_count = 0
+          end
+        end
+        cycle_number = (cycle_number + 1) % @report_every
+      end
+    end
+
+    def pipeline_report_snapshot
+      @pipeline.reporter.snapshot
+    end
+
+    # A pipeline shutdown is stalled if
+    # * at least REPORT_EVERY reports have been created
+    # * the inflight event count is in monotonically increasing
+    # * there are worker threads running which aren't blocked on SizedQueue pop/push
+    # * the stalled thread list is constant in the previous REPORT_EVERY reports
+    def shutdown_stalled?
+      return false unless @reports.size == @report_every #
+      # is stalled if inflight count is either constant or increasing
+      stalled_event_count = @reports.each_cons(2).all? do |prev_report, next_report|
+        prev_report.inflight_count <= next_report.inflight_count
+      end
+      if stalled_event_count
+        @reports.each_cons(2).all? do |prev_report, next_report|
+          prev_report.stalling_threads == next_report.stalling_threads
+        end
+      else
+        false
+      end
+    end
+
+    def force_exit
+      exit(-1)
+    end
+  end
+end
diff --git a/logstash-core/locales/en.yml b/logstash-core/locales/en.yml
index 446c406148b..17d389d5391 100644
--- a/logstash-core/locales/en.yml
+++ b/logstash-core/locales/en.yml
@@ -60,9 +60,9 @@ en:
       sighup: >-
         SIGHUP received.
       sigint: >-
-        SIGINT received. Shutting down the pipeline.
+        SIGINT received. Shutting down the agent.
       sigterm: >-
-        SIGTERM received. Shutting down the pipeline.
+        SIGTERM received. Shutting down the agent.
       slow_shutdown: |-
         Received shutdown signal, but pipeline is still waiting for in-flight events
         to be processed. Sending another ^C will force quit Logstash, but this may cause
@@ -171,6 +171,10 @@ en:
         pipeline-batch-delay: |+
           When creating pipeline batches, how long to wait while polling
           for the next event.
+        auto_reload: |+
+          Monitor configuration changes and reload
+          whenever it is changed.
+          NOTE: use SIGHUP to manually reload the config
         log: |+
           Write logstash internal logs to the given
           file. Without this flag, logstash will emit
diff --git a/logstash-core/locales/en.yml.orig b/logstash-core/locales/en.yml.orig
new file mode 100644
index 00000000000..1f6dc21117b
--- /dev/null
+++ b/logstash-core/locales/en.yml.orig
@@ -0,0 +1,219 @@
+# YAML notes
+#   |- means 'scalar block' useful for formatted text
+#   > means 'scalar block' but it chomps all newlines. Useful 
+#     for unformatted text.
+en:
+  oops: |-
+    The error reported is: 
+      %{error}
+  logstash:
+    error: >-
+      Error: %{error}
+    environment:
+      jruby-required:  >-
+        JRuby is required
+      missing-jars: >-
+        Could not find jar files under %{pattern}
+    pipeline:
+      worker-error: |-
+        A plugin had an unrecoverable error. Will restart this plugin.
+          Plugin: %{plugin}
+          Error: %{error}
+      worker-error-debug: |-
+        A plugin had an unrecoverable error. Will restart this plugin.
+          Plugin: %{plugin}
+          Error: %{error}
+          Exception: %{exception}
+          Stack: %{stacktrace}
+      plugin-loading-error: >-
+        Couldn't find any %{type} plugin named '%{name}'. Are you
+        sure this is correct? Trying to load the %{name} %{type} plugin
+        resulted in this error: %{error}
+      plugin-type-loading-error: >-
+        Could not find any plugin type named '%{type}'. Check for typos.
+        Valid plugin types are 'input' 'filter' and 'output'
+      output-worker-unsupported: >-
+        %{plugin} output plugin: setting 'workers => %{worker_count}' is not
+        supported by this plugin. I will continue working as if you had not set
+        this setting.
+      output-worker-unsupported-with-message: >-
+        %{plugin} output plugin: setting 'workers => %{worker_count}' is not
+        supported by this plugin. I will continue working as if you had not set
+        this setting.
+    plugin:
+      deprecated_milestone: >-
+        %{plugin} plugin is using the 'milestone' method to declare the version
+        of the plugin this method is deprecated in favor of declaring the
+        version inside the gemspec.
+      no_version: >-
+        %{name} plugin doesn't have a version. This plugin isn't well
+         supported by the community and likely has no maintainer.
+      version:
+        0-9-x:
+         Using version 0.9.x %{type} plugin '%{name}'. This plugin should work but
+         would benefit from use by folks like you. Please let us know if you
+         find bugs or have suggestions on how to improve this plugin.
+        0-1-x: >-
+         Using version 0.1.x %{type} plugin '%{name}'. This plugin isn't well
+         supported by the community and likely has no maintainer.
+    agent:
+      sighup: >-
+        SIGHUP received.
+      sigint: >-
+        SIGINT received. Shutting down the pipeline.
+      sigterm: >-
+        SIGTERM received. Shutting down the pipeline.
+      slow_shutdown: |-
+        Received shutdown signal, but pipeline is still waiting for in-flight events
+        to be processed. Sending another ^C will force quit Logstash, but this may cause
+        data loss.
+      forced_sigint: >-
+        SIGINT received. Terminating immediately..
+    runner:
+      short-help: |-
+        usage:
+          bin/logstash -f CONFIG_FILE [-t] [--quiet|verbose|debug] [-w COUNT] [-l LOG]
+          bin/logstash -e CONFIG_STR [-t] [--quiet|verbose|debug] [-w COUNT] [-l LOG]
+          bin/logstash -i SHELL [--quiet|verbose|debug]
+          bin/logstash -V [--verbose|debug]
+          bin/logstash --help
+      missing-configuration: >-
+        No configuration file was specified. Perhaps you forgot to provide
+        the '-f yourlogstash.conf' flag?
+      invalid-shell: >-
+        Invalid option for interactive Ruby shell. Use either "irb" or "pry"
+      configtest-flag-information: |-
+        You may be interested in the '--configtest' flag which you can use to validate
+        logstash's configuration before you choose to restart a running system.
+      configuration:
+        obsolete: >-
+          The setting `%{name}` in plugin `%{plugin}` is obsolete and is no
+          longer available. %{extra} If you have any questions about this, you
+          are invited to visit https://discuss.elastic.co/c/logstash and ask.
+        file-not-found: |-
+          No config files found: %{path}
+          Can you make sure this path is a logstash config file?
+        scheme-not-supported: |-
+          URI scheme not supported: %{path}
+          Either pass a local file path or "file|http://" URI
+        fetch-failed: |-
+          Unable to fetch config from: %{path}
+          Reason: %{message}
+        setting_missing: |-
+          Missing a required setting for the %{plugin} %{type} plugin:
+
+            %{type} {
+              %{plugin} {
+                %{setting} => # SETTING MISSING
+                ...
+              }
+            }
+        setting_invalid: |-
+          Invalid setting for %{plugin} %{type} plugin:
+
+            %{type} {
+              %{plugin} {
+                # This setting must be a %{value_type}
+                # %{note}
+                %{setting} => %{value}
+                ...
+              }
+            }
+        invalid_plugin_settings: >-
+          Something is wrong with your configuration.
+        invalid_plugin_settings_duplicate_keys: |-
+          Duplicate keys found in your configuration: [%{keys}]
+          At line: %{line}, column %{column} (byte %{byte})
+          after %{after}
+        invalid_plugin_register: >-
+          Cannot register %{plugin} %{type} plugin.
+          The error reported is: 
+            %{error}
+        plugin_path_missing: >-
+          You specified a plugin path that does not exist: %{path}
+        no_plugins_found: |-
+          Could not find any plugins in "%{path}"
+          I tried to find files matching the following, but found none: 
+            %{plugin_glob}
+        log_file_failed: |-
+          Failed to open %{path} for writing: %{error}
+
+          This is often a permissions issue, or the wrong 
+          path was specified?
+      flag:
+        # Note: Wrap these at 55 chars so they display nicely when clamp emits
+        # them in an 80-character terminal
+        config: |+
+          Load the logstash config from a specific file
+          or directory.  If a directory is given, all
+          files in that directory will be concatenated
+          in lexicographical order and then parsed as a
+          single config file. You can also specify
+          wildcards (globs) and any matched files will
+          be loaded in the order described above.
+        config-string: |+
+          Use the given string as the configuration
+          data. Same syntax as the config file. If no
+          input is specified, then the following is
+          used as the default input:
+          "%{default_input}"
+          and if no output is specified, then the
+          following is used as the default output:
+          "%{default_output}"
+          If you wish to use both defaults, please use
+          the empty string for the '-e' flag.
+        configtest: |+
+          Check configuration for valid syntax and then exit.
+        pipeline-workers: |+
+          Sets the number of pipeline workers to run.
+        pipeline-batch-size: |+
+          Size of batches the pipeline is to work in.
+        pipeline-batch-delay: |+
+          When creating pipeline batches, how long to wait while polling
+          for the next event.
+        log: |+
+          Write logstash internal logs to the given
+          file. Without this flag, logstash will emit
+          logs to standard output.
+        verbosity: |+
+          Increase verbosity of logstash internal logs.
+          Specifying once will show 'informational'
+          logs. Specifying twice will show 'debug'
+          logs. This flag is deprecated. You should use
+          --verbose or --debug instead.
+        version: |+
+          Emit the version of logstash and its friends,
+          then exit.
+        pluginpath: |+
+          A path of where to find plugins. This flag
+          can be given multiple times to include
+          multiple paths. Plugins are expected to be
+          in a specific directory hierarchy:
+          'PATH/logstash/TYPE/NAME.rb' where TYPE is
+          'inputs' 'filters', 'outputs' or 'codecs'
+          and NAME is the name of the plugin.
+        quiet: |+
+          Quieter logstash logging. This causes only 
+          errors to be emitted.
+        verbose: |+
+          More verbose logging. This causes 'info' 
+          level logs to be emitted.
+        debug: |+
+          Most verbose logging. This causes 'debug'
+          level logs to be emitted.
+        unsafe_shutdown: |+
+          Force logstash to exit during shutdown even
+          if there are still inflight events in memory.
+          By default, logstash will refuse to quit until all
+          received events have been pushed to the outputs.
+        rubyshell: |+
+          Drop to shell instead of running as normal.
+          Valid shells are "irb" and "pry"
+<<<<<<< 25b8d151177c0104ce6d229403458689b841482b
+        node_name: |+
+          Specify the name of this logstash instance, if no value is given
+          it will default to the current hostname.
+=======
+>>>>>>> Pluggable agents
+        agent: |+
+          Specify an alternate agent plugin name.
\ No newline at end of file
diff --git a/logstash-core/spec/logstash/agent_spec.rb b/logstash-core/spec/logstash/agent_spec.rb
index cdb0fb66d24..2458dff9b10 100644
--- a/logstash-core/spec/logstash/agent_spec.rb
+++ b/logstash-core/spec/logstash/agent_spec.rb
@@ -1,31 +1,135 @@
 # encoding: utf-8
-require "logstash/agent"
-require "spec_helper"
+require 'spec_helper'
+require 'stud/temporary'
 
 describe LogStash::Agent do
-  def make_agent(options={})
-    LogStash::Agent.new(Cabin::Channel.get(), options)
+
+  let(:logger) { double("logger") }
+  let(:agent_args) { { :logger => logger } }
+  subject { LogStash::Agent.new(agent_args) }
+
+  before :each do
+    [:info, :warn, :error, :fatal, :debug].each do |level|
+      allow(logger).to receive(level)
+    end
   end
 
-  context "#node_name" do
-    let(:hostname) { "the-logstash" }
+  context "when passing :pipeline_settings" do
+    let(:config_string) { "input { } filter { drop { } } output { }" }
+    let(:pipeline_settings) { { :pipeline_workers => 4 } }
+    let(:agent_args) do
+      {
+        :logger => logger,
+        :auto_reload => true,
+        :reload_interval => 0.01,
+        :config_string => config_string,
+        :pipeline_settings => pipeline_settings
+      }
+    end
+    it "should delegate pipeline_settings to new pipelines" do
+      expect(subject).to receive(:add_pipeline).with("base", config_string, pipeline_settings)
+      subject.execute
+    end
+  end
 
-    before do
-      allow(Socket).to receive(:gethostname).and_return(hostname)
+  describe "#execute" do
+    context "when auto_reload is false" do
+      let(:agent_args) { { :logger => logger, :auto_reload => false, :reload_interval => 0.01 } }
+      context "if state is clean" do
+        it "should only reload_state once" do
+          allow(subject).to receive(:sleep)
+          expect(subject).to receive(:reload_state!).exactly(:once)
+          t = Thread.new { subject.execute }
+          sleep 0.1
+          Stud.stop!(t)
+          t.join
+        end
+      end
     end
 
-    it "fallback to hostname when no name is provided" do
-      expect(make_agent.node_name).to be(hostname)
+    context "when auto_reload is true" do
+      let(:agent_args) { { :logger => logger, :auto_reload => true, :reload_interval => 0.01 } }
+      context "if state is clean" do
+        it "should periodically reload_state" do
+          expect(subject).to receive(:reload_state!).at_least(:twice)
+          t = Thread.new { subject.execute }
+          sleep 0.1
+          Stud.stop!(t)
+          t.join
+        end
+      end
     end
+  end
 
-    it "uses the user provided name" do
-      expect(make_agent({ :node_name => "a-name" }).node_name).to eq("a-name")
+  describe "#reload_state!" do
+    context "when fetching a new state" do
+      it "upgrades the state" do
+        allow(subject).to receive(:fetch_state).and_return("input { plugin {} } output { plugin {} }")
+        expect(subject).to receive(:upgrade_state)
+        subject.send(:reload_state!)
+      end
+    end
+    context "when fetching the same state" do
+      it "doesn't upgrade the state" do
+        allow(subject).to receive(:fetch_state).and_return("")
+        expect(subject).to_not receive(:upgrade_state)
+        subject.send(:reload_state!)
+      end
     end
   end
 
-  context "#node_uuid" do
-    it "create a unique uuid between agent instances" do
-      expect(make_agent.node_uuid).not_to be(make_agent.node_uuid)
+  describe "#upgrade_state" do
+    context "when the upgrade fails" do
+      before :each do
+        allow(subject).to receive(:fetch_state).and_return("input { plugin {} } output { plugin {} }")
+        allow(subject).to receive(:add_pipeline).and_raise(StandardError)
+      end
+      it "leaves the state untouched" do
+        subject.send(:reload_state!)
+        expect(subject.state).to eq("")
+      end
+      context "and current state is empty" do
+        it "should not start a pipeline" do
+          expect(subject).to_not receive(:start_pipeline)
+          subject.send(:reload_state!)
+        end
+      end
+    end
+
+    context "when the upgrade succeeds" do
+      let(:new_state) { "input { generator { count => 1 } } output { stdout {} }" }
+      before :each do
+        allow(subject).to receive(:fetch_state).and_return(new_state)
+        allow(subject).to receive(:add_pipeline)
+      end
+      it "updates the state" do
+        subject.send(:reload_state!)
+        expect(subject.state).to eq(new_state)
+      end
+      it "starts the pipeline" do
+        expect(subject).to receive(:start_pipeline)
+        subject.send(:reload_state!)
+      end
     end
   end
+
+  describe "#fetch_state" do
+    let(:file_config) { "input { generator { count => 100 } } output { stdout { } }" }
+    let(:cli_config) { "filter { drop { } } " }
+    let(:tmp_config_path) { Stud::Temporary.pathname }
+    let(:agent_args) { { :logger => logger, :config_string => "filter { drop { } } ", :config_path => tmp_config_path } }
+
+    before :each do
+      IO.write(tmp_config_path, file_config)
+    end
+
+    after :each do
+      File.unlink(tmp_config_path)
+    end
+
+    it "should join the config string and config path content" do
+      expect(subject.send(:fetch_state).strip).to eq(cli_config + IO.read(tmp_config_path))
+    end
+
+  end
 end
diff --git a/logstash-core/spec/logstash/agent_spec.rb.orig b/logstash-core/spec/logstash/agent_spec.rb.orig
new file mode 100644
index 00000000000..d342bcc6f5d
--- /dev/null
+++ b/logstash-core/spec/logstash/agent_spec.rb.orig
@@ -0,0 +1,164 @@
+# encoding: utf-8
+require 'spec_helper'
+require 'stud/temporary'
+
+describe LogStash::Agent do
+
+  let(:logger) { double("logger") }
+  let(:agent_args) { { :logger => logger } }
+  subject { LogStash::Agent.new(agent_args) }
+
+  before :each do
+    [:info, :warn, :error, :fatal, :debug].each do |level|
+      allow(logger).to receive(level)
+    end
+  end
+
+  context "when passing :pipeline_settings" do
+    let(:config_string) { "input { } filter { drop { } } output { }" }
+    let(:pipeline_settings) { { :filter_workers => 4 } }
+    let(:agent_args) do
+      {
+        :logger => logger,
+        :auto_reload => true,
+        :reload_interval => 0.01,
+        :config_string => config_string,
+        :pipeline_settings => pipeline_settings
+      }
+    end
+    it "should delegate pipeline_settings to new pipelines" do
+      expect(subject).to receive(:add_pipeline).with("base", config_string, pipeline_settings)
+      subject.execute
+    end
+  end
+
+  describe "#execute" do
+    context "when auto_reload is false" do
+      let(:agent_args) { { :logger => logger, :auto_reload => false, :reload_interval => 0.01 } }
+      context "if state is clean" do
+        it "should only reload_state once" do
+          allow(subject).to receive(:sleep)
+          expect(subject).to receive(:reload_state!).exactly(:once)
+          t = Thread.new { subject.execute }
+          sleep 0.1
+          Stud.stop!(t)
+          t.join
+        end
+      end
+    end
+
+    context "when auto_reload is true" do
+      let(:agent_args) { { :logger => logger, :auto_reload => true, :reload_interval => 0.01 } }
+      context "if state is clean" do
+        it "should periodically reload_state" do
+          expect(subject).to receive(:reload_state!).at_least(:twice)
+          t = Thread.new { subject.execute }
+          sleep 0.1
+          Stud.stop!(t)
+          t.join
+        end
+      end
+    end
+  end
+
+  describe "#reload_state!" do
+    context "when fetching a new state" do
+      it "upgrades the state" do
+        allow(subject).to receive(:fetch_state).and_return("input { plugin {} } output { plugin {} }")
+        expect(subject).to receive(:upgrade_state)
+        subject.send(:reload_state!)
+      end
+    end
+    context "when fetching the same state" do
+      it "doesn't upgrade the state" do
+        allow(subject).to receive(:fetch_state).and_return("")
+        expect(subject).to_not receive(:upgrade_state)
+        subject.send(:reload_state!)
+      end
+    end
+  end
+
+  describe "#upgrade_state" do
+    context "when the upgrade fails" do
+      before :each do
+        allow(subject).to receive(:fetch_state).and_return("input { plugin {} } output { plugin {} }")
+        allow(subject).to receive(:add_pipeline).and_raise(StandardError)
+      end
+      it "leaves the state untouched" do
+        subject.send(:reload_state!)
+        expect(subject.state).to eq("")
+      end
+      context "and current state is empty" do
+        it "should not start a pipeline" do
+          expect(subject).to_not receive(:start_pipeline)
+          subject.send(:reload_state!)
+        end
+      end
+    end
+
+    context "when the upgrade succeeds" do
+      let(:new_state) { "input { generator { count => 1 } } output { stdout {} }" }
+      before :each do
+        allow(subject).to receive(:fetch_state).and_return(new_state)
+        allow(subject).to receive(:add_pipeline)
+      end
+      it "updates the state" do
+        subject.send(:reload_state!)
+        expect(subject.state).to eq(new_state)
+      end
+      it "starts the pipeline" do
+        expect(subject).to receive(:start_pipeline)
+        subject.send(:reload_state!)
+      end
+    end
+  end
+
+  describe "#fetch_state" do
+    let(:file_config) { "input { generator { count => 100 } } output { stdout { } }" }
+    let(:cli_config) { "filter { drop { } } " }
+    let(:tmp_config_path) { Stud::Temporary.pathname }
+    let(:agent_args) { { :logger => logger, :config_string => "filter { drop { } } ", :config_path => tmp_config_path } }
+
+    before :each do
+      IO.write(tmp_config_path, file_config)
+    end
+
+    after :each do
+      File.unlink(tmp_config_path)
+    end
+
+    it "should join the config string and config path content" do
+      expect(subject.send(:fetch_state).strip).to eq(cli_config + IO.read(tmp_config_path))
+    end
+
+  end
+<<<<<<< HEAD
+
+  def make_agent(options={})
+    LogStash::Agent.new(Cabin::Channel.get(), options)
+  end
+
+  context "#node_name" do
+    let(:hostname) { "the-logstash" }
+
+    before do
+      allow(Socket).to receive(:gethostname).and_return(hostname)
+    end
+
+    it "fallback to hostname when no name is provided" do
+      expect(make_agent.node_name).to be(hostname)
+    end
+
+    it "uses the user provided name" do
+      expect(make_agent({ :node_name => "a-name" }).node_name).to eq("a-name")
+    end
+  end
+
+  context "#node_uuid" do
+    it "create a unique uuid between agent instances" do
+      expect(make_agent.node_uuid).not_to be(make_agent.node_uuid)
+    end
+  end
+=======
+>>>>>>> 94d6759... pass pipeline_settings from runner to pipeline through agent
+end
diff --git a/logstash-core/spec/logstash/runner_spec.rb b/logstash-core/spec/logstash/runner_spec.rb
index 994fa57f7bd..813f6cc9eec 100644
--- a/logstash-core/spec/logstash/runner_spec.rb
+++ b/logstash-core/spec/logstash/runner_spec.rb
@@ -26,11 +26,11 @@ def run(args); end
 
       before do
         allow(agent).to receive(:logger=).with(anything)
+        allow(agent).to receive(:shutdown)
       end
 
       it "should execute the agent" do
         expect(subject).to receive(:create_agent).and_return(agent)
-        expect(agent).to receive(:add_pipeline).once
         expect(agent).to receive(:execute).once
         subject.run(args)
       end
@@ -48,7 +48,9 @@ def run(args); end
   end
 
   context "--agent" do
-    class DummyAgent < LogStash::Agent; end
+    class DummyAgent < LogStash::Agent
+      def initialize; end
+    end
 
     let(:agent_name) { "testagent" }
     subject { LogStash::Runner.new("") }
diff --git a/logstash-core/spec/logstash/runner_spec.rb.orig b/logstash-core/spec/logstash/runner_spec.rb.orig
new file mode 100644
index 00000000000..5e146268d7c
--- /dev/null
+++ b/logstash-core/spec/logstash/runner_spec.rb.orig
@@ -0,0 +1,119 @@
+# encoding: utf-8
+require "spec_helper"
+require "logstash/runner"
+require "stud/task"
+
+class NullRunner
+  def run(args); end
+end
+
+describe LogStash::Runner do
+
+  subject { LogStash::Runner }
+  let(:channel) { Cabin::Channel.new }
+
+  before :each do
+    allow(Cabin::Channel).to receive(:get).with(LogStash).and_return(channel)
+  end
+
+  describe "argument parsing" do
+<<<<<<< 25b8d151177c0104ce6d229403458689b841482b
+    subject { LogStash::Runner.new("") }
+    context "when -e is given" do
+
+      let(:args) { ["-e", "input {} output {}"] }
+=======
+
+    before do
+      #subject.configure # setup_agent requires this to give it logging
+      #subject.setup_agent
+    end
+
+    subject { LogStash::Runner.new("") }
+    context "when -e is given" do
+
+      let(:args) { ["-e", ""] }
+>>>>>>> Pluggable agents
+      let(:agent) { double("agent") }
+      let(:agent_logger) { double("agent logger") }
+
+      before do
+        allow(agent).to receive(:logger=).with(anything)
+      end
+
+      it "should execute the agent" do
+        expect(subject).to receive(:create_agent).and_return(agent)
+        expect(agent).to receive(:add_pipeline).once
+        expect(agent).to receive(:execute).once
+        subject.run(args)
+      end
+    end
+
+    context "with no arguments" do
+      let(:args) { [] }
+      it "should show help" do
+        expect(channel).to receive(:warn).once
+        expect(channel).to receive(:fatal).once
+        expect(subject).to receive(:show_short_help).once
+        subject.run(args)
+      end
+    end
+  end
+
+  context "--agent" do
+    class DummyAgent < LogStash::Agent; end
+
+    let(:agent_name) { "testagent" }
+    subject { LogStash::Runner.new("") }
+
+    before do
+      LogStash::AgentPluginRegistry.register(agent_name, DummyAgent)
+      allow(subject).to receive(:execute) # stub this out to reduce test work/output
+      subject.run(["-a", "testagent", "-e" "input {} output {}"])
+    end
+
+    it "should set the proper agent" do
+      expect(subject.create_agent.class).to eql(DummyAgent)
+    end
+  end
+
+  context "--agent" do
+    # class DummyAgent < LogStash::Agent; end
+    #
+    # let(:agent_name) { "testagent" }
+    # let(:dummy_agent_class) { DummyAgentClass }
+    # subject { LogStash::Runner.new("-a testagent") }
+    #
+    # before do
+    #   LogStash::AgentPluginManager.register(agent_name, DummyAgent)
+    # end
+    #
+    # it "should set the proper agent" do
+    #   expect(subject.agent_class).to eql(DummyAgent)
+    # end
+  end
+
+  context "--pluginpath" do
+    subject { LogStash::Runner.new("") }
+    let(:single_path) { "/some/path" }
+    let(:multiple_paths) { ["/some/path1", "/some/path2"] }
+
+    it "should add single valid dir path to the environment" do
+      expect(File).to receive(:directory?).and_return(true)
+      expect(LogStash::Environment).to receive(:add_plugin_path).with(single_path)
+      subject.configure_plugin_paths(single_path)
+    end
+
+    it "should fail with single invalid dir path" do
+      expect(File).to receive(:directory?).and_return(false)
+      expect(LogStash::Environment).not_to receive(:add_plugin_path)
+      expect{subject.configure_plugin_paths(single_path)}.to raise_error(LogStash::ConfigurationError)
+    end
+
+    it "should add multiple valid dir path to the environment" do
+      expect(File).to receive(:directory?).exactly(multiple_paths.size).times.and_return(true)
+      multiple_paths.each{|path| expect(LogStash::Environment).to receive(:add_plugin_path).with(path)}
+      subject.configure_plugin_paths(multiple_paths)
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/shutdown_controller_spec.rb b/logstash-core/spec/logstash/shutdown_controller_spec.rb
index 3e777aafe9b..411c03beb41 100644
--- a/logstash-core/spec/logstash/shutdown_controller_spec.rb
+++ b/logstash-core/spec/logstash/shutdown_controller_spec.rb
@@ -6,7 +6,7 @@
 
   let(:check_every) { 0.01 }
   let(:check_threshold) { 100 }
-  subject { LogStash::ShutdownController.new(pipeline, check_every) }
+  subject { LogStash::ShutdownController.new(pipeline, Thread.current, check_every) }
   let(:pipeline) { double("pipeline") }
   let(:reporter) { double("reporter") }
   let(:reporter_snapshot) { double("reporter snapshot") }
