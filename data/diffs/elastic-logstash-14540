diff --git a/logstash-core/spec/logstash/agent/metrics_spec.rb b/logstash-core/spec/logstash/agent/metrics_spec.rb
index 4a7186ff427..04ce55352f5 100644
--- a/logstash-core/spec/logstash/agent/metrics_spec.rb
+++ b/logstash-core/spec/logstash/agent/metrics_spec.rb
@@ -73,6 +73,15 @@ def mhash(*path_elements)
       expect(mval(:stats, :reloads, :successes)).to eq(0)
       expect(mval(:stats, :reloads, :failures)).to eq(0)
     end
+
+    it "makes the top-level flow metrics available" do
+      expect(mval(:stats, :flow, :input_throughput)).to be_a_kind_of(java.util.Map)
+      expect(mval(:stats, :flow, :output_throughput)).to be_a_kind_of(java.util.Map)
+      expect(mval(:stats, :flow, :filter_throughput)).to be_a_kind_of(java.util.Map)
+      expect(mval(:stats, :flow, :queue_backpressure)).to be_a_kind_of(java.util.Map)
+      expect(mval(:stats, :flow, :worker_concurrency)).to be_a_kind_of(java.util.Map)
+    end
+
   end
 
   context "when we try to start one pipeline" do
diff --git a/logstash-core/spec/logstash/agent_spec.rb b/logstash-core/spec/logstash/agent_spec.rb
index 0575bdfd46b..f5d6405ec8a 100644
--- a/logstash-core/spec/logstash/agent_spec.rb
+++ b/logstash-core/spec/logstash/agent_spec.rb
@@ -476,6 +476,28 @@
           expect(value).to be > initial_generator_threshold
         end
 
+        it "does not reset the global flow metrics" do
+          snapshot = subject.metric.collector.snapshot_metric
+          subject.capture_flow_metrics
+
+          flow_metrics = snapshot.metric_store.get_with_path("/stats/flow")[:stats][:flow]
+
+          input_throughput_current = flow_metrics[:input_throughput].value.get("current")
+          input_throughput_lifetime = flow_metrics[:input_throughput].value.get("lifetime")
+          filter_throughput_current = flow_metrics[:filter_throughput].value.get("current")
+          filter_throughput_lifetime = flow_metrics[:filter_throughput].value.get("lifetime")
+          worker_concurrency_current = flow_metrics[:worker_concurrency].value.get("current")
+          worker_concurrency_lifetime = flow_metrics[:worker_concurrency].value.get("lifetime")
+
+          # rates depend on [events/wall-clock time], the expectation is non-zero values
+          expect(input_throughput_current).to be > 0
+          expect(input_throughput_lifetime).to be > 0
+          expect(filter_throughput_current).to be > 0
+          expect(filter_throughput_lifetime).to be > 0
+          expect(worker_concurrency_current).to be > 0
+          expect(worker_concurrency_lifetime).to be > 0
+        end
+
         it "increases the successful reload count" do
           skip("This test fails randomly, tracked in https://github.com/elastic/logstash/issues/8005")
           snapshot = subject.metric.collector.snapshot_metric
diff --git a/logstash-core/spec/logstash/api/commands/stats_spec.rb b/logstash-core/spec/logstash/api/commands/stats_spec.rb
index eed8cdff93d..f7ecb0ebe7d 100644
--- a/logstash-core/spec/logstash/api/commands/stats_spec.rb
+++ b/logstash-core/spec/logstash/api/commands/stats_spec.rb
@@ -75,6 +75,19 @@
     end
   end
 
+  describe "#metric flows" do
+    let(:report_method) { :flow }
+
+    it "should validate flow metric keys are exist" do
+      expect(report.keys).to include(
+                               :input_throughput,
+                               :output_throughput,
+                               :filter_throughput,
+                               :queue_backpressure,
+                               :worker_concurrency)
+    end
+  end
+
   describe "#hot_threads" do
     let(:report_method) { :hot_threads }
 
diff --git a/logstash-core/spec/logstash/api/modules/node_stats_spec.rb b/logstash-core/spec/logstash/api/modules/node_stats_spec.rb
index 789be64a9f2..ef3c0e50328 100644
--- a/logstash-core/spec/logstash/api/modules/node_stats_spec.rb
+++ b/logstash-core/spec/logstash/api/modules/node_stats_spec.rb
@@ -87,8 +87,22 @@
         "percent"=>Numeric,
         # load_average is not supported on Windows, set it below
       }
-    },
-    "pipelines" => {
+   },
+   "events" => {
+      "duration_in_millis" => Numeric,
+      "in" => Numeric,
+      "filtered" => Numeric,
+      "out" => Numeric,
+      "queue_push_duration_in_millis" => Numeric
+   },
+   "flow" => {
+      "output_throughput" => Hash,
+      "filter_throughput" => Hash,
+      "queue_backpressure" => Hash,
+      "worker_concurrency" => Hash,
+      "input_throughput" => Hash
+   },
+   "pipelines" => {
      "main" => {
        "events" => {
          "duration_in_millis" => Numeric,
