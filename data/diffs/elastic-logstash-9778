diff --git a/ci/integration_tests.sh b/ci/integration_tests.sh
index 0d2a3a2b398..4954d4420f1 100755
--- a/ci/integration_tests.sh
+++ b/ci/integration_tests.sh
@@ -5,7 +5,7 @@
 # uses at least 1g of memory, If we don't do this we can get OOM issues when
 # installing gems. See https://github.com/elastic/logstash/issues/5179
 export JRUBY_OPTS="-J-Xmx1g"
-export GRADLE_OPTS="-Xmx2g -Dorg.gradle.daemon=false -Dorg.gradle.logging.level=info"
+export GRADLE_OPTS="-Xmx2g -Dorg.gradle.daemon=false -Dorg.gradle.logging.level=info -Dfile.encoding=UTF-8"
 
 export SPEC_OPTS="--order rand --format documentation"
 export CI=true
diff --git a/x-pack/qa/integration/management/multiple_pipelines_spec.rb b/x-pack/qa/integration/management/multiple_pipelines_spec.rb
index e9246bf4a31..b2799f6680a 100644
--- a/x-pack/qa/integration/management/multiple_pipelines_spec.rb
+++ b/x-pack/qa/integration/management/multiple_pipelines_spec.rb
@@ -69,7 +69,7 @@
   end
 
   it "should immediately register a new pipeline state document when the pipeline is reloaded" do
-    wait(20).for do
+    wait(40).for do
       count_hashes(@pipelines.keys)
     end.to eq(2)
 
@@ -84,7 +84,7 @@
       push_elasticsearch_config(pipeline_id, config)
     end
 
-    wait(20).for do
+    wait(40).for do
       count_hashes(@pipelines.keys)
     end.to eq(4)
   end
@@ -96,7 +96,7 @@ def count_hashes(pipelines)
     elasticsearch_client.indices.refresh
 
     query = {
-      "size": 0, 
+      "size": 0,
       "query": {
         "term": {
           "type": {
@@ -124,7 +124,7 @@ def count_hashes(pipelines)
 
     begin
       res = elasticsearch_client.search(index: '.monitoring-logstash-*', body: query)
-    rescue Elasticsearch::Transport::Transport::Errors::ServiceUnavailable 
+    rescue Elasticsearch::Transport::Transport::Errors::ServiceUnavailable
       return nil
     end
 
