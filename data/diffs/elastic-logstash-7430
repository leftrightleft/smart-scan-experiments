diff --git a/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb b/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
index c8494378cc4..6ff97b46967 100644
--- a/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
+++ b/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
@@ -5,8 +5,73 @@ class WrappedSynchronousQueue
     java_import java.util.concurrent.SynchronousQueue
     java_import java.util.concurrent.TimeUnit
 
+    attr_reader :read_file_pool, :write_file_pool
+
     def initialize
       @queue = java.util.concurrent.SynchronousQueue.new
+
+      # This should really be the number of workers, but I just set it here to a high number
+      # out of laziness. This controls the number of inflight batches, and as a result, the number
+      # of buffered events
+      num_files = 20
+
+      @write_file_pool = java.util.concurrent.ArrayBlockingQueue.new(num_files)
+      @read_file_pool = java.util.concurrent.ArrayBlockingQueue.new(num_files+200)
+
+      num_files.times do |t|
+        @write_file_pool.put(::File.open("./lsq/#{t}.batch", "a+"))
+      end
+
+      read_file_pool = @read_file_pool
+      write_file_pool = @write_file_pool
+      queue = @queue
+
+      1.times do
+        Thread.new do |t|
+          current_file = @write_file_pool.take()
+          count = 0
+          steals_received = 0
+          batches_sent = 0
+          events_sent = 0
+
+          while true
+            event_or_signal = queue.poll(5, TimeUnit::MILLISECONDS)
+            next if event_or_signal.nil?
+
+            if event_or_signal == :shutdown
+              STDERR.write("BATCH AVG: #{events_sent/batches_sent} in #{batches_sent} batches")
+              break
+            end
+
+            if event_or_signal == :steal
+              steals_received += 1
+            end
+
+            # Steals received really needs to be autotuned based on the poll time * number of workers
+            # This is fine for benchmarking it with 1-4 workers. It only really might make the wallclock
+            # slow by a little bit. At higher worker counts it will cause the batch size to slip below 1024
+            # which will give bad benchmark results
+            if count >= 1024 || (steals_received > 20  && count > 1)
+              next if count < 1 # You can't steal nothin'!
+              current_file.fsync
+              count = 0
+              read_file_pool.put(current_file)
+              current_file = write_file_pool.take()
+              batches_sent += 1
+              steals_received = 0
+            end
+
+            if event_or_signal.is_a?(::LogStash::Event)
+              count += 1
+              json = event_or_signal.to_json
+              current_file.write(json)
+              current_file.write("\n")
+              current_file.flush
+              events_sent += 1
+            end
+          end
+        end
+      end
     end
 
     # Push an object to the queue if the queue is full
@@ -47,7 +112,7 @@ def read_client
     end
 
     def close
-      # ignore
+      @queue.put :shutdown
     end
 
     class ReadClient
@@ -66,10 +131,12 @@ def initialize(queue, batch_size = 125, wait_for = 250)
         @inflight_clocks = {}
         @batch_size = batch_size
         @wait_for = wait_for
+
+        @read_file_pool = queue.read_file_pool
       end
 
       def close
-        # noop, compat with acked queue read client
+        @read_file_pool.put(:shutdown)
       end
 
       def empty?
@@ -144,6 +211,7 @@ def set_current_thread_inflight_batch(batch)
       end
 
       def close_batch(batch)
+        batch.close
         @mutex.lock
         begin
           # there seems to be concurrency issues with metrics, keep it in the mutex
@@ -185,6 +253,8 @@ def add_output_metrics(batch)
     end
 
     class ReadBatch
+      attr_reader :file
+
       def initialize(queue, size, wait)
         @queue = queue
         @size = size
@@ -202,14 +272,29 @@ def initialize(queue, size, wait)
       end
 
       def read_next
-        @size.times do |t|
-          event = @queue.poll(@wait)
-          return if event.nil? # queue poll timed out
+        @file = @queue.read_file_pool.poll(5, TimeUnit::MILLISECONDS)
+        break if file == :shutdown
+        if file.nil?
+          @queue.push(:steal)
+          return
+        end
+
+        return if @file == :shutdown
 
+        @file.rewind
+        @file.each_line do |line|
+          event = Event.from_json(line).first
           @originals[event] = true
         end
       end
 
+      def close
+        if @file
+          @file.truncate(0)
+          @queue.write_file_pool.put(file);
+        end
+      end
+
       def merge(event)
         return if event.nil? || @originals.key?(event)
         # take care not to cause @generated to change during iteration
