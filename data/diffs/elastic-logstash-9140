diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index ac013e23590..fbdf73e082f 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -418,14 +418,14 @@ def worker_loop(batch_size, batch_delay)
       signal = @signal_queue.poll || NO_SIGNAL
       shutdown_requested |= signal.shutdown? # latch on shutdown signal
 
-      batch = @filter_queue_client.read_batch # metrics are started in read_batch
-      batch_size = batch.size
+      batch = @filter_queue_client.read_batch.to_java # metrics are started in read_batch
+      batch_size = batch.filteredSize
       if batch_size > 0
         @events_consumed.add(batch_size)
         filter_batch(batch)
       end
       flush_filters_to_batch(batch, :final => false) if signal.flush?
-      if batch.size > 0
+      if batch.filteredSize > 0
         output_batch(batch, output_events_map)
         @filter_queue_client.close_batch(batch)
       end
@@ -435,7 +435,7 @@ def worker_loop(batch_size, batch_delay)
 
     # we are shutting down, queue is drained if it was required, now  perform a final flush.
     # for this we need to create a new empty batch to contain the final flushed events
-    batch = @filter_queue_client.new_batch
+    batch = @filter_queue_client.to_java.newBatch
     @filter_queue_client.start_metrics(batch) # explicitly call start_metrics since we dont do a read_batch here
     flush_filters_to_batch(batch, :final => true)
     output_batch(batch, output_events_map)
@@ -448,7 +448,7 @@ def filter_batch(batch)
       batch.merge(e) unless e.cancelled?
     end
     @filter_queue_client.add_filtered_metrics(batch.filtered_size)
-    @events_filtered.add(batch.size)
+    @events_filtered.add(batch.filteredSize)
   rescue Exception => e
     # Plugins authors should manage their own exceptions in the plugin code
     # but if an exception is raised up to the worker thread they are considered
@@ -465,7 +465,7 @@ def filter_batch(batch)
   # Take an array of events and send them to the correct output
   def output_batch(batch, output_events_map)
     # Build a mapping of { output_plugin => [events...]}
-    batch.each do |event|
+    batch.to_a.each do |event|
       # We ask the AST to tell us which outputs to send each event to
       # Then, we stick it in the correct bin
       output_func(event).each do |output|
diff --git a/logstash-core/lib/logstash/queue_factory.rb b/logstash-core/lib/logstash/queue_factory.rb
index 60103cb7f70..91152bde264 100644
--- a/logstash-core/lib/logstash/queue_factory.rb
+++ b/logstash-core/lib/logstash/queue_factory.rb
@@ -2,7 +2,6 @@
 require "fileutils"
 require "logstash/event"
 require "logstash/namespace"
-require "logstash/util/wrapped_acked_queue"
 
 module LogStash
   class QueueFactory
diff --git a/logstash-core/lib/logstash/util/wrapped_acked_queue.rb b/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
deleted file mode 100644
index b65e7171ff1..00000000000
--- a/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
+++ /dev/null
@@ -1,80 +0,0 @@
-# encoding: utf-8
-
-require "concurrent"
-# This is an adapted copy of the wrapped_synchronous_queue file
-# ideally this should be moved to Java/JRuby
-
-module LogStash; module Util
-  # Some specialized constructors. The calling code *does* need to know what kind it creates but
-  # not the internal implementation e.g. LogStash::AckedMemoryQueue etc.
-  # Note the use of allocate - this is what new does before it calls initialize.
-  # Note that the new method has been made private this is because there is no
-  # default queue implementation.
-  # It would be expensive to create a persistent queue in the new method
-  # to then throw it away in favor of a memory based one directly after.
-  # Especially in terms of (mmap) memory allocation and proper close sequencing.
-
-  class WrappedAckedQueue
-    class QueueClosedError < ::StandardError; end
-    class NotImplementedError < ::StandardError; end
-
-    def self.create_file_based(path, capacity, max_events, checkpoint_max_writes, checkpoint_max_acks, checkpoint_max_interval, max_bytes)
-      self.allocate.with_queue(
-        LogStash::AckedQueue.new(path, capacity, max_events, checkpoint_max_writes, checkpoint_max_acks, checkpoint_max_interval, max_bytes)
-      )
-    end
-
-    private_class_method :new
-
-    attr_reader :queue
-
-    def with_queue(queue)
-      @queue = queue
-      @queue.open
-      @closed = java.util.concurrent.atomic.AtomicBoolean.new(false)
-      self
-    end
-
-    def closed?
-      @closed.get
-    end
-
-    # Push an object to the queue if the queue is full
-    # it will block until the object can be added to the queue.
-    #
-    # @param [Object] Object to add to the queue
-    def push(obj)
-      check_closed("write")
-      @queue.write(obj)
-    end
-    alias_method(:<<, :push)
-
-    def read_batch(size, wait)
-      check_closed("read a batch")
-      @queue.read_batch(size, wait)
-    end
-
-    def write_client
-      LogStash::AckedWriteClient.create(@queue, @closed)
-    end
-
-    def read_client()
-      LogStash::AckedReadClient.create(self)
-    end
-
-    def check_closed(action)
-      if @closed.get
-        raise QueueClosedError.new("Attempted to #{action} on a closed AckedQueue")
-      end
-    end
-
-    def is_empty?
-      @queue.is_empty?
-    end
-
-    def close
-      @queue.close
-      @closed.set(true)
-    end
-  end
-end end
diff --git a/logstash-core/spec/logstash/acked_queue_concurrent_stress_spec.rb b/logstash-core/spec/logstash/acked_queue_concurrent_stress_spec.rb
index a511e81fecd..7ca6c94e4a5 100644
--- a/logstash-core/spec/logstash/acked_queue_concurrent_stress_spec.rb
+++ b/logstash-core/spec/logstash/acked_queue_concurrent_stress_spec.rb
@@ -1,5 +1,4 @@
 # encoding: utf-8
-require "logstash/util/wrapped_acked_queue"
 require "logstash/event"
 require "logstash/instrument/namespaced_metric"
 
@@ -40,10 +39,10 @@
           begin
             tally = 0
             while true
-              batch = _reader.read_batch
-              break if batch.size.zero? && writers_finished.value == true && queue.queue.is_fully_acked?
+              batch = _reader.read_batch.to_java
+              break if batch.filteredSize == 0 && writers_finished.value == true && queue.queue.is_fully_acked?
               sleep(rand * 0.01) if simulate_work
-              tally += batch.size
+              tally += batch.filteredSize
               batch.close
             end
             _counts[_i] = tally
diff --git a/logstash-core/spec/logstash/instrument/wrapped_write_client_spec.rb b/logstash-core/spec/logstash/instrument/wrapped_write_client_spec.rb
index 7639a9e0c6a..9a48a665ad9 100644
--- a/logstash-core/spec/logstash/instrument/wrapped_write_client_spec.rb
+++ b/logstash-core/spec/logstash/instrument/wrapped_write_client_spec.rb
@@ -3,6 +3,7 @@
 require "logstash/event"
 require_relative "../../support/mocks_classes"
 require "spec_helper"
+require "java"
 
 describe LogStash::WrappedWriteClient do
   let!(:write_client) { queue.write_client }
@@ -23,7 +24,8 @@ def threaded_read_client
         if Time.now - started_at > 60
           raise "Took too much time to read from the queue"
         end
-        batch_size = read_client.read_batch.size
+        batch = read_client.read_batch.to_java
+        batch_size = batch.filteredSize()
 
         break if batch_size > 0
       }
@@ -122,4 +124,5 @@ def threaded_read_client
 
     include_examples "queue tests"
   end
+
 end
diff --git a/logstash-core/spec/logstash/util/wrapped_acked_queue_spec.rb b/logstash-core/spec/logstash/util/wrapped_acked_queue_spec.rb
index f10d415e6db..bfa52370651 100644
--- a/logstash-core/spec/logstash/util/wrapped_acked_queue_spec.rb
+++ b/logstash-core/spec/logstash/util/wrapped_acked_queue_spec.rb
@@ -1,6 +1,5 @@
 # encoding: utf-8
 require "spec_helper"
-require "logstash/util/wrapped_acked_queue"
 
 describe LogStash::WrappedAckedQueue do
   shared_examples "queue tests" do
@@ -15,15 +14,16 @@
 
     it "not is_empty? when all elements are not acked" do
       queue.push(LogStash::Event.new)
-      batch = queue.read_batch(1, 250)
-      expect(batch.get_elements.size).to eq(1)
+      batch = queue.read_batch(1, 250).to_java
+      expect(batch.size()).to eq(1)
+
       expect(queue.is_empty?).to be_falsey
     end
 
     it "is_empty? when all elements are acked" do
       queue.push(LogStash::Event.new)
-      batch = queue.read_batch(1, 250)
-      expect(batch.get_elements.size).to eq(1)
+      batch = queue.read_batch(1, 250).to_java
+      expect(batch.size()).to eq(1)
       expect(queue.is_empty?).to be_falsey
       batch.close
       expect(queue.is_empty?).to be_truthy
diff --git a/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb b/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb
index 45771ce333f..852b819a920 100644
--- a/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb
+++ b/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb
@@ -63,12 +63,12 @@
             5.times {|i| batch.push(LogStash::Event.new({"message" => "value-#{i}"}))}
             write_client.push_batch(batch)
 
-            read_batch = read_client.read_batch
+            read_batch = read_client.read_batch.to_java
             sleep(0.1) # simulate some work for the `duration_in_millis`
             # TODO: this interaction should be cleaned in an upcoming PR,
             # This is what the current pipeline does.
-            read_client.add_filtered_metrics(read_batch.filtered_size)
-            read_client.add_output_metrics(read_batch.filtered_size)
+            read_client.add_filtered_metrics(read_batch.filteredSize)
+            read_client.add_output_metrics(read_batch.filteredSize)
             read_client.close_batch(read_batch)
             store = collector.snapshot_metric.metric_store
 
@@ -97,8 +97,8 @@
             messages << message
           end
           write_client.push_batch(batch)
-          read_batch = read_client.read_batch
-          expect(read_batch.size).to eq(5)
+          read_batch = read_client.read_batch.to_java
+          expect(read_batch.filteredSize).to eq(5)
           read_batch.to_a.each do |data|
             message = data.get("message")
             expect(messages).to include(message)
@@ -111,7 +111,7 @@
           end
           # expect(read_batch.cancelled_size).to eq(2) # disabled for https://github.com/elastic/logstash/issues/6055
           received = []
-          read_batch.each do |data|
+          read_batch.to_a.each do |data|
             received << data.get("message")
           end
           (0..2).each {|i| expect(received).to include("value-#{i}")}
diff --git a/logstash-core/src/main/java/org/logstash/RubyUtil.java b/logstash-core/src/main/java/org/logstash/RubyUtil.java
index a4e4d0185d4..68c9eb2e55e 100644
--- a/logstash-core/src/main/java/org/logstash/RubyUtil.java
+++ b/logstash-core/src/main/java/org/logstash/RubyUtil.java
@@ -10,13 +10,11 @@
 import org.jruby.runtime.ObjectAllocator;
 import org.logstash.ackedqueue.ext.JRubyAckedQueueExt;
 import org.logstash.ackedqueue.ext.JRubyWrappedAckedQueueExt;
-import org.logstash.ackedqueue.ext.RubyAckedBatch;
+import org.logstash.execution.QueueReadClientBase;
 import org.logstash.ext.JRubyWrappedWriteClientExt;
-import org.logstash.ext.JrubyAckedReadBatchExt;
 import org.logstash.ext.JrubyAckedReadClientExt;
 import org.logstash.ext.JrubyAckedWriteClientExt;
 import org.logstash.ext.JrubyEventExtLibrary;
-import org.logstash.ext.JrubyMemoryReadBatchExt;
 import org.logstash.ext.JrubyMemoryReadClientExt;
 import org.logstash.ext.JrubyMemoryWriteClientExt;
 import org.logstash.ext.JrubyTimestampExtLibrary;
@@ -39,8 +37,6 @@ public final class RubyUtil {
 
     public static final RubyClass RUBY_EVENT_CLASS;
 
-    public static final RubyClass RUBY_ACKED_BATCH_CLASS;
-
     public static final RubyClass RUBY_TIMESTAMP_CLASS;
 
     public static final RubyClass PARSER_ERROR;
@@ -51,12 +47,10 @@ public final class RubyUtil {
 
     public static final RubyClass TIMESTAMP_PARSER_ERROR;
 
-    public static final RubyClass MEMORY_READ_BATCH_CLASS;
-
-    public static final RubyClass ACKED_READ_BATCH_CLASS;
-
     public static final RubyClass WRAPPED_WRITE_CLIENT_CLASS;
 
+    public static final RubyClass QUEUE_READ_CLIENT_BASE_CLASS;
+
     public static final RubyClass MEMORY_READ_CLIENT_CLASS;
 
     public static final RubyClass ACKED_READ_CLIENT_CLASS;
@@ -77,16 +71,14 @@ public final class RubyUtil {
         RUBY_TIMESTAMP_CLASS = setupLogstashClass(
             JrubyTimestampExtLibrary.RubyTimestamp::new, JrubyTimestampExtLibrary.RubyTimestamp.class
         );
-        MEMORY_READ_BATCH_CLASS =
-            setupLogstashClass(JrubyMemoryReadBatchExt::new, JrubyMemoryReadBatchExt.class);
-        ACKED_READ_BATCH_CLASS =
-            setupLogstashClass(JrubyAckedReadBatchExt::new, JrubyAckedReadBatchExt.class);
         WRAPPED_WRITE_CLIENT_CLASS =
             setupLogstashClass(JRubyWrappedWriteClientExt::new, JRubyWrappedWriteClientExt.class);
+        QUEUE_READ_CLIENT_BASE_CLASS =
+                setupLogstashClass(ObjectAllocator.NOT_ALLOCATABLE_ALLOCATOR, QueueReadClientBase.class);
         MEMORY_READ_CLIENT_CLASS =
-            setupLogstashClass(JrubyMemoryReadClientExt::new, JrubyMemoryReadClientExt.class);
+            setupLogstashClass(QUEUE_READ_CLIENT_BASE_CLASS, JrubyMemoryReadClientExt::new, JrubyMemoryReadClientExt.class);
         ACKED_READ_CLIENT_CLASS =
-            setupLogstashClass(JrubyAckedReadClientExt::new, JrubyAckedReadClientExt.class);
+            setupLogstashClass(QUEUE_READ_CLIENT_BASE_CLASS, JrubyAckedReadClientExt::new, JrubyAckedReadClientExt.class);
         MEMORY_WRITE_CLIENT_CLASS =
             setupLogstashClass(JrubyMemoryWriteClientExt::new, JrubyMemoryWriteClientExt.class);
         ACKED_WRITE_CLIENT_CLASS =
@@ -129,7 +121,6 @@ public final class RubyUtil {
         RUBY_EVENT_CLASS.setConstant("VERSION_ONE", RUBY.newString(Event.VERSION_ONE));
         RUBY_EVENT_CLASS.defineAnnotatedMethods(JrubyEventExtLibrary.RubyEvent.class);
         RUBY_EVENT_CLASS.defineAnnotatedConstants(JrubyEventExtLibrary.RubyEvent.class);
-        RUBY_ACKED_BATCH_CLASS = setupLogstashClass(RubyAckedBatch::new, RubyAckedBatch.class);
         RUBY.getGlobalVariables().set("$LS_JARS_LOADED", RUBY.newString("true"));
     }
 
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/AckedBatch.java b/logstash-core/src/main/java/org/logstash/ackedqueue/AckedBatch.java
new file mode 100644
index 00000000000..fb88dff7ac4
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/AckedBatch.java
@@ -0,0 +1,36 @@
+package org.logstash.ackedqueue;
+
+import java.io.IOException;
+import org.jruby.RubyHash;
+import org.jruby.runtime.ThreadContext;
+import org.logstash.Event;
+import org.logstash.ext.JrubyEventExtLibrary;
+
+public final class AckedBatch {
+    private static final long serialVersionUID = -3118949118637372130L;
+    private Batch batch;
+
+    public static AckedBatch create(Batch batch) {
+        final AckedBatch ackedBatch = new AckedBatch();
+        ackedBatch.batch = batch;
+        return ackedBatch;
+    }
+
+    public RubyHash toRubyHash(ThreadContext context) {
+        final RubyHash result = RubyHash.newHash(context.runtime);
+        this.batch.getElements().forEach(e -> result.put(
+            JrubyEventExtLibrary.RubyEvent.newRubyEvent(context.runtime, (Event) e),
+            context.tru
+            )
+        );
+        return result;
+    }
+
+    public int size() {
+        return batch.size();
+    }
+
+    public void close() throws IOException {
+        batch.close();
+    }
+}
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/AckedReadBatch.java b/logstash-core/src/main/java/org/logstash/ackedqueue/AckedReadBatch.java
new file mode 100644
index 00000000000..c4569ca659b
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/AckedReadBatch.java
@@ -0,0 +1,84 @@
+package org.logstash.ackedqueue;
+
+import org.jruby.RubyArray;
+import org.jruby.RubyHash;
+import org.jruby.runtime.ThreadContext;
+import org.jruby.runtime.builtin.IRubyObject;
+import org.logstash.ackedqueue.ext.JRubyAckedQueueExt;
+import org.logstash.execution.MemoryReadBatch;
+import org.logstash.execution.QueueBatch;
+import org.logstash.ext.JrubyEventExtLibrary;
+
+import java.io.IOException;
+import java.util.Collection;
+
+import static org.logstash.RubyUtil.RUBY;
+
+public final class AckedReadBatch implements QueueBatch {
+
+    private AckedBatch ackedBatch;
+
+    private RubyHash originals;
+
+    private RubyHash generated;
+
+    public static AckedReadBatch create(final JRubyAckedQueueExt queue, final int size,
+                                        final long timeout) {
+        return new AckedReadBatch(queue, size, timeout);
+    }
+
+    private AckedReadBatch(final JRubyAckedQueueExt queue, final int size, final long timeout) {
+        ThreadContext context = RUBY.getCurrentContext();
+        AckedBatch batch = null;
+        try {
+            batch = queue.readBatch(size, timeout);
+        } catch (IOException e) {
+            throw new IllegalStateException(e);
+        }
+        if (batch == null) {
+            originals = RubyHash.newHash(context.runtime);
+            ackedBatch = null;
+        } else {
+            ackedBatch = batch;
+            originals = ackedBatch.toRubyHash(context);
+        }
+        generated = RubyHash.newHash(context.runtime);
+    }
+
+    @Override
+    public void merge(final IRubyObject event) {
+        if (!event.isNil() && !originals.containsKey(event)) {
+            generated.put(event, RUBY.getTrue());
+        }
+    }
+
+    @Override
+    public RubyArray to_a() {
+        ThreadContext context = RUBY.getCurrentContext();
+        final RubyArray result = context.runtime.newArray(filteredSize());
+        for (final JrubyEventExtLibrary.RubyEvent event
+                : (Collection<JrubyEventExtLibrary.RubyEvent>) originals.keys()) {
+            if (!MemoryReadBatch.isCancelled(event)) {
+                result.add(event);
+            }
+        }
+        for (final JrubyEventExtLibrary.RubyEvent event
+                : (Collection<JrubyEventExtLibrary.RubyEvent>) generated.keys()) {
+            if (!MemoryReadBatch.isCancelled(event)) {
+                result.add(event);
+            }
+        }
+        return result;
+    }
+
+    public void close() throws IOException {
+        if (ackedBatch != null) {
+            ackedBatch.close();
+        }
+    }
+
+    @Override
+    public int filteredSize() {
+        return originals.size() + generated.size();
+    }
+}
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyAckedQueueExt.java b/logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyAckedQueueExt.java
index 064a4f3a73d..54a783958a3 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyAckedQueueExt.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyAckedQueueExt.java
@@ -8,11 +8,13 @@
 import org.jruby.RubyObject;
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;
+import org.jruby.javasupport.JavaObject;
 import org.jruby.runtime.Arity;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.Event;
 import org.logstash.RubyUtil;
+import org.logstash.ackedqueue.AckedBatch;
 import org.logstash.ackedqueue.Batch;
 import org.logstash.ackedqueue.Queue;
 import org.logstash.ackedqueue.SettingsImpl;
@@ -137,14 +139,19 @@ public IRubyObject ruby_write(ThreadContext context, IRubyObject event) {
     @JRubyMethod(name = "read_batch", required = 2)
     public IRubyObject ruby_read_batch(ThreadContext context, IRubyObject limit,
         IRubyObject timeout) {
-        Batch b;
+        AckedBatch b;
         try {
-            b = this.queue.readBatch(RubyFixnum.num2int(limit), RubyFixnum.num2int(timeout));
+            b = readBatch(RubyFixnum.num2int(limit), RubyFixnum.num2int(timeout));
         } catch (IOException e) {
             throw RubyUtil.newRubyIOError(context.runtime, e);
         }
         // TODO: return proper Batch object
-        return (b == null) ? context.nil : RubyAckedBatch.create(context.runtime, b);
+        return (b == null) ? context.nil : JavaObject.wrap(context.runtime, b);
+    }
+
+    public AckedBatch readBatch(int limit, long timeout) throws IOException {
+        Batch b = queue.readBatch(limit, timeout);
+        return (b == null) ? null : AckedBatch.create(b);
     }
 
     @JRubyMethod(name = "is_fully_acked?")
@@ -157,6 +164,10 @@ public IRubyObject ruby_is_empty(ThreadContext context) {
         return RubyBoolean.newBoolean(context.runtime, this.queue.isEmpty());
     }
 
+    public boolean isEmpty() {
+        return queue.isEmpty();
+    }
+
     @JRubyMethod(name = "close")
     public IRubyObject ruby_close(ThreadContext context) {
         try {
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyWrappedAckedQueueExt.java b/logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyWrappedAckedQueueExt.java
index 9a477104711..78de8d830ab 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyWrappedAckedQueueExt.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyWrappedAckedQueueExt.java
@@ -112,7 +112,7 @@ public IRubyObject rubyWriteClient(final ThreadContext context) {
 
     @JRubyMethod(name = "read_client")
     public IRubyObject rubyReadClient(final ThreadContext context) {
-        return JrubyAckedReadClientExt.create(this);
+        return JrubyAckedReadClientExt.create(queue);
     }
 
     @JRubyMethod(name = "is_empty?")
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/ext/RubyAckedBatch.java b/logstash-core/src/main/java/org/logstash/ackedqueue/ext/RubyAckedBatch.java
deleted file mode 100644
index b731a55e7a0..00000000000
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/ext/RubyAckedBatch.java
+++ /dev/null
@@ -1,53 +0,0 @@
-package org.logstash.ackedqueue.ext;
-
-import java.io.IOException;
-import org.jruby.Ruby;
-import org.jruby.RubyClass;
-import org.jruby.RubyHash;
-import org.jruby.RubyObject;
-import org.jruby.anno.JRubyClass;
-import org.jruby.anno.JRubyMethod;
-import org.jruby.runtime.ThreadContext;
-import org.jruby.runtime.builtin.IRubyObject;
-import org.logstash.Event;
-import org.logstash.RubyUtil;
-import org.logstash.ackedqueue.Batch;
-import org.logstash.ext.JrubyEventExtLibrary;
-
-@JRubyClass(name = "AckedBatch")
-public final class RubyAckedBatch extends RubyObject {
-    private static final long serialVersionUID = -3118949118637372130L;
-    private Batch batch;
-
-    public RubyAckedBatch(Ruby runtime, RubyClass klass) {
-        super(runtime, klass);
-    }
-
-    public static RubyAckedBatch create(Ruby runtime, Batch batch) {
-        final RubyAckedBatch ackedBatch =
-            new RubyAckedBatch(runtime, RubyUtil.RUBY_ACKED_BATCH_CLASS);
-        ackedBatch.batch = batch;
-        return ackedBatch;
-    }
-
-    @JRubyMethod(name = "get_elements")
-    public IRubyObject ruby_get_elements(ThreadContext context) {
-        final RubyHash result = RubyHash.newHash(context.runtime);
-        this.batch.getElements().forEach(e -> result.put(
-            JrubyEventExtLibrary.RubyEvent.newRubyEvent(context.runtime, (Event) e),
-            context.tru
-            )
-        );
-        return result;
-    }
-
-    @JRubyMethod(name = "close")
-    public IRubyObject ruby_close(ThreadContext context) {
-        try {
-            this.batch.close();
-        } catch (IOException e) {
-            throw RubyUtil.newRubyIOError(context.runtime, e);
-        }
-        return context.nil;
-    }
-}
diff --git a/logstash-core/src/main/java/org/logstash/execution/MemoryReadBatch.java b/logstash-core/src/main/java/org/logstash/execution/MemoryReadBatch.java
new file mode 100644
index 00000000000..cb97f90da39
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/execution/MemoryReadBatch.java
@@ -0,0 +1,62 @@
+package org.logstash.execution;
+
+import org.jruby.RubyArray;
+import org.jruby.runtime.ThreadContext;
+import org.jruby.runtime.builtin.IRubyObject;
+import org.logstash.ext.JrubyEventExtLibrary;
+
+import java.util.LinkedHashSet;
+
+import static org.logstash.RubyUtil.RUBY;
+
+public final class MemoryReadBatch implements QueueBatch {
+
+    private final LinkedHashSet<IRubyObject> events;
+
+    public MemoryReadBatch() {
+        this(new LinkedHashSet<>());
+    }
+
+    public MemoryReadBatch(final LinkedHashSet<IRubyObject> events) {
+        this.events = events;
+    }
+
+    public static boolean isCancelled(final IRubyObject event) {
+        return ((JrubyEventExtLibrary.RubyEvent) event).getEvent().isCancelled();
+    }
+
+    public static MemoryReadBatch create(LinkedHashSet<IRubyObject> events) {
+        return new MemoryReadBatch(events);
+    }
+
+    public static MemoryReadBatch create() {
+        return create(new LinkedHashSet<>());
+    }
+
+    @Override
+    public RubyArray to_a() {
+        ThreadContext context = RUBY.getCurrentContext();
+        final RubyArray result = context.runtime.newArray(events.size());
+        for (final IRubyObject event : events) {
+            if (!isCancelled(event)) {
+                result.add(event);
+            }
+        }
+        return result;
+    }
+
+    @Override
+    public void merge(final IRubyObject event) {
+        events.add(event);
+    }
+
+    @Override
+    public int filteredSize() {
+        return events.size();
+    }
+
+    @Override
+    public void close() {
+        // no-op
+    }
+}
diff --git a/logstash-core/src/main/java/org/logstash/execution/QueueBatch.java b/logstash-core/src/main/java/org/logstash/execution/QueueBatch.java
new file mode 100644
index 00000000000..b83a5212e82
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/execution/QueueBatch.java
@@ -0,0 +1,13 @@
+package org.logstash.execution;
+
+import org.jruby.RubyArray;
+import org.jruby.runtime.builtin.IRubyObject;
+
+import java.io.IOException;
+
+public interface QueueBatch {
+    int filteredSize();
+    RubyArray to_a();
+    void merge(IRubyObject event);
+    void close() throws IOException;
+}
diff --git a/logstash-core/src/main/java/org/logstash/execution/QueueReadClient.java b/logstash-core/src/main/java/org/logstash/execution/QueueReadClient.java
new file mode 100644
index 00000000000..d1f0d45d7cf
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/execution/QueueReadClient.java
@@ -0,0 +1,13 @@
+package org.logstash.execution;
+
+import java.io.IOException;
+
+public interface QueueReadClient {
+    QueueBatch readBatch() throws InterruptedException;
+    QueueBatch newBatch();
+    void startMetrics(QueueBatch batch);
+    void addOutputMetrics(int filteredSize);
+    void addFilteredMetrics(int filteredSize);
+    void closeBatch(QueueBatch batch) throws IOException;
+    boolean isEmpty();
+}
diff --git a/logstash-core/src/main/java/org/logstash/execution/QueueReadClientBase.java b/logstash-core/src/main/java/org/logstash/execution/QueueReadClientBase.java
new file mode 100644
index 00000000000..21a71fa051b
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/execution/QueueReadClientBase.java
@@ -0,0 +1,187 @@
+package org.logstash.execution;
+
+import org.jruby.Ruby;
+import org.jruby.RubyClass;
+import org.jruby.RubyHash;
+import org.jruby.RubyNumeric;
+import org.jruby.RubyObject;
+import org.jruby.RubySymbol;
+import org.jruby.anno.JRubyClass;
+import org.jruby.anno.JRubyMethod;
+import org.jruby.java.proxies.JavaProxy;
+import org.jruby.javasupport.JavaObject;
+import org.jruby.runtime.ThreadContext;
+import org.jruby.runtime.builtin.IRubyObject;
+import org.logstash.RubyUtil;
+import org.logstash.instrument.metrics.counter.LongCounter;
+
+import java.io.IOException;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.TimeUnit;
+
+@JRubyClass(name = "QueueReadClientBase")
+public abstract class QueueReadClientBase extends RubyObject implements QueueReadClient {
+
+    private static final RubySymbol OUT_KEY = RubyUtil.RUBY.newSymbol("out");
+    private static final RubySymbol FILTERED_KEY = RubyUtil.RUBY.newSymbol("filtered");
+    private static final RubySymbol DURATION_IN_MILLIS_KEY =
+            RubyUtil.RUBY.newSymbol("duration_in_millis");
+
+    protected final ConcurrentHashMap<Long, QueueBatch> inflightBatches =
+            new ConcurrentHashMap<>();
+    protected final ConcurrentHashMap<Long, Long> inflightClocks = new ConcurrentHashMap<>();
+    protected int batchSize = 125;
+    protected long waitForNanos = 50 * 1000 * 1000; // 50 millis to nanos
+    protected long waitForMillis = 50;
+    protected LongCounter eventMetricOut;
+    protected LongCounter eventMetricFiltered;
+    protected LongCounter eventMetricTime;
+    protected LongCounter pipelineMetricOut;
+    protected LongCounter pipelineMetricFiltered;
+    protected LongCounter pipelineMetricTime;
+
+    protected QueueReadClientBase(final Ruby runtime, final RubyClass metaClass) {
+        super(runtime, metaClass);
+    }
+
+    @JRubyMethod(name = "inflight_batches")
+    public IRubyObject rubyGetInflightBatches(final ThreadContext context) {
+        final RubyHash result = RubyHash.newHash(context.runtime);
+        result.putAll(inflightBatches);
+        return result;
+    }
+
+    @JRubyMethod(name = "set_events_metric", required = 1)
+    public IRubyObject setEventsMetric(final ThreadContext context, IRubyObject metric) {
+        eventMetricOut = LongCounter.fromRubyBase(metric, OUT_KEY);
+        eventMetricFiltered = LongCounter.fromRubyBase(metric, FILTERED_KEY);
+        eventMetricTime = LongCounter.fromRubyBase(metric, DURATION_IN_MILLIS_KEY);
+        return this;
+    }
+
+    @JRubyMethod(name = "set_pipeline_metric", required = 1)
+    public IRubyObject setPipelineMetric(final ThreadContext context, IRubyObject metric) {
+        pipelineMetricOut = LongCounter.fromRubyBase(metric, OUT_KEY);
+        pipelineMetricFiltered = LongCounter.fromRubyBase(metric, FILTERED_KEY);
+        pipelineMetricTime = LongCounter.fromRubyBase(metric, DURATION_IN_MILLIS_KEY);
+        return this;
+    }
+
+    @JRubyMethod(name = "set_batch_dimensions")
+    public IRubyObject rubySetBatchDimensions(final ThreadContext context, IRubyObject batchSize,
+                                              IRubyObject waitForMillis) {
+        setBatchDimensions(((RubyNumeric) batchSize).getIntValue(),
+                ((RubyNumeric) waitForMillis).getIntValue());
+        return this;
+    }
+
+    public void setBatchDimensions(int batchSize, int waitForMillis) {
+        this.batchSize = batchSize;
+        this.waitForNanos = TimeUnit.NANOSECONDS.convert(waitForMillis, TimeUnit.MILLISECONDS);
+        this.waitForMillis = waitForMillis;
+    }
+
+    @JRubyMethod(name = "empty?")
+    public IRubyObject rubyIsEmpty(final ThreadContext context) {
+        return context.runtime.newBoolean(isEmpty());
+    }
+
+    @JRubyMethod(name = "close")
+    public void rubyClose(final ThreadContext context) {
+        try {
+            close();
+        } catch (IOException e) {
+            throw RubyUtil.newRubyIOError(context.runtime, e);
+        }
+    }
+
+    @JRubyMethod(name = "read_batch")
+    public IRubyObject rubyReadBatch(final ThreadContext context) throws InterruptedException {
+        return JavaObject.wrap(context.runtime, readBatch());
+    }
+
+    @Override
+    public void closeBatch(QueueBatch batch) throws IOException {
+        batch.close();
+        inflightBatches.remove(Thread.currentThread().getId());
+        Long startTime = inflightClocks.remove(Thread.currentThread().getId());
+        if (startTime != null && batch.filteredSize() > 0) {
+            // stop timer and record metrics iff the batch is non-empty.
+            long elapsedTimeMillis = (System.nanoTime() - startTime) / 1_000_000;
+            eventMetricTime.increment(elapsedTimeMillis);
+            pipelineMetricTime.increment(elapsedTimeMillis);
+        }
+    }
+
+    /**
+     * Closes the specified batch. This JRuby extension method is currently used only in the
+     * original pipeline and rspec tests.
+     */
+    @JRubyMethod(name = "close_batch")
+    public void rubyCloseBatch(final ThreadContext context, IRubyObject batch) throws IOException {
+        closeBatch(extractQueueBatch(batch));
+    }
+
+    /**
+     * Initializes metric on the specified batch. This JRuby extension method is currently used
+     * only in the original pipeline and rspec tests.
+     */
+    @JRubyMethod(name = "start_metrics")
+    public void rubyStartMetrics(final ThreadContext context, IRubyObject batch) {
+        startMetrics(extractQueueBatch(batch));
+    }
+
+    /**
+     * Extracts QueueBatch from one of two possible IRubyObject classes. Only the Ruby pipeline
+     * uses JavaProxy instances, so once that is fully deprecated, this method can be simplified
+     * to eliminate the type check.
+     */
+    private static QueueBatch extractQueueBatch(final IRubyObject batch) {
+        if (batch instanceof JavaProxy) {
+            return (QueueBatch) ((JavaObject)batch.dataGetStruct()).getValue();
+        } else {
+            return (QueueBatch)((JavaObject)batch).getValue();
+        }
+    }
+
+    /**
+     * Increments the filter metrics. This JRuby extension method is currently used
+     * only in the original pipeline and rspec tests.
+     */
+    @JRubyMethod(name = "add_filtered_metrics")
+    public void rubyAddFilteredMetrics(final ThreadContext context, IRubyObject size) {
+        addFilteredMetrics(((RubyNumeric)size).getIntValue());
+    }
+
+    /**
+     * Increments the output metrics. This JRuby extension method is currently used
+     * only in the original pipeline and rspec tests.
+     */
+    @JRubyMethod(name = "add_output_metrics")
+    public void rubyAddOutputMetrics(final ThreadContext context, IRubyObject size) {
+        addOutputMetrics(((RubyNumeric)size).getIntValue());
+    }
+
+    @Override
+    public void startMetrics(QueueBatch batch) {
+        long threadId = Thread.currentThread().getId();
+        inflightBatches.put(threadId, batch);
+        inflightClocks.put(threadId, System.nanoTime());
+    }
+
+    @Override
+    public void addFilteredMetrics(int filteredSize) {
+        eventMetricFiltered.increment(filteredSize);
+        pipelineMetricFiltered.increment(filteredSize);
+    }
+
+    @Override
+    public void addOutputMetrics(int filteredSize) {
+        eventMetricOut.increment(filteredSize);
+        pipelineMetricOut.increment(filteredSize);
+    }
+
+    public abstract void close() throws IOException;
+    public abstract boolean isEmpty();
+
+}
diff --git a/logstash-core/src/main/java/org/logstash/execution/WorkerLoop.java b/logstash-core/src/main/java/org/logstash/execution/WorkerLoop.java
index c925c3bd324..1640a63f1c5 100644
--- a/logstash-core/src/main/java/org/logstash/execution/WorkerLoop.java
+++ b/logstash-core/src/main/java/org/logstash/execution/WorkerLoop.java
@@ -5,7 +5,6 @@
 import java.util.concurrent.atomic.LongAdder;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import org.jruby.RubyArray;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.RubyUtil;
@@ -20,7 +19,7 @@ public final class WorkerLoop implements Runnable {
 
     private final BlockingQueue<IRubyObject> signalQueue;
 
-    private final IRubyObject readClient;
+    private final QueueReadClient readClient;
 
     private final AtomicBoolean flushing;
 
@@ -31,7 +30,7 @@ public final class WorkerLoop implements Runnable {
     private final boolean drainQueue;
 
     public WorkerLoop(final CompiledPipeline pipeline, final BlockingQueue<IRubyObject> signalQueue,
-        final IRubyObject readClient, final LongAdder filteredCounter,
+        final QueueReadClient readClient, final LongAdder filteredCounter,
         final LongAdder consumedCounter, final AtomicBoolean flushing, final boolean drainQueue) {
         this.consumedCounter = consumedCounter;
         this.filteredCounter = filteredCounter;
@@ -51,30 +50,26 @@ public void run() {
                 final IRubyObject signal = signalQueue.poll();
                 shutdownRequested = shutdownRequested
                     || signal != null && signal.callMethod(context, "shutdown?").isTrue();
-                final IRubyObject batch = readClient.callMethod(context, "read_batch");
-                consumedCounter.add(
-                    (long) batch.callMethod(context, "size").convertToInteger().getIntValue()
-                );
+                final QueueBatch batch = readClient.readBatch();
+                consumedCounter.add(batch.filteredSize());
                 final boolean isFlush = signal != null && signal.callMethod(context, "flush?").isTrue();
-                readClient.callMethod(context, "start_metrics", batch);
-                execution.compute((RubyArray) batch.callMethod(context, "to_a"), isFlush, false);
-                filteredCounter.add(
-                    (long) batch.callMethod(context, "size").convertToInteger().getIntValue()
-                );
-                final IRubyObject filteredSize = batch.callMethod(context, "filtered_size");
-                readClient.callMethod(context, "add_output_metrics", filteredSize);
-                readClient.callMethod(context, "add_filtered_metrics", filteredSize);
-                readClient.callMethod(context, "close_batch", batch);
+                readClient.startMetrics(batch);
+                execution.compute(batch.to_a(), isFlush, false);
+                int filteredCount = batch.filteredSize();
+                filteredCounter.add(filteredCount);
+                readClient.addOutputMetrics(filteredCount);
+                readClient.addFilteredMetrics(filteredCount);
+                readClient.closeBatch(batch);
                 if (isFlush) {
                     flushing.set(false);
                 }
-            } while (!shutdownRequested || isDraining(context));
+            } while (!shutdownRequested || isDraining());
             //we are shutting down, queue is drained if it was required, now  perform a final flush.
             //for this we need to create a new empty batch to contain the final flushed events
-            final IRubyObject batch = readClient.callMethod(context, "new_batch");
-            readClient.callMethod(context, "start_metrics", batch);
-            execution.compute((RubyArray) batch.callMethod(context, "to_a"), true, false);
-            readClient.callMethod(context, "close_batch", batch);
+            final QueueBatch batch = readClient.newBatch();
+            readClient.startMetrics(batch);
+            execution.compute(batch.to_a(), true, false);
+            readClient.closeBatch(batch);
         } catch (final Exception ex) {
             LOGGER.error(
                 "Exception in pipelineworker, the pipeline stopped processing new events, please check your filter configuration and restart Logstash.",
@@ -84,7 +79,7 @@ public void run() {
         }
     }
 
-    private boolean isDraining(final ThreadContext context) {
-        return drainQueue && !readClient.callMethod(context, "empty?").isTrue();
+    private boolean isDraining() {
+        return drainQueue && !readClient.isEmpty();
     }
 }
diff --git a/logstash-core/src/main/java/org/logstash/ext/JrubyAckedReadBatchExt.java b/logstash-core/src/main/java/org/logstash/ext/JrubyAckedReadBatchExt.java
deleted file mode 100644
index 50ba68f7d2f..00000000000
--- a/logstash-core/src/main/java/org/logstash/ext/JrubyAckedReadBatchExt.java
+++ /dev/null
@@ -1,123 +0,0 @@
-package org.logstash.ext;
-
-import java.util.Collection;
-import org.jruby.Ruby;
-import org.jruby.RubyArray;
-import org.jruby.RubyClass;
-import org.jruby.RubyEnumerator;
-import org.jruby.RubyHash;
-import org.jruby.RubyObject;
-import org.jruby.anno.JRubyClass;
-import org.jruby.anno.JRubyMethod;
-import org.jruby.runtime.Block;
-import org.jruby.runtime.ThreadContext;
-import org.jruby.runtime.builtin.IRubyObject;
-import org.logstash.RubyUtil;
-import org.logstash.ackedqueue.ext.RubyAckedBatch;
-
-@JRubyClass(name = "AckedReadBatch")
-public final class JrubyAckedReadBatchExt extends RubyObject {
-
-    private RubyAckedBatch ackedBatch;
-
-    private RubyHash originals;
-
-    private RubyHash generated;
-
-    public JrubyAckedReadBatchExt(final Ruby runtime, final RubyClass metaClass) {
-        super(runtime, metaClass);
-    }
-
-    public static JrubyAckedReadBatchExt create(final ThreadContext context,
-        final IRubyObject queue, final IRubyObject size, final IRubyObject timeout) {
-        final JrubyAckedReadBatchExt batch =
-            new JrubyAckedReadBatchExt(context.runtime, RubyUtil.ACKED_READ_BATCH_CLASS);
-        return (JrubyAckedReadBatchExt) batch.ruby_initialize(context, queue, size, timeout);
-    }
-
-    @JRubyMethod(name = "initialize", required = 3)
-    public IRubyObject ruby_initialize(final ThreadContext context, final IRubyObject queue,
-        final IRubyObject size, final IRubyObject timeout) {
-        final IRubyObject batch =
-            queue.callMethod(context, "read_batch", new IRubyObject[]{size, timeout});
-        if (batch.isNil()) {
-            originals = RubyHash.newHash(context.runtime);
-            ackedBatch = null;
-        } else {
-            ackedBatch = (RubyAckedBatch) batch;
-            originals = (RubyHash) ackedBatch.ruby_get_elements(context);
-        }
-        generated = RubyHash.newHash(context.runtime);
-        return this;
-    }
-
-    @JRubyMethod
-    public IRubyObject merge(final ThreadContext context, final IRubyObject event) {
-        if (!event.isNil() && !originals.containsKey(event)) {
-            generated.put(event, context.tru);
-        }
-        return this;
-    }
-
-    @JRubyMethod(name = "to_a")
-    public RubyArray toArray(final ThreadContext context) {
-        final RubyArray result = context.runtime.newArray(filteredSize());
-        for (final JrubyEventExtLibrary.RubyEvent event
-            : (Collection<JrubyEventExtLibrary.RubyEvent>) originals.keys()) {
-            if (!JrubyMemoryReadBatchExt.isCancelled(event)) {
-                result.add(event);
-            }
-        }
-        for (final JrubyEventExtLibrary.RubyEvent event
-            : (Collection<JrubyEventExtLibrary.RubyEvent>) generated.keys()) {
-            if (!JrubyMemoryReadBatchExt.isCancelled(event)) {
-                result.add(event);
-            }
-        }
-        return result;
-    }
-
-    @JRubyMethod
-    public IRubyObject each(final ThreadContext context, final Block block) {
-        if (!block.isGiven()) {
-            return RubyEnumerator.enumeratorizeWithSize(
-                context, this, "each", args -> getRuntime().newFixnum(filteredSize())
-            );
-        }
-        for (final JrubyEventExtLibrary.RubyEvent event :
-            (Collection<JrubyEventExtLibrary.RubyEvent>) originals.keys()) {
-            if (!JrubyMemoryReadBatchExt.isCancelled(event)) {
-                block.yield(context, event);
-            }
-        }
-        for (final JrubyEventExtLibrary.RubyEvent event :
-            (Collection<JrubyEventExtLibrary.RubyEvent>) generated.keys()) {
-            if (!JrubyMemoryReadBatchExt.isCancelled(event)) {
-                block.yield(context, event);
-            }
-        }
-        return this;
-    }
-
-    @JRubyMethod
-    public IRubyObject close(final ThreadContext context) {
-        if (ackedBatch != null) {
-            ackedBatch.ruby_close(context);
-        }
-        return this;
-    }
-
-    @JRubyMethod(name = {"size", "filtered_size"})
-    public IRubyObject rubySize(final ThreadContext context) {
-        return context.runtime.newFixnum(filteredSize());
-    }
-
-    @JRubyMethod(name = "starting_size")
-    public IRubyObject rubyStartingSize(final ThreadContext context) {
-        return context.runtime.newFixnum(originals.size());
-    }
-
-    public int filteredSize() {
-        return originals.size() + generated.size();
-    }
-}
diff --git a/logstash-core/src/main/java/org/logstash/ext/JrubyAckedReadClientExt.java b/logstash-core/src/main/java/org/logstash/ext/JrubyAckedReadClientExt.java
index be8f4cb96cf..cdd92551791 100644
--- a/logstash-core/src/main/java/org/logstash/ext/JrubyAckedReadClientExt.java
+++ b/logstash-core/src/main/java/org/logstash/ext/JrubyAckedReadClientExt.java
@@ -1,40 +1,25 @@
 package org.logstash.ext;
 
-import java.util.concurrent.ConcurrentHashMap;
 import org.jruby.Ruby;
 import org.jruby.RubyClass;
-import org.jruby.RubyHash;
-import org.jruby.RubyNumeric;
-import org.jruby.RubyObject;
-import org.jruby.RubySymbol;
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.RubyUtil;
-import org.logstash.instrument.metrics.counter.LongCounter;
+import org.logstash.ackedqueue.AckedReadBatch;
+import org.logstash.ackedqueue.ext.JRubyAckedQueueExt;
+import org.logstash.ackedqueue.ext.JRubyWrappedAckedQueueExt;
+import org.logstash.execution.QueueBatch;
+import org.logstash.execution.QueueReadClient;
+import org.logstash.execution.QueueReadClientBase;
 
-@JRubyClass(name = "AckedReadClient")
-public final class JrubyAckedReadClientExt extends RubyObject {
+import java.io.IOException;
 
-    private static final RubySymbol OUT_KEY = RubyUtil.RUBY.newSymbol("out");
-    private static final RubySymbol FILTERED_KEY = RubyUtil.RUBY.newSymbol("filtered");
-    private static final RubySymbol DURATION_IN_MILLIS_KEY =
-        RubyUtil.RUBY.newSymbol("duration_in_millis");
+@JRubyClass(name = "AckedReadClient", parent = "QueueReadClientBase")
+public final class JrubyAckedReadClientExt extends QueueReadClientBase implements QueueReadClient {
 
-    private final ConcurrentHashMap<Long, IRubyObject> inflightBatches = new ConcurrentHashMap<>();
-
-    private final ConcurrentHashMap<Long, Long> inflightClocks = new ConcurrentHashMap<>();
-
-    private IRubyObject queue;
-    private IRubyObject batchSize = RubyNumeric.int2fix(RubyUtil.RUBY, 125);
-    private IRubyObject waitForMillis = RubyNumeric.int2fix(RubyUtil.RUBY, 50);
-    private LongCounter eventMetricOut;
-    private LongCounter eventMetricFiltered;
-    private LongCounter eventMetricTime;
-    private LongCounter pipelineMetricOut;
-    private LongCounter pipelineMetricFiltered;
-    private LongCounter pipelineMetricTime;
+    private JRubyAckedQueueExt queue;
 
     @JRubyMethod(meta = true, required = 1)
     public static JrubyAckedReadClientExt create(final ThreadContext context,
@@ -55,110 +40,30 @@ public JrubyAckedReadClientExt(final Ruby runtime, final RubyClass metaClass) {
     private JrubyAckedReadClientExt(final Ruby runtime, final RubyClass metaClass,
         final IRubyObject queue) {
         super(runtime, metaClass);
-        this.queue = queue;
+        this.queue = (JRubyAckedQueueExt)queue;
     }
 
-    @JRubyMethod(name = "close")
-    public void rubyClose(final ThreadContext context) {
-        queue.callMethod(context, "close");
+    @Override
+    public void close() throws IOException {
+        queue.close();
     }
 
+    @Override
     public boolean isEmpty() {
-        return rubyIsEmpty(RubyUtil.RUBY.getCurrentContext()).isTrue();
-    }
-
-    @JRubyMethod(name = "empty?")
-    public IRubyObject rubyIsEmpty(final ThreadContext context) {
-        return queue.callMethod(context, "is_empty?");
-    }
-
-    @JRubyMethod(name = "set_batch_dimensions")
-    public IRubyObject rubySetBatchDimensions(final ThreadContext context, IRubyObject batchSize,
-        IRubyObject waitForMillis) {
-        this.batchSize = batchSize;
-        this.waitForMillis = waitForMillis;
-        return this;
-    }
-
-    @JRubyMethod(name = "set_events_metric", required = 1)
-    public IRubyObject setEventsMetric(final ThreadContext context, IRubyObject metric) {
-        eventMetricOut = LongCounter.fromRubyBase(metric, OUT_KEY);
-        eventMetricFiltered = LongCounter.fromRubyBase(metric, FILTERED_KEY);
-        eventMetricTime = LongCounter.fromRubyBase(metric, DURATION_IN_MILLIS_KEY);
-        return this;
-    }
-
-    @JRubyMethod(name = "set_pipeline_metric", required = 1)
-    public IRubyObject setPipelineMetric(final ThreadContext context, IRubyObject metric) {
-        pipelineMetricOut = LongCounter.fromRubyBase(metric, OUT_KEY);
-        pipelineMetricFiltered = LongCounter.fromRubyBase(metric, FILTERED_KEY);
-        pipelineMetricTime = LongCounter.fromRubyBase(metric, DURATION_IN_MILLIS_KEY);
-        return this;
-    }
-
-    @JRubyMethod(name = "inflight_batches")
-    public IRubyObject rubyGetInflightBatches(final ThreadContext context) {
-        final RubyHash result = RubyHash.newHash(context.runtime);
-        result.putAll(inflightBatches);
-        return result;
+        return queue.isEmpty();
     }
 
-    @JRubyMethod(name = "new_batch")
-    public IRubyObject newBatch(final ThreadContext context) {
-        return JrubyAckedReadBatchExt.create(
-            context, queue, context.runtime.newFixnum(0),
-            context.runtime.newFixnum(0)
-        );
+    @Override
+    public QueueBatch newBatch() {
+        return AckedReadBatch.create(queue, 0, 0);
     }
 
-    @JRubyMethod(name = "read_batch")
-    public IRubyObject readBatch(final ThreadContext context) {
-        JrubyAckedReadBatchExt batch =
-            JrubyAckedReadBatchExt.create(context, queue, batchSize, waitForMillis);
+    @Override
+    public QueueBatch readBatch() {
+        AckedReadBatch batch =
+            AckedReadBatch.create(queue, batchSize, waitForMillis);
         startMetrics(batch);
         return batch;
     }
 
-    @JRubyMethod(name = "start_metrics")
-    public IRubyObject rubyStartMetrics(final ThreadContext context, IRubyObject batch) {
-        startMetrics((JrubyAckedReadBatchExt) batch);
-        return this;
-    }
-
-    @JRubyMethod(name = "close_batch", required = 1)
-    public IRubyObject closeBatch(final ThreadContext context, IRubyObject batch) {
-        JrubyAckedReadBatchExt typedBatch = (JrubyAckedReadBatchExt) batch;
-        typedBatch.close(context);
-        inflightBatches.remove(Thread.currentThread().getId());
-        Long startTime = inflightClocks.remove(Thread.currentThread().getId());
-        if (startTime != null && typedBatch.filteredSize() > 0) {
-            // stop timer and record metrics iff the batch is non-empty.
-            long elapsedTimeMillis = (System.nanoTime() - startTime) / 1_000_000;
-            eventMetricTime.increment(elapsedTimeMillis);
-            pipelineMetricTime.increment(elapsedTimeMillis);
-        }
-        return this;
-    }
-
-    @JRubyMethod(name = "add_filtered_metrics", required = 1)
-    public IRubyObject addFilteredMetrics(final ThreadContext context, IRubyObject filteredSize) {
-        int typedFilteredSize = ((RubyNumeric) filteredSize).getIntValue();
-        eventMetricFiltered.increment(typedFilteredSize);
-        pipelineMetricFiltered.increment(typedFilteredSize);
-        return this;
-    }
-
-    @JRubyMethod(name = "add_output_metrics", required = 1)
-    public IRubyObject addOutputMetrics(final ThreadContext context, IRubyObject filteredSize) {
-        int typedFilteredSize = ((RubyNumeric) filteredSize).getIntValue();
-        eventMetricOut.increment(typedFilteredSize);
-        pipelineMetricOut.increment(typedFilteredSize);
-        return this;
-    }
-
-    private void startMetrics(JrubyAckedReadBatchExt batch) {
-        long threadId = Thread.currentThread().getId();
-        inflightBatches.put(threadId, batch);
-        inflightClocks.put(threadId, System.nanoTime());
-    }
 }
diff --git a/logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadBatchExt.java b/logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadBatchExt.java
deleted file mode 100644
index 4790cfacc89..00000000000
--- a/logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadBatchExt.java
+++ /dev/null
@@ -1,84 +0,0 @@
-package org.logstash.ext;
-
-import java.util.LinkedHashSet;
-import org.jruby.Ruby;
-import org.jruby.RubyArray;
-import org.jruby.RubyClass;
-import org.jruby.RubyEnumerator;
-import org.jruby.RubyObject;
-import org.jruby.anno.JRubyClass;
-import org.jruby.anno.JRubyMethod;
-import org.jruby.runtime.Block;
-import org.jruby.runtime.ThreadContext;
-import org.jruby.runtime.builtin.IRubyObject;
-import org.logstash.RubyUtil;
-
-@JRubyClass(name = "MemoryReadBatch")
-public final class JrubyMemoryReadBatchExt extends RubyObject {
-
-    private final LinkedHashSet<IRubyObject> events;
-
-    public JrubyMemoryReadBatchExt(final Ruby runtime, final RubyClass metaClass) {
-        this(runtime, metaClass, new LinkedHashSet<>());
-    }
-
-    public JrubyMemoryReadBatchExt(final Ruby runtime, final RubyClass metaClass, final LinkedHashSet<IRubyObject> events) {
-        super(runtime, metaClass);
-        this.events = events;
-    }
-
-    public static boolean isCancelled(final IRubyObject event) {
-        return ((JrubyEventExtLibrary.RubyEvent) event).getEvent().isCancelled();
-    }
-
-    public static JrubyMemoryReadBatchExt create(LinkedHashSet<IRubyObject> events) {
-        JrubyMemoryReadBatchExt batch = new JrubyMemoryReadBatchExt(RubyUtil.RUBY,
-                RubyUtil.MEMORY_READ_BATCH_CLASS, events);
-        return batch;
-    }
-
-    public static JrubyMemoryReadBatchExt create() {
-        return create(new LinkedHashSet<>());
-    }
-
-    @JRubyMethod(name = "to_a")
-    public RubyArray toArray(final ThreadContext context) {
-        final RubyArray result = context.runtime.newArray(events.size());
-        for (final IRubyObject event : events) {
-            if (!isCancelled(event)) {
-                result.add(event);
-            }
-        }
-        return result;
-    }
-
-    @JRubyMethod(required = 1)
-    public IRubyObject merge(final ThreadContext context, final IRubyObject event) {
-        events.add(event);
-        return this;
-    }
-
-    @JRubyMethod(name = "filtered_size", alias = "size")
-    public IRubyObject filteredSize(final ThreadContext context) {
-        return context.runtime.newFixnum(events.size());
-    }
-
-    public int filteredSize() {
-        return events.size();
-    }
-
-    @JRubyMethod
-    public IRubyObject each(final ThreadContext context, final Block block) {
-        if (!block.isGiven()) {
-            return RubyEnumerator.enumeratorizeWithSize(
-                context, this, "each", args -> getRuntime().newFixnum(events.size())
-            );
-        }
-        for (final IRubyObject event : events) {
-            if (!isCancelled(event)) {
-                block.yield(context, event);
-            }
-        }
-        return this;
-    }
-}
diff --git a/logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadClientExt.java b/logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadClientExt.java
index 0fc95860c20..2dba2253eee 100644
--- a/logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadClientExt.java
+++ b/logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadClientExt.java
@@ -1,41 +1,22 @@
 package org.logstash.ext;
 
-import java.util.concurrent.BlockingQueue;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.TimeUnit;
 import org.jruby.Ruby;
 import org.jruby.RubyClass;
-import org.jruby.RubyHash;
-import org.jruby.RubyNumeric;
-import org.jruby.RubyObject;
-import org.jruby.RubySymbol;
 import org.jruby.anno.JRubyClass;
-import org.jruby.anno.JRubyMethod;
-import org.jruby.runtime.ThreadContext;
-import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.RubyUtil;
 import org.logstash.common.LsQueueUtils;
-import org.logstash.instrument.metrics.counter.LongCounter;
+import org.logstash.execution.MemoryReadBatch;
+import org.logstash.execution.QueueBatch;
+import org.logstash.execution.QueueReadClient;
+import org.logstash.execution.QueueReadClientBase;
 
-@JRubyClass(name = "MemoryReadClient")
-public final class JrubyMemoryReadClientExt extends RubyObject {
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.TimeUnit;
 
-    private static final RubySymbol OUT_KEY = RubyUtil.RUBY.newSymbol("out");
-    private static final RubySymbol FILTERED_KEY = RubyUtil.RUBY.newSymbol("filtered");
-    private static final RubySymbol DURATION_IN_MILLIS_KEY =
-            RubyUtil.RUBY.newSymbol("duration_in_millis");
+@JRubyClass(name = "MemoryReadClient", parent = "QueueReadClientBase")
+public final class JrubyMemoryReadClientExt extends QueueReadClientBase implements QueueReadClient {
 
     private BlockingQueue queue;
-    private final ConcurrentHashMap<Long, IRubyObject> inflightBatches = new ConcurrentHashMap<>();
-    private final ConcurrentHashMap<Long, Long> inflightClocks = new ConcurrentHashMap<>();
-    private int batchSize;
-    private long waitForNanos;
-    private LongCounter eventMetricOut;
-    private LongCounter eventMetricFiltered;
-    private LongCounter eventMetricTime;
-    private LongCounter pipelineMetricOut;
-    private LongCounter pipelineMetricFiltered;
-    private LongCounter pipelineMetricTime;
 
     public JrubyMemoryReadClientExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);
@@ -46,7 +27,8 @@ private JrubyMemoryReadClientExt(final Ruby runtime, final RubyClass metaClass,
         super(runtime, metaClass);
         this.queue = queue;
         this.batchSize = batchSize;
-        waitForNanos = TimeUnit.NANOSECONDS.convert(waitForMillis, TimeUnit.MILLISECONDS);
+        this.waitForNanos = TimeUnit.NANOSECONDS.convert(waitForMillis, TimeUnit.MILLISECONDS);
+        this.waitForMillis = waitForMillis;
     }
 
     public static JrubyMemoryReadClientExt create(BlockingQueue queue, int batchSize,
@@ -55,110 +37,28 @@ public static JrubyMemoryReadClientExt create(BlockingQueue queue, int batchSize
                 RubyUtil.MEMORY_READ_CLIENT_CLASS, queue, batchSize, waitForMillis);
     }
 
-    @JRubyMethod(name = "close")
-    public void rubyClose(final ThreadContext context) {
-        // noop, for compatibility with acked queue read client
+    @Override
+    public void close() {
+        // no-op
     }
 
+    @Override
     public boolean isEmpty() {
         return queue.isEmpty();
     }
 
-    @JRubyMethod(name = "empty?")
-    public IRubyObject rubyIsEmpty(final ThreadContext context) {
-        return context.runtime.newBoolean(isEmpty());
-    }
-
-    public void setBatchDimensions(int batchSize, int waitForMillis) {
-        this.batchSize = batchSize;
-        waitForNanos = TimeUnit.NANOSECONDS.convert(waitForMillis, TimeUnit.MILLISECONDS);
-    }
-
-    @JRubyMethod(name = "set_batch_dimensions")
-    public IRubyObject rubySetBatchDimensions(final ThreadContext context, IRubyObject batchSize,
-                                              IRubyObject waitForMillis) {
-        setBatchDimensions(((RubyNumeric) batchSize).getIntValue(),
-                ((RubyNumeric) waitForMillis).getIntValue());
-        return this;
-    }
-
-    @JRubyMethod(name = "set_events_metric", required = 1)
-    public IRubyObject setEventsMetric(final ThreadContext context, IRubyObject metric) {
-        eventMetricOut = LongCounter.fromRubyBase(metric, OUT_KEY);
-        eventMetricFiltered = LongCounter.fromRubyBase(metric, FILTERED_KEY);
-        eventMetricTime = LongCounter.fromRubyBase(metric, DURATION_IN_MILLIS_KEY);
-        return this;
-    }
-
-    @JRubyMethod(name = "set_pipeline_metric", required = 1)
-    public IRubyObject setPipelineMetric(final ThreadContext context, IRubyObject metric) {
-        pipelineMetricOut = LongCounter.fromRubyBase(metric, OUT_KEY);
-        pipelineMetricFiltered = LongCounter.fromRubyBase(metric, FILTERED_KEY);
-        pipelineMetricTime = LongCounter.fromRubyBase(metric, DURATION_IN_MILLIS_KEY);
-        return this;
+    @Override
+    public QueueBatch newBatch() {
+        return MemoryReadBatch.create();
     }
 
-    @JRubyMethod(name = "inflight_batches")
-    public IRubyObject rubyGetInflightBatches(final ThreadContext context) {
-        final RubyHash result = RubyHash.newHash(context.runtime);
-        result.putAll(inflightBatches);
-        return result;
-    }
-
-    // create a new, empty batch
-    @JRubyMethod(name = "new_batch")
-    public IRubyObject newBatch(final ThreadContext context) {
-        return JrubyMemoryReadBatchExt.create();
-    }
-
-    @JRubyMethod(name = "read_batch")
-    public IRubyObject readBatch(final ThreadContext context) throws InterruptedException {
-        JrubyMemoryReadBatchExt batch = JrubyMemoryReadBatchExt.create(
+    @Override
+    public QueueBatch readBatch() throws InterruptedException {
+        MemoryReadBatch batch = MemoryReadBatch.create(
                 LsQueueUtils.drain(queue, batchSize, waitForNanos));
         startMetrics(batch);
         return batch;
     }
 
-    @JRubyMethod(name = "start_metrics")
-    public IRubyObject rubyStartMetrics(final ThreadContext context, IRubyObject batch) {
-        startMetrics((JrubyMemoryReadBatchExt) batch);
-        return this;
-    }
-
-    private void startMetrics(JrubyMemoryReadBatchExt batch) {
-        long threadId = Thread.currentThread().getId();
-        inflightBatches.put(threadId, batch);
-        inflightClocks.put(threadId, System.nanoTime());
-    }
-
-    @JRubyMethod(name = "close_batch", required = 1)
-    public IRubyObject closeBatch(final ThreadContext context, IRubyObject batch) {
-        JrubyMemoryReadBatchExt typedBatch = (JrubyMemoryReadBatchExt) batch;
-        inflightBatches.remove(Thread.currentThread().getId());
-        Long startTime = inflightClocks.remove(Thread.currentThread().getId());
-        if (startTime != null && typedBatch.filteredSize() > 0) {
-            // stop timer and record metrics iff the batch is non-empty.
-            long elapsedTimeMillis = (System.nanoTime() - startTime) / 1_000_000;
-            eventMetricTime.increment(elapsedTimeMillis);
-            pipelineMetricTime.increment(elapsedTimeMillis);
-        }
-        return this;
-    }
-
-    @JRubyMethod(name = "add_filtered_metrics", required = 1)
-    public IRubyObject addFilteredMetrics(final ThreadContext context, IRubyObject filteredSize) {
-        int typedFilteredSize = ((RubyNumeric) filteredSize).getIntValue();
-        eventMetricFiltered.increment(typedFilteredSize);
-        pipelineMetricFiltered.increment(typedFilteredSize);
-        return this;
-    }
-
-    @JRubyMethod(name = "add_output_metrics", required = 1)
-    public IRubyObject addOutputMetrics(final ThreadContext context, IRubyObject filteredSize) {
-        int typedFilteredSize = ((RubyNumeric) filteredSize).getIntValue();
-        eventMetricOut.increment(typedFilteredSize);
-        pipelineMetricOut.increment(typedFilteredSize);
-        return this;
-    }
 
 }
diff --git a/logstash-core/src/test/java/org/logstash/ext/JrubyMemoryReadClientExtTest.java b/logstash-core/src/test/java/org/logstash/ext/JrubyMemoryReadClientExtTest.java
index 1639aac68c5..b66279525c3 100644
--- a/logstash-core/src/test/java/org/logstash/ext/JrubyMemoryReadClientExtTest.java
+++ b/logstash-core/src/test/java/org/logstash/ext/JrubyMemoryReadClientExtTest.java
@@ -1,5 +1,6 @@
 package org.logstash.ext;
 
+import java.io.IOException;
 import java.util.Map;
 import java.util.concurrent.ArrayBlockingQueue;
 import java.util.concurrent.BlockingQueue;
@@ -8,6 +9,7 @@
 import org.jruby.runtime.builtin.IRubyObject;
 import org.junit.Test;
 import org.logstash.RubyUtil;
+import org.logstash.execution.QueueBatch;
 
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -18,17 +20,17 @@
 public final class JrubyMemoryReadClientExtTest {
 
     @Test
-    public void testInflightBatchesTracking() throws InterruptedException {
+    public void testInflightBatchesTracking() throws InterruptedException, IOException {
         final BlockingQueue<JrubyEventExtLibrary.RubyEvent> queue =
             new ArrayBlockingQueue<>(10);
         final JrubyMemoryReadClientExt client =
             JrubyMemoryReadClientExt.create(queue, 5, 50);
         final ThreadContext context = RubyUtil.RUBY.getCurrentContext();
-        final IRubyObject batch = client.readBatch(context);
+        final QueueBatch batch = client.readBatch();
         final RubyHash inflight = (RubyHash) client.rubyGetInflightBatches(context);
         assertThat(inflight.size(), is(1));
         assertThat(inflight.get(Thread.currentThread().getId()), is(batch));
-        client.closeBatch(context, batch);
+        client.closeBatch(batch);
         assertThat(((Map<?, ?>) client.rubyGetInflightBatches(context)).size(), is(0));
     }
 }
