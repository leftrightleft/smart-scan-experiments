diff --git a/logstash-core/lib/logstash/agent.rb b/logstash-core/lib/logstash/agent.rb
index e6eecdfd706..0514ef577d5 100644
--- a/logstash-core/lib/logstash/agent.rb
+++ b/logstash-core/lib/logstash/agent.rb
@@ -2,11 +2,6 @@
 require "logstash/environment"
 require "logstash/errors"
 require "logstash/config/cpu_core_strategy"
-require "logstash/instrument/collector"
-require "logstash/instrument/metric"
-require "logstash/instrument/periodic_pollers"
-require "logstash/instrument/collector"
-require "logstash/instrument/metric"
 require "logstash/pipeline"
 require "logstash/webserver"
 require "logstash/event_dispatcher"
@@ -19,6 +14,8 @@
 require "socket"
 require "securerandom"
 
+java_import org.logstash.instrument.witness.Witness
+
 LogStash::Environment.load_locale!
 
 class LogStash::Agent
@@ -34,6 +31,8 @@ class LogStash::Agent
   #   :auto_reload [Boolean] - enable reloading of pipelines
   #   :reload_interval [Integer] - reload pipelines every X seconds
   def initialize(settings = LogStash::SETTINGS, source_loader = nil)
+    witness = Witness.new
+    Witness.setInstance(witness)
     @logger = self.class.logger
     @settings = settings
     @auto_reload = setting("config.reload.automatic")
@@ -61,16 +60,12 @@ def initialize(settings = LogStash::SETTINGS, source_loader = nil)
     # Normalize time interval to seconds
     @reload_interval = setting("config.reload.interval") / 1_000_000_000.0
 
-    @collect_metric = setting("metric.collect")
-
-    # Create the collectors and configured it with the library
-    configure_metrics_collectors
+    #TODO: jake - start periodic pollers
 
-    @state_resolver = LogStash::StateResolver.new(metric)
+    @state_resolver = LogStash::StateResolver.new
 
-    @pipeline_reload_metric = metric.namespace([:stats, :pipelines])
-    @instance_reload_metric = metric.namespace([:stats, :reloads])
-    initialize_agent_metrics
+    @witness_pipelines = witness.pipelines
+    @witness_reloads = witness.reloads
 
     @dispatcher = LogStash::EventDispatcher.new(self)
     LogStash::PLUGIN_REGISTRY.hooks.register_emitter(self.class, dispatcher)
@@ -183,7 +178,6 @@ def uptime
   end
 
   def shutdown
-    stop_collecting_metrics
     stop_webserver
     transition_to_stopped
     converge_result = shutdown_pipelines
@@ -342,7 +336,7 @@ def converge_state(pipeline_actions)
         rescue SystemExit => e
           converge_result.add(action, e)
         rescue Exception => e
-          logger.error("Failed to execute action", :action => action, :exception => e.class.name, :message => e.message)
+          logger.error("Failed to execute action", :action => action, :exception => e.class.name, :message => e.message, :backtrace => e.backtrace)
           converge_result.add(action, e)
         end
       end
@@ -398,28 +392,6 @@ def stop_webserver
     @webserver.stop if @webserver
   end
 
-  def configure_metrics_collectors
-    @collector = LogStash::Instrument::Collector.new
-
-    @metric = if collect_metrics?
-      @logger.debug("Agent: Configuring metric collection")
-      LogStash::Instrument::Metric.new(@collector)
-    else
-      LogStash::Instrument::NullMetric.new(@collector)
-    end
-
-    @periodic_pollers = LogStash::Instrument::PeriodicPollers.new(@metric, settings.get("queue.type"), self)
-    @periodic_pollers.start
-  end
-
-  def stop_collecting_metrics
-    @periodic_pollers.stop
-  end
-
-  def collect_metrics?
-    @collect_metric
-  end
-
   def shutdown_pipelines
     logger.debug("Shutting down all pipelines", :pipelines_count => pipelines_count)
 
@@ -464,51 +436,27 @@ def update_metrics(converge_result)
 
   def update_success_metrics(action, action_result)
     case action
-      when LogStash::PipelineAction::Create
-        # When a pipeline is successfully created we create the metric
-        # place holder related to the lifecycle of the pipeline
-        initialize_pipeline_metrics(action)
       when LogStash::PipelineAction::Reload
         update_successful_reload_metrics(action, action_result)
     end
   end
 
   def update_failures_metrics(action, action_result)
-    if action.is_a?(LogStash::PipelineAction::Create)
-      # force to create the metric fields
-      initialize_pipeline_metrics(action)
-    end
-
-    @instance_reload_metric.increment(:failures)
-
-    @pipeline_reload_metric.namespace([action.pipeline_id, :reloads]).tap do |n|
-      n.increment(:failures)
-      n.gauge(:last_error, { :message => action_result.message, :backtrace => action_result.backtrace})
-      n.gauge(:last_failure_timestamp, LogStash::Timestamp.now)
-    end
-  end
 
-  def initialize_agent_metrics
-    @instance_reload_metric.increment(:successes, 0)
-    @instance_reload_metric.increment(:failures, 0)
-  end
+    @witness_reloads.failure
 
-  def initialize_pipeline_metrics(action)
-    @pipeline_reload_metric.namespace([action.pipeline_id, :reloads]).tap do |n|
-      n.increment(:successes, 0)
-      n.increment(:failures, 0)
-      n.gauge(:last_error, nil)
-      n.gauge(:last_success_timestamp, nil)
-      n.gauge(:last_failure_timestamp, nil)
-    end
+    witness_pipeline_reloads = @witness_pipelines.pipeline(action.pipeline_id).reloads
+    witness_pipeline_reloads.failure
+    witness_pipeline_reloads.error.message(action_result.message)
+    witness_pipeline_reloads.error.backtrace(action_result.backtrace.to_s)
+    witness_pipeline_reloads.last_failure_timestamp(LogStash::Timestamp.now)
   end
 
   def update_successful_reload_metrics(action, action_result)
-    @instance_reload_metric.increment(:successes)
+    @witness_reloads.success
 
-    @pipeline_reload_metric.namespace([action.pipeline_id, :reloads]).tap do |n|
-      n.increment(:successes)
-      n.gauge(:last_success_timestamp, action_result.executed_at)
-    end
+    witness_pipeline_reloads = @witness_pipelines.pipeline(action.pipeline_id).reloads
+    witness_pipeline_reloads.success
+    witness_pipeline_reloads.last_success_timestamp(action_result.executed_at)
   end
 end # class LogStash::Agent
diff --git a/logstash-core/lib/logstash/environment.rb b/logstash-core/lib/logstash/environment.rb
index f064f4e0d5b..fb9f76954eb 100644
--- a/logstash-core/lib/logstash/environment.rb
+++ b/logstash-core/lib/logstash/environment.rb
@@ -27,7 +27,6 @@ module Environment
            Setting::Boolean.new("config.reload.automatic", false),
            Setting::TimeValue.new("config.reload.interval", "3s"), # in seconds
            Setting::Boolean.new("config.support_escapes", false),
-           Setting::Boolean.new("metric.collect", true),
             Setting::String.new("pipeline.id", "main"),
            Setting::Boolean.new("pipeline.system", false),
    Setting::PositiveInteger.new("pipeline.workers", LogStash::Config::CpuCoreStrategy.maximum),
diff --git a/logstash-core/lib/logstash/instrument/collector.rb b/logstash-core/lib/logstash/instrument/collector.rb
deleted file mode 100644
index 4971695a2c9..00000000000
--- a/logstash-core/lib/logstash/instrument/collector.rb
+++ /dev/null
@@ -1,69 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/snapshot"
-require "logstash/instrument/metric_store"
-require "logstash/util/loggable"
-require "concurrent/timer_task"
-require "observer"
-require "singleton"
-require "thread"
-
-module LogStash module Instrument
-  # The Collector is the single point of reference for all
-  # the metrics collection inside logstash, the metrics library will make
-  # direct calls to this class.
-  class Collector
-    include LogStash::Util::Loggable
-
-    SNAPSHOT_ROTATION_TIME_SECS = 1 # seconds
-    SNAPSHOT_ROTATION_TIMEOUT_INTERVAL_SECS = 10 * 60 # seconds
-
-    attr_accessor :agent
-
-    def initialize
-      @metric_store = MetricStore.new
-      @agent = nil
-    end
-
-    # The metric library will call this unique interface
-    # its the job of the collector to update the store with new metric
-    # of update the metric
-    #
-    # If there is a problem with the key or the type of metric we will record an error
-    # but we won't stop processing events, theses errors are not considered fatal.
-    #
-    def push(namespaces_path, key, type, *metric_type_params)
-      begin
-        get(namespaces_path, key, type).execute(*metric_type_params)
-      rescue MetricStore::NamespacesExpectedError => e
-        logger.error("Collector: Cannot record metric", :exception => e)
-      rescue NameError => e
-        logger.error("Collector: Cannot create concrete class for this metric type",
-                     :type => type,
-                     :namespaces_path => namespaces_path,
-                     :key => key,
-                     :metrics_params => metric_type_params,
-                     :exception => e,
-                     :stacktrace => e.backtrace)
-      end
-    end
-
-    def get(namespaces_path, key, type)
-      @metric_store.fetch_or_store(namespaces_path, key) do
-        LogStash::Instrument::MetricType.create(type, namespaces_path, key)
-      end
-    end
-
-    # Snapshot the current Metric Store and return it immediately,
-    # This is useful if you want to get access to the current metric store without
-    # waiting for a periodic call.
-    #
-    # @return [LogStash::Instrument::MetricStore]
-    def snapshot_metric
-      Snapshot.new(@metric_store.dup)
-    end
-
-    def clear(keypath)
-      @metric_store.prune(keypath)
-    end
-  end
-end; end
diff --git a/logstash-core/lib/logstash/instrument/global_metrics.rb b/logstash-core/lib/logstash/instrument/global_metrics.rb
deleted file mode 100644
index dde654d213e..00000000000
--- a/logstash-core/lib/logstash/instrument/global_metrics.rb
+++ /dev/null
@@ -1,13 +0,0 @@
-class GlobalMetrics
-  class Stats(metric)
-    @metric = metric
-  end
-
-  def initialize(metric)
-    @metric = metric
-
-    @pipeline_reloads = metric.namespace([:stats, :pipelines])
-  end
-
-
-end
\ No newline at end of file
diff --git a/logstash-core/lib/logstash/instrument/metric.rb b/logstash-core/lib/logstash/instrument/metric.rb
deleted file mode 100644
index d31a8613dad..00000000000
--- a/logstash-core/lib/logstash/instrument/metric.rb
+++ /dev/null
@@ -1,105 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/collector"
-require "concurrent"
-
-module LogStash module Instrument
-  class MetricException < Exception; end
-  class MetricNoKeyProvided < MetricException; end
-  class MetricNoBlockProvided < MetricException; end
-  class MetricNoNamespaceProvided < MetricException; end
-
-  # This class provide the interface between the code, the collector and the format
-  # of the recorded metric.
-  class Metric
-    attr_reader :collector
-
-    def initialize(collector)
-      @collector = collector
-    end
-
-    def increment(namespace, key, value = 1)
-      self.class.validate_key!(key)
-      collector.push(namespace, key, :counter, :increment, value)
-    end
-
-    def decrement(namespace, key, value = 1)
-      self.class.validate_key!(key)
-      collector.push(namespace, key, :counter, :decrement, value)
-    end
-
-    def gauge(namespace, key, value)
-      self.class.validate_key!(key)
-      collector.push(namespace, key, :gauge, :set, value)
-    end
-
-    def time(namespace, key)
-      self.class.validate_key!(key)
-
-      if block_given?
-        timer = TimedExecution.new(self, namespace, key)
-        content = yield
-        timer.stop
-        return content
-      else
-        TimedExecution.new(self, namespace, key)
-      end
-    end
-
-    def report_time(namespace, key, duration)
-      self.class.validate_key!(key)
-      collector.push(namespace, key, :counter, :increment, duration)
-    end
-
-    # This method return a metric instance tied to a specific namespace
-    # so instead of specifying the namespace on every call.
-    #
-    # Example:
-    #   metric.increment(:namespace, :mykey, 200)
-    #   metric.increment(:namespace, :mykey_2, 200)
-    #
-    #   namespaced_metric = metric.namespace(:namespace)
-    #   namespaced_metric.increment(:mykey, 200)
-    #   namespaced_metric.increment(:mykey_2, 200)
-    # ```
-    #
-    # @param name [Array<String>] Name of the namespace
-    # @param name [String] Name of the namespace
-    def namespace(name)
-      raise MetricNoNamespaceProvided if name.nil? || name.empty?
-
-      NamespacedMetric.new(self, name)
-    end
-
-    def self.validate_key!(key)
-      raise MetricNoKeyProvided if key.nil? || key.empty?
-    end
-
-    private
-    # Allow to calculate the execution of a block of code.
-    # This class support 2 differents syntax a block or the return of
-    # the object itself, but in the later case the metric won't be recorded
-    # Until we call `#stop`.
-    #
-    # @see LogStash::Instrument::Metric#time
-    class TimedExecution
-      MILLISECONDS = 1_000.0.freeze
-
-      def initialize(metric, namespace, key)
-        @metric = metric
-        @namespace = namespace
-        @key = key
-        start
-      end
-
-      def start
-        @start_time = Time.now
-      end
-
-      def stop
-        execution_time = (MILLISECONDS * (Time.now - @start_time)).to_i
-        @metric.report_time(@namespace, @key, execution_time)
-        execution_time
-      end
-    end
-  end
-end; end
diff --git a/logstash-core/lib/logstash/instrument/metric_store.rb b/logstash-core/lib/logstash/instrument/metric_store.rb
deleted file mode 100644
index 09e803a46fa..00000000000
--- a/logstash-core/lib/logstash/instrument/metric_store.rb
+++ /dev/null
@@ -1,326 +0,0 @@
-# encoding: utf-8
-require "concurrent"
-require "logstash/instrument/metric_type"
-require "thread"
-
-module LogStash module Instrument
-  # The Metric store the data structure that make sure the data is
-  # saved in a retrievable way, this is a wrapper around multiples ConcurrentHashMap
-  # acting as a tree like structure.
-  class MetricStore
-    class NamespacesExpectedError < StandardError; end
-    class MetricNotFound < StandardError; end
-
-    KEY_PATH_SEPARATOR = "/".freeze
-
-    # Lets me a bit flexible on the coma usage in the path
-    # definition
-    FILTER_KEYS_SEPARATOR = /\s?*,\s*/.freeze
-
-    def initialize
-      # We keep the structured cache to allow
-      # the api to search the content of the differents nodes
-      @store = Concurrent::Map.new
-
-      # This hash has only one dimension
-      # and allow fast retrieval of the metrics
-      @fast_lookup = Concurrent::Map.new
-
-      # This Mutex block the critical section for the
-      # structured hash, it block the zone when we first insert a metric
-      # in the structured hash or when we query it for search or to make
-      # the result available in the API.
-      @structured_lookup_mutex = Mutex.new
-    end
-
-    # This method use the namespace and key to search the corresponding value of
-    # the hash, if it doesn't exist it will create the appropriate namespaces
-    # path in the hash and return `new_value`
-    #
-    # @param [Array] The path where the values should be located
-    # @param [Symbol] The metric key
-    # @return [Object] Return the new_value of the retrieve object in the tree
-    def fetch_or_store(namespaces, key, default_value = nil)
-
-      # We first check in the `@fast_lookup` store to see if we have already see that metrics before,
-      # This give us a `o(1)` access, which is faster than searching through the structured
-      # data store (Which is a `o(n)` operation where `n` is the number of element in the namespace and
-      # the value of the key). If the metric is already present in the `@fast_lookup`, then that value is sent
-      # back directly to the caller.
-      #
-      # BUT. If the value is not present in the `@fast_lookup` the value will be inserted and we assume that we don't
-      # have it in the `@metric_store` for structured search so we add it there too.
-
-      value = @fast_lookup.get(namespaces.dup << key)
-      if value.nil?
-        value = block_given? ? yield(key) : default_value
-        @fast_lookup.put(namespaces.dup << key, value)
-        @structured_lookup_mutex.synchronize do
-            # If we cannot find the value this mean we need to save it in the store.
-          fetch_or_store_namespaces(namespaces).fetch_or_store(key, value)
-        end
-      end
-      return value;
-    end
-
-    # This method allow to retrieve values for a specific path,
-    # This method support the following queries
-    #
-    # stats/pipelines/pipeline_X
-    # stats/pipelines/pipeline_X,pipeline_2
-    # stats/os,jvm
-    #
-    # If you use the `,` on a key the metric store will return the both values at that level
-    #
-    # The returned hash will keep the same structure as it had in the `Concurrent::Map`
-    # but will be a normal ruby hash. This will allow the api to easily serialize the content
-    # of the map
-    #
-    # @param [Array] The path where values should be located
-    # @return [Hash]
-    def get_with_path(path)
-      get(*key_paths(path))
-    end
-
-    # Similar to `get_with_path` but use symbols instead of string
-    #
-    # @param [Array<Symbol>]
-    # @return [Hash]
-    def get(*key_paths)
-      # Normalize the symbols access
-      key_paths.map(&:to_sym)
-      new_hash = Hash.new
-
-      @structured_lookup_mutex.synchronize do
-        get_recursively(key_paths, @store, new_hash)
-      end
-
-      new_hash
-    end
-
-    # Retrieve values like `get`, but don't return them fully nested.
-    # This means that if you call `get_shallow(:foo, :bar)` the result will not
-    # be nested inside of `{:foo {:bar => values}`.
-    #
-    # @param [Array<Symbol>]
-    # @return [Hash]
-    def get_shallow(*key_paths)
-      key_paths.reduce(get(*key_paths)) {|acc, p| acc[p]}
-    end
-
-
-    # Return a hash including the values of the keys given at the path given
-    # 
-    # Example Usage:
-    # extract_metrics(
-    #   [:jvm, :process],
-    #   :open_file_descriptors,
-    #   [:cpu, [:total_in_millis, :percent]]
-    #   [:pipelines, [:one, :two], :size]
-    # )
-    # 
-    # Returns:
-    # # From the jvm.process metrics namespace
-    # {
-    #   :open_file_descriptors => 123
-    #   :cpu => { :total_in_millis => 456, :percent => 789 }
-    #   :pipelines => {
-    #                   :one => {:size => 90210},
-    #                   :two => {:size => 8675309}
-    #                 }
-    # }
-    def extract_metrics(path, *keys)
-      keys.reduce({}) do |acc,k|
-        # Simplify 1-length keys
-        k = k.first if k.is_a?(Array) && k.size == 1
-
-        # If we have array values here we need to recurse
-        # There are two levels of looping here, one for the paths we might pass in
-        # one for the upcoming keys we might pass in
-        if k.is_a?(Array)
-          # We need to build up future executions to extract_metrics
-          # which means building up the path and keys arguments.
-          # We need a nested loop her to execute all permutations of these in case we hit
-          # something like [[:a,:b],[:c,:d]] which produces 4 different metrics
-          next_paths = Array(k.first)
-          next_keys = Array(k[1])
-          rest = k[2..-1]
-          next_paths.each do |next_path|
-            # If there already is a hash at this location use that so we don't overwrite it
-            np_hash = acc[next_path] || {}
-            
-            acc[next_path] = next_keys.reduce(np_hash) do |a,next_key|
-              a.merge! extract_metrics(path + [next_path], [next_key, *rest])
-            end
-          end
-        else # Scalar value
-          res = get_shallow(*path)[k]
-          acc[k] = res ? res.value : nil
-        end
-        
-        acc
-      end
-    end    
-
-    def has_metric?(*path)
-      @fast_lookup[path]
-    end
-
-    # Return all the individuals Metric,
-    # This call mimic a Enum's each if a block is provided
-    #
-    # @param path [String] The search path for metrics
-    # @param [Array] The metric for the specific path
-    def each(path = nil, &block)
-      metrics = if path.nil?
-        get_all
-      else
-        transform_to_array(get_with_path(path))
-      end
-
-      block_given? ? metrics.each(&block) : metrics
-    end
-    alias_method :all, :each
-
-    def prune(path)
-      key_paths = key_paths(path).map(&:to_sym)
-      @structured_lookup_mutex.synchronize do
-        keys_to_delete = @fast_lookup.keys.select {|namespace| (key_paths - namespace[0..-2]).empty? }
-        keys_to_delete.each {|k| @fast_lookup.delete(k) }
-        delete_from_map(@store, key_paths)
-      end
-    end
-
-    def size
-      @fast_lookup.size
-    end
-
-    private
-    def get_all
-      @fast_lookup.values
-    end
-
-    def key_paths(path)
-      path.gsub(/^#{KEY_PATH_SEPARATOR}+/, "").split(KEY_PATH_SEPARATOR)
-    end
-
-    # This method take an array of keys and recursively search the metric store structure
-    # and return a filtered hash of the structure. This method also take into consideration
-    # getting two different branchs.
-    #
-    #
-    # If one part of the `key_paths` contains a filter key with the following format.
-    # "pipeline01, pipeline_02", It know that need to fetch the branch `pipeline01` and `pipeline02`
-    #
-    # Look at the rspec test for more usage.
-    #
-    # @param key_paths [Array<Symbol>] The list of keys part to filter
-    # @param map [Concurrent::Map] The the part of map to search in
-    # @param new_hash [Hash] The hash to populate with the results.
-    # @return Hash
-    def get_recursively(key_paths, map, new_hash)
-      key_candidates = extract_filter_keys(key_paths.shift)
-
-      key_candidates.each do |key_candidate|
-        raise MetricNotFound, "For path: #{key_candidate}. Map keys: #{map.keys}" if map[key_candidate].nil?
-
-        if key_paths.empty? # End of the user requested path
-          if map[key_candidate].is_a?(Concurrent::Map)
-            new_hash[key_candidate] = transform_to_hash(map[key_candidate])
-          else
-            new_hash[key_candidate] = map[key_candidate]
-          end
-        else
-          if map[key_candidate].is_a?(Concurrent::Map)
-            new_hash[key_candidate] = get_recursively(key_paths, map[key_candidate], {})
-          else
-            new_hash[key_candidate] = map[key_candidate]
-          end
-        end
-      end
-      return new_hash
-    end
-
-    def extract_filter_keys(key)
-      key.to_s.strip.split(FILTER_KEYS_SEPARATOR).map(&:to_sym)
-    end
-
-    # Take a hash and recursively flatten it into an array.
-    # This is useful if you are only interested in the leaf of the tree.
-    # Mostly used with `each` to get all the metrics from a specific namespaces
-    #
-    # This could be moved to `LogStash::Util` once this api stabilize
-    #
-    # @return [Array] One dimension array
-     def transform_to_array(map)
-      map.values.collect do |value|
-        value.is_a?(Hash) ? transform_to_array(value) : value
-      end.flatten
-    end
-
-    # Transform the Concurrent::Map hash into a ruby hash format,
-    # This is used to be serialize at the web api layer.
-    #
-    # This could be moved to `LogStash::Util` once this api stabilize
-    #
-    # @return [Hash]
-    def transform_to_hash(map, new_hash = Hash.new)
-      map.each_pair do |key, value|
-        if value.is_a?(Concurrent::Map)
-          new_hash[key] = {}
-          transform_to_hash(value, new_hash[key])
-        else
-          new_hash[key] = value
-        end
-      end
-
-      return new_hash
-    end
-
-    # This method iterate through the namespace path and try to find the corresponding
-    # value for the path, if any part of the path is not found it will
-    # create it.
-    #
-    # @param [Array] The path where values should be located
-    # @raise [ConcurrentMapExpected] Raise if the retrieved object isn't a `Concurrent::Map`
-    # @return [Concurrent::Map] Map where the metrics should be saved
-    def fetch_or_store_namespaces(namespaces_path)
-      path_map = fetch_or_store_namespace_recursively(@store, namespaces_path)
-
-      # This mean one of the namespace and key are colliding
-      # and we have to deal it upstream.
-      unless path_map.is_a?(Concurrent::Map)
-        raise NamespacesExpectedError, "Expecting a `Namespaces` but found class:  #{path_map.class.name} for namespaces_path: #{namespaces_path}"
-      end
-
-      return path_map
-    end
-
-    # Recursively fetch or create the namespace paths through the `MetricStove`
-    # This algorithm use an index to known which keys to search in the map.
-    # This doesn't cloning the array if we want to give a better feedback to the user
-    #
-    # @param [Concurrent::Map] Map to search for the key
-    # @param [Array] List of path to create
-    # @param [Fixnum] Which part from the list to create
-    #
-    def fetch_or_store_namespace_recursively(map, namespaces_path, idx = 0)
-      current = namespaces_path[idx]
-
-      # we are at the end of the namespace path, break out of the recursion
-      return map if current.nil?
-
-      new_map = map.fetch_or_store(current) { Concurrent::Map.new }
-      return fetch_or_store_namespace_recursively(new_map, namespaces_path, idx + 1)
-    end
-
-    def delete_from_map(map, keys)
-      key = keys.first
-      if keys.size == 1
-        map.delete(key)
-      else
-        delete_from_map(map[key], keys[1..-1]) unless map[key].nil?
-      end
-    end
-  end
-end; end
diff --git a/logstash-core/lib/logstash/instrument/metric_type.rb b/logstash-core/lib/logstash/instrument/metric_type.rb
deleted file mode 100644
index 85b82de4c3b..00000000000
--- a/logstash-core/lib/logstash/instrument/metric_type.rb
+++ /dev/null
@@ -1,22 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/metric_type/counter"
-require "logstash/instrument/metric_type/gauge"
-
-module LogStash module Instrument
-  module MetricType
-    METRIC_TYPE_LIST = {
-      :counter => LogStash::Instrument::MetricType::Counter,
-      :gauge => LogStash::Instrument::MetricType::Gauge
-    }.freeze
-
-    # Use the string to generate a concrete class for this metrics
-    #
-    # @param [String] The name of the class
-    # @param [Array] Namespaces list
-    # @param [String] The metric key
-    # @raise [NameError] If the class is not found
-    def self.create(type, namespaces, key)
-      METRIC_TYPE_LIST[type].new(namespaces, key)
-    end
-  end
-end; end
diff --git a/logstash-core/lib/logstash/instrument/metric_type/counter.rb b/logstash-core/lib/logstash/instrument/metric_type/counter.rb
deleted file mode 100644
index 2feeb2d7791..00000000000
--- a/logstash-core/lib/logstash/instrument/metric_type/counter.rb
+++ /dev/null
@@ -1,17 +0,0 @@
-#encoding: utf-8
-java_import org.logstash.instrument.metrics.counter.LongCounter
-
-module LogStash module Instrument module MetricType
-  class Counter < LongCounter
-
-    def initialize(namespaces, key)
-      super(key.to_s)
-
-    end
-
-    def execute(action, value = 1)
-      send(action, value)
-    end
-
-  end
-end; end; end
diff --git a/logstash-core/lib/logstash/instrument/metric_type/gauge.rb b/logstash-core/lib/logstash/instrument/metric_type/gauge.rb
deleted file mode 100644
index e6492305e4a..00000000000
--- a/logstash-core/lib/logstash/instrument/metric_type/gauge.rb
+++ /dev/null
@@ -1,16 +0,0 @@
-# encoding: utf-8
-java_import org.logstash.instrument.metrics.gauge.LazyDelegatingGauge
-module LogStash module Instrument module MetricType
-  class Gauge < LazyDelegatingGauge
-
-    def initialize(namespaces, key)
-      super(key.to_s)
-    end
-
-    def execute(action, value = nil)
-      send(action, value)
-    end
-
-  end
-end; end; end
-
diff --git a/logstash-core/lib/logstash/instrument/namespaced_metric.rb b/logstash-core/lib/logstash/instrument/namespaced_metric.rb
deleted file mode 100644
index 40afa45424a..00000000000
--- a/logstash-core/lib/logstash/instrument/namespaced_metric.rb
+++ /dev/null
@@ -1,58 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/metric"
-
-module LogStash module Instrument
-  # This class acts a a proxy between the metric library and the user calls.
-  #
-  # This is the class that plugins authors will use to interact with the `MetricStore`
-  # It has the same public interface as `Metric` class but doesnt require to send
-  # the namespace on every call.
-  #
-  # @see Logstash::Instrument::Metric
-  class NamespacedMetric
-    attr_reader :namespace_name
-    # Create metric with a specific namespace
-    #
-    # @param metric [LogStash::Instrument::Metric] The metric instance to proxy
-    # @param namespace [Array] The namespace to use
-    def initialize(metric, namespace_name)
-      @metric = metric
-      @namespace_name = Array(namespace_name)
-    end
-
-    def increment(key, value = 1)
-      @metric.increment(namespace_name, key, value)
-    end
-
-    def decrement(key, value = 1)
-      @metric.decrement(namespace_name, key, value)
-    end
-
-    def gauge(key, value)
-      @metric.gauge(namespace_name, key, value)
-    end
-
-    def report_time(key, duration)
-      @metric.report_time(namespace_name, key, duration)
-    end
-
-    def time(key, &block)
-      @metric.time(namespace_name, key, &block)
-    end
-
-    def collector
-      @metric.collector
-    end
-    
-    def counter(key)
-      collector.get(@namespace_name, key, :counter)
-    end
-
-    def namespace(name)
-      NamespacedMetric.new(metric, namespace_name + Array(name))
-    end
-
-    private
-    attr_reader :metric
-  end
-end; end
diff --git a/logstash-core/lib/logstash/instrument/namespaced_null_metric.rb b/logstash-core/lib/logstash/instrument/namespaced_null_metric.rb
deleted file mode 100644
index 1a3b6f9c1d1..00000000000
--- a/logstash-core/lib/logstash/instrument/namespaced_null_metric.rb
+++ /dev/null
@@ -1,58 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/null_metric"
-
-module LogStash module Instrument
-  # This class acts a a proxy between the metric library and the user calls.
-  #
-  # This is the class that plugins authors will use to interact with the `MetricStore`
-  # It has the same public interface as `Metric` class but doesnt require to send
-  # the namespace on every call.
-  #
-  # @see Logstash::Instrument::Metric
-  class NamespacedNullMetric
-    attr_reader :namespace_name
-    # Create metric with a specific namespace
-    #
-    # @param metric [LogStash::Instrument::Metric] The metric instance to proxy
-    # @param namespace [Array] The namespace to use
-    def initialize(metric = nil, namespace_name = :null)
-      @metric = metric
-      @namespace_name = Array(namespace_name)
-    end
-
-    def increment(key, value = 1)
-    end
-
-    def decrement(key, value = 1)
-    end
-
-    def gauge(key, value)
-    end
-
-    def report_time(key, duration)
-    end
-
-    def time(key, &block)
-      if block_given?
-        yield
-      else
-        ::LogStash::Instrument::NullMetric::NullTimedExecution
-      end
-    end
-
-    def collector
-      @metric.collector
-    end
-
-    def counter(_)
-      ::LogStash::Instrument::NullMetric::NullGauge
-    end
-
-    def namespace(name)
-      NamespacedNullMetric.new(metric, namespace_name + Array(name))
-    end
-
-    private
-    attr_reader :metric
-  end
-end; end
diff --git a/logstash-core/lib/logstash/instrument/null_metric.rb b/logstash-core/lib/logstash/instrument/null_metric.rb
deleted file mode 100644
index f56028d4580..00000000000
--- a/logstash-core/lib/logstash/instrument/null_metric.rb
+++ /dev/null
@@ -1,71 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/metric"
-
-module LogStash module Instrument
-  # This class is used in the context when we disable the metric collection
-  # for specific plugin to replace the `NamespacedMetric` class with this one
-  # which doesn't produce any metric to the collector.
-  class NullMetric
-    attr_reader :namespace_name, :collector
-
-    def initialize(collector = nil)
-      @collector = collector
-    end
-
-    def increment(namespace, key, value = 1)
-      Metric.validate_key!(key)
-    end
-
-    def decrement(namespace, key, value = 1)
-      Metric.validate_key!(key)
-    end
-
-    def gauge(namespace, key, value)
-      Metric.validate_key!(key)
-    end
-
-    def report_time(namespace, key, duration)
-      Metric.validate_key!(key)
-    end
-
-    # We have to manually redefine this method since it can return an
-    # object this object also has to be implemented as a NullObject
-    def time(namespace, key)
-      Metric.validate_key!(key)
-      if block_given?
-        yield
-      else
-        NullTimedExecution
-      end
-    end
-
-    def counter(_)
-      NullGauge
-    end
-
-    def namespace(name)
-      raise MetricNoNamespaceProvided if name.nil? || name.empty?
-      NamespacedNullMetric.new(self, name)
-    end
-
-    def self.validate_key!(key)
-      raise MetricNoKeyProvided if key.nil? || key.empty?
-    end
-
-    private
-
-    class NullGauge
-      def self.increment(_)
-      end
-    end
-
-    # Null implementation of the internal timer class
-    #
-    # @see LogStash::Instrument::TimedExecution`
-    class NullTimedExecution
-      def self.stop
-        0
-      end
-    end
-  end
-end; end
diff --git a/logstash-core/lib/logstash/instrument/snapshot.rb b/logstash-core/lib/logstash/instrument/snapshot.rb
deleted file mode 100644
index 62a12677fdb..00000000000
--- a/logstash-core/lib/logstash/instrument/snapshot.rb
+++ /dev/null
@@ -1,15 +0,0 @@
-# encoding: utf-8
-require "logstash/util/loggable"
-
-module LogStash module Instrument
-  class Snapshot
-    include LogStash::Util::Loggable
-
-    attr_reader :metric_store, :created_at
-
-    def initialize(metric_store, created_at = Time.now)
-      @metric_store = metric_store
-      @created_at = created_at
-    end
-  end
-end; end
diff --git a/logstash-core/spec/logstash/agent_spec.rb b/logstash-core/spec/logstash/agent_spec.rb
index 49752a22579..3a52455c8f3 100644
--- a/logstash-core/spec/logstash/agent_spec.rb
+++ b/logstash-core/spec/logstash/agent_spec.rb
@@ -329,7 +329,6 @@
 
     let(:agent_args) do
       {
-        "metric.collect" => true,
         "path.config" => config_file
       }
     end
@@ -382,40 +381,36 @@
       after(:each) { File.unlink(new_file) }
 
       it "resets the pipeline metric collector" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:events][:in].value
+        value = Witness.instance.pipeline("main").events.snitch.in
         expect(value).to be <= new_config_generator_counter
       end
 
       it "does not reset the global event count" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/events")[:stats][:events][:in].value
+        value = Witness.instance.events.snitch.in
         expect(value).to be > initial_generator_threshold
       end
 
       it "increases the successful reload count" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:successes].value
+        value = Witness.instance.pipeline("main").reloads.snitch.successes
         expect(value).to eq(1)
-        instance_value = snapshot.metric_store.get_with_path("/stats")[:stats][:reloads][:successes].value
+        instance_value = Witness.instance.reloads.snitch.successes
         expect(instance_value).to eq(1)
       end
 
       it "does not set the failure reload timestamp" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_failure_timestamp].value
+        value = Witness.instance.pipeline("main").reloads.snitch.last_failure_timestamp
         expect(value).to be(nil)
       end
 
       it "sets the success reload timestamp" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_success_timestamp].value
+        value = Witness.instance.pipeline("main").reloads.snitch.last_success_timestamp
         expect(value).to be_a(Timestamp)
       end
 
       it "does not set the last reload error" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_error].value
+        value = Witness.instance.pipeline("main").reloads.error.snitch.backtrace
+        expect(value).to be(nil)
+        value = Witness.instance.pipeline("main").reloads.error.snitch.message
         expect(value).to be(nil)
       end
     end
@@ -425,33 +420,29 @@
       before(:each) { subject.converge_state_and_update }
 
       it "does not increase the successful reload count" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:successes].value
+        value = Witness.instance.pipeline("main").reloads.snitch.successes
         expect(value).to eq(0)
       end
 
       it "does not set the successful reload timestamp" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_success_timestamp].value
+        value = Witness.instance.pipeline("main").reloads.snitch.last_success_timestamp
         expect(value).to be(nil)
       end
 
       it "sets the failure reload timestamp" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_failure_timestamp].value
+        value = Witness.instance.pipeline("main").reloads.snitch.last_failure_timestamp
         expect(value).to be_a(Timestamp)
       end
 
       it "sets the last reload error" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_error].value
-        expect(value).to be_a(Hash)
-        expect(value).to include(:message, :backtrace)
+        value = Witness.instance.pipeline("main").reloads.error.snitch.message
+        expect(value).to_not be_nil
+        value = Witness.instance.pipeline("main").reloads.error.snitch.backtrace
+        expect(value).to_not be_nil
       end
 
       it "increases the failed reload count" do
-        snapshot = subject.metric.collector.snapshot_metric
-        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:failures].value
+        value = Witness.instance.pipeline("main").reloads.snitch.failures
         expect(value).to be > 0
       end
     end
@@ -462,7 +453,6 @@
         {
           "config.reload.automatic" => false,
           "pipeline.batch.size" => 1,
-          "metric.collect" => true,
           "path.config" => config_file
         }
       end
@@ -479,17 +469,13 @@ def register
 
       it "does not increase the successful reload count" do
         expect { subject.converge_state_and_update }.to_not change {
-          snapshot = subject.metric.collector.snapshot_metric
-          reload_metrics = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads]
-          reload_metrics[:successes].value
+          Witness.instance.pipeline("main").reloads.snitch.successes
         }
       end
 
       it "increases the failures reload count" do
         expect { subject.converge_state_and_update }.to change {
-          snapshot = subject.metric.collector.snapshot_metric
-          reload_metrics = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads]
-          reload_metrics[:failures].value
+          Witness.instance.pipeline("main").reloads.snitch.failures
         }.by(1)
       end
     end
diff --git a/logstash-core/spec/logstash/instrument/collector_spec.rb b/logstash-core/spec/logstash/instrument/collector_spec.rb
deleted file mode 100644
index b5c9b3073de..00000000000
--- a/logstash-core/spec/logstash/instrument/collector_spec.rb
+++ /dev/null
@@ -1,53 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/collector"
-require "spec_helper"
-
-describe LogStash::Instrument::Collector do
-  subject { LogStash::Instrument::Collector.new }
-  describe "#push" do
-    let(:namespaces_path) { [:root, :pipelines, :pipelines01] }
-    let(:key) { :my_key }
-
-    context "when the `MetricType` exist" do
-      it "store the metric of type `counter`" do
-        subject.push(namespaces_path, key, :counter, :increment)
-      end
-    end
-
-    context "when the `MetricType` doesn't exist" do
-      let(:wrong_type) { :donotexist }
-
-      it "logs an error but dont crash" do
-        expect(subject.logger).to receive(:error)
-          .with("Collector: Cannot create concrete class for this metric type",
-        hash_including({ :type => wrong_type, :namespaces_path => namespaces_path }))
-
-          subject.push(namespaces_path, key, wrong_type, :increment)
-      end
-    end
-
-    context "when there is a conflict with the metric key" do
-      let(:conflicting_namespaces) { [namespaces_path, key].flatten }
-
-      it "logs an error but dont crash" do
-        subject.push(namespaces_path, key, :counter, :increment)
-
-        expect(subject.logger).to receive(:error)
-          .with("Collector: Cannot record metric",
-          hash_including({ :exception => instance_of(LogStash::Instrument::MetricStore::NamespacesExpectedError) }))
-
-          subject.push(conflicting_namespaces, :random_key, :counter, :increment)
-      end
-    end
-  end
-
-  describe "#snapshot_metric" do
-    it "return a `LogStash::Instrument::MetricStore`" do
-      expect(subject.snapshot_metric).to be_kind_of(LogStash::Instrument::Snapshot)
-    end
-
-    it "returns a clone of the metric store" do
-      expect(subject.snapshot_metric).not_to eq(subject.snapshot_metric)
-    end
-  end
-end
diff --git a/logstash-core/spec/logstash/instrument/metric_spec.rb b/logstash-core/spec/logstash/instrument/metric_spec.rb
deleted file mode 100644
index 123a47be268..00000000000
--- a/logstash-core/spec/logstash/instrument/metric_spec.rb
+++ /dev/null
@@ -1,111 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/metric"
-require "logstash/instrument/collector"
-require_relative "../../support/matchers"
-require "spec_helper"
-
-describe LogStash::Instrument::Metric do
-  let(:collector) { [] }
-  let(:namespace) { :root }
-
-  subject { LogStash::Instrument::Metric.new(collector) }
-
-  context "#increment" do
-    it "a counter by 1" do
-      metric = subject.increment(:root, :error_rate)
-      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :increment, 1)
-    end
-
-    it "a counter by a provided value" do
-      metric = subject.increment(:root, :error_rate, 20)
-      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :increment, 20)
-    end
-
-    it "raises an exception if the key is an empty string" do
-      expect { subject.increment(:root, "", 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
-    end
-
-    it "raise an exception if the key is nil" do
-      expect { subject.increment(:root, nil, 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
-    end
-  end
-
-  context "#decrement" do
-    it "a counter by 1" do
-      metric = subject.decrement(:root, :error_rate)
-      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :decrement, 1)
-    end
-
-    it "a counter by a provided value" do
-      metric = subject.decrement(:root, :error_rate, 20)
-      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :decrement, 20)
-    end
-
-    it "raises an exception if the key is an empty string" do
-      expect { subject.decrement(:root, "", 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
-    end
-
-    it "raise an exception if the key is nil" do
-      expect { subject.decrement(:root, nil, 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
-    end
-  end
-
-  context "#gauge" do
-    it "set the value of a key" do
-      metric = subject.gauge(:root, :size_queue, 20)
-      expect(collector).to be_a_metric_event([:root, :size_queue], :gauge, :set, 20)
-    end
-
-    it "raises an exception if the key is an empty string" do
-      expect { subject.gauge(:root, "", 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
-    end
-
-    it "raise an exception if the key is nil" do
-      expect { subject.gauge(:root, nil, 20) }.to raise_error(LogStash::Instrument::MetricNoKeyProvided)
-    end
-  end
-
-  context "#time" do
-    let(:sleep_time) { 2 }
-    let(:sleep_time_ms) { sleep_time * 1_000 }
-
-    it "records the duration" do
-      subject.time(:root, :duration_ms) { sleep(sleep_time) }
-
-      expect(collector.last).to be_within(sleep_time_ms).of(sleep_time_ms + 5)
-      expect(collector[0]).to match(:root)
-      expect(collector[1]).to be(:duration_ms)
-      expect(collector[2]).to be(:counter)
-    end
-
-    it "returns the value of the executed block" do
-      expect(subject.time(:root, :testing) { "hello" }).to eq("hello")
-    end
-
-    it "return a TimedExecution" do
-      execution = subject.time(:root, :duration_ms)
-      sleep(sleep_time)
-      execution_time = execution.stop
-
-      expect(execution_time).to eq(collector.last)
-      expect(collector.last).to be_within(sleep_time_ms).of(sleep_time_ms + 0.1)
-      expect(collector[0]).to match(:root)
-      expect(collector[1]).to be(:duration_ms)
-      expect(collector[2]).to be(:counter)
-    end
-  end
-
-  context "#namespace" do
-    let(:sub_key) { :my_sub_key }
-
-    it "creates a new metric object and append the `sub_key` to the `base_key`" do
-      expect(subject.namespace(sub_key).namespace_name).to eq([sub_key])
-    end
-
-    it "uses the same collector as the creator class" do
-      child = subject.namespace(sub_key)
-      metric = child.increment(:error_rate)
-      expect(collector).to be_a_metric_event([sub_key, :error_rate], :counter, :increment, 1)
-    end
-  end
-end
diff --git a/logstash-core/spec/logstash/instrument/metric_store_spec.rb b/logstash-core/spec/logstash/instrument/metric_store_spec.rb
deleted file mode 100644
index dac026643cb..00000000000
--- a/logstash-core/spec/logstash/instrument/metric_store_spec.rb
+++ /dev/null
@@ -1,274 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/metric_store"
-
-describe LogStash::Instrument::MetricStore do
-  let(:namespaces) { [ :root, :pipelines, :pipeline_01 ] }
-  let(:key) { :events_in }
-  let(:counter) { LogStash::Instrument::MetricType::Counter.new(namespaces, key) }
-
-  context "when the metric object doesn't exist" do
-    it "store the object" do
-      expect(subject.fetch_or_store(namespaces, key, counter)).to eq(counter)
-    end
-
-    it "support a block as argument" do
-      expect(subject.fetch_or_store(namespaces, key) { counter }).to eq(counter)
-    end
-  end
-
-  context "when the metric object exist in the namespace"  do
-    let(:new_counter) { LogStash::Instrument::MetricType::Counter.new(namespaces, key) }
-
-    it "return the object" do
-      subject.fetch_or_store(namespaces, key, counter)
-      expect(subject.fetch_or_store(namespaces, key, new_counter)).to eq(counter)
-    end
-  end
-
-  context "when the namespace end node isn't a map" do
-    let(:conflicting_namespaces) { [:root, :pipelines, :pipeline_01, :events_in] }
-
-    it "raise an exception" do
-      subject.fetch_or_store(namespaces, key, counter)
-      expect { subject.fetch_or_store(conflicting_namespaces, :new_key, counter) }.to raise_error(LogStash::Instrument::MetricStore::NamespacesExpectedError)
-    end
-  end
-
-  context "retrieving events" do
-    let(:metric_events) {
-      [
-        [[:node, :sashimi, :pipelines, :pipeline01, :plugins, :"logstash-output-elasticsearch"], :event_in, :increment],
-        [[:node, :sashimi, :pipelines, :pipeline01], :processed_events_in, :increment],
-        [[:node, :sashimi, :pipelines, :pipeline01], :processed_events_out, :increment],
-        [[:node, :sashimi, :pipelines, :pipeline02], :processed_events_out, :increment],
-      ]
-    }
-
-    before :each do
-      # Lets add a few metrics in the store before trying to find them
-      metric_events.each do |namespaces, metric_key, action|
-        metric = subject.fetch_or_store(namespaces, metric_key, LogStash::Instrument::MetricType::Counter.new(namespaces, metric_key))
-        metric.execute(action)
-      end
-    end
-
-    context "#has_metric?" do
-      context "when the path exist" do
-        it "returns true" do
-          expect(subject.has_metric?(:node, :sashimi, :pipelines, :pipeline01, :plugins, :"logstash-output-elasticsearch", :event_in)).to be_truthy
-        end
-      end
-
-      context "when the path doesn't exist" do
-        it "returns false" do
-          expect(subject.has_metric?(:node, :sashimi, :pipelines, :pipeline01, :plugins, :"logstash-input-nothing")).to be_falsey
-        end
-      end
-    end
-
-    describe "#get" do
-      context "when the path exist" do
-        it "retrieves end of of a branch" do
-          metrics = subject.get(:node, :sashimi, :pipelines, :pipeline01, :plugins, :"logstash-output-elasticsearch")
-          expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => a_hash_including(:plugins => a_hash_including(:"logstash-output-elasticsearch" => anything)))))))
-        end
-
-        it "retrieves branch" do
-          metrics = subject.get(:node, :sashimi, :pipelines, :pipeline01)
-          expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything)))))
-        end
-
-        it "allow to retrieve a specific metrics" do
-          metrics = subject.get(:node, :sashimi, :pipelines, :pipeline01, :plugins, :"logstash-output-elasticsearch", :event_in)
-          expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => a_hash_including(:plugins => a_hash_including(:"logstash-output-elasticsearch" => a_hash_including(:event_in => be_kind_of(LogStash::Instrument::MetricType::Counter)))))))))
-        end
-
-        context "with filtered keys" do
-          it "allows to retrieve multiple keys on the same level" do
-            metrics = subject.get(:node, :sashimi, :pipelines, :"pipeline01,pipeline02")
-            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything, :pipeline02 => anything)))))
-          end
-
-          it "supports space in the keys" do
-            metrics = subject.get(:node, :sashimi, :pipelines, :"pipeline01, pipeline02 ")
-            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything, :pipeline02 => anything)))))
-          end
-
-          it "retrieves only the requested keys" do
-            metrics = subject.get(:node, :sashimi, :pipelines, :"pipeline01,pipeline02", :processed_events_in)
-            expect(metrics[:node][:sashimi][:pipelines].keys).to include(:pipeline01, :pipeline02)
-          end
-        end
-
-        context "when the path doesnt exist" do
-          it "raise an exception" do
-            expect { subject.get(:node, :sashimi, :dontexist) }.to raise_error(LogStash::Instrument::MetricStore::MetricNotFound, /dontexist/)
-          end
-        end
-      end
-
-      describe "#get_with_path" do
-        context "when the path exist" do
-          it "removes the first `/`" do
-            metrics = subject.get_with_path("/node/sashimi/")
-            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => anything)))
-          end
-
-          it "retrieves end of of a branch" do
-            metrics = subject.get_with_path("node/sashimi/pipelines/pipeline01/plugins/logstash-output-elasticsearch")
-            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => a_hash_including(:plugins => a_hash_including(:"logstash-output-elasticsearch" => anything)))))))
-          end
-
-          it "retrieves branch" do
-            metrics = subject.get_with_path("node/sashimi/pipelines/pipeline01")
-            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything)))))
-          end
-
-          it "allow to retrieve a specific metrics" do
-            metrics = subject.get_with_path("node/sashimi/pipelines/pipeline01/plugins/logstash-output-elasticsearch/event_in")
-            expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => a_hash_including(:plugins => a_hash_including(:"logstash-output-elasticsearch" => a_hash_including(:event_in => be_kind_of(LogStash::Instrument::MetricType::Counter)))))))))
-          end
-
-          context "with filtered keys" do
-            it "allows to retrieve multiple keys on the same level" do
-              metrics = subject.get_with_path("node/sashimi/pipelines/pipeline01,pipeline02/plugins/logstash-output-elasticsearch/event_in")
-              expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything, :pipeline02 => anything)))))
-            end
-
-            it "supports space in the keys" do
-              metrics = subject.get_with_path("node/sashimi/pipelines/pipeline01, pipeline02 /plugins/logstash-output-elasticsearch/event_in")
-              expect(metrics).to match(a_hash_including(:node => a_hash_including(:sashimi => a_hash_including(:pipelines  => a_hash_including(:pipeline01 => anything, :pipeline02 => anything)))))
-            end
-
-            it "retrieves only the requested keys" do
-              metrics = subject.get(:node, :sashimi, :pipelines, :"pipeline01,pipeline02", :processed_events_in)
-              expect(metrics[:node][:sashimi][:pipelines].keys).to include(:pipeline01, :pipeline02)
-            end
-          end
-        end
-      end
-
-      context "when the path doesnt exist" do
-        it "raise an exception" do
-          expect { subject.get_with_path("node/sashimi/dontexist, pipeline02 /plugins/logstash-output-elasticsearch/event_in") }.to raise_error(LogStash::Instrument::MetricStore::MetricNotFound, /dontexist/)
-        end
-      end
-    end
-
-    describe "get_shallow" do
-      it "should retrieve a path as a single value" do
-        r = subject.get_shallow(:node, :sashimi, :pipelines, :pipeline01, :processed_events_in)
-        expect(r.value).to eql(1)
-      end
-    end
-
-    describe "extract_metrics" do
-      it "should retrieve non-nested values correctly" do
-        r = subject.extract_metrics(
-          [:node, :sashimi, :pipelines, :pipeline01],
-          :processed_events_in,
-          :processed_events_out,
-        )
-        expect(r[:processed_events_in]).to eql(1)
-        expect(r[:processed_events_out]).to eql(1)
-      end
-
-      it "should retrieve nested values correctly alongside non-nested ones" do
-        r = subject.extract_metrics(
-          [:node, :sashimi, :pipelines, :pipeline01],
-          :processed_events_in,
-          [:plugins, :"logstash-output-elasticsearch", :event_in]
-        )
-       expect(r[:processed_events_in]).to eql(1)
-        expect(r[:plugins][:"logstash-output-elasticsearch"][:event_in]).to eql(1)
-      end
-
-      it "should retrieve multiple nested keys at a given location" do
-        r = subject.extract_metrics(
-          [:node, :sashimi, :pipelines],
-          [:pipeline01, [:processed_events_in, :processed_events_out]]
-        )
-
-        expect(r[:pipeline01][:processed_events_in]).to eql(1)
-        expect(r[:pipeline01][:processed_events_out]).to eql(1)
-      end
-
-      it "should retrieve a single key nested in multiple places" do
-        r = subject.extract_metrics(
-          [:node, :sashimi, :pipelines],
-          [[:pipeline01, :pipeline02], :processed_events_out]
-        )
-
-        expect(r[:pipeline01][:processed_events_out]).to eql(1)
-        expect(r[:pipeline02][:processed_events_out]).to eql(1)
-      end
-
-      it "handle overlaps of paths" do
-        r = subject.extract_metrics(
-          [:node, :sashimi, :pipelines],
-          [:pipeline01, :processed_events_in],
-          [[:pipeline01, :pipeline02], :processed_events_out]
-        )
-
-        expect(r[:pipeline01][:processed_events_in]).to eql(1)
-        expect(r[:pipeline01][:processed_events_out]).to eql(1)
-        expect(r[:pipeline02][:processed_events_out]).to eql(1)
-      end
-    end
-
-    describe "#size" do
-      it "returns the number of unique metrics" do
-        expect(subject.size).to eq(metric_events.size)
-      end
-    end
-
-    describe "#each" do
-      it "retrieves all the metric" do
-        expect(subject.each.size).to eq(metric_events.size)
-      end
-
-      it "returns metric types" do
-        metrics = []
-        subject.each { |i| metrics << i }
-        expect(metrics.size).to eq(metric_events.size)
-      end
-
-      it "retrieves all the metrics from a specific branch" do
-        metrics = []
-        subject.each("node/sashimi/pipelines/pipeline01") { |i| metrics << i }
-        expect(metrics.size).to eq(3)
-      end
-    end
-  end
-
-  describe "#prune" do
-    let(:metric_events) {
-      [
-        [[:node, :sashimi, :pipelines, :pipeline01, :plugins, :"logstash-output-elasticsearch"], :event_in, :increment],
-        [[:node, :sashimi, :pipelines, :pipeline01], :processed_events_in, :increment],
-        [[:node, :sashimi, :pipelines, :pipeline01], :processed_events_out, :increment],
-        [[:node, :sashimi, :pipelines, :pipeline02], :processed_events_out, :increment],
-      ]
-    }
-
-    before :each do
-      # Lets add a few metrics in the store before trying to find them
-      metric_events.each do |namespaces, metric_key, action|
-        metric = subject.fetch_or_store(namespaces, metric_key, LogStash::Instrument::MetricType::Counter.new(namespaces, metric_key))
-        metric.execute(action)
-      end
-    end
-
-    it "should remove all keys with the same starting path as the argument" do
-      expect(subject.get(:node, :sashimi, :pipelines, :pipeline01)).to be_a(Hash)
-      subject.prune("/node/sashimi/pipelines/pipeline01")
-      expect { subject.get(:node, :sashimi, :pipelines, :pipeline01) }.to raise_error LogStash::Instrument::MetricStore::MetricNotFound
-    end
-
-    it "should keep other metrics on different path branches" do
-      expect(subject.get(:node, :sashimi, :pipelines, :pipeline02)).to be_a(Hash)
-      subject.prune("/node/sashimi/pipelines/pipeline01")
-      expect { subject.get(:node, :sashimi, :pipelines, :pipeline02) }.to_not raise_error
-    end
-  end
-end
diff --git a/logstash-core/spec/logstash/instrument/metric_type/counter_spec.rb b/logstash-core/spec/logstash/instrument/metric_type/counter_spec.rb
deleted file mode 100644
index 82b7c581acc..00000000000
--- a/logstash-core/spec/logstash/instrument/metric_type/counter_spec.rb
+++ /dev/null
@@ -1,23 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/metric_type/counter"
-require "spec_helper"
-
-describe LogStash::Instrument::MetricType::Counter do
-  let(:namespaces) { [:root, :pipelines, :pipeline_01] }
-  let(:key) { :mykey }
-
-  subject { LogStash::Instrument::MetricType::Counter.new(namespaces, key) }
-
-  describe "#increment" do
-    it "increment the counter" do
-      expect{ subject.increment }.to change { subject.value }.by(1)
-    end
-  end
-
-  context "When serializing to JSON" do
-    it "serializes the value" do
-      expect(LogStash::Json.dump(subject)).to eq("0")
-    end
-  end
-
-end
diff --git a/logstash-core/spec/logstash/instrument/metric_type/gauge_spec.rb b/logstash-core/spec/logstash/instrument/metric_type/gauge_spec.rb
deleted file mode 100644
index 69ee278a0e7..00000000000
--- a/logstash-core/spec/logstash/instrument/metric_type/gauge_spec.rb
+++ /dev/null
@@ -1,30 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/metric_type/gauge"
-require "logstash/json"
-require "spec_helper"
-
-describe LogStash::Instrument::MetricType::Gauge do
-  let(:namespaces) { [:root, :pipelines, :pipeline_01] }
-  let(:key) { :mykey }
-  let(:value) { "hello" }
-
-  subject { described_class.new(namespaces, key) }
-
-  before :each do
-    subject.execute(:set, value)
-  end
-
-  describe "#execute" do
-    it "set the value of the gauge" do
-      expect(subject.value).to eq(value)
-    end
-  end
-
-  context "When serializing to JSON" do
-    it "serializes the value" do
-      expect(LogStash::Json.dump(subject)).to eq("\"#{value}\"")
-    end
-  end
-
-
-end
diff --git a/logstash-core/spec/logstash/instrument/namespaced_metric_spec.rb b/logstash-core/spec/logstash/instrument/namespaced_metric_spec.rb
deleted file mode 100644
index b4446afbfce..00000000000
--- a/logstash-core/spec/logstash/instrument/namespaced_metric_spec.rb
+++ /dev/null
@@ -1,92 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/namespaced_metric"
-require "logstash/instrument/metric"
-require_relative "../../support/matchers"
-require_relative "../../support/shared_examples"
-require "spec_helper"
-
-describe LogStash::Instrument::NamespacedMetric do
-  let(:namespace) { :root }
-  let(:collector) { [] }
-  let(:metric) { LogStash::Instrument::Metric.new(collector) }
-
-  subject { described_class.new(metric, namespace) }
-
-  it "defines the same interface as `Metric`" do
-    expect(described_class).to implement_interface_of(LogStash::Instrument::Metric)
-  end
-
-  it "returns a TimedException when we call without a block" do
-    expect(subject.time(:duration_ms)).to be_kind_of(LogStash::Instrument::Metric::TimedExecution)
-  end
-
-  it "returns the value of the block" do
-    expect(subject.time(:duration_ms) { "hello" }).to eq("hello")
-  end
-
-  it "its doesnt change the original `namespace` when creating a subnamespace" do
-    new_namespace = subject.namespace(:wally)
-
-    expect(subject.namespace_name).to eq([namespace])
-    expect(new_namespace.namespace_name).to eq([:root, :wally])
-  end
-
-  context "#increment" do
-    it "a counter by 1" do
-      metric = subject.increment(:error_rate)
-      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :increment, 1)
-    end
-
-    it "a counter by a provided value" do
-      metric = subject.increment(:error_rate, 20)
-      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :increment, 20)
-    end
-  end
-
-  context "#decrement" do
-    it "a counter by 1" do
-      metric = subject.decrement(:error_rate)
-      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :decrement, 1)
-    end
-
-    it "a counter by a provided value" do
-      metric = subject.decrement(:error_rate, 20)
-      expect(collector).to be_a_metric_event([:root, :error_rate], :counter, :decrement, 20)
-    end
-  end
-
-  context "#gauge" do
-    it "set the value of a key" do
-      metric = subject.gauge(:size_queue, 20)
-      expect(collector).to be_a_metric_event([:root, :size_queue], :gauge, :set, 20)
-    end
-  end
-
-  context "#time" do
-    let(:sleep_time) { 2 }
-    let(:sleep_time_ms) { sleep_time * 1_000 }
-
-    it "records the duration" do
-      subject.time(:duration_ms) { sleep(sleep_time) }
-
-      expect(collector.last).to be_within(sleep_time_ms).of(sleep_time_ms + 5)
-      expect(collector[0]).to match([:root])
-      expect(collector[1]).to be(:duration_ms)
-      expect(collector[2]).to be(:counter)
-    end
-
-    it "return a TimedExecution" do
-      execution = subject.time(:duration_ms)
-      sleep(sleep_time)
-      execution_time = execution.stop
-
-      expect(execution_time).to eq(collector.last)
-      expect(collector.last).to be_within(sleep_time_ms).of(sleep_time_ms + 0.1)
-      expect(collector[0]).to match([:root])
-      expect(collector[1]).to be(:duration_ms)
-      expect(collector[2]).to be(:counter)
-    end
-  end
-
-  include_examples "metrics commons operations"
-end
diff --git a/logstash-core/spec/logstash/instrument/namespaced_null_metric_spec.rb b/logstash-core/spec/logstash/instrument/namespaced_null_metric_spec.rb
deleted file mode 100644
index fdd831dfbfc..00000000000
--- a/logstash-core/spec/logstash/instrument/namespaced_null_metric_spec.rb
+++ /dev/null
@@ -1,33 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/namespaced_null_metric"
-require "logstash/instrument/null_metric"
-require_relative "../../support/matchers"
-require "spec_helper"
-
-describe LogStash::Instrument::NamespacedNullMetric do
-  let(:namespace) { :root }
-  let(:collector) { [] }
-  let(:metric) { LogStash::Instrument::NullMetric.new(collector) }
-
-  subject { described_class.new(metric, namespace) }
-
-  it "defines the same interface as `Metric`" do
-    expect(described_class).to implement_interface_of(LogStash::Instrument::NamespacedMetric)
-  end
-
-  it "returns a TimedException when we call without a block" do
-    expect(subject.time(:duration_ms)).to be(LogStash::Instrument::NullMetric::NullTimedExecution)
-  end
-
-  it "returns the value of the block" do
-    expect(subject.time(:duration_ms) { "hello" }).to eq("hello")
-  end
-
-  it "its doesnt change the original `namespace` when creating a subnamespace" do
-    new_namespace = subject.namespace(:wally)
-
-    expect(subject.namespace_name).to eq([namespace])
-    expect(new_namespace.namespace_name).to eq([:root, :wally])
-  end
-
-end
diff --git a/logstash-core/spec/logstash/instrument/null_metric_spec.rb b/logstash-core/spec/logstash/instrument/null_metric_spec.rb
deleted file mode 100644
index 27a861eae69..00000000000
--- a/logstash-core/spec/logstash/instrument/null_metric_spec.rb
+++ /dev/null
@@ -1,23 +0,0 @@
-# encoding: utf-8
-require "logstash/instrument/null_metric"
-require "logstash/instrument/namespaced_metric"
-require_relative "../../support/shared_examples"
-require_relative "../../support/matchers"
-require "spec_helper"
-
-describe LogStash::Instrument::NullMetric do
-
-  let(:key) { "test" }
-  let(:collector) { [] }
-  subject { LogStash::Instrument::NullMetric.new(collector) }
-
-  it "defines the same interface as `Metric`" do
-    expect(described_class).to implement_interface_of(LogStash::Instrument::Metric)
-  end
-
-  describe "#namespace" do
-    it "return a NamespacedNullMetric" do
-      expect(subject.namespace(key)).to be_kind_of LogStash::Instrument::NamespacedNullMetric
-    end
-  end
-end
