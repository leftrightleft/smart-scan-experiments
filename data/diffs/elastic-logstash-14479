diff --git a/logstash-core/lib/logstash/api/commands/stats.rb b/logstash-core/lib/logstash/api/commands/stats.rb
index 4c52857b3bd..45a4d63b42b 100644
--- a/logstash-core/lib/logstash/api/commands/stats.rb
+++ b/logstash-core/lib/logstash/api/commands/stats.rb
@@ -81,6 +81,16 @@ def events
           {}
         end
 
+        def flow
+          extract_metrics(
+            [:stats, :flow],
+            :concurrency
+          )
+        rescue LogStash::Instrument::MetricStore::MetricNotFound
+          # if the stats/events metrics have not yet been populated, return an empty map
+          {}
+        end
+
         def pipeline(pipeline_id = nil, opts={})
           extended_stats = LogStash::Config::PipelinesInfo.format_pipelines_info(
             service.agent,
@@ -165,6 +175,7 @@ def plugin_stats(stats, plugin_type)
           def report(stats, extended_stats=nil, opts={})
             ret = {
               :events => stats[:events],
+              :flow => stats[:flow],
               :plugins => {
                 :inputs => plugin_stats(stats, :inputs),
                 :codecs => plugin_stats(stats, :codecs),
diff --git a/logstash-core/lib/logstash/api/modules/node_stats.rb b/logstash-core/lib/logstash/api/modules/node_stats.rb
index 5f1ffae2ba2..2bd017458fc 100644
--- a/logstash-core/lib/logstash/api/modules/node_stats.rb
+++ b/logstash-core/lib/logstash/api/modules/node_stats.rb
@@ -35,6 +35,7 @@ class NodeStats < ::LogStash::Api::Modules::Base
             :jvm => jvm_payload,
             :process => process_payload,
             :events => events_payload,
+            :flow => flow_payload,
             :pipelines => pipeline_payload,
             :reloads => reloads_payload,
             :os => os_payload,
@@ -61,6 +62,10 @@ def events_payload
           @stats.events
         end
 
+        def flow_payload
+          @stats.flow
+        end
+
         def jvm_payload
           @stats.jvm
         end
diff --git a/logstash-core/lib/logstash/config/pipelines_info.rb b/logstash-core/lib/logstash/config/pipelines_info.rb
index ce38306c1b8..c72eef6d690 100644
--- a/logstash-core/lib/logstash/config/pipelines_info.rb
+++ b/logstash-core/lib/logstash/config/pipelines_info.rb
@@ -21,6 +21,7 @@ def self.format_pipelines_info(agent, metric_store, extended_performance_collect
       # It is important that we iterate via the agent's pipelines vs. the
       # metrics pipelines. This prevents race conditions as pipeline stats may be
       # populated before the agent has it in its own pipelines state
+      # TODO: analyze/investigate if we are okay to use metric store
       stats = metric_store.get_with_path("/stats/pipelines").dig(:stats, :pipelines) || {}
       agent.running_pipelines.map do |pipeline_id, pipeline|
         p_stats = stats.fetch(pipeline_id) { Hash.new }
@@ -33,6 +34,7 @@ def self.format_pipelines_info(agent, metric_store, extended_performance_collect
           "hash" => pipeline.lir.unique_hash,
           "ephemeral_id" => pipeline.ephemeral_id,
           "events" => format_pipeline_events(p_stats[:events]),
+          "flow" => format_pipeline_flow(p_stats[:flow]),
           "queue" => format_queue_stats(pipeline_id, metric_store),
           "reloads" => {
             "successes" => (p_stats.dig(:reloads, :successes)&.value || 0),
@@ -46,6 +48,20 @@ def self.format_pipelines_info(agent, metric_store, extended_performance_collect
       end.compact
     end
 
+    def self.format_pipeline_flow(stats, result = {})
+      (stats || {}).each do |stage, counter|
+        if counter.class.eql?(Hash)
+          result[stage.to_s] = {}
+          (counter || {}).each do |key, value|
+            result[stage.to_s] = format_pipeline_flow(counter, result[stage.to_s])
+          end
+        else
+          result[stage.to_s] = counter.value
+        end
+      end
+      result
+    end
+
     def self.format_pipeline_events(stats)
       result = {}
       (stats || {}).each { |stage, counter| result[stage.to_s] = counter.value }
diff --git a/logstash-core/lib/logstash/instrument/periodic_poller/flow_rate.rb b/logstash-core/lib/logstash/instrument/periodic_poller/flow_rate.rb
new file mode 100644
index 00000000000..b4f5dfe19b1
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/periodic_poller/flow_rate.rb
@@ -0,0 +1,38 @@
+# Licensed to Elasticsearch B.V. under one or more contributor
+# license agreements. See the NOTICE file distributed with
+# this work for additional information regarding copyright
+# ownership. Elasticsearch B.V. licenses this file to you under
+# the Apache License, Version 2.0 (the "License"); you may
+# not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#  http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+
+require 'logstash/instrument/periodic_poller/base'
+
+module LogStash module Instrument module PeriodicPoller
+  class FlowRate < Base
+    def initialize(metric, agent, options = {})
+      super(metric, options)
+      @metric = metric
+      @agent = agent
+    end
+
+    def collect
+      pipelines = @agent.running_user_defined_pipelines
+      pipelines.each do |_, pipeline|
+        unless pipeline.nil?
+          pipeline.collect_pipeline_flow_rates
+          pipeline.store_pipeline_flow_rates
+        end
+      end
+    end
+  end
+end end end
diff --git a/logstash-core/lib/logstash/instrument/periodic_pollers.rb b/logstash-core/lib/logstash/instrument/periodic_pollers.rb
index 345dc7c3d6d..2fae2629f3a 100644
--- a/logstash-core/lib/logstash/instrument/periodic_pollers.rb
+++ b/logstash-core/lib/logstash/instrument/periodic_pollers.rb
@@ -19,6 +19,7 @@
 require "logstash/instrument/periodic_poller/os"
 require "logstash/instrument/periodic_poller/jvm"
 require "logstash/instrument/periodic_poller/pq"
+require "logstash/instrument/periodic_poller/flow_rate"
 
 module LogStash module Instrument
   # Each PeriodPoller manager his own thread to do the poller
@@ -32,7 +33,8 @@ def initialize(metric, queue_type, agent)
       @periodic_pollers = [PeriodicPoller::Os.new(metric),
                            PeriodicPoller::JVM.new(metric),
                            PeriodicPoller::PersistentQueue.new(metric, queue_type, agent),
-                           PeriodicPoller::DeadLetterQueue.new(metric, agent)]
+                           PeriodicPoller::DeadLetterQueue.new(metric, agent),
+                           PeriodicPoller::FlowRate.new(metric, agent)]
     end
 
     def start
diff --git a/logstash-core/lib/logstash/java_pipeline.rb b/logstash-core/lib/logstash/java_pipeline.rb
index 04063782faa..2b230c7cdee 100644
--- a/logstash-core/lib/logstash/java_pipeline.rb
+++ b/logstash-core/lib/logstash/java_pipeline.rb
@@ -121,6 +121,7 @@ def start
     # this is useful in the context of pipeline reloading
     collect_stats
     collect_dlq_stats
+    register_pipeline_flow_rates
 
     @logger.debug("Starting pipeline", default_logging_keys)
 
@@ -533,6 +534,7 @@ def clear_pipeline_metrics
       # we want to keep other metrics like reload counts and error messages
       collector.clear("stats/pipelines/#{pipeline_id}/plugins")
       collector.clear("stats/pipelines/#{pipeline_id}/events")
+      collector.clear("stats/pipelines/#{pipeline_id}/flow")
     end
   end
 
diff --git a/logstash-core/src/main/java/org/logstash/RubyUtil.java b/logstash-core/src/main/java/org/logstash/RubyUtil.java
index abf86480298..9d5b6cc4967 100644
--- a/logstash-core/src/main/java/org/logstash/RubyUtil.java
+++ b/logstash-core/src/main/java/org/logstash/RubyUtil.java
@@ -657,4 +657,12 @@ public static <T extends IRubyObject> T nilSafeCast(final IRubyObject objectOrNi
 
         return objectAsCasted;
     }
+
+    public static IRubyObject toSymbolArray(final String... strings) {
+        final IRubyObject[] res = new IRubyObject[strings.length];
+        for (int i = 0; i < strings.length; ++i) {
+            res[i] = RubyUtil.RUBY.newSymbol(strings[i]);
+        }
+        return RubyUtil.RUBY.newArray(res);
+    }
 }
diff --git a/logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java b/logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java
index ece0df7b7c2..bbed0597478 100644
--- a/logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java
+++ b/logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java
@@ -32,6 +32,7 @@
 import java.time.Duration;
 import java.util.Arrays;
 import java.util.List;
+import java.util.Objects;
 import java.util.UUID;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
@@ -110,12 +111,6 @@ public class AbstractPipelineExt extends RubyBasicObject {
 
     private static final RubySymbol PATH = RubyUtil.RUBY.newSymbol("path");
 
-    private static final RubySymbol TYPE_KEY = RubyUtil.RUBY.newSymbol("type");
-
-    private static final RubySymbol QUEUE_KEY = RubyUtil.RUBY.newSymbol("queue");
-
-    private static final RubySymbol DLQ_KEY = RubyUtil.RUBY.newSymbol("dlq");
-
     private static final RubySymbol STORAGE_POLICY =
             RubyUtil.RUBY.newSymbol("storage_policy");
 
@@ -215,7 +210,7 @@ public final AbstractPipelineExt initialize(final ThreadContext context,
     }
 
     /**
-     * queue opening needs to happen out of the the initialize method because the
+     * queue opening needs to happen out of the initialize method because the
      * AbstractPipeline is used for pipeline config validation and the queue
      * should not be opened for this. This should be called only in the actual
      * Pipeline/JavaPipeline initialisation.
@@ -412,10 +407,11 @@ public final IRubyObject collectStats(final ThreadContext context) throws IOExce
             context,
             RubyArray.newArray(
                 context.runtime,
-                Arrays.asList(MetricKeys.STATS_KEY, MetricKeys.PIPELINES_KEY, pipelineId.asString().intern(), QUEUE_KEY)
+                Arrays.asList(MetricKeys.STATS_KEY, MetricKeys.PIPELINES_KEY,
+                        pipelineId.asString().intern(), MetricKeys.QUEUE_KEY)
             )
         );
-        pipelineMetric.gauge(context, TYPE_KEY, getSetting(context, "queue.type"));
+        pipelineMetric.gauge(context, MetricKeys.TYPE_KEY, getSetting(context, "queue.type"));
         if (queue instanceof JRubyWrappedAckedQueueExt) {
             final JRubyAckedQueueExt inner = ((JRubyWrappedAckedQueueExt) queue).rubyGetQueue();
             final RubyString dirPath = inner.ruby_dir_path(context);
@@ -520,17 +516,19 @@ protected SecretStore getSecretStore(final ThreadContext context) {
     }
 
     private AbstractNamespacedMetricExt getDlqMetric(final ThreadContext context) {
-        if (dlqMetric == null) {
-            dlqMetric = metric.namespace(
-                context, RubyArray.newArray(
-                    context.runtime,
-                    Arrays.asList(
-                        MetricKeys.STATS_KEY, MetricKeys.PIPELINES_KEY,
-                        pipelineId.asString().intern(), DLQ_KEY
-                    )
-                )
-            );
+        if (Objects.isNull(dlqMetric)) {
+            dlqMetric = getMetric(context,
+                    MetricKeys.STATS_KEY, MetricKeys.PIPELINES_KEY,
+                    pipelineId.asString().intern(), MetricKeys.DLQ_KEY);
         }
         return dlqMetric;
     }
+
+    protected AbstractNamespacedMetricExt getMetric(final ThreadContext context,
+                                                  final IRubyObject... keys) {
+        return metric().namespace(context,
+                RubyArray.newArray(
+                        context.runtime,
+                        Arrays.asList(keys)));
+    }
 }
diff --git a/logstash-core/src/main/java/org/logstash/execution/JavaBasePipelineExt.java b/logstash-core/src/main/java/org/logstash/execution/JavaBasePipelineExt.java
index 1be5781862c..39e777365d0 100644
--- a/logstash-core/src/main/java/org/logstash/execution/JavaBasePipelineExt.java
+++ b/logstash-core/src/main/java/org/logstash/execution/JavaBasePipelineExt.java
@@ -26,6 +26,7 @@
 import org.jruby.RubyArray;
 import org.jruby.RubyBoolean;
 import org.jruby.RubyClass;
+import org.jruby.RubySymbol;
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;
 import org.jruby.javasupport.JavaUtil;
@@ -36,12 +37,25 @@
 import org.logstash.config.ir.CompiledPipeline;
 import org.logstash.execution.queue.QueueWriter;
 import org.logstash.ext.JRubyWrappedWriteClientExt;
+import org.logstash.instrument.metrics.AbstractNamespacedMetricExt;
+import org.logstash.instrument.metrics.FlowMetric;
+import org.logstash.instrument.metrics.MetricKeys;
+import org.logstash.instrument.metrics.UptimeMetric;
+import org.logstash.instrument.metrics.counter.LongCounter;
 import org.logstash.plugins.factory.ExecutionContextFactoryExt;
 import org.logstash.plugins.factory.PluginMetricsFactoryExt;
 import org.logstash.plugins.factory.PluginFactoryExt;
 
 import java.security.NoSuchAlgorithmException;
+import java.time.temporal.ChronoUnit;
+import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.Objects;
 import java.util.stream.Stream;
 
 /**
@@ -62,6 +76,12 @@ public final class JavaBasePipelineExt extends AbstractPipelineExt {
 
     private @SuppressWarnings("rawtypes") RubyArray outputs;
 
+    private Map<RubySymbol, FlowMetric> flowMetrics;
+
+    private AbstractNamespacedMetricExt eventsMetric;
+
+    private AbstractNamespacedMetricExt flowMetric;
+
     public JavaBasePipelineExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);
     }
@@ -147,6 +167,58 @@ public IRubyObject isShutdownRequested(final ThreadContext context) {
         throw new IllegalStateException("Pipeline implementation does not provide `shutdown_requested?`, which is a Logstash internal error.");
     }
 
+    @JRubyMethod(name = "register_pipeline_flow_rates")
+    public IRubyObject registerPipelineFlowRatesMetric(final ThreadContext context) {
+        UptimeMetric uptimeMetric = new UptimeMetric(pipelineId().asJavaString() + ".uptime_in_millis", ChronoUnit.MILLIS);
+        // TODO: generate and add all target metrics
+        Map<RubySymbol, FlowMetric> metricMap = new HashMap<>();
+        Arrays.asList(MetricKeys.FLOW_KEYS).forEach(key -> {
+            if (MetricKeys.CONCURRENCY_KEY.eql(key)) {
+
+            } else if (MetricKeys.INPUT_THROUGHPUT_KEY.eql(key)) {
+                metricMap.put(key, createFlowMetric(context, MetricKeys.IN_KEY, uptimeMetric));
+            } else if (MetricKeys.FILTER_THROUGHPUT_KEY.eql(key)) {
+                metricMap.put(key, createFlowMetric(context, MetricKeys.FILTERED_KEY, uptimeMetric));
+            } else if (MetricKeys.OUTPUT_THROUGHPUT_KEY.eql(key)) {
+                metricMap.put(key, createFlowMetric(context, MetricKeys.OUT_KEY, uptimeMetric));
+            } else if (MetricKeys.BACKPRESSURE_KEY.eql(key)) {
+
+            }
+        });
+        flowMetrics = Map.copyOf(metricMap);
+        return context.nil;
+    }
+
+    @JRubyMethod(name = "collect_pipeline_flow_rates")
+    public IRubyObject collectPipelineFlowRates(final ThreadContext context) {
+        for (RubySymbol key : flowMetrics.keySet()) {
+            flowMetrics.get(key).capture();
+        }
+        return context.nil;
+    }
+
+    @JRubyMethod(name = "store_pipeline_flow_rates")
+    public IRubyObject fetchPipelineFlowRates(final ThreadContext context) {
+        if (Objects.isNull(flowMetric)) {
+            flowMetric = getMetric(context,
+                    MetricKeys.STATS_KEY, MetricKeys.PIPELINES_KEY,
+                    pipelineId().asString().intern(), MetricKeys.FLOW_KEY);
+        }
+
+        for (RubySymbol key : flowMetrics.keySet()) {
+            final AbstractNamespacedMetricExt metric = flowMetric.namespace(
+                    context, RubyArray.newArray(context.runtime, key));
+            Map<String, Double> rates = flowMetrics.get(key).getAvailableRates();
+            System.out.println("Available rates, size: " + rates.size());
+            rates.forEach((rateKey, value) -> {
+                System.out.println("[Rates] Name: " + key + ", rate: " + value);
+                metric.gauge(context, RubyUtil.RUBY.newSymbol(rateKey), context.runtime.newFloat(value));
+            });
+        }
+
+        return context.nil;
+    }
+
     public QueueWriter getQueueWriter(final String inputName) {
         return new JRubyWrappedWriteClientExt(RubyUtil.RUBY, RubyUtil.WRAPPED_WRITE_CLIENT_CLASS)
             .initialize(
@@ -157,4 +229,16 @@ public QueueWriter getQueueWriter(final String inputName) {
                 }
             );
     }
+
+    private FlowMetric createFlowMetric(final ThreadContext context,
+                               final RubySymbol metricKey,
+                               final UptimeMetric uptimeMetric) {
+        if (Objects.isNull(eventsMetric)) {
+            eventsMetric = getMetric(context,
+                    MetricKeys.STATS_KEY, MetricKeys.PIPELINES_KEY, pipelineId(), MetricKeys.EVENTS_KEY);
+        }
+
+        LongCounter inMetric = LongCounter.fromRubyBase(eventsMetric, metricKey);
+        return new FlowMetric(inMetric, uptimeMetric);
+    }
 }
diff --git a/logstash-core/src/main/java/org/logstash/ext/JRubyWrappedWriteClientExt.java b/logstash-core/src/main/java/org/logstash/ext/JRubyWrappedWriteClientExt.java
index 0c850e1964c..b5e87a029fe 100644
--- a/logstash-core/src/main/java/org/logstash/ext/JRubyWrappedWriteClientExt.java
+++ b/logstash-core/src/main/java/org/logstash/ext/JRubyWrappedWriteClientExt.java
@@ -146,15 +146,7 @@ private void incrementTimers(final long start) {
 
     private static AbstractNamespacedMetricExt getMetric(final AbstractMetricExt base,
         final String... keys) {
-        return base.namespace(RubyUtil.RUBY.getCurrentContext(), toSymbolArray(keys));
-    }
-
-    private static IRubyObject toSymbolArray(final String... strings) {
-        final IRubyObject[] res = new IRubyObject[strings.length];
-        for (int i = 0; i < strings.length; ++i) {
-            res[i] = RubyUtil.RUBY.newSymbol(strings[i]);
-        }
-        return RubyUtil.RUBY.newArray(res);
+        return base.namespace(RubyUtil.RUBY.getCurrentContext(), RubyUtil.toSymbolArray(keys));
     }
 
     @Override
diff --git a/logstash-core/src/main/java/org/logstash/instrument/metrics/FlowMetric.java b/logstash-core/src/main/java/org/logstash/instrument/metrics/FlowMetric.java
new file mode 100644
index 00000000000..0d48f3e186c
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/instrument/metrics/FlowMetric.java
@@ -0,0 +1,78 @@
+package org.logstash.instrument.metrics;
+
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Objects;
+import java.util.concurrent.atomic.AtomicReference;
+
+public class FlowMetric {
+
+    // metric sources
+    private final Metric<? extends Number> numeratorMetric;
+    private final Metric<? extends Number> denominatorMetric;
+
+    // useful capture nodes for calculation
+    private final Capture baseline;
+
+    private final AtomicReference<Capture> head;
+    private final AtomicReference<Capture> instant = new AtomicReference<>();
+
+    public FlowMetric(final Metric<? extends Number> numeratorMetric, final Metric<? extends Number> denominatorMetric) {
+        this.numeratorMetric = numeratorMetric;
+        this.denominatorMetric = denominatorMetric;
+
+        this.baseline = doCapture();
+        this.head = new AtomicReference<>(this.baseline);
+    }
+
+    public void capture() {
+        final Capture previousHead = head.getAndSet(doCapture());
+        instant.set(previousHead);
+    }
+
+    public Map<String,Double> getAvailableRates() {
+        final Capture headCapture = head.get();
+        if (Objects.isNull(headCapture)) {
+            return Map.of();
+        }
+
+        final Map<String, Double> rates = new HashMap<>();
+
+        final Double lifetimeRate = headCapture.calculateRate(baseline);
+        if (Objects.nonNull(lifetimeRate)) {
+            rates.put("lifetime", lifetimeRate);
+        }
+
+        final Capture instantCapture = instant.get();
+        final Double currentRate = headCapture.calculateRate(instantCapture);
+        if (Objects.nonNull(currentRate)) {
+            rates.put("current", currentRate);
+        }
+
+        return Map.copyOf(rates);
+    }
+
+    Capture doCapture() {
+        return new Capture(numeratorMetric.getValue(), denominatorMetric.getValue());
+    }
+
+    private static class Capture {
+        private final Number numerator;
+        private final Number denominator;
+
+        public Capture(final Number numerator, final Number denominator) {
+            this.numerator = numerator;
+            this.denominator = denominator;
+        }
+
+        Double calculateRate(final Capture baseline) {
+            if (Objects.isNull(baseline)) { return null; }
+            if (baseline == this) { return null; }
+
+            final double deltaNumerator = this.numerator.doubleValue() - baseline.numerator.doubleValue();
+            final double deltaDenominator = this.denominator.doubleValue() - baseline.denominator.doubleValue();
+
+            return deltaNumerator / deltaDenominator;
+        }
+    }
+}
\ No newline at end of file
diff --git a/logstash-core/src/main/java/org/logstash/instrument/metrics/ManualAdvanceClock.java b/logstash-core/src/main/java/org/logstash/instrument/metrics/ManualAdvanceClock.java
new file mode 100644
index 00000000000..93137739704
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/instrument/metrics/ManualAdvanceClock.java
@@ -0,0 +1,51 @@
+package org.logstash.instrument.metrics;
+
+import java.time.Clock;
+import java.time.Duration;
+import java.time.Instant;
+import java.time.ZoneId;
+import java.util.Objects;
+import java.util.concurrent.atomic.AtomicReference;
+
+class ManualAdvanceClock extends Clock {
+    private final ZoneId zoneId;
+    private final AtomicReference<Instant> currentInstant;
+
+    public ManualAdvanceClock(final Instant currentInstant, final ZoneId zoneId) {
+        this(new AtomicReference<>(currentInstant), zoneId);
+    }
+
+    public ManualAdvanceClock(final Instant currentInstant) {
+        this(currentInstant, null);
+    }
+
+    private ManualAdvanceClock(final AtomicReference<Instant> currentInstant, final ZoneId zoneId) {
+        this.currentInstant = currentInstant;
+        this.zoneId = Objects.requireNonNullElseGet(zoneId, ZoneId::systemDefault);
+    }
+
+    @Override
+    public ZoneId getZone() {
+        return this.zoneId;
+    }
+
+    @Override
+    public Clock withZone(ZoneId zone) {
+        return new ManualAdvanceClock(this.currentInstant, zone);
+    }
+
+    @Override
+    public Instant instant() {
+        return currentInstant.get();
+    }
+
+    public void advance(final Duration duration) {
+        if (duration.isZero()) {
+            return;
+        }
+        if (duration.isNegative()) {
+            throw new IllegalArgumentException("duration must not be negative");
+        }
+        this.currentInstant.updateAndGet(previous -> previous.plus(duration));
+    }
+}
\ No newline at end of file
diff --git a/logstash-core/src/main/java/org/logstash/instrument/metrics/MetricKeys.java b/logstash-core/src/main/java/org/logstash/instrument/metrics/MetricKeys.java
index eb7b6fcc1d2..4d82651712c 100644
--- a/logstash-core/src/main/java/org/logstash/instrument/metrics/MetricKeys.java
+++ b/logstash-core/src/main/java/org/logstash/instrument/metrics/MetricKeys.java
@@ -45,4 +45,24 @@ private MetricKeys() {
     public static final RubySymbol FILTERED_KEY = RubyUtil.RUBY.newSymbol("filtered");
 
     public static final RubySymbol STATS_KEY = RubyUtil.RUBY.newSymbol("stats");
+
+    public static final RubySymbol TYPE_KEY = RubyUtil.RUBY.newSymbol("type");
+
+    public static final RubySymbol QUEUE_KEY = RubyUtil.RUBY.newSymbol("queue");
+
+    public static final RubySymbol DLQ_KEY = RubyUtil.RUBY.newSymbol("dlq");
+
+    public static final RubySymbol FLOW_KEY = RubyUtil.RUBY.newSymbol("flow");
+
+    public static final RubySymbol CONCURRENCY_KEY = RubyUtil.RUBY.newSymbol("concurrency");
+
+    public static final RubySymbol INPUT_THROUGHPUT_KEY = RubyUtil.RUBY.newSymbol("input_throughput");
+
+    public static final RubySymbol FILTER_THROUGHPUT_KEY = RubyUtil.RUBY.newSymbol("filter_throughput");
+
+    public static final RubySymbol OUTPUT_THROUGHPUT_KEY = RubyUtil.RUBY.newSymbol("output_throughput");
+
+    public static final RubySymbol BACKPRESSURE_KEY = RubyUtil.RUBY.newSymbol("backpressure");
+
+    public static final RubySymbol[] FLOW_KEYS = { CONCURRENCY_KEY, INPUT_THROUGHPUT_KEY, FILTER_THROUGHPUT_KEY, OUTPUT_THROUGHPUT_KEY, BACKPRESSURE_KEY };
 }
diff --git a/logstash-core/src/main/java/org/logstash/instrument/metrics/UptimeMetric.java b/logstash-core/src/main/java/org/logstash/instrument/metrics/UptimeMetric.java
new file mode 100644
index 00000000000..aa1bc902828
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/instrument/metrics/UptimeMetric.java
@@ -0,0 +1,83 @@
+package org.logstash.instrument.metrics;
+
+import java.time.Clock;
+import java.time.Instant;
+import java.time.temporal.ChronoUnit;
+import java.time.temporal.TemporalUnit;
+import java.util.Objects;
+
+/**
+ * The {@link UptimeMetric} is an auto-advancing {@link Metric} whose value
+ * represents the amount of time since instantiation. It can be made to track the
+ * advancement of the clock in one of several {@link TemporalUnit}s.
+ */
+public class UptimeMetric extends AbstractMetric<Long> {
+    private final Clock clock;
+    private final Instant startInstant;
+
+    private final TemporalUnit temporalUnit;
+
+    /**
+     * Constructs an {@link UptimeMetric} whose name is "uptime_in_millis" and whose units are milliseconds
+     */
+    public UptimeMetric() {
+        this("uptime_in_millis", ChronoUnit.MILLIS);
+    }
+
+    /**
+     * Constructs an {@link UptimeMetric} with the provided name and units.
+     * @param name the name of the metric, which is used by our metric store, API retrieval, etc.
+     * @param temporalUnit the units in which to keep track of uptime (millis, seconds, etc.)
+     */
+    public UptimeMetric(final String name, final TemporalUnit temporalUnit) {
+        this(name, temporalUnit, Clock.systemUTC());
+    }
+
+    UptimeMetric(final String name, final TemporalUnit temporalUnit, final Clock clock) {
+        this(name, temporalUnit, clock, clock.instant());
+    }
+
+    UptimeMetric(final String name, final TemporalUnit temporalUnit, final Clock clock, final Instant startInstant) {
+        super(Objects.requireNonNull(name, "name"));
+        this.clock = Objects.requireNonNull(clock, "clock");
+        this.temporalUnit = Objects.requireNonNull(temporalUnit, "temporalUnit");
+        this.startInstant = Objects.requireNonNull(startInstant, "startInstant");
+    }
+
+    /**
+     * @return the number of {@link TemporalUnit}s that have elapsed
+     *         since this {@link UptimeMetric} was instantiated
+     */
+    @Override
+    public Long getValue() {
+        return this.startInstant.until(this.clock.instant(), temporalUnit);
+    }
+
+    /**
+     * @return the {@link MetricType}{@code .COUNTER_LONG} associated with
+     *         long-valued metrics that only-increment, for use in Monitoring data structuring.
+     */
+    @Override
+    public MetricType getType() {
+        return MetricType.COUNTER_LONG;
+    }
+
+    /**
+     * @return the {@link TemporalUnit} associated with this {@link UptimeMetric}.
+     */
+    public TemporalUnit getTemporalUnit() {
+        return temporalUnit;
+    }
+
+    /**
+     * Constructs a _copy_ of this {@link UptimeMetric} with a new name and temporalUnit, but whose
+     * uptime is tracking from the same instant as this instance.
+     *
+     * @param name the new metric's name (typically includes units)
+     * @param temporalUnit the new metric's units
+     * @return a _copy_ of this {@link UptimeMetric}.
+     */
+    public UptimeMetric withTemporalUnit(final String name, final TemporalUnit temporalUnit) {
+        return new UptimeMetric(name, temporalUnit, this.clock, this.startInstant);
+    }
+}
\ No newline at end of file
