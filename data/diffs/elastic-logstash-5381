diff --git a/logstash-core/lib/logstash/agent.rb b/logstash-core/lib/logstash/agent.rb
index 21fa2196e03..be846734486 100644
--- a/logstash-core/lib/logstash/agent.rb
+++ b/logstash-core/lib/logstash/agent.rb
@@ -46,7 +46,6 @@ def initialize(settings = LogStash::SETTINGS)
 
     @collect_metric = setting("metric.collect")
 
-
     # Create the collectors and configured it with the library
     configure_metrics_collectors
   end
diff --git a/logstash-core/lib/logstash/api/command_factory.rb b/logstash-core/lib/logstash/api/command_factory.rb
index df26ccad546..4de019a186d 100644
--- a/logstash-core/lib/logstash/api/command_factory.rb
+++ b/logstash-core/lib/logstash/api/command_factory.rb
@@ -3,6 +3,7 @@
 require "logstash/api/commands/system/basicinfo_command"
 require "logstash/api/commands/system/plugins_command"
 require "logstash/api/commands/stats"
+require "logstash/api/commands/node"
 
 
 module LogStash
@@ -15,7 +16,8 @@ def initialize(service)
         @factory = {
           :system_basic_info => ::LogStash::Api::Commands::System::BasicInfo,
           :plugins_command => ::LogStash::Api::Commands::System::Plugins,
-          :stats => ::LogStash::Api::Commands::Stats
+          :stats => ::LogStash::Api::Commands::Stats,
+          :node => ::LogStash::Api::Commands::Node
         }
       end
 
diff --git a/logstash-core/lib/logstash/api/commands/base.rb b/logstash-core/lib/logstash/api/commands/base.rb
index 1ca1d879832..c2fd22a05a4 100644
--- a/logstash-core/lib/logstash/api/commands/base.rb
+++ b/logstash-core/lib/logstash/api/commands/base.rb
@@ -19,6 +19,10 @@ def uptime
         def started_at
           (LogStash::Agent::STARTED_AT.to_f * 1000.0).to_i
         end
+
+        def extract_metrics(path, *keys)
+          service.extract_metrics(path, *keys)
+        end
       end
     end
   end
diff --git a/logstash-core/lib/logstash/api/commands/node.rb b/logstash-core/lib/logstash/api/commands/node.rb
new file mode 100644
index 00000000000..cc74e0bb82b
--- /dev/null
+++ b/logstash-core/lib/logstash/api/commands/node.rb
@@ -0,0 +1,116 @@
+require "logstash/api/commands/base"
+
+module LogStash
+  module Api
+    module Commands
+      class Node < Commands::Base
+        def all
+          {
+            :pipeline => pipeline,
+            :os => os,
+            :jvm => jvm
+          }           
+        end
+        
+        def pipeline
+          extract_metrics(
+            [:stats, :pipelines, :main, :config],
+            :workers, :batch_size, :batch_delay
+          )
+        end
+
+        def os
+          {
+            :name => java.lang.System.getProperty("os.name"),
+            :arch => java.lang.System.getProperty("os.arch"),
+            :version => java.lang.System.getProperty("os.version"),
+            :available_processors => java.lang.Runtime.getRuntime().availableProcessors()
+          }
+        end
+
+        def jvm
+          memory_bean = ManagementFactory.getMemoryMXBean()
+          {
+            :pid =>  ManagementFactory.getRuntimeMXBean().getName().split("@").first.to_i,
+            :version => java.lang.System.getProperty("java.version"),
+            :vm_name => java.lang.System.getProperty("java.vm.name"),
+            :vm_version => java.lang.System.getProperty("java.version"),
+            :vm_vendor => java.lang.System.getProperty("java.vendor"),
+            :vm_name => java.lang.System.getProperty("java.vm.name"),            
+            :start_time_in_millis => started_at,
+            :mem => {
+              :heap_init_in_bytes => (memory_bean.getHeapMemoryUsage().getInit() < 0 ? 0 : memory_bean.getHeapMemoryUsage().getInit()),
+              :heap_max_in_bytes => (memory_bean.getHeapMemoryUsage().getMax() < 0 ? 0 : memory_bean.getHeapMemoryUsage().getMax()),
+              :non_heap_init_in_bytes => (memory_bean.getNonHeapMemoryUsage().getInit() < 0 ? 0 : memory_bean.getNonHeapMemoryUsage().getInit()),
+              :non_heap_max_in_bytes => (memory_bean.getNonHeapMemoryUsage().getMax() < 0 ? 0 : memory_bean.getNonHeapMemoryUsage().getMax())
+            }
+          }
+        end
+
+        def hot_threads(options={})
+          HotThreadsReport.new(self, options)
+        end
+
+        class HotThreadsReport
+          HOT_THREADS_STACK_TRACES_SIZE_DEFAULT = 10.freeze
+          
+          def initialize(cmd, options)
+            @cmd = cmd
+            filter = { :stacktrace_size => options.fetch(:stacktrace_size, HOT_THREADS_STACK_TRACES_SIZE_DEFAULT) }
+            jr_dump = JRMonitor.threads.generate(filter)
+            @thread_dump = ::LogStash::Util::ThreadDump.new(options.merge(:dump => jr_dump))
+          end
+          
+          def to_s
+            hash = to_hash
+            report =  "#{I18n.t("logstash.web_api.hot_threads.title", :hostname => hash[:hostname], :time => hash[:time], :top_count => @thread_dump.top_count )} \n"
+            report << '=' * 80
+            report << "\n"
+            hash[:threads].each do |thread|
+              thread_report = ""
+              thread_report = "#{I18n.t("logstash.web_api.
+                                hot_threads.thread_title", :percent_of_cpu_time => thread[:percent_of_cpu_time], :thread_state => thread[:state], :thread_name => thread[:name])} \n"
+              thread_report = "#{thread[:percent_of_cpu_time]} % of of cpu usage by #{thread[:state]} thread named '#{thread[:name]}'\n"
+              thread_report << "#{thread[:path]}\n" if thread[:path]
+              thread[:traces].each do |trace|
+                thread_report << "\t#{trace}\n"
+              end
+              report << thread_report
+              report << '-' * 80
+              report << "\n"
+            end
+            report
+          end
+
+          def to_hash
+            hash = { :hostname => @cmd.hostname, :time => Time.now.iso8601, :busiest_threads => @thread_dump.top_count, :threads => [] }
+            @thread_dump.each do |thread_name, _hash|
+              thread_name, thread_path = _hash["thread.name"].split(": ")
+              thread = { :name => thread_name,
+                         :percent_of_cpu_time => cpu_time_as_percent(_hash),
+                         :state => _hash["thread.state"]
+                       }
+              thread[:path] = thread_path if thread_path
+              traces = []
+              _hash["thread.stacktrace"].each do |trace|
+                traces << trace
+              end
+              thread[:traces] = traces unless traces.empty?
+              hash[:threads] << thread
+            end
+            hash
+          end
+
+          def cpu_time_as_percent(hash)
+            (((cpu_time(hash) / @cmd.uptime * 1.0)*10000).to_i)/100.0
+          end
+
+          def cpu_time(hash)
+            hash["cpu.time"] / 1000000.0
+          end
+
+        end
+      end
+    end
+  end
+end
diff --git a/logstash-core/lib/logstash/api/commands/stats.rb b/logstash-core/lib/logstash/api/commands/stats.rb
index 6d4ef2430fc..8737d65ebd7 100644
--- a/logstash-core/lib/logstash/api/commands/stats.rb
+++ b/logstash-core/lib/logstash/api/commands/stats.rb
@@ -5,99 +5,50 @@ module LogStash
   module Api
     module Commands
       class Stats < Commands::Base
-
         def jvm
-          {:threads => service.get_shallow(:jvm, :threads)}
+          {
+            :threads => extract_metrics(
+              [:jvm, :threads],
+              :count,
+              :peak_count
+            )
+          }
         end
 
         def process
-          service.get_shallow(:jvm, :process)
+          extract_metrics(
+            [:jvm, :process],
+            :open_file_descriptors,
+            :peak_open_file_descriptors,
+            :max_file_descriptors,
+            [:mem, [:total_virtual_in_bytes]],
+            [:cpu, [:total_in_millis, :percent]]
+          )
         end
 
         def events
-          service.get_shallow(:stats, :events)
+          extract_metrics(
+            [:stats, :events],
+            :in, :filtered, :out
+          )
         end
 
         def memory
-          memory = LogStash::Json.load(service.get(:jvm_memory_stats))
+          memory = service.get_shallow(:jvm, :memory)
           {
-            :heap_used_in_bytes => memory["heap"]["used_in_bytes"],
-            :heap_used_percent => memory["heap"]["used_percent"],
-            :heap_committed_in_bytes => memory["heap"]["committed_in_bytes"],
-            :heap_max_in_bytes => memory["heap"]["max_in_bytes"],
-            :heap_used_in_bytes => memory["heap"]["used_in_bytes"],
-            :non_heap_used_in_bytes => memory["non_heap"]["used_in_bytes"],
-            :non_heap_committed_in_bytes => memory["non_heap"]["committed_in_bytes"],
-            :pools => memory["pools"].inject({}) do |acc, (type, hash)|
+            :heap_used_in_bytes => memory[:heap][:used_in_bytes],
+            :heap_used_percent => memory[:heap][:used_percent],
+            :heap_committed_in_bytes => memory[:heap][:committed_in_bytes],
+            :heap_max_in_bytes => memory[:heap][:max_in_bytes],
+            :heap_used_in_bytes => memory[:heap][:used_in_bytes],
+            :non_heap_used_in_bytes => memory[:non_heap][:used_in_bytes],
+            :non_heap_committed_in_bytes => memory[:non_heap][:committed_in_bytes],
+            :pools => memory[:pools].inject({}) do |acc, (type, hash)|
               hash.delete("committed_in_bytes")
               acc[type] = hash
               acc
             end
           }
-        end
-
-        def hot_threads(options={})
-          HotThreadsReport.new(self, options)
-        end
-
-        class HotThreadsReport
-          HOT_THREADS_STACK_TRACES_SIZE_DEFAULT = 10.freeze
-          
-          def initialize(cmd, options)
-            @cmd = cmd
-            filter = { :stacktrace_size => options.fetch(:stacktrace_size, HOT_THREADS_STACK_TRACES_SIZE_DEFAULT) }
-            jr_dump = JRMonitor.threads.generate(filter)
-            @thread_dump = ::LogStash::Util::ThreadDump.new(options.merge(:dump => jr_dump))
-          end
-          
-          def to_s
-            hash = to_hash
-            report =  "#{I18n.t("logstash.web_api.hot_threads.title", :hostname => hash[:hostname], :time => hash[:time], :top_count => @thread_dump.top_count )} \n"
-            report << '=' * 80
-            report << "\n"
-            hash[:threads].each do |thread|
-              thread_report = ""
-              thread_report = "#{I18n.t("logstash.web_api.
-                                hot_threads.thread_title", :percent_of_cpu_time => thread[:percent_of_cpu_time], :thread_state => thread[:state], :thread_name => thread[:name])} \n"
-              thread_report = "#{thread[:percent_of_cpu_time]} % of of cpu usage by #{thread[:state]} thread named '#{thread[:name]}'\n"
-              thread_report << "#{thread[:path]}\n" if thread[:path]
-              thread[:traces].each do |trace|
-                thread_report << "\t#{trace}\n"
-              end
-              report << thread_report
-              report << '-' * 80
-              report << "\n"
-            end
-            report
-          end
-
-          def to_hash
-            hash = { :hostname => @cmd.hostname, :time => Time.now.iso8601, :busiest_threads => @thread_dump.top_count, :threads => [] }
-            @thread_dump.each do |thread_name, _hash|
-              thread_name, thread_path = _hash["thread.name"].split(": ")
-              thread = { :name => thread_name,
-                         :percent_of_cpu_time => cpu_time_as_percent(_hash),
-                         :state => _hash["thread.state"]
-                       }
-              thread[:path] = thread_path if thread_path
-              traces = []
-              _hash["thread.stacktrace"].each do |trace|
-                traces << trace
-              end
-              thread[:traces] = traces unless traces.empty?
-              hash[:threads] << thread
-            end
-            hash
-          end
-
-          def cpu_time_as_percent(hash)
-            (((cpu_time(hash) / @cmd.uptime * 1.0)*10000).to_i)/100.0
-          end
-
-          def cpu_time(hash)
-            hash["cpu.time"] / 1000000.0
-          end
-
         end       
       end
     end
diff --git a/logstash-core/lib/logstash/api/modules/node.rb b/logstash-core/lib/logstash/api/modules/node.rb
index b5139a027ea..2ba3f933e77 100644
--- a/logstash-core/lib/logstash/api/modules/node.rb
+++ b/logstash-core/lib/logstash/api/modules/node.rb
@@ -5,7 +5,26 @@ module LogStash
   module Api
     module Modules
       class Node < ::LogStash::Api::Modules::Base
-        # return hot threads information
+        def node
+          factory.build(:node)
+        end
+        
+        get "/" do
+          respond_with node.all
+        end
+
+        get "/os" do
+          respond_with :os => node.os
+        end
+
+        get "/jvm" do
+          respond_with :jvm => node.jvm          
+        end
+
+        get "/pipeline" do
+          respond_with :pipeline => node.pipeline
+        end
+        
         get "/hot_threads" do
           ignore_idle_threads = params["ignore_idle_threads"] || true
 
@@ -15,10 +34,9 @@ class Node < ::LogStash::Api::Modules::Base
           }
           options[:threads] = params["threads"].to_i if params.has_key?("threads")
 
-          stats = factory.build(:stats)
-          as    = options[:human] ? :string : :json
-          respond_with(stats.hot_threads(options), {:as => as})
-        end
+          as = options[:human] ? :string : :json
+          respond_with({:hot_threads => node.hot_threads(options)}, {:as => as})
+        end       
       end
     end
   end
diff --git a/logstash-core/lib/logstash/api/modules/node_stats.rb b/logstash-core/lib/logstash/api/modules/node_stats.rb
index a744eb8ee33..73a7e1bd1b8 100644
--- a/logstash-core/lib/logstash/api/modules/node_stats.rb
+++ b/logstash-core/lib/logstash/api/modules/node_stats.rb
@@ -3,6 +3,11 @@ module LogStash
   module Api
     module Modules
       class NodeStats < ::LogStash::Api::Modules::Base
+        #set :environment, :test
+        #set :dump_errors, true
+        #set :raise_errors, true
+        #set :logging, Logger.new(STDERR)
+        
         
         before do
           @stats = factory.build(:stats)
@@ -14,7 +19,8 @@ class NodeStats < ::LogStash::Api::Modules::Base
           payload = {
             :events => events_payload,
             :jvm => jvm_payload,
-            :process => process_payload
+            :process => process_payload,
+            :mem => mem_payload
           }
 
           respond_with payload
@@ -40,6 +46,10 @@ class NodeStats < ::LogStash::Api::Modules::Base
           respond_with :process => process_payload
         end
 
+        get "/mem" do
+          respond_with :mem => mem_payload
+        end
+
         private
 
         def events_payload
@@ -53,6 +63,10 @@ def jvm_payload
         def process_payload
           @stats.process
         end
+
+        def mem_payload
+          @stats.memory
+        end
       end
     end
   end
diff --git a/logstash-core/lib/logstash/api/rack_app.rb b/logstash-core/lib/logstash/api/rack_app.rb
index 6c551b3277c..6a5507d0a32 100644
--- a/logstash-core/lib/logstash/api/rack_app.rb
+++ b/logstash-core/lib/logstash/api/rack_app.rb
@@ -104,7 +104,7 @@ def self.rack_namespaces(agent)
           "/_node" => LogStash::Api::Modules::Node,
           "/_stats" => LogStash::Api::Modules::Stats,
           "/_node/stats" => LogStash::Api::Modules::NodeStats,
-          "/_plugins" => LogStash::Api::Modules::Plugins
+          "/_node/plugins" => LogStash::Api::Modules::Plugins
         }
       end
     end
diff --git a/logstash-core/lib/logstash/api/service.rb b/logstash-core/lib/logstash/api/service.rb
index d286f8f0ca0..32563fc994e 100644
--- a/logstash-core/lib/logstash/api/service.rb
+++ b/logstash-core/lib/logstash/api/service.rb
@@ -26,14 +26,8 @@ def get_shallow(*path)
         snapshot.metric_store.get_shallow(*path)
       end
 
-      def get(key)
-        metric_store = @snapshot_rotation_mutex.synchronize { @snapshot.metric_store }
-        if key == :jvm_memory_stats
-          data = metric_store.get_shallow(:jvm, :memory)
-        else
-          data = metric_store.get_with_path("stats/events")
-        end
-        LogStash::Json.dump(data)
+      def extract_metrics(path, *keys)
+        snapshot.metric_store.extract_metrics(path, *keys)
       end
     end
   end
diff --git a/logstash-core/lib/logstash/instrument/metric_store.rb b/logstash-core/lib/logstash/instrument/metric_store.rb
index 653f6774440..de3c8b3b8dd 100644
--- a/logstash-core/lib/logstash/instrument/metric_store.rb
+++ b/logstash-core/lib/logstash/instrument/metric_store.rb
@@ -110,6 +110,60 @@ def get_shallow(*key_paths)
       key_paths.reduce(get(*key_paths)) {|acc, p| acc[p]}
     end
 
+
+    # Return a hash including the values of the keys given at the path given
+    # 
+    # Example Usage:
+    # extract_metrics(
+    #   [:jvm, :process],
+    #   :open_file_descriptors,
+    #   [:cpu, [:total_in_millis, :percent]]
+    #   [:pipelines, [:one, :two], :size]
+    # )
+    # 
+    # Returns:
+    # # From the jvm.process metrics namespace
+    # {
+    #   :open_file_descriptors => 123
+    #   :cpu => { :total_in_millis => 456, :percent => 789 }
+    #   :pipelines => {
+    #                   :one => {:size => 90210},
+    #                   :two => {:size => 8675309}
+    #                 }
+    # }
+    def extract_metrics(path, *keys)
+      keys.reduce({}) do |acc,k|
+        # Simplifiy 1-length keys
+        k = k.first if k.is_a?(Array) && k.size == 1
+
+        # If we have array values here we need to recurse
+        # There are two levels of looping here, one for the paths we might pass in
+        # one for the upcoming keys we might pass in
+        if k.is_a?(Array)
+          # We need to build up future executions to extract_metrics
+          # which means building up the path and keys arguments.
+          # We need a nested loop her to execute all permutations of these in case we hit
+          # something like [[:a,:b],[:c,:d]] which produces 4 different metrics
+          next_paths = Array(k.first)
+          next_keys = Array(k[1])
+          rest = k[2..-1]
+          next_paths.each do |next_path|
+            # If there already is a hash at this location use that so we don't overwrite it
+            np_hash = acc[next_path] || {}
+            
+            acc[next_path] = next_keys.reduce(np_hash) do |a,next_key|
+              a.merge! extract_metrics(path + [next_path], [next_key, *rest])
+            end
+          end
+        else # Scalar value
+          res = get_shallow(*path)[k]
+          acc[k] = res ? res.value : nil
+        end
+        
+        acc
+      end
+    end    
+
     # Return all the individuals Metric,
     # This call mimic a Enum's each if a block is provided
     #
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 8c6a6cf221c..024f75c7f1a 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -188,6 +188,12 @@ def start_workers
       batch_size = @settings.get("pipeline.batch.size")
       batch_delay = @settings.get("pipeline.batch.delay")
       max_inflight = batch_size * pipeline_workers
+
+      config_metric = metric.namespace([:stats, :pipelines, pipeline_id.to_s.to_sym, :config])   
+      config_metric.gauge(:workers, pipeline_workers)
+      config_metric.gauge(:batch_size, batch_size)
+      config_metric.gauge(:batch_delay, batch_delay)
+      
       @logger.info("Starting pipeline",
                    "id" => self.pipeline_id,
                    "pipeline.workers" => pipeline_workers,
diff --git a/logstash-core/spec/api/lib/api/node_plugins_spec.rb b/logstash-core/spec/api/lib/api/node_plugins_spec.rb
new file mode 100644
index 00000000000..d78340effd3
--- /dev/null
+++ b/logstash-core/spec/api/lib/api/node_plugins_spec.rb
@@ -0,0 +1,32 @@
+# encoding: utf-8
+require_relative "../../spec_helper"
+require "sinatra"
+require "logstash/api/modules/plugins"
+require "logstash/json"
+
+describe LogStash::Api::Modules::Plugins do
+  include_context "api setup"
+
+  extend ResourceDSLMethods
+
+  before(:all) do
+    do_request { get "/" }
+  end
+
+  let(:payload) { LogStash::Json.load(last_response.body) }
+
+  describe "retrieving plugins" do
+    it "should return OK" do
+      expect(last_response).to be_ok
+    end
+
+    it "should return a list of plugins" do      
+      expect(payload["plugins"]).to be_a(Array)
+    end
+
+    it "should return the total number of plugins" do
+      expect(payload["total"]).to be_a(Numeric)
+    end
+    
+  end
+end
diff --git a/logstash-core/spec/api/lib/api/node_spec.rb b/logstash-core/spec/api/lib/api/node_spec.rb
index ae548337dde..c9317231449 100644
--- a/logstash-core/spec/api/lib/api/node_spec.rb
+++ b/logstash-core/spec/api/lib/api/node_spec.rb
@@ -34,7 +34,7 @@
       end
 
       it "should return information for <= # requested threads" do
-        expect(payload["threads"].count).to be <= 5
+        expect(payload["hot_threads"]["threads"].count).to be <= 5
       end
     end
 
@@ -55,5 +55,44 @@
       end
     end
 
+    describe "Generic JSON testing" do
+      extend ResourceDSLMethods
+      
+      root_structure = {
+        "pipeline" => {
+          "workers" => Numeric,
+          "batch_size" => Numeric,
+          "batch_delay" => Numeric
+        },
+        "os" => {
+          "name" => String,
+          "arch" => String,
+          "version" => String,
+          "available_processors" => Numeric
+        },
+        "jvm" => {
+          "pid" => Numeric,
+          "version" => String,
+          "vm_name" => String,
+          "vm_version" => String,
+          "vm_vendor" => String,
+          "start_time_in_millis" => Numeric,
+          "mem" => {
+            "heap_init_in_bytes" => Numeric,
+            "heap_max_in_bytes" => Numeric,
+            "non_heap_init_in_bytes" => Numeric,
+            "non_heap_max_in_bytes" => Numeric
+          }
+        },
+        "hot_threads"=> {
+          "hostname" => String,
+          "time" => String,
+          "busiest_threads" => Numeric,
+          "threads" => Array
+        }
+      }
+      
+      test_api_and_resources(root_structure, :exclude_from_root => ["hot_threads"])
+    end   
   end
 end
diff --git a/logstash-core/spec/api/lib/api/node_stats_spec.rb b/logstash-core/spec/api/lib/api/node_stats_spec.rb
index addb45667e0..44cc0a3c37e 100644
--- a/logstash-core/spec/api/lib/api/node_stats_spec.rb
+++ b/logstash-core/spec/api/lib/api/node_stats_spec.rb
@@ -33,8 +33,36 @@
         "total_in_millis"=>Numeric,
         "percent"=>Numeric
       }
+    },    
+    "mem" => {
+      "heap_used_in_bytes" => Numeric,
+      "heap_used_percent" => Numeric,
+      "heap_committed_in_bytes" => Numeric,
+      "heap_max_in_bytes" => Numeric,
+      "non_heap_used_in_bytes" => Numeric,
+      "non_heap_committed_in_bytes" => Numeric,
+      "pools" => {
+        "survivor" => {
+          "peak_used_in_bytes" => Numeric,
+          "used_in_bytes" => Numeric,
+          "peak_max_in_bytes" => Numeric,
+          "max_in_bytes" => Numeric
+        },
+        "old" => {
+          "peak_used_in_bytes" => Numeric,
+          "used_in_bytes" => Numeric,
+          "peak_max_in_bytes" => Numeric,
+          "max_in_bytes" => Numeric
+        },
+        "young" => {
+          "peak_used_in_bytes" => Numeric,
+          "used_in_bytes" => Numeric,
+          "peak_max_in_bytes" => Numeric,
+          "max_in_bytes" => Numeric
+        }
+      }
     }
   }
-
+  
   test_api_and_resources(root_structure)
 end
diff --git a/logstash-core/spec/api/lib/api/support/resource_dsl_methods.rb b/logstash-core/spec/api/lib/api/support/resource_dsl_methods.rb
index 786a37f984a..0e75c5d00fd 100644
--- a/logstash-core/spec/api/lib/api/support/resource_dsl_methods.rb
+++ b/logstash-core/spec/api/lib/api/support/resource_dsl_methods.rb
@@ -24,12 +24,16 @@ def test_api(expected, path)
         expect(last_response).to be_ok
       end
       
-      hash_to_mapping(expected).each do |path,klass|
-        dotted = path.join(".")
+      hash_to_mapping(expected).each do |resource_path,klass|
+        dotted = resource_path.join(".")
         
-        it "should set '#{dotted}' to be a '#{klass}'" do
-          path_value = path.reduce(payload) {|acc,v| acc[v]}
-          expect(path_value).to be_a(klass), "could not find '#{dotted}' in #{payload}"
+        it "should set '#{dotted}' at '#{path}' to be a '#{klass}'" do
+          expect(last_response).to be_ok # fail early if need be
+          resource_path_value = resource_path.reduce(payload) do |acc,v|
+            expect(acc.has_key?(v)).to eql(true), "Expected to find value '#{v}' in structure '#{acc}', but could not. Payload was '#{payload}'"
+            acc[v]
+          end
+          expect(resource_path_value).to be_a(klass), "could not find '#{dotted}' in #{payload}"
         end
       end
     end
@@ -37,8 +41,11 @@ def test_api(expected, path)
     yield if block_given? # Add custom expectations
   end
 
-  def test_api_and_resources(expected)
-    test_api(expected, "/")
+  def test_api_and_resources(expected, xopts={})
+    xopts[:exclude_from_root] ||= []
+    root_expectation = expected.clone
+    xopts[:exclude_from_root].each {|k| root_expectation.delete(k)}
+    test_api(root_expectation, "/")
 
     expected.keys.each do |key|
       test_api({key => expected[key]}, "/#{key}")
diff --git a/logstash-core/spec/logstash/instrument/metric_store_spec.rb b/logstash-core/spec/logstash/instrument/metric_store_spec.rb
index 4371977355b..7e579064129 100644
--- a/logstash-core/spec/logstash/instrument/metric_store_spec.rb
+++ b/logstash-core/spec/logstash/instrument/metric_store_spec.rb
@@ -142,6 +142,67 @@
       end
     end
 
+    describe "get_shallow" do
+      it "should retrieve a path as a single value" do
+        r = subject.get_shallow(:node, :sashimi, :pipelines, :pipeline01, :processed_events_in)
+        expect(r.value).to eql(1)
+      end
+    end
+
+    describe "extract_metrics" do
+      it "should retrieve non-nested values correctly" do
+        r = subject.extract_metrics(
+          [:node, :sashimi, :pipelines, :pipeline01],
+          :processed_events_in,
+          :processed_events_out,
+        )
+        expect(r[:processed_events_in]).to eql(1)
+        expect(r[:processed_events_out]).to eql(1)
+      end
+
+      it "should retrieve nested values correctly alongside non-nested ones" do
+        r = subject.extract_metrics(
+          [:node, :sashimi, :pipelines, :pipeline01],
+          :processed_events_in,
+          [:plugins, :"logstash-output-elasticsearch", :event_in]
+        )
+       expect(r[:processed_events_in]).to eql(1)
+        expect(r[:plugins][:"logstash-output-elasticsearch"][:event_in]).to eql(1)
+      end
+
+      it "should retrieve multiple nested keys at a given location" do
+        r = subject.extract_metrics(
+          [:node, :sashimi, :pipelines],
+          [:pipeline01, [:processed_events_in, :processed_events_out]]
+        )
+
+        expect(r[:pipeline01][:processed_events_in]).to eql(1)
+        expect(r[:pipeline01][:processed_events_out]).to eql(1)
+      end
+
+      it "should retrieve a single key nested in multiple places" do
+        r = subject.extract_metrics(
+          [:node, :sashimi, :pipelines],
+          [[:pipeline01, :pipeline02], :processed_events_out]
+        )
+
+        expect(r[:pipeline01][:processed_events_out]).to eql(1)
+        expect(r[:pipeline02][:processed_events_out]).to eql(1)
+      end
+
+      it "handle overlaps of paths" do
+        r = subject.extract_metrics(
+          [:node, :sashimi, :pipelines],
+          [:pipeline01, :processed_events_in],
+          [[:pipeline01, :pipeline02], :processed_events_out]
+        )
+
+        expect(r[:pipeline01][:processed_events_in]).to eql(1)
+        expect(r[:pipeline01][:processed_events_out]).to eql(1)
+        expect(r[:pipeline02][:processed_events_out]).to eql(1)
+      end
+    end
+
     describe "#each" do
       it "retrieves all the metric" do
         expect(subject.each.size).to eq(metric_events.size)
