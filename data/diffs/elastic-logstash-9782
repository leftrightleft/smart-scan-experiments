diff --git a/README.md b/README.md
index a8d2bedd854..76f13ece2aa 100644
--- a/README.md
+++ b/README.md
@@ -108,7 +108,7 @@ rake bootstrap
 rake plugin:install-default
 ```
 
-This will install the 80+ default plugins which makes Logstash ready to connect to multiple data sources, perform transformations and send the results to Elasticsearch and other destinatins.
+This will install the 80+ default plugins which makes Logstash ready to connect to multiple data sources, perform transformations and send the results to Elasticsearch and other destinations.
 
 To verify your environment, run the following to send your first event:
 
diff --git a/Rakefile b/Rakefile
index b853e472a51..71f49fe54e7 100644
--- a/Rakefile
+++ b/Rakefile
@@ -16,8 +16,8 @@ Packaging?
 
 Developing?
   `rake bootstrap`          installs any dependencies for doing Logstash development
-  `rake test:install-core`  installs any dependencies for testing Logstasch core
-  `rake test:core`          to run Logstasch core tests
+  `rake test:install-core`  installs any dependencies for testing Logstash core
+  `rake test:core`          to run Logstash core tests
   `rake vendor:clean`       clean vendored dependencies used for Logstash development
 HELP
 end
diff --git a/ci/unit_tests.bat b/ci/unit_tests.bat
index cfa972d4d1a..e1c1148a6ab 100644
--- a/ci/unit_tests.bat
+++ b/ci/unit_tests.bat
@@ -6,7 +6,7 @@ if "%WORKSPACE%" == "" (
   exit /B 1
 )
 
-:: see if %WORKSPACE% is alread mapped to a drive
+:: see if %WORKSPACE% is already mapped to a drive
 for /f "tokens=1* delims==> " %%G IN ('subst') do (
   set sdrive=%%G
   :: removing extra space
diff --git a/config/pipelines.yml b/config/pipelines.yml
index 8df27ba392c..0ecf72adf53 100644
--- a/config/pipelines.yml
+++ b/config/pipelines.yml
@@ -1,7 +1,7 @@
 # List of pipelines to be loaded by Logstash
 #
 # This document must be a list of dictionaries/hashes, where the keys/values are pipeline settings.
-# Default values for ommitted settings are read from the `logstash.yml` file.
+# Default values for omitted settings are read from the `logstash.yml` file.
 # When declaring multiple pipelines, each MUST have its own `pipeline.id`.
 #
 # Example of two pipelines:
diff --git a/docs/index.asciidoc b/docs/index.asciidoc
index cd4a8a5d476..e8281cfd2c4 100644
--- a/docs/index.asciidoc
+++ b/docs/index.asciidoc
@@ -62,7 +62,7 @@ include::static/advanced-pipeline.asciidoc[]
 :edit_url: https://github.com/elastic/logstash/edit/{branch}/docs/static/life-of-an-event.asciidoc
 include::static/life-of-an-event.asciidoc[]
 
-// Lostash setup
+// Logstash setup
 
 :edit_url: https://github.com/elastic/logstash/edit/{branch}/docs/static/setting-up-logstash.asciidoc
 include::static/setting-up-logstash.asciidoc[]
diff --git a/docs/static/deploying.asciidoc b/docs/static/deploying.asciidoc
index f1dc91a0716..d07fd5d168a 100644
--- a/docs/static/deploying.asciidoc
+++ b/docs/static/deploying.asciidoc
@@ -205,7 +205,7 @@ SocketAppender to send JSON to the Logstash TCP input. Alternatively, log4j2
 can also log to a file for collection with FIlebeat. Usage of the log4j1
 SocketAppender is not recommended.
 
-IoT devices like Rasberry Pis, smartphones, and connected vehicles often send
+IoT devices like Raspberry Pis, smartphones, and connected vehicles often send
 telemetry data through one of these protocols.
 
 [float]
diff --git a/docs/static/docker.asciidoc b/docs/static/docker.asciidoc
index a70eefca6bd..1987831cbc5 100644
--- a/docs/static/docker.asciidoc
+++ b/docs/static/docker.asciidoc
@@ -163,7 +163,7 @@ documentation>> can be configured with this technique.
 
 NOTE: Defining settings with environment variables causes `logstash.yml` to
 be modified in place. This behaviour is likely undesirable if `logstash.yml` was
-bind-mounted from the host system. Thus, it is not reccomended to
+bind-mounted from the host system. Thus, it is not recommended to
 combine the bind-mount technique with the environment variable technique. It
 is best to choose a single method for defining Logstash settings.
 
diff --git a/docs/static/logstash-glossary.asciidoc b/docs/static/logstash-glossary.asciidoc
index 82f04943471..d184899f37a 100644
--- a/docs/static/logstash-glossary.asciidoc
+++ b/docs/static/logstash-glossary.asciidoc
@@ -39,7 +39,7 @@ file::
 	A resource storing binary data (which might be text, image, application, etc.) on a physical storage media. In the Logstash context, a common input source which monitors a growing collection of text-based log lines.
 
 filter:
-	An intermediary processing mechanism in the Lostash pipeline. Typically, filters act upon event data after it has been ingested via inputs, by mutating, enriching, and/or modifying the data according to configuration rules. The second phase of the typical Logstash pipeline (inputs->filters->outputs).
+	An intermediary processing mechanism in the Logstash pipeline. Typically, filters act upon event data after it has been ingested via inputs, by mutating, enriching, and/or modifying the data according to configuration rules. The second phase of the typical Logstash pipeline (inputs->filters->outputs).
 
 fluentd::
 	Like Logstash, another open-source tool for collecting logs and events, with plugins to extend functionality.
diff --git a/docs/static/modules.asciidoc b/docs/static/modules.asciidoc
index 5e92268ada1..eaa4c961c22 100644
--- a/docs/static/modules.asciidoc
+++ b/docs/static/modules.asciidoc
@@ -33,7 +33,7 @@ bin/logstash --modules MODULE_NAME --setup [-M "CONFIG_SETTING=VALUE"]
 ----
 
 
-//TODO: For 6.0, show how to run mutliple modules
+//TODO: For 6.0, show how to run multiple modules
 
 Where:
 
diff --git a/logstash-core/lib/logstash/config/modules_common.rb b/logstash-core/lib/logstash/config/modules_common.rb
index e75c389c7e3..28a9f22c935 100644
--- a/logstash-core/lib/logstash/config/modules_common.rb
+++ b/logstash-core/lib/logstash/config/modules_common.rb
@@ -27,7 +27,7 @@ def self.pipeline_configs(settings)
           end
 
       if modules_array.empty?
-        # no specifed modules
+        # no specified modules
         return pipelines
       end
       logger.debug("Specified modules", :modules_array => modules_array.to_s)
@@ -73,9 +73,9 @@ def self.pipeline_configs(settings)
           LogStash::Modules::SettingsMerger.merge_kibana_auth!(module_hash)
           current_module.with_settings(module_hash)
           config_test = settings.get("config.test_and_exit")
-          modul_setup = settings.get("modules_setup")
+          module_setup = settings.get("modules_setup")
           # Only import data if it's not a config test and --setup is true
-          if !config_test && modul_setup
+          if !config_test && module_setup
             logger.info("Setting up the #{module_name} module")
             esclient = LogStash::ElasticsearchClient.build(module_hash)
             kbnclient = LogStash::Modules::KibanaClient.new(module_hash)
diff --git a/logstash-core/lib/logstash/java_pipeline.rb b/logstash-core/lib/logstash/java_pipeline.rb
index 183a7cf4848..65913445009 100644
--- a/logstash-core/lib/logstash/java_pipeline.rb
+++ b/logstash-core/lib/logstash/java_pipeline.rb
@@ -320,7 +320,7 @@ def shutdown(&before_stop)
 
     stop_inputs
 
-    # We make this call blocking, so we know for sure when the method return the shtudown is
+    # We make this call blocking, so we know for sure when the method return the shutdown is
     # stopped
     wait_for_workers
     clear_pipeline_metrics
diff --git a/logstash-core/lib/logstash/modules/kibana_config.rb b/logstash-core/lib/logstash/modules/kibana_config.rb
index 0e932c03eba..528eed6af5d 100644
--- a/logstash-core/lib/logstash/modules/kibana_config.rb
+++ b/logstash-core/lib/logstash/modules/kibana_config.rb
@@ -8,7 +8,7 @@ module LogStash module Modules class KibanaConfig
   include LogStash::Util::Loggable
 
   ALLOWED_DIRECTORIES = ["search", "visualization"]
-  attr_reader :index_name # not used when importing via kibana but for BWC with ElastsearchConfig
+  attr_reader :index_name # not used when importing via kibana but for BWC with ElasticsearchConfig
 
   # We name it `modul` here because `module` has meaning in Ruby.
   def initialize(modul, settings)
diff --git a/logstash-core/lib/logstash/modules/logstash_config.rb b/logstash-core/lib/logstash/modules/logstash_config.rb
index c72e0029990..aade095bbbb 100644
--- a/logstash-core/lib/logstash/modules/logstash_config.rb
+++ b/logstash-core/lib/logstash/modules/logstash_config.rb
@@ -39,7 +39,7 @@ def csv_string(array)
   def get_setting(setting_class)
     raw_value = @settings[setting_class.name]
     # If we dont check for NIL, the Settings class will try to coerce the value
-    # and most of the it will fails when a NIL value is explicitely set.
+    # and most of the it will fails when a NIL value is explicitly set.
     # This will be fixed once we wrap the plugins settings into a Settings class
     setting_class.set(raw_value) unless raw_value.nil?
     setting_class.value
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 2f648a147b3..cdd56a69d15 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -458,7 +458,7 @@ def shutdown(&before_stop)
 
     stop_inputs
 
-    # We make this call blocking, so we know for sure when the method return the shtudown is
+    # We make this call blocking, so we know for sure when the method return the shutdown is
     # stopped
     wait_for_workers
     clear_pipeline_metrics
diff --git a/logstash-core/lib/logstash/pipeline_settings.rb b/logstash-core/lib/logstash/pipeline_settings.rb
index bf01742aff1..e25f41ed424 100644
--- a/logstash-core/lib/logstash/pipeline_settings.rb
+++ b/logstash-core/lib/logstash/pipeline_settings.rb
@@ -46,7 +46,7 @@ def self.from_settings(settings)
 
     def register(setting)
       unless SETTINGS_WHITE_LIST.include?(setting.name)
-        raise ArgumentError.new("Only pipeline related settings can be registed in a PipelineSettings object. Received \"#{setting.name}\". Allowed settings: #{SETTINGS_WHITE_LIST}")
+        raise ArgumentError.new("Only pipeline related settings can be registered in a PipelineSettings object. Received \"#{setting.name}\". Allowed settings: #{SETTINGS_WHITE_LIST}")
       end
       super(setting)
     end
diff --git a/logstash-core/spec/logstash/acked_queue_concurrent_stress_spec.rb b/logstash-core/spec/logstash/acked_queue_concurrent_stress_spec.rb
index 5646edddd9d..43eb667edf3 100644
--- a/logstash-core/spec/logstash/acked_queue_concurrent_stress_spec.rb
+++ b/logstash-core/spec/logstash/acked_queue_concurrent_stress_spec.rb
@@ -70,7 +70,7 @@ def publisher(items, writer)
       it "writes, reads, closes and reopens" do
         Thread.abort_on_exception = true
 
-        # force lazy initialization to avoid concurency issues within threads
+        # force lazy initialization to avoid concurrency issues within threads
         counts
         queue
 
diff --git a/logstash-core/spec/logstash/agent/metrics_spec.rb b/logstash-core/spec/logstash/agent/metrics_spec.rb
index a66aac1067c..cdf33ef74ce 100644
--- a/logstash-core/spec/logstash/agent/metrics_spec.rb
+++ b/logstash-core/spec/logstash/agent/metrics_spec.rb
@@ -229,7 +229,7 @@ def mhash(*path_elements)
         # since the pipeline is async, it can actually take some time to have metrics recordings
         # so we try a few times
         try(20) do
-          expect { mhash(:stats, :pipelines, :main, :events) }.not_to raise_error , "Events pipelien stats should exist"
+          expect { mhash(:stats, :pipelines, :main, :events) }.not_to raise_error , "Events pipeline stats should exist"
           expect { mhash(:stats, :pipelines, :main, :plugins) }.not_to raise_error, "Plugins pipeline stats should exist"
         end
 
diff --git a/logstash-core/spec/logstash/converge_result_spec.rb b/logstash-core/spec/logstash/converge_result_spec.rb
index 4fab83430d1..ea13a0bb1eb 100644
--- a/logstash-core/spec/logstash/converge_result_spec.rb
+++ b/logstash-core/spec/logstash/converge_result_spec.rb
@@ -90,7 +90,7 @@
   end
 
   context "when all the actions are executed" do
-    context "all succesfull" do
+    context "all successful" do
       let(:success_action) { LogStash::PipelineAction::Stop.new(:success) }
       let(:success_action_2) { LogStash::PipelineAction::Stop.new(:success_2) }
 
diff --git a/logstash-core/spec/logstash/util/secretstore_spec.rb b/logstash-core/spec/logstash/util/secretstore_spec.rb
index 5a868f7c96c..bb9221ad645 100644
--- a/logstash-core/spec/logstash/util/secretstore_spec.rb
+++ b/logstash-core/spec/logstash/util/secretstore_spec.rb
@@ -12,7 +12,7 @@
     end
 
     it "should be not exist" do
-      expect(subject.exists(LogStash::SETTINGS.get_setting("keystore.file").value, LogStash::SETTINGS.get_setting("keystore.classname").value)).to be_falsy
+      expect(subject.exists(LogStash::SETTINGS.get_setting("keystore.file").value, LogStash::SETTINGS.get_setting("keystore.classname").value)).to be_falsey
       expect(subject.getIfExists(LogStash::SETTINGS.get_setting("keystore.file").value, LogStash::SETTINGS.get_setting("keystore.classname").value)).to be_nil
     end
   end
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java b/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
index 94b73f716bd..503b41bae41 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
@@ -171,7 +171,7 @@ public void open() throws IOException {
 
             // at this point we have a head checkpoint to figure queue recovery
 
-            // as we load pages, compute actuall disk needed substracting existing pages size to the required maxBytes
+            // as we load pages, compute actually disk needed substracting existing pages size to the required maxBytes
             long diskNeeded = this.maxBytes;
 
             // reconstruct all tail pages state upto but excluding the head page
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java b/logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
index da600d1a9f6..7fbbcf50477 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
@@ -173,7 +173,7 @@ public String hashSource() {
         return this.uniqueHash();
     }
 
-    // Can be overriden in subclasses to define multiple
+    // Can be overridden in subclasses to define multiple
     // expected Edge classes this Vertex can take.
     // If any EdgeFactory instances are returned this Vertex is considered
     // a partial leaf.
diff --git a/logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/PluginWitness.java b/logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/PluginWitness.java
index fa70808fdda..ee8990dfe5b 100644
--- a/logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/PluginWitness.java
+++ b/logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/PluginWitness.java
@@ -238,7 +238,7 @@ public static final class Snitch {
             private final PluginWitness.CustomWitness witness;
 
             /**
-             * Construtor
+             * Constructor
              *
              * @param witness the witness
              */
diff --git a/logstash-core/src/main/java/org/logstash/instrument/witness/schedule/ScheduledWitness.java b/logstash-core/src/main/java/org/logstash/instrument/witness/schedule/ScheduledWitness.java
index 79499b60002..8f3ce4e5a2c 100644
--- a/logstash-core/src/main/java/org/logstash/instrument/witness/schedule/ScheduledWitness.java
+++ b/logstash-core/src/main/java/org/logstash/instrument/witness/schedule/ScheduledWitness.java
@@ -10,7 +10,7 @@ public interface ScheduledWitness {
     /**
      * The duration between updates for this witness
      *
-     * @return the {@link Duration} between scheduled updates. For example {@link Duration#ofMinutes(long)} with a value of 5 would schedule this implemenation to
+     * @return the {@link Duration} between scheduled updates. For example {@link Duration#ofMinutes(long)} with a value of 5 would schedule this implementation to
      * self-populate every 5 minute. Defaults to every 60 seconds. - Note, implementations may not allow schedules faster then every 1 second.
      */
     default Duration every() {
diff --git a/logstash-core/src/main/java/org/logstash/secret/SecretIdentifier.java b/logstash-core/src/main/java/org/logstash/secret/SecretIdentifier.java
index b28d4549646..73673654d12 100644
--- a/logstash-core/src/main/java/org/logstash/secret/SecretIdentifier.java
+++ b/logstash-core/src/main/java/org/logstash/secret/SecretIdentifier.java
@@ -79,7 +79,7 @@ public int hashCode() {
     }
 
     /**
-     * Converts this object to a format acceptable external {@link String} format. Note - no gauruntees are made with respect to encoding or safe use. For example, the external
+     * Converts this object to a format acceptable external {@link String} format. Note - no guarantees are made with respect to encoding or safe use. For example, the external
      * format may not be URL safely encoded.
      *
      * @return the externally formatted {@link String}
diff --git a/logstash-core/src/test/java/org/logstash/EventTest.java b/logstash-core/src/test/java/org/logstash/EventTest.java
index 3e0f63b101a..405e7d91a18 100644
--- a/logstash-core/src/test/java/org/logstash/EventTest.java
+++ b/logstash-core/src/test/java/org/logstash/EventTest.java
@@ -435,7 +435,7 @@ public void metadataFieldsShouldBeValuefied() {
     }
 
     @Test
-    public void metadataRootShouldBeValueified() {
+    public void metadataRootShouldBeValuefied() {
         final Event event = new Event();
 
         final Map<String, Object> metadata = new HashMap<>();
diff --git a/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java b/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
index b658460329d..a01c95c9da6 100644
--- a/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
+++ b/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
@@ -570,7 +570,7 @@ public void resumeWriteOnNoLongerFullQueueTest() throws IOException, Interrupted
 
             assertThat(q.isFull(), is(false));
 
-            // read 1 page (10 events) here while not full yet so that the read will not singal the not full state
+            // read 1 page (10 events) here while not full yet so that the read will not signal the not full state
             // we want the batch closing below to signal the not full state
             Batch b = q.readBatch(10, TimeUnit.SECONDS.toMillis(1));
 
@@ -915,7 +915,7 @@ public void testZeroByteFullyAckedPageOnOpen() throws IOException {
             q.write(element2);
             assertThat(q.tailPages.size(), is(1));
 
-            // work directly on the tail page and not the queue to avoid habing the queue purge the page
+            // work directly on the tail page and not the queue to avoid having the queue purge the page
             // but make sure the tail page checkpoint marks it as fully acked
             Page tp = q.tailPages.get(0);
             Batch b = new Batch(tp.read(1), q);
diff --git a/logstash-core/src/test/java/org/logstash/ackedqueue/io/LongVectorTest.java b/logstash-core/src/test/java/org/logstash/ackedqueue/io/LongVectorTest.java
index 6655f47c670..10c20ebcc36 100644
--- a/logstash-core/src/test/java/org/logstash/ackedqueue/io/LongVectorTest.java
+++ b/logstash-core/src/test/java/org/logstash/ackedqueue/io/LongVectorTest.java
@@ -21,7 +21,7 @@ public void storesAndResizes() {
     }
 
     @Test
-    public void storesVecorAndResizes() {
+    public void storesVectorAndResizes() {
         final int count = 1000;
         final LongVector vector1 = new LongVector(count);
         for (long i = 0L; i < count; ++i) {
diff --git a/logstash-core/src/test/resources/org/logstash/config/ir/complex.cfg b/logstash-core/src/test/resources/org/logstash/config/ir/complex.cfg
index 216969520b8..b00085e6bdf 100644
--- a/logstash-core/src/test/resources/org/logstash/config/ir/complex.cfg
+++ b/logstash-core/src/test/resources/org/logstash/config/ir/complex.cfg
@@ -1813,7 +1813,7 @@ filter {
 			}		
 			mutate {
 				add_field => [ "received_at", "%{@timestamp}" ]
-				id => "filter_mutate_nginx-access_add_receieved_at"
+				id => "filter_mutate_nginx-access_add_received_at"
 			}
 		}
 	}
diff --git a/qa/README.md b/qa/README.md
index 6d4b09820f5..c9ae013002d 100644
--- a/qa/README.md
+++ b/qa/README.md
@@ -123,7 +123,7 @@ Important bits here are:
 have to go under specific bootstrap scripts (see ```specific: true ```
 in the platform definition).
 
-This file is the one that you will use to know about differnt OS's
+This file is the one that you will use to know about different OS's
 testes, add new ones, etc..
 
 ### I want to add a test, what should I do?
diff --git a/qa/integration/services/logstash_service.rb b/qa/integration/services/logstash_service.rb
index ce571514eed..5f0f603cfb8 100644
--- a/qa/integration/services/logstash_service.rb
+++ b/qa/integration/services/logstash_service.rb
@@ -50,7 +50,7 @@ def initialize(settings)
 
   def alive?
     if @process.nil? || @process.exited?
-      raise "Logstash process is not up because of an errot, or it stopped"
+      raise "Logstash process is not up because of an error, or it stopped"
     else
       @process.alive?
     end
diff --git a/qa/integration/specs/cli/http_proxy_install_spec.rb b/qa/integration/specs/cli/http_proxy_install_spec.rb
index 92c5675f508..9ffcef5cdc5 100644
--- a/qa/integration/specs/cli/http_proxy_install_spec.rb
+++ b/qa/integration/specs/cli/http_proxy_install_spec.rb
@@ -9,7 +9,7 @@
 require "fileutils"
 
 # Theses tests doesn't currently work on Travis, since we need to run them in a sudo
-# environment and we do that other tests are faillings. This is probably due to IPv4 vs IPv6 settings
+# environment and we do that other tests are failings. This is probably due to IPv4 vs IPv6 settings
 # in the VM vs the container.
 #
 # We are working to bring the test to our internal Jenkins environment.
diff --git a/spec/unit/plugin_manager/proxy_support_spec.rb b/spec/unit/plugin_manager/proxy_support_spec.rb
index 432f78cd41b..4e7df213a57 100644
--- a/spec/unit/plugin_manager/proxy_support_spec.rb
+++ b/spec/unit/plugin_manager/proxy_support_spec.rb
@@ -1,4 +1,4 @@
-# encoeing: utf-8
+# encoding: utf-8
 require "pluginmanager/proxy_support"
 require "rexml/document"
 require "fileutils"
diff --git a/x-pack/lib/monitoring/inputs/metrics.rb b/x-pack/lib/monitoring/inputs/metrics.rb
index 6f77f0bea93..fc133b9d983 100644
--- a/x-pack/lib/monitoring/inputs/metrics.rb
+++ b/x-pack/lib/monitoring/inputs/metrics.rb
@@ -11,8 +11,8 @@
 require "thread"
 
 module LogStash module Inputs
-  # The Metrics input recieves periodic metric data snapshot from Logstash core.
-  # This input is responsible for registring itself to the collector.
+  # The Metrics input receives periodic metric data snapshot from Logstash core.
+  # This input is responsible for registering itself to the collector.
   # The collector class will periodically emits new snapshot of the system, JVM and other metric data.
   # This input further transform it into a `Logstash::Event`, which can be consumed by the shipper and
   # shipped to Elasticsearch
diff --git a/x-pack/spec/monitoring/inputs/timer_task_logger_spec.rb b/x-pack/spec/monitoring/inputs/timer_task_logger_spec.rb
index c137b066e47..32388961c38 100644
--- a/x-pack/spec/monitoring/inputs/timer_task_logger_spec.rb
+++ b/x-pack/spec/monitoring/inputs/timer_task_logger_spec.rb
@@ -13,7 +13,7 @@
     let(:result) { :dummy_result }
 
     context "when there is no exception" do
-      it "succesfully run" do
+      it "successfully run" do
         expect { subject.update(run_at, result, nil) }.not_to raise_error
       end
     end
