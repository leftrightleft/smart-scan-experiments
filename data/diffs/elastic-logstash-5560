diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index aded23ba5b5..d2bd7dddc13 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -33,7 +33,9 @@ module LogStash; class Pipeline
     :thread,
     :config_str,
     :settings,
-    :metric
+    :metric,
+    :filter_queue_client,
+    :input_queue_client
 
   MAX_INFLIGHT_WARN_THRESHOLD = 10_000
 
@@ -82,14 +84,18 @@ def initialize(config_str, settings = LogStash::SETTINGS, namespaced_metric = ni
       raise
     end
 
-    @input_queue = LogStash::Util::WrappedSynchronousQueue.new
+    queue = LogStash::Util::WrappedSynchronousQueue.new
+    @input_queue_client = queue.write_client
+    @filter_queue_client = queue.read_client
+    # Note that @infilght_batches as a central mechanism for tracking inflight
+    # batches will fail if we have multiple read clients here.
+    @filter_queue_client.set_events_metric(metric.namespace([:stats, :events]))
+    @filter_queue_client.set_pipeline_metric(
+        metric.namespace([:stats, :pipelines, pipeline_id.to_s.to_sym, :events])
+    )
     @events_filtered = Concurrent::AtomicFixnum.new(0)
     @events_consumed = Concurrent::AtomicFixnum.new(0)
 
-    # We generally only want one thread at a time able to access pop/take/poll operations
-    # from this queue. We also depend on this to be able to block consumers while we snapshot
-    # in-flight buffers
-    @input_queue_pop_mutex = Mutex.new
     @input_threads = []
     # @ready requires thread safety since it is typically polled from outside the pipeline thread
     @ready = Concurrent::AtomicBoolean.new(false)
@@ -176,8 +182,6 @@ def stopped?
   end
 
   def start_workers
-    @inflight_batches = {}
-
     @worker_threads.clear # In case we're restarting the pipeline
     begin
       start_inputs
@@ -187,13 +191,14 @@ def start_workers
       pipeline_workers = safe_pipeline_worker_count
       batch_size = @settings.get("pipeline.batch.size")
       batch_delay = @settings.get("pipeline.batch.delay")
+
       max_inflight = batch_size * pipeline_workers
 
-      config_metric = metric.namespace([:stats, :pipelines, pipeline_id.to_s.to_sym, :config])   
+      config_metric = metric.namespace([:stats, :pipelines, pipeline_id.to_s.to_sym, :config])
       config_metric.gauge(:workers, pipeline_workers)
       config_metric.gauge(:batch_size, batch_size)
       config_metric.gauge(:batch_delay, batch_delay)
-      
+
       @logger.info("Starting pipeline",
                    "id" => self.pipeline_id,
                    "pipeline.workers" => pipeline_workers,
@@ -211,7 +216,7 @@ def start_workers
         end
       end
     ensure
-      # it is important to garantee @ready to be true after the startup sequence has been completed
+      # it is important to guarantee @ready to be true after the startup sequence has been completed
       # to potentially unblock the shutdown method which may be waiting on @ready to proceed
       @ready.make_true
     end
@@ -222,73 +227,39 @@ def start_workers
   def worker_loop(batch_size, batch_delay)
     running = true
 
-    namespace_events = metric.namespace([:stats, :events])
-    namespace_pipeline = metric.namespace([:stats, :pipelines, pipeline_id.to_s.to_sym, :events])
+    @filter_queue_client.set_batch_dimensions(batch_size, batch_delay)
 
     while running
-      # To understand the purpose behind this synchronize please read the body of take_batch
-      input_batch, signal = @input_queue_pop_mutex.synchronize { take_batch(batch_size, batch_delay) }
-      running = false if signal == LogStash::SHUTDOWN
-
-      @events_consumed.increment(input_batch.size)
-      namespace_events.increment(:in, input_batch.size)
-      namespace_pipeline.increment(:in, input_batch.size)
+      batch = @filter_queue_client.take_batch
+      @events_consumed.increment(batch.size)
+      running = false if batch.shutdown_signal_received?
+      filter_batch(batch)
 
-      filtered_batch = filter_batch(input_batch)
-
-      if signal # Flush on SHUTDOWN or FLUSH
-        flush_options = (signal == LogStash::SHUTDOWN) ? {:final => true} : {}
-        flush_filters_to_batch(filtered_batch, flush_options)
+      if batch.shutdown_signal_received? || batch.flush_signal_received?
+        flush_filters_to_batch(batch)
       end
 
-      @events_filtered.increment(filtered_batch.size)
-
-      namespace_events.increment(:filtered, filtered_batch.size)
-      namespace_pipeline.increment(:filtered, filtered_batch.size)
-
-      output_batch(filtered_batch)
-
-      namespace_events.increment(:out, filtered_batch.size)
-      namespace_pipeline.increment(:out, filtered_batch.size)
-
-      inflight_batches_synchronize { set_current_thread_inflight_batch(nil) }
+      output_batch(batch)
+      @filter_queue_client.close_batch(batch)
     end
   end
 
-  def take_batch(batch_size, batch_delay)
-    batch = []
-    # Since this is externally synchronized in `worker_look` wec can guarantee that the visibility of an insight batch
-    # guaranteed to be a full batch not a partial batch
-    set_current_thread_inflight_batch(batch)
-
-    signal = false
-    batch_size.times do |t|
-      event = (t == 0) ? @input_queue.take : @input_queue.poll(batch_delay)
-
-      if event.nil?
-        next
-      elsif event == LogStash::SHUTDOWN || event == LogStash::FLUSH
-        # We MUST break here. If a batch consumes two SHUTDOWN events
-        # then another worker may have its SHUTDOWN 'stolen', thus blocking
-        # the pipeline. We should stop doing work after flush as well.
-        signal = event
-        break
-      else
-        batch << event
-      end
-    end
-
-    [batch, signal]
-  end
-
   def filter_batch(batch)
-    batch.reduce([]) do |acc,e|
-      if e.is_a?(LogStash::Event)
-        filtered = filter_func(e)
-        filtered.each {|fe| acc << fe unless fe.cancelled?}
+    batch.each do |event|
+      if event.is_a?(LogStash::Event)
+        filtered = filter_func(event)
+        filtered.each do |e|
+          #these are both original and generated events
+          if e.cancelled?
+            batch.cancel(e)
+          else
+            batch.merge(e)
+          end
+        end
       end
-      acc
     end
+    @filter_queue_client.add_filtered_metrics(batch)
+    @events_filtered.increment(batch.size)
   rescue Exception => e
     # Plugins authors should manage their own exceptions in the plugin code
     # but if an exception is raised up to the worker thread they are considered
@@ -304,31 +275,21 @@ def filter_batch(batch)
   # Take an array of events and send them to the correct output
   def output_batch(batch)
     # Build a mapping of { output_plugin => [events...]}
-    outputs_events = batch.reduce(Hash.new { |h, k| h[k] = [] }) do |acc, event|
+    output_events_map = Hash.new { |h, k| h[k] = [] }
+    batch.each do |event|
       # We ask the AST to tell us which outputs to send each event to
       # Then, we stick it in the correct bin
 
       # output_func should never return anything other than an Array but we have lots of legacy specs
       # that monkeypatch it and return nil. We can deprecate  "|| []" after fixing these specs
-      outputs_for_event = output_func(event) || []
-
-      outputs_for_event.each { |output| acc[output] << event }
-      acc
+      (output_func(event) || []).each do |output|
+        output_events_map[output].push(event)
+      end
     end
-
     # Now that we have our output to event mapping we can just invoke each output
     # once with its list of events
-    outputs_events.each { |output, events| output.multi_receive(events) }
-  end
-
-  def set_current_thread_inflight_batch(batch)
-    @inflight_batches[Thread.current] = batch
-  end
-
-  def inflight_batches_synchronize
-    @input_queue_pop_mutex.synchronize do
-      yield(@inflight_batches)
-    end
+    output_events_map.each { |output, events| output.multi_receive(events) }
+    @filter_queue_client.add_output_metrics(batch)
   end
 
   def wait_inputs
@@ -359,7 +320,7 @@ def start_input(plugin)
   def inputworker(plugin)
     LogStash::Util::set_thread_name("[#{pipeline_id}]<#{plugin.class.config_name}")
     begin
-      plugin.run(@input_queue)
+      plugin.run(@input_queue_client)
     rescue => e
       if plugin.stop?
         @logger.debug("Input plugin raised exception during shutdown, ignoring it.",
@@ -413,7 +374,7 @@ def shutdown_workers
     # Each worker thread will receive this exactly once!
     @worker_threads.each do |t|
       @logger.debug("Pushing shutdown", :thread => t.inspect)
-      @input_queue.push(LogStash::SHUTDOWN)
+      @input_queue_client.push(LogStash::SHUTDOWN)
     end
 
     @worker_threads.each do |t|
@@ -453,7 +414,7 @@ def filter(event, &block)
   end
 
 
-  # perform filters flush and yeild flushed event to the passed block
+  # perform filters flush and yield flushed event to the passed block
   # @param options [Hash]
   # @option options [Boolean] :final => true to signal a final shutdown flush
   def flush_filters(options = {}, &block)
@@ -483,7 +444,7 @@ def shutdown_flusher
   def flush
     if @flushing.compare_and_set(false, true)
       @logger.debug? && @logger.debug("Pushing flush onto pipeline")
-      @input_queue.push(LogStash::FLUSH)
+      @input_queue_client.push(LogStash::FLUSH)
     end
   end
 
@@ -497,18 +458,22 @@ def uptime
   end
 
   # perform filters flush into the output queue
+  #
+  # @param batch [ReadClient::ReadBatch]
   # @param options [Hash]
-  # @option options [Boolean] :final => true to signal a final shutdown flush
   def flush_filters_to_batch(batch, options = {})
+    options[:final] = batch.shutdown_signal_received?
     flush_filters(options) do |event|
-      unless event.cancelled?
+      if event.cancelled?
+        batch.cancel(event)
+      else
         @logger.debug? and @logger.debug("Pushing flushed events", :event => event)
-        batch << event
+        batch.merge(event)
       end
     end
 
     @flushing.set(false)
-  end # flush_filters_to_output!
+  end # flush_filters_to_batch
 
   def plugin_threads_info
     input_threads = @input_threads.select {|t| t.alive? }
diff --git a/logstash-core/lib/logstash/pipeline_reporter.rb b/logstash-core/lib/logstash/pipeline_reporter.rb
index c7ae6ca847c..31aaf28416e 100644
--- a/logstash-core/lib/logstash/pipeline_reporter.rb
+++ b/logstash-core/lib/logstash/pipeline_reporter.rb
@@ -39,7 +39,7 @@ def format_threads_by_plugin
     end
   end
 
-  def initialize(logger,pipeline)
+  def initialize(logger, pipeline)
     @logger = logger
     @pipeline = pipeline
   end
@@ -52,7 +52,8 @@ def snapshot
   end
 
   def to_hash
-    pipeline.inflight_batches_synchronize do |batch_map|
+    # pipeline.filter_queue_client.inflight_batches is synchronized
+    pipeline.filter_queue_client.inflight_batches do |batch_map|
       worker_states_snap = worker_states(batch_map) # We only want to run this once
       inflight_count = worker_states_snap.map {|s| s[:inflight_count] }.reduce(0, :+)
 
@@ -83,17 +84,17 @@ def plugin_threads
     pipeline.plugin_threads
   end
 
-  # Not threadsafe! must be called within an `inflight_batches_synchronize` block
+  # Not threadsafe! ensure synchronization
   def worker_states(batch_map)
-      pipeline.worker_threads.map.with_index do |thread,idx|
-        status = thread.status || "dead"
-        inflight_count = batch_map[thread] ? batch_map[thread].size : 0
-        {
-          :status => status,
-          :alive => thread.alive?,
-          :index => idx,
-          :inflight_count => inflight_count
-        }
+    pipeline.worker_threads.map.with_index do |thread, idx|
+      status = thread.status || "dead"
+      inflight_count = batch_map[thread] ? batch_map[thread].size : 0
+      {
+        :status => status,
+        :alive => thread.alive?,
+        :index => idx,
+        :inflight_count => inflight_count
+      }
     end
   end
 
@@ -111,4 +112,4 @@ def output_info
       }
     end
   end
-end end
\ No newline at end of file
+end end
diff --git a/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb b/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
index a8822ca0af5..9cb8c5ecfa1 100644
--- a/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
+++ b/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
@@ -37,5 +37,225 @@ def take
     def poll(millis)
       @queue.poll(millis, TimeUnit::MILLISECONDS)
     end
+
+    def write_client
+      WriteClient.new(self)
+    end
+
+    def read_client()
+      ReadClient.new(self)
+    end
+
+    class ReadClient
+      # We generally only want one thread at a time able to access pop/take/poll operations
+      # from this queue. We also depend on this to be able to block consumers while we snapshot
+      # in-flight buffers
+
+      def initialize(queue, batch_size = 125, wait_for = 5)
+        @queue = queue
+        @mutex = Mutex.new
+        # Note that @infilght_batches as a central mechanism for tracking inflight
+        # batches will fail if we have multiple read clients in the pipeline.
+        @inflight_batches = {}
+        @batch_size = batch_size
+        @wait_for = wait_for
+      end
+
+      def set_batch_dimensions(batch_size, wait_for)
+        @batch_size = batch_size
+        @wait_for = wait_for
+      end
+
+      def set_events_metric(metric)
+        @event_metric = metric
+      end
+
+      def set_pipeline_metric(metric)
+        @pipeline_metric = metric
+      end
+
+      def inflight_batches
+        @mutex.synchronize do
+          yield(@inflight_batches)
+        end
+      end
+
+      def current_inflight_batch
+        @inflight_batches.fetch(Thread.current, [])
+      end
+
+      def take_batch
+        @mutex.synchronize do
+          batch = ReadBatch.new(@queue, @batch_size, @wait_for)
+          add_starting_metrics(batch)
+          set_current_thread_inflight_batch(batch)
+          batch
+        end
+      end
+
+      def set_current_thread_inflight_batch(batch)
+        @inflight_batches[Thread.current] = batch
+      end
+
+      def close_batch(batch)
+        @mutex.synchronize do
+          @inflight_batches.delete(Thread.current)
+        end
+      end
+
+      def add_starting_metrics(batch)
+        return if @event_metric.nil? || @pipeline_metric.nil?
+        @event_metric.increment(:in, batch.starting_size)
+        @pipeline_metric.increment(:in, batch.starting_size)
+      end
+
+      def add_filtered_metrics(batch)
+        @event_metric.increment(:filtered, batch.filtered_size)
+        @pipeline_metric.increment(:filtered, batch.filtered_size)
+      end
+
+      def add_output_metrics(batch)
+        @event_metric.increment(:out, batch.filtered_size)
+        @pipeline_metric.increment(:out, batch.filtered_size)
+      end
+    end
+
+    class ReadBatch
+      def initialize(queue, size, wait)
+        @shutdown_signal_received = false
+        @flush_signal_received = false
+        @originals = Hash.new
+        @cancelled = Hash.new
+        @generated = Hash.new
+        @iterating_temp = Hash.new
+        @iterating = false # Atomic Boolean maybe? Although batches are not shared across threads
+        take_originals_from_queue(queue, size, wait)
+      end
+
+      def merge(event)
+        return if event.nil? || @originals.key?(event)
+        # take care not to cause @generated to change during iteration
+        # @iterating_temp is merged after the iteration
+        if iterating?
+          @iterating_temp[event] = true
+        else
+          # the periodic flush could generate events outside of an each iteration
+          @generated[event] = true
+        end
+      end
+
+      def cancel(event)
+        @cancelled[event] = true
+      end
+
+      def each(&blk)
+        # take care not to cause @originals or @generated to change during iteration
+        @iterating = true
+        @originals.each do |e, _|
+          blk.call(e) unless @cancelled.include?(e)
+        end
+        @generated.each do |e, _|
+          blk.call(e) unless @cancelled.include?(e)
+        end
+        @iterating = false
+        update_generated
+      end
+
+      def size
+        filtered_size
+      end
+
+      def starting_size
+        @originals.size
+      end
+
+      def filtered_size
+        @originals.size + @generated.size
+      end
+
+      def cancelled_size
+        @cancelled.size
+      end
+
+      def shutdown_signal_received?
+        @shutdown_signal_received
+      end
+
+      def flush_signal_received?
+        @flush_signal_received
+      end
+
+      private
+
+      def iterating?
+        @iterating
+      end
+
+      def update_generated
+        @generated.update(@iterating_temp)
+        @iterating_temp.clear
+      end
+
+      def take_originals_from_queue(queue, size, wait)
+        size.times do |t|
+          event = (t == 0) ? queue.take : queue.poll(wait)
+          if event.nil?
+            # queue poll timed out
+            next
+          elsif event == LogStash::SHUTDOWN
+            # We MUST break here. If a batch consumes two SHUTDOWN events
+            # then another worker may have its SHUTDOWN 'stolen', thus blocking
+            # the pipeline.
+            @shutdown_signal_received = true
+            break
+          elsif event == LogStash::FLUSH
+            # See comment above
+            # We should stop doing work after flush as well.
+            @flush_signal_received = true
+            break
+          else
+            @originals[event] = true
+          end
+        end
+      end
+    end
+
+    class WriteClient
+      def initialize(queue)
+        @queue = queue
+      end
+
+      def get_new_batch
+        WriteBatch.new
+      end
+
+      def push(event)
+        @queue.push(event)
+      end
+      alias_method(:<<, :push)
+
+      def push_batch(batch)
+        batch.each do |event|
+          push(event)
+        end
+      end
+    end
+
+    class WriteBatch
+      def initialize
+        @events = []
+      end
+
+      def push(event)
+        @events.push(event)
+      end
+      alias_method(:<<, :push)
+
+      def each(&blk)
+        @events.each do |e|
+          blk.call(e)
+        end
+      end
+    end
   end
 end end
diff --git a/logstash-core/spec/logstash/pipeline_spec.rb b/logstash-core/spec/logstash/pipeline_spec.rb
index 823e2cb5df9..a0290b1da16 100644
--- a/logstash-core/spec/logstash/pipeline_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_spec.rb
@@ -360,7 +360,6 @@ class TestPipeline < LogStash::Pipeline
   end
 
   context "compiled filter funtions" do
-
     context "new events should propagate down the filters" do
       config <<-CONFIG
         filter {
@@ -466,11 +465,12 @@ class TestPipeline < LogStash::Pipeline
       pipeline = LogStash::Pipeline.new(config, pipeline_settings_obj)
       Thread.new { pipeline.run }
       sleep 0.1 while !pipeline.ready?
-      # give us a bit of time to flush the events
       wait(5).for do
-        next unless output && output.events && !(event = output.events.pop).nil?
-        event.get("message").split("\n").count
-      end.to eq(number_of_events)
+        # give us a bit of time to flush the events
+        output.events.empty?
+      end.to be_falsey
+      event = output.events.pop
+      expect(event.get("message").count("\n")).to eq(99)
       pipeline.shutdown
     end
   end
@@ -604,7 +604,7 @@ class TestPipeline < LogStash::Pipeline
 
       Thread.new { subject.run }
       # make sure we have received all the generated events
-      sleep 1 while dummyoutput.events.size < number_of_events
+      sleep 0.25 while dummyoutput.events.size < number_of_events
     end
 
     after :each do
@@ -614,7 +614,7 @@ class TestPipeline < LogStash::Pipeline
     context "global metric" do
       let(:collected_metric) { metric_store.get_with_path("stats/events") }
 
-      it "populates the differents" do
+      it "populates the different metrics" do
         expect(collected_metric[:stats][:events][:in].value).to eq(number_of_events)
         expect(collected_metric[:stats][:events][:filtered].value).to eq(number_of_events)
         expect(collected_metric[:stats][:events][:out].value).to eq(number_of_events)
diff --git a/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb b/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb
index 871952482aa..12317f838a9 100644
--- a/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb
+++ b/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb
@@ -3,26 +3,74 @@
 require "logstash/util/wrapped_synchronous_queue"
 
 describe LogStash::Util::WrappedSynchronousQueue do
- context "#offer" do
-   context "queue is blocked" do
-     it "fails and give feedback" do
-       expect(subject.offer("Bonjour", 2)).to be_falsey
-     end
-   end
-
-   context "queue is not blocked" do
-     before do
-       @consumer = Thread.new { loop { subject.take } }
-       sleep(0.1)
-     end
-
-     after do
-       @consumer.kill
-     end
-     
-     it "inserts successfully" do
-       expect(subject.offer("Bonjour", 20)).to be_truthy
-     end
-   end
- end
+  context "#offer" do
+    context "queue is blocked" do
+      it "fails and give feedback" do
+        expect(subject.offer("Bonjour", 2)).to be_falsey
+      end
+    end
+
+    context "queue is not blocked" do
+      before do
+        @consumer = Thread.new { loop { subject.take } }
+        sleep(0.1)
+      end
+
+      after do
+        @consumer.kill
+      end
+
+      it "inserts successfully" do
+        expect(subject.offer("Bonjour", 20)).to be_truthy
+      end
+    end
+  end
+
+  describe "queue clients" do
+    context "when requesting a write client" do
+      it "returns a client" do
+        expect(subject.write_client).to be_a(LogStash::Util::WrappedSynchronousQueue::WriteClient)
+      end
+    end
+
+    context "when requesting a read client" do
+      it "returns a client" do
+        expect(subject.read_client).to be_a(LogStash::Util::WrappedSynchronousQueue::ReadClient)
+      end
+    end
+
+    class DummyQueue < Array
+      def take() shift(); end
+      def poll(*) shift(); end
+    end
+
+    describe "WriteClient | ReadClient" do
+      context "when writing to the queue" do
+        let(:queue) { DummyQueue.new }
+        let(:write_client) { LogStash::Util::WrappedSynchronousQueue::WriteClient.new(queue)}
+        let(:read_client)  { LogStash::Util::WrappedSynchronousQueue::ReadClient.new(queue)}
+        it "appends batches to the queue" do
+          batch = write_client.get_new_batch
+          5.times {|i| batch.push("value-#{i}")}
+          write_client.push_batch(batch)
+          read_batch = read_client.take_batch
+          expect(read_batch.size).to eq(5)
+          i = 0
+          read_batch.each do |data|
+            expect(data).to eq("value-#{i}")
+            read_batch.cancel("value-#{i}") if i > 2
+            read_batch.merge("generated-#{i}") if i > 2
+            i += 1
+          end
+          expect(read_batch.cancelled_size).to eq(2)
+          i = 0
+          read_batch.each do |data|
+            expect(data).to eq("value-#{i}") if i < 3
+            expect(data).to eq("generated-#{i}") if i > 2
+            i += 1
+          end
+        end
+      end
+    end
+  end
 end
