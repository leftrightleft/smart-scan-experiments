diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/HeadPage.java b/logstash-core/src/main/java/org/logstash/ackedqueue/HeadPage.java
deleted file mode 100644
index 870eed78aa0..00000000000
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/HeadPage.java
+++ /dev/null
@@ -1,120 +0,0 @@
-package org.logstash.ackedqueue;
-
-import org.logstash.ackedqueue.io.CheckpointIO;
-import org.logstash.ackedqueue.io.PageIO;
-
-import java.io.IOException;
-import java.util.BitSet;
-
-public class HeadPage extends Page {
-
-    // create a new HeadPage object and new page.{pageNum} empty valid data file
-    public HeadPage(int pageNum, Queue queue, PageIO pageIO) {
-        super(pageNum, queue, 0, 0, 0, new BitSet(), pageIO);
-    }
-
-    // create a new HeadPage object from an existing checkpoint and open page.{pageNum} empty valid data file
-    // @param pageIO is expected to be open/recover/create
-    public HeadPage(Checkpoint checkpoint, Queue queue, PageIO pageIO) {
-        super(checkpoint.getPageNum(), queue, checkpoint.getMinSeqNum(), checkpoint.getElementCount(), checkpoint.getFirstUnackedSeqNum(), new BitSet(), pageIO);
-
-        assert checkpoint.getMinSeqNum() == pageIO.getMinSeqNum() && checkpoint.getElementCount() == pageIO.getElementCount() :
-                String.format("checkpoint minSeqNum=%d or elementCount=%d is different than pageIO minSeqNum=%d or elementCount=%d", checkpoint.getMinSeqNum(), checkpoint.getElementCount(), pageIO.getMinSeqNum(), pageIO.getElementCount());
-
-        // this page ackedSeqNums bitset is a new empty bitset, if we have some acked elements, set them in the bitset
-        if (checkpoint.getFirstUnackedSeqNum() > checkpoint.getMinSeqNum()) {
-            this.ackedSeqNums.flip(0, (int) (checkpoint.getFirstUnackedSeqNum() - checkpoint.getMinSeqNum()));
-        }
-    }
-
-    // verify if data size plus overhead is not greater than the page capacity
-    public boolean hasCapacity(int byteSize) {
-        return this.pageIO.persistedByteCount(byteSize) <= this.pageIO.getCapacity();
-    }
-
-    public boolean hasSpace(int byteSize) {
-        return this.pageIO.hasSpace((byteSize));
-    }
-
-    public void write(byte[] bytes, long seqNum, int checkpointMaxWrites) throws IOException {
-        this.pageIO.write(bytes, seqNum);
-
-        if (this.minSeqNum <= 0) {
-            this.minSeqNum = seqNum;
-            this.firstUnreadSeqNum = seqNum;
-        }
-        this.elementCount++;
-
-        // force a checkpoint if we wrote checkpointMaxWrites elements since last checkpoint
-        // the initial condition of an "empty" checkpoint, maxSeqNum() will return -1
-        if (checkpointMaxWrites > 0 && (seqNum >= this.lastCheckpoint.maxSeqNum() + checkpointMaxWrites)) {
-            // did we write more than checkpointMaxWrites elements? if so checkpoint now
-            checkpoint();
-        }
-    }
-
-    public void ensurePersistedUpto(long seqNum) throws IOException {
-        long lastCheckpointUptoSeqNum = this.lastCheckpoint.getMinSeqNum() + this.lastCheckpoint.getElementCount();
-
-        // if the last checkpoint for this headpage already included the given seqNum, no need to fsync/checkpoint
-        if (seqNum > lastCheckpointUptoSeqNum) {
-            // head page checkpoint does a data file fsync
-            checkpoint();
-        }
-    }
-
-    public TailPage behead() throws IOException {
-        checkpoint();
-
-        TailPage tailPage = new TailPage(this);
-
-        // first thing that must be done after beheading is to create a new checkpoint for that new tail page
-        // tail page checkpoint does NOT includes a fsync
-        tailPage.checkpoint();
-
-        // TODO: should we have a better deactivation strategy to avoid too rapid reactivation scenario?
-        Page firstUnreadPage = queue.firstUnreadPage();
-        if (firstUnreadPage == null || (tailPage.getPageNum() > firstUnreadPage.getPageNum())) {
-            // deactivate if this new tailPage is not where the read is occurring
-            tailPage.getPageIO().deactivate();
-        }
-
-        return tailPage;
-    }
-
-    // head page checkpoint, fsync data page if writes occured since last checkpoint
-    // update checkpoint only if it changed since lastCheckpoint
-    public void checkpoint() throws IOException {
-
-         if (this.elementCount > this.lastCheckpoint.getElementCount()) {
-             // fsync & checkpoint if data written since last checkpoint
-
-             this.pageIO.ensurePersisted();
-             forceCheckpoint();
-        } else {
-             Checkpoint checkpoint = new Checkpoint(this.pageNum, this.queue.firstUnackedPageNum(), firstUnackedSeqNum(), this.minSeqNum, this.elementCount);
-             if (! checkpoint.equals(this.lastCheckpoint)) {
-                 // checkpoint only if it changed since last checkpoint
-
-                 // non-dry code with forceCheckpoint() to avoid unnecessary extra new Checkpoint object creation
-                 CheckpointIO io = queue.getCheckpointIO();
-                 io.write(io.headFileName(), checkpoint);
-                 this.lastCheckpoint = checkpoint;
-             }
-         }
-      }
-
-    // unconditionally update head checkpoint
-    public void forceCheckpoint() throws IOException {
-        Checkpoint checkpoint = new Checkpoint(this.pageNum, this.queue.firstUnackedPageNum(), firstUnackedSeqNum(), this.minSeqNum, this.elementCount);
-        CheckpointIO io = queue.getCheckpointIO();
-        io.write(io.headFileName(), checkpoint);
-        this.lastCheckpoint = checkpoint;
-    }
-
-    public void close() throws IOException {
-        checkpoint();
-        this.pageIO.close();
-    }
-
-}
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/Page.java b/logstash-core/src/main/java/org/logstash/ackedqueue/Page.java
index 9abdfe1f02b..f09990d9a45 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/Page.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/Page.java
@@ -2,19 +2,20 @@
 
 import java.io.Closeable;
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.BitSet;
-import java.util.List;
+
+import org.logstash.ackedqueue.io.CheckpointIO;
 import org.logstash.ackedqueue.io.LongVector;
 import org.logstash.ackedqueue.io.PageIO;
 
-public abstract class Page implements Closeable {
+public final class Page implements Closeable {
     protected final int pageNum;
     protected long minSeqNum; // TODO: see if we can make it final?
     protected int elementCount;
     protected long firstUnreadSeqNum;
     protected final Queue queue;
     protected PageIO pageIO;
+    private boolean writable;
 
     // bit 0 is minSeqNum
     // TODO: go steal LocalCheckpointService in feature/seq_no from ES
@@ -22,7 +23,7 @@ public abstract class Page implements Closeable {
     protected BitSet ackedSeqNums;
     protected Checkpoint lastCheckpoint;
 
-    public Page(int pageNum, Queue queue, long minSeqNum, int elementCount, long firstUnreadSeqNum, BitSet ackedSeqNums, PageIO pageIO) {
+    public Page(int pageNum, Queue queue, long minSeqNum, int elementCount, long firstUnreadSeqNum, BitSet ackedSeqNums, PageIO pageIO, boolean writable) {
         this.pageNum = pageNum;
         this.queue = queue;
 
@@ -32,6 +33,7 @@ public Page(int pageNum, Queue queue, long minSeqNum, int elementCount, long fir
         this.ackedSeqNums = ackedSeqNums;
         this.lastCheckpoint = new Checkpoint(0, 0, 0, 0, 0);
         this.pageIO = pageIO;
+        this.writable = writable;
     }
 
     public String toString() {
@@ -39,11 +41,11 @@ public String toString() {
     }
 
     /**
-     * @param limit the maximum number of elements to read
-     * @return {@link SequencedList} collection of elements read. the number of elements can be {@literal <=} limit
+     * @param limit the maximum number of elements to read, actual number readcan be smaller
+     * @return {@link SequencedList} collection of serialized elements read
+     * @throws IOException
      */
     public SequencedList<byte[]> read(int limit) throws IOException {
-
         // first make sure this page is activated, activating previously activated is harmless
         this.pageIO.activate();
 
@@ -56,6 +58,27 @@ public SequencedList<byte[]> read(int limit) throws IOException {
         return serialized;
     }
 
+    public void write(byte[] bytes, long seqNum, int checkpointMaxWrites) throws IOException {
+        if (! this.writable) {
+            throw new IllegalStateException(String.format("page=%d is not writable", this.pageNum));
+        }
+
+        this.pageIO.write(bytes, seqNum);
+
+        if (this.minSeqNum <= 0) {
+            this.minSeqNum = seqNum;
+            this.firstUnreadSeqNum = seqNum;
+        }
+        this.elementCount++;
+
+        // force a checkpoint if we wrote checkpointMaxWrites elements since last checkpoint
+        // the initial condition of an "empty" checkpoint, maxSeqNum() will return -1
+        if (checkpointMaxWrites > 0 && (seqNum >= this.lastCheckpoint.maxSeqNum() + checkpointMaxWrites)) {
+            // did we write more than checkpointMaxWrites elements? if so checkpoint now
+            checkpoint();
+        }
+    }
+
     /**
      * Page is considered empty if it does not contain any element or if all elements are acked.
      *
@@ -83,14 +106,17 @@ public long unreadCount() {
         return this.elementCount <= 0 ? 0 : Math.max(0, (maxSeqNum() - this.firstUnreadSeqNum) + 1);
     }
 
-    // update the page acking bitset. trigger checkpoint on the page if it is fully acked or if we acked more than the
-    // configured threshold checkpointMaxAcks.
-    // note that if the fully acked tail page is the first unacked page, it is not really necessary to also checkpoint
-    // the head page to update firstUnackedPageNum because it will be updated in the next upcoming head page checkpoint
-    // and in a crash condition, the Queue open recovery will detect and purge fully acked pages
-    //
-    // @param seqNums the list of same-page seqNums to ack
-    // @param checkpointMaxAcks the number of acks that will trigger a page checkpoint
+    /**
+     * update the page acking bitset. trigger checkpoint on the page if it is fully acked or if we acked more than the
+     * configured threshold checkpointMaxAcks.
+     * note that if the fully acked tail page is the first unacked page, it is not really necessary to also checkpoint
+     * the head page to update firstUnackedPageNum because it will be updated in the next upcoming head page checkpoint
+     * and in a crash condition, the Queue open recovery will detect and purge fully acked pages
+     *
+     * @param seqNums the list of same-page seqNums to ack
+     * @param checkpointMaxAcks number of acks before forcing a checkpoint
+     * @throws IOException
+     */
     public void ack(LongVector seqNums, int checkpointMaxAcks) throws IOException {
         final int count = seqNums.size();
         for (int i = 0; i < count; ++i) {
@@ -100,7 +126,7 @@ public void ack(LongVector seqNums, int checkpointMaxAcks) throws IOException {
             assert seqNum >= this.minSeqNum :
                     String.format("seqNum=%d is smaller than minSeqnum=%d", seqNum, this.minSeqNum);
 
-            assert seqNum < this.minSeqNum + this.elementCount:
+            assert seqNum < this.minSeqNum + this.elementCount :
                     String.format("seqNum=%d is greater than minSeqnum=%d + elementCount=%d = %d", seqNum, this.minSeqNum, this.elementCount, this.minSeqNum + this.elementCount);
             int index = (int)(seqNum - this.minSeqNum);
 
@@ -123,9 +149,102 @@ public void ack(LongVector seqNums, int checkpointMaxAcks) throws IOException {
         }
     }
 
-    public abstract void checkpoint() throws IOException;
+    public void checkpoint() throws IOException {
+        if (this.writable) {
+            headPageCheckpoint();
+        } else {
+            tailPageCheckpoint();
+        }
+    }
+
+    private void headPageCheckpoint() throws IOException {
+        if (this.elementCount > this.lastCheckpoint.getElementCount()) {
+            // fsync & checkpoint if data written since last checkpoint
+
+            this.pageIO.ensurePersisted();
+            this.forceCheckpoint();
+        } else {
+            Checkpoint checkpoint = new Checkpoint(this.pageNum, this.queue.firstUnackedPageNum(), this.firstUnackedSeqNum(), this.minSeqNum, this.elementCount);
+            if (! checkpoint.equals(this.lastCheckpoint)) {
+                // checkpoint only if it changed since last checkpoint
+
+                // non-dry code with forceCheckpoint() to avoid unnecessary extra new Checkpoint object creation
+                CheckpointIO io = this.queue.getCheckpointIO();
+                io.write(io.headFileName(), checkpoint);
+                this.lastCheckpoint = checkpoint;
+            }
+        }
+
+    }
+
+    public void tailPageCheckpoint() throws IOException {
+        // since this is a tail page and no write can happen in this page, there is no point in performing a fsync on this page, just stamp checkpoint
+        CheckpointIO io = this.queue.getCheckpointIO();
+        this.lastCheckpoint = io.write(io.tailFileName(this.pageNum), this.pageNum, 0, this.firstUnackedSeqNum(), this.minSeqNum, this.elementCount);
+    }
+
+
+    public void ensurePersistedUpto(long seqNum) throws IOException {
+        long lastCheckpointUptoSeqNum = this.lastCheckpoint.getMinSeqNum() + this.lastCheckpoint.getElementCount();
 
-    public abstract void close() throws IOException;
+        // if the last checkpoint for this headpage already included the given seqNum, no need to fsync/checkpoint
+        if (seqNum > lastCheckpointUptoSeqNum) {
+            // head page checkpoint does a data file fsync
+            checkpoint();
+        }
+    }
+
+    public void forceCheckpoint() throws IOException {
+        Checkpoint checkpoint = new Checkpoint(this.pageNum, this.queue.firstUnackedPageNum(), this.firstUnackedSeqNum(), this.minSeqNum, this.elementCount);
+        CheckpointIO io = this.queue.getCheckpointIO();
+        io.write(io.headFileName(), checkpoint);
+        this.lastCheckpoint = checkpoint;
+    }
+
+    public void behead() throws IOException {
+        checkpoint();
+
+        this.writable = false;
+        this.lastCheckpoint = new Checkpoint(0, 0, 0, 0, 0);
+
+        // first thing that must be done after beheading is to create a new checkpoint for that new tail page
+        // tail page checkpoint does NOT includes a fsync
+        checkpoint();
+
+        // TODO: should we have a better deactivation strategy to avoid too rapid reactivation scenario?
+        Page firstUnreadPage = queue.firstUnreadPage();
+        if (firstUnreadPage == null || (this.getPageNum() > firstUnreadPage.getPageNum())) {
+            // deactivate if this new tailPage is not where the read is occurring
+            this.getPageIO().deactivate();
+        }
+    }
+
+    public boolean hasSpace(int byteSize) {
+        return this.pageIO.hasSpace((byteSize));
+    }
+
+    /**
+     * verify if data size plus overhead is not greater than the page capacity
+     *
+     * @param byteSize the date size to verify
+     * @return true if data plus overhead fit in page
+     */
+    public boolean hasCapacity(int byteSize) {
+        return this.pageIO.persistedByteCount(byteSize) <= this.pageIO.getCapacity();
+    }
+
+    public void close() throws IOException {
+        checkpoint();
+        if (this.pageIO != null) {
+            this.pageIO.close();
+        }
+    }
+
+    public void purge() throws IOException {
+        if (this.pageIO != null) {
+            this.pageIO.purge(); // page IO purge calls close
+        }
+    }
 
     public int getPageNum() {
         return pageNum;
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/PageFactory.java b/logstash-core/src/main/java/org/logstash/ackedqueue/PageFactory.java
new file mode 100644
index 00000000000..403ec3e009a
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/PageFactory.java
@@ -0,0 +1,90 @@
+package org.logstash.ackedqueue;
+
+import org.logstash.ackedqueue.io.PageIO;
+
+import java.io.IOException;
+import java.util.BitSet;
+
+class PageFactory {
+
+    /**
+     * create a new head page object and new page.{@literal {pageNum}} empty valid data file
+     *
+     * @param pageNum the new head page page number
+     * @param queue the {@link Queue} instance
+     * @param pageIO the {@link PageIO} delegate
+     * @return {@link Page} the new head page
+     */
+    public static Page newHeadPage(int pageNum, Queue queue, PageIO pageIO) {
+        return new Page(pageNum, queue, 0, 0, 0, new BitSet(), pageIO, true);
+    }
+
+    /**
+     * create a new head page from an existing {@link Checkpoint} and open page.{@literal {pageNum}} empty valid data file
+     *
+     * @param checkpoint existing head page {@link Checkpoint}
+     * @param queue the {@link Queue} instance
+     * @param pageIO the {@link PageIO} delegate
+     * @return {@link Page} the new head page
+     */
+    public static Page newHeadPage(Checkpoint checkpoint, Queue queue, PageIO pageIO) throws IOException {
+        final Page p = new Page(
+                checkpoint.getPageNum(),
+                queue,
+                checkpoint.getMinSeqNum(),
+                checkpoint.getElementCount(),
+                checkpoint.getFirstUnackedSeqNum(),
+                new BitSet(),
+                pageIO,
+                true
+        );
+        try {
+            assert checkpoint.getMinSeqNum() == pageIO.getMinSeqNum() && checkpoint.getElementCount() == pageIO.getElementCount() :
+                    String.format("checkpoint minSeqNum=%d or elementCount=%d is different than pageIO minSeqNum=%d or elementCount=%d", checkpoint.getMinSeqNum(), checkpoint.getElementCount(), pageIO.getMinSeqNum(), pageIO.getElementCount());
+
+            // this page ackedSeqNums bitset is a new empty bitset, if we have some acked elements, set them in the bitset
+            if (checkpoint.getFirstUnackedSeqNum() > checkpoint.getMinSeqNum()) {
+                p.ackedSeqNums.flip(0, (int) (checkpoint.getFirstUnackedSeqNum() - checkpoint.getMinSeqNum()));
+            }
+
+            return p;
+        } catch (Exception e) {
+            p.close();
+            throw e;
+        }
+    }
+
+    /**
+     * create a new tail page for an exiting Checkpoint and data file
+     *
+     * @param checkpoint existing tail page {@link Checkpoint}
+     * @param queue the {@link Queue} instance
+     * @param pageIO the {@link PageIO} delegate
+     * @return {@link Page} the new tail page
+     */
+    public static Page newTailPage(Checkpoint checkpoint, Queue queue, PageIO pageIO) throws IOException {
+        final Page p = new Page(
+                checkpoint.getPageNum(),
+                queue,
+                checkpoint.getMinSeqNum(),
+                checkpoint.getElementCount(),
+                checkpoint.getFirstUnackedSeqNum(),
+                new BitSet(),
+                pageIO,
+                false
+        );
+
+        try {
+            // this page ackedSeqNums bitset is a new empty bitset, if we have some acked elements, set them in the bitset
+            if (checkpoint.getFirstUnackedSeqNum() > checkpoint.getMinSeqNum()) {
+                p.ackedSeqNums.flip(0, (int) (checkpoint.getFirstUnackedSeqNum() - checkpoint.getMinSeqNum()));
+            }
+
+            return p;
+        } catch (Exception e) {
+            p.close();
+            throw e;
+        }
+    }
+
+}
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java b/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
index 29f85f98087..1682e885619 100644
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
+++ b/logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
@@ -37,15 +37,15 @@ public final class Queue implements Closeable {
 
     private long seqNum;
 
-    protected HeadPage headPage;
+    protected Page headPage;
 
     // complete list of all non fully acked pages. note that exact sequentially by pageNum cannot be assumed
     // because any fully acked page will be removed from this list potentially creating pageNum gaps in the list.
-    protected final List<TailPage> tailPages;
+    protected final List<Page> tailPages;
 
     // this list serves the only purpose of quickly retrieving the first unread page, operation necessary on every read
     // reads will simply remove the first page from the list when fully read and writes will append new pages upon beheading
-    protected final List<TailPage> unreadTailPages;
+    protected final List<Page> unreadTailPages;
 
     // checkpoints that were not purged in the acking code to keep contiguous checkpoint files
     // regardless of the correcponding data file purge.
@@ -212,7 +212,7 @@ public void open() throws IOException {
                 }
                 headCheckpoint = new Checkpoint(headCheckpoint.getPageNum(), headCheckpoint.getFirstUnackedPageNum(), firstUnackedSeqNum, pageIO.getMinSeqNum(), pageIO.getElementCount());
             }
-            this.headPage = new HeadPage(headCheckpoint, this, pageIO);
+            this.headPage = PageFactory.newHeadPage(headCheckpoint, this, pageIO);
 
             if (this.headPage.getMinSeqNum() <= 0 && this.headPage.getElementCount() <= 0) {
                 // head page is empty, let's keep it as-is
@@ -223,7 +223,8 @@ public void open() throws IOException {
                 this.headPage.checkpoint();
             } else {
                 // head page is non-empty, transform it into a tail page and create a new empty head page
-                addPage(headCheckpoint, this.headPage.behead());
+                this.headPage.behead();
+                addPage(headCheckpoint, this.headPage);
 
                 headPageNum = headCheckpoint.getPageNum() + 1;
                 newCheckpointedHeadpage(headPageNum);
@@ -272,11 +273,11 @@ private void addIO(Checkpoint checkpoint, PageIO pageIO) throws IOException {
                 // create a tail page with a null PageIO and add it to tail pages but not unreadTailPages
                 // since it is fully read because also fully acked
                 // TODO: I don't like this null pageIO tail page...
-                this.tailPages.add(new TailPage(checkpoint, this, null));
+                this.tailPages.add(PageFactory.newTailPage(checkpoint, this, null));
             }
         } else {
             pageIO.open(checkpoint.getMinSeqNum(), checkpoint.getElementCount());
-            TailPage page = new TailPage(checkpoint, this, pageIO);
+            Page page = PageFactory.newTailPage(checkpoint, this, pageIO);
 
             this.tailPages.add(page);
             this.unreadTailPages.add(page);
@@ -295,7 +296,7 @@ private void addIO(Checkpoint checkpoint, PageIO pageIO) throws IOException {
 
     // add a read tail page into this queue structures but also verify that this tail page
     // is not fully acked in which case it will be purged
-    private void addPage(Checkpoint checkpoint, TailPage page) throws IOException {
+    private void addPage(Checkpoint checkpoint, Page page) throws IOException {
         if (checkpoint.isFullyAcked()) {
             // first make sure any fully acked page per the checkpoint is purged if not already
             try { page.getPageIO().purge(); } catch (NoSuchFileException e) { /* ignore */ }
@@ -312,7 +313,7 @@ private void addPage(Checkpoint checkpoint, TailPage page) throws IOException {
                 // create a tail page with a null PageIO and add it to tail pages but not unreadTailPages
                 // since it is fully read because also fully acked
                 // TODO: I don't like this null pageIO tail page...
-                this.tailPages.add(new TailPage(checkpoint, this, null));
+                this.tailPages.add(PageFactory.newTailPage(checkpoint, this, null));
             }
         } else {
             this.tailPages.add(page);
@@ -335,7 +336,7 @@ private void addPage(Checkpoint checkpoint, TailPage page) throws IOException {
     private void newCheckpointedHeadpage(int pageNum) throws IOException {
         PageIO headPageIO = this.pageIOFactory.build(pageNum, this.pageCapacity, this.dirPath);
         headPageIO.create();
-        this.headPage = new HeadPage(pageNum, this, headPageIO);
+        this.headPage = PageFactory.newHeadPage(pageNum, this, headPageIO);
         this.headPage.forceCheckpoint();
         this.currentByteSize += headPageIO.getCapacity();
     }
@@ -345,10 +346,6 @@ private void newCheckpointedHeadpage(int pageNum) throws IOException {
     public long write(Queueable element) throws IOException {
         byte[] data = element.serialize();
 
-        if (! this.headPage.hasCapacity(data.length)) {
-            throw new IOException("data to be written is bigger than page capacity");
-        }
-
         // the write strategy with regard to the isFull() state is to assume there is space for this element
         // and write it, then after write verify if we just filled the queue and wait on the notFull condition
         // *after* the write which is both safer for a crash condition, and the queue closing sequence. In the former case
@@ -358,6 +355,9 @@ public long write(Queueable element) throws IOException {
 
         lock.lock();
         try {
+            if (! this.headPage.hasCapacity(data.length)) {
+                throw new IOException("data to be written is bigger than page capacity");
+            }
 
             // create a new head page if the current does not have sufficient space left for data to be written
             if (! this.headPage.hasSpace(data.length)) {
@@ -370,16 +370,14 @@ public long write(Queueable element) throws IOException {
                     // purge the old headPage because its full and fully acked
                     // there is no checkpoint file to purge since just creating a new TailPage from a HeadPage does
                     // not trigger a checkpoint creation in itself
-                    TailPage tailPage = new TailPage(this.headPage);
-                    tailPage.purge();
-                    currentByteSize -= tailPage.getPageIO().getCapacity();
+                    this.headPage.purge();
+                    currentByteSize -= this.headPage.getPageIO().getCapacity();
                 } else {
                     // beheading includes checkpoint+fsync if required
-                    TailPage tailPage = this.headPage.behead();
-
-                    this.tailPages.add(tailPage);
-                    if (! tailPage.isFullyRead()) {
-                        this.unreadTailPages.add(tailPage);
+                    this.headPage.behead();
+                    this.tailPages.add(this.headPage);
+                    if (! this.headPage.isFullyRead()) {
+                        this.unreadTailPages.add(this.headPage);
                     }
                 }
 
@@ -437,13 +435,18 @@ public long write(Queueable element) throws IOException {
      * @return True iff the queue is full
      */
     public boolean isFull() {
-        if (this.maxBytes > 0L && (
-            this.currentByteSize > this.maxBytes 
-                || this.currentByteSize == this.maxBytes && !headPage.hasSpace(1)
-        )) {
-            return true;
-        } else {
-            return ((this.maxUnread > 0) && this.unreadCount >= this.maxUnread);
+        lock.lock();
+        try {
+            if (this.maxBytes > 0L && (
+                this.currentByteSize > this.maxBytes
+                    || this.currentByteSize == this.maxBytes && !this.headPage.hasSpace(1)
+            )) {
+                return true;
+            } else {
+                return ((this.maxUnread > 0) && this.unreadCount >= this.maxUnread);
+            }
+        } finally {
+            lock.unlock();
         }
     }
 
@@ -582,10 +585,10 @@ private Batch _readPageBatch(Page p, int limit) throws IOException {
     }
 
     private static class TailPageResult {
-        public TailPage page;
+        public Page page;
         public int index;
 
-        public TailPageResult(TailPage page, int index) {
+        public TailPageResult(Page page, int index) {
             this.page = page;
             this.index = index;
         }
@@ -597,7 +600,7 @@ private TailPageResult binaryFindPageForSeqnum(long seqNum) {
         int hi = this.tailPages.size() - 1;
         while (lo <= hi) {
             int mid = lo + (hi - lo) / 2;
-            TailPage p = this.tailPages.get(mid);
+            Page p = this.tailPages.get(mid);
 
             if (seqNum < p.getMinSeqNum()) {
                 hi = mid - 1;
@@ -613,7 +616,7 @@ private TailPageResult binaryFindPageForSeqnum(long seqNum) {
     // perform a linear search through tail pages to find in which page this seqNum falls into
     private TailPageResult linearFindPageForSeqnum(long seqNum) {
         for (int i = 0; i < this.tailPages.size(); i++) {
-            TailPage p = this.tailPages.get(i);
+            Page p = this.tailPages.get(i);
             if (p.getMinSeqNum() > 0 && seqNum >= p.getMinSeqNum() && seqNum < p.getMinSeqNum() + p.getElementCount()) {
                 return new TailPageResult(p, i);
             }
@@ -638,7 +641,7 @@ public void ack(LongVector seqNums) throws IOException {
 
             if (this.tailPages.size() > 0) {
                 // short-circuit: first check in the first tail page as it is the most likely page where acking will happen
-                TailPage p = this.tailPages.get(0);
+                Page p = this.tailPages.get(0);
                 if (p.getMinSeqNum() > 0 && firstAckSeqNum >= p.getMinSeqNum() && firstAckSeqNum < p.getMinSeqNum() + p.getElementCount()) {
                     result = new TailPageResult(p, 0);
                 } else {
@@ -719,7 +722,7 @@ public void close() throws IOException {
                 // TODO: not sure if we need to do this here since the headpage close will also call ensurePersisted
                 ensurePersistedUpto(this.seqNum);
 
-                for (TailPage p : this.tailPages) { p.close(); }
+                for (Page p : this.tailPages) { p.close(); }
                 this.headPage.close();
 
                 // release all referenced objects
@@ -749,25 +752,35 @@ public void close() throws IOException {
         }
     }
 
-    Page firstUnreadPage() {
-        // look at head page if no unreadTailPages
-        return (this.unreadTailPages.isEmpty()) ? (this.headPage.isFullyRead() ? null : this.headPage) : this.unreadTailPages.get(0);
+    public Page firstUnreadPage() {
+        lock.lock();
+        try {
+            // look at head page if no unreadTailPages
+            return (this.unreadTailPages.isEmpty()) ? (this.headPage.isFullyRead() ? null : this.headPage) : this.unreadTailPages.get(0);
+        } finally {
+            lock.unlock();
+        }
     }
 
     private void removeUnreadPage(Page p) {
         // HeadPage is not part of the unreadTailPages, just ignore
-        if (p instanceof TailPage){
+        if (p != this.headPage) {
             // the page to remove should always be the first one
             assert this.unreadTailPages.get(0) == p : String.format("unread page is not first in unreadTailPages list");
             this.unreadTailPages.remove(0);
         }
     }
 
-    int firstUnackedPageNum() {
-        if (this.tailPages.isEmpty()) {
-            return this.headPage.getPageNum();
+    public int firstUnackedPageNum() {
+        lock.lock();
+        try {
+            if (this.tailPages.isEmpty()) {
+                return this.headPage.getPageNum();
+            }
+            return this.tailPages.get(0).getPageNum();
+        } finally {
+            lock.unlock();
         }
-        return this.tailPages.get(0).getPageNum();
     }
 
     public long getAckedCount() {
diff --git a/logstash-core/src/main/java/org/logstash/ackedqueue/TailPage.java b/logstash-core/src/main/java/org/logstash/ackedqueue/TailPage.java
deleted file mode 100644
index c7b03c07855..00000000000
--- a/logstash-core/src/main/java/org/logstash/ackedqueue/TailPage.java
+++ /dev/null
@@ -1,48 +0,0 @@
-package org.logstash.ackedqueue;
-
-import org.logstash.ackedqueue.io.CheckpointIO;
-import org.logstash.ackedqueue.io.PageIO;
-
-import java.io.IOException;
-import java.util.BitSet;
-
-public class TailPage extends Page {
-
-    // create a new TailPage object from a HeadPage object
-    public TailPage(HeadPage page) {
-        super(page.pageNum, page.queue, page.minSeqNum, page.elementCount, page.firstUnreadSeqNum, page.ackedSeqNums, page.pageIO);
-    }
-
-    // create a new TailPage object for an exiting Checkpoint and data file
-    // @param pageIO the PageIO object is expected to be open/recover/create
-    public TailPage(Checkpoint checkpoint, Queue queue, PageIO pageIO) {
-        super(checkpoint.getPageNum(), queue, checkpoint.getMinSeqNum(), checkpoint.getElementCount(), checkpoint.getFirstUnackedSeqNum(), new BitSet(), pageIO);
-
-        // this page ackedSeqNums bitset is a new empty bitset, if we have some acked elements, set them in the bitset
-        if (checkpoint.getFirstUnackedSeqNum() > checkpoint.getMinSeqNum()) {
-            this.ackedSeqNums.flip(0, (int) (checkpoint.getFirstUnackedSeqNum() - checkpoint.getMinSeqNum()));
-        }
-    }
-
-    public void checkpoint() throws IOException {
-        // TODO: not concurrent for first iteration:
-
-        // since this is a tail page and no write can happen in this page, there is no point in performing a fsync on this page, just stamp checkpoint
-        CheckpointIO io = queue.getCheckpointIO();
-        this.lastCheckpoint = io.write(io.tailFileName(this.pageNum), this.pageNum, 0, firstUnackedSeqNum(), this.minSeqNum, this.elementCount);
-    }
-
-    // delete all IO files associated with this page
-    public void purge() throws IOException {
-        if (this.pageIO != null) {
-            this.pageIO.purge(); // page IO purge calls close
-        }
-    }
-
-    public void close() throws IOException {
-        checkpoint();
-        if (this.pageIO != null) {
-            this.pageIO.close();
-        }
-    }
-}
diff --git a/logstash-core/src/test/java/org/logstash/ackedqueue/HeadPageTest.java b/logstash-core/src/test/java/org/logstash/ackedqueue/HeadPageTest.java
index b38b237eade..e7a80cb67eb 100644
--- a/logstash-core/src/test/java/org/logstash/ackedqueue/HeadPageTest.java
+++ b/logstash-core/src/test/java/org/logstash/ackedqueue/HeadPageTest.java
@@ -14,12 +14,12 @@ public class HeadPageTest {
     @Test
     public void newHeadPage() throws IOException {
         Settings s = TestSettings.volatileQueueSettings(100);
-        // Close method on HeadPage requires an instance of Queue that has already been opened.
+        // Close method on Page requires an instance of Queue that has already been opened.
         try (Queue q = new Queue(s)) {
             q.open();
             PageIO pageIO = s.getPageIOFactory().build(0, 100, "dummy");
             pageIO.create();
-            try (final HeadPage p = new HeadPage(0, q, pageIO)) {
+            try (final Page p = PageFactory.newHeadPage(0, q, pageIO)) {
                 assertThat(p.getPageNum(), is(equalTo(0)));
                 assertThat(p.isFullyRead(), is(true));
                 assertThat(p.isFullyAcked(), is(false));
@@ -36,7 +36,7 @@ public void pageWrite() throws IOException {
         Settings s = TestSettings.volatileQueueSettings(singleElementCapacityForByteBufferPageIO(element));
         try(Queue q = new Queue(s)) {
             q.open();
-            HeadPage p = q.headPage;
+            Page p = q.headPage;
 
             assertThat(p.hasSpace(element.serialize().length), is(true));
             p.write(element.serialize(), 0, 1);
@@ -56,7 +56,7 @@ public void pageWriteAndReadSingle() throws IOException {
         Settings s = TestSettings.volatileQueueSettings(singleElementCapacity);
         try(Queue q = new Queue(s)) {
             q.open();
-            HeadPage p = q.headPage;
+            Page p = q.headPage;
 
             assertThat(p.hasSpace(element.serialize().length), is(true));
             p.write(element.serialize(), seqNum, 1);
@@ -79,7 +79,7 @@ public void inEmpty() throws IOException {
         Settings s = TestSettings.volatileQueueSettings(1000);
         try(Queue q = new Queue(s)) {
             q.open();
-            HeadPage p = q.headPage;
+            Page p = q.headPage;
 
             assertThat(p.isEmpty(), is(true));
             p.write(element.serialize(), 1, 1);
@@ -99,7 +99,7 @@ public void pageWriteAndReadMulti() throws IOException {
         Settings s = TestSettings.volatileQueueSettings(singleElementCapacityForByteBufferPageIO(element));
         try(Queue q = new Queue(s)) {
             q.open();
-            HeadPage p = q.headPage;
+            Page p = q.headPage;
 
             assertThat(p.hasSpace(element.serialize().length), is(true));
             p.write(element.serialize(), seqNum, 1);
diff --git a/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java b/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
index 1d87c276e4a..4754953f30e 100644
--- a/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
+++ b/logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
@@ -233,7 +233,7 @@ public void writeMultiPageWithInOrderAcking() throws IOException {
             assertThat(q.tailPages.size(), is(1));
 
             // lets keep a ref to that tail page before acking
-            TailPage tailPage = q.tailPages.get(0);
+            Page tailPage = q.tailPages.get(0);
 
             assertThat(tailPage.isFullyRead(), is(true));
 
@@ -863,7 +863,7 @@ public void testZeroByteFullyAckedPageOnOpen() throws IOException {
 
             // work directly on the tail page and not the queue to avoid habing the queue purge the page
             // but make sure the tail page checkpoint marks it as fully acked
-            TailPage tp = q.tailPages.get(0);
+            Page tp = q.tailPages.get(0);
             Batch b = new Batch(tp.read(1), q);
             assertThat(b.getElements().get(0), is(element1));
             tp.ack(b.getSeqNums(), 1);
