diff --git a/config/logstash.yml b/config/logstash.yml
new file mode 100644
index 00000000000..897972450fd
--- /dev/null
+++ b/config/logstash.yml
@@ -0,0 +1,102 @@
+# Settings file in YAML
+#
+# Settings can be specified either in hierarchical form, e.g.:
+#
+#   pipeline:
+#     batch:
+#       size: 125
+#       delay: 5
+#
+# Or as flat keys:
+#
+#   pipeline.batch.size: 125
+#   pipeline.batch.delay: 5
+#
+# ------------  Node identity ------------
+#
+# Use a descriptive name for the node:
+#
+# node.name: test
+#
+# If omitted the node name will default to the machine's host name
+#
+# ------------ Pipeline Settings --------------
+#
+# Set the number of workers that will, in parallel, execute the filters+outputs
+# stage of the pipeline.
+#
+# This defaults to half the number of the host's CPU cores.
+#
+# pipeline.workers: 2
+#
+# How many workers should be used per output plugin instance
+#
+# pipeline.output.workers: 1
+#
+# How many events to retrieve from inputs before sending to filters+workers
+#
+# pipeline.batch.size: 125
+#
+# How long to wait before dispatching an undersized batch to filters+workers
+# Value is in seconds.
+#
+# pipeline.batch.delay: 5
+#
+# Force Logstash to exit during shutdown even if there are still inflight
+# events in memory. By default, logstash will refuse to quit until all
+# received events have been pushed to the outputs.
+#
+# WARNING: enabling this can lead to data loss during shutdown
+#
+# pipeline.unsafe_shutdown: false
+#
+# ------------ Pipeline Configuration Settings --------------
+#
+# Allow the pipeline configuration to be injected with environment variables
+#
+# config.allow_env: false
+#
+# Where to fetch the pipeline configuration for the main pipeline
+#
+# config.path:
+#
+# PIpeline configuration string for the main pipeline
+#
+# config.string:
+#
+# At startup, test if the configuration is valid and exit (dry run)
+#
+# config.test: false
+#
+# Periodically check if the configuration has changed and reload the pipeline
+# This can also be triggered manually through the SIGHUP signal
+#
+# config.reload.auto: false
+#
+# How often to check if the pipeline configuration has changed (in seconds)
+#
+# config.reload.interval", Numeric, 3),
+#
+# ------------ Metrics Settings --------------
+#
+# Bind address for the metrics REST endpoint
+#
+# web_api.http.host: "127.0.0.1"
+#
+# Bind port for the metrics REST endpoint
+#
+# web_api.http.port: 9600
+#
+# ------------ Debugging Settings --------------
+#
+# debug: false
+# quiet: false
+# verbose: false
+# debug.config: false
+# log.path:
+# log.json: false
+#
+# ------------ Other Settings --------------
+#
+# Where to find custom plugins
+# plugin.paths: []
diff --git a/docs/static/command-line-flags.asciidoc b/docs/static/command-line-flags.asciidoc
index 272968a5311..076e45d36c4 100644
--- a/docs/static/command-line-flags.asciidoc
+++ b/docs/static/command-line-flags.asciidoc
@@ -5,30 +5,30 @@ Logstash has the following flags. You can use the `--help` flag to display this
 
 [source,shell]
 ----------------------------------
--f, --config CONFIGFILE
+-f, --config.path CONFIGFILE
  Load the Logstash config from a specific file, directory, or a wildcard. If
  given a directory or wildcard, config files will be read from the directory in
  alphabetical order.
 
--e CONFIGSTRING
+-e, --config.string CONFIGSTRING
  Use the given string as the configuration data. Same syntax as the config file.
  If not input is specified, 'stdin { type => stdin }' is default. If no output
  is specified, 'stdout { codec => rubydebug }}' is default.
 
--w, --filterworkers COUNT
+-w, --pipeline.workers COUNT
  Sets the number of pipeline workers (threads) to run for filter and output
  processing (default: number of cores).
  If you find that events are backing up, or that the CPU is not saturated, consider increasing
  this number to better utilize machine processing power.
 
--b, --pipeline-batch-size SIZE
+-b, --pipeline.batch.size SIZE
  This parameter defines the maximum number of events an individual worker thread will collect
  before attempting to execute its filters and outputs. Default is 125 events.
  Larger batch sizes are generally more efficient, but come at the cost of increased memory
  overhead. You may have to increase the JVM heap size by setting the `LS_HEAP_SIZE`
  variable to effectively use the option.
 
--u, --pipeline-batch-delay DELAY_IN_MS
+-u, --pipeline.batch.delay DELAY_IN_MS
  When creating pipeline event batches, how long to wait while polling for the next event.
  Default is 5ms.
 
@@ -41,7 +41,7 @@ Logstash has the following flags. You can use the `--help` flag to display this
 --debug
  Increase verbosity to the last level (trace), more verbose.
 
---debug-config
+--debug.config
  Print the compiled config ruby code out as a debug log (you must also have --debug enabled).
  WARNING: This will include any 'password' options passed to plugin configs as plaintext, and may result
  in plaintext passwords appearing in your logs!
@@ -49,31 +49,36 @@ Logstash has the following flags. You can use the `--help` flag to display this
 -V, --version
   Display the version of Logstash.
 
--p, --pluginpath
+-p, --plugin.path
   A path of where to find plugins. This flag can be given multiple times to include
   multiple paths. Plugins are expected to be in a specific directory hierarchy:
   'PATH/logstash/TYPE/NAME.rb' where TYPE is 'inputs' 'filters', 'outputs' or 'codecs'
   and NAME is the name of the plugin.
 
--t, --configtest
+-t, --config.test
   Checks configuration and then exit. Note that grok patterns are not checked for
   correctness with this flag.
   Logstash can read multiple config files from a directory. If you combine this
   flag with `--debug`, Logstash will log the combined config file, annotating the
   individual config blocks with the source file it came from.
   
--r, --[no-]auto-reload
+-r, --config.reload.auto
   Monitor configuration changes and reload the configuration whenever it is changed.
 
---reload-interval RELOAD_INTERVAL
+--config.reload.interval RELOAD_INTERVAL
   Specifies how often Logstash checks the config files for changes. The default is every 3 seconds.
 
---http-host WEB_API_HTTP_HOST 
+--web_api.http.host WEB_API_HTTP_HOST
   Web API binding host (default: "127.0.0.1")
 
---http-port WEB_API_HTTP_PORT
+--web_api.http.port WEB_API_HTTP_PORT
   Web API http port (default: 9600)
 
+--pipeline.unsafe_shutdown
+  Force logstash to exit during shutdown even if there are still inflight events
+  in memory. By default, logstash will refuse to quit until all received events
+  have been pushed to the outputs.
+
 -h, --help
   Print help
 ----------------------------------
diff --git a/docs/static/life-of-an-event.asciidoc b/docs/static/life-of-an-event.asciidoc
index a4712ba46c4..b85549ecc36 100644
--- a/docs/static/life-of-an-event.asciidoc
+++ b/docs/static/life-of-an-event.asciidoc
@@ -119,12 +119,12 @@ num_pipeline_workers.times do
 end
 wait_for_threads_to_terminate()
 
-There are three configurable options in the pipeline, `--pipeline-workers`, `--pipeline-batch-size`, and `--pipeline-batch-delay`.
-The `--pipeline-workers` or `-w` parameter determines how many threads to run for filter and output processing. If you find that events are backing up, or that the CPU is not saturated, consider increasing the value of this parameter to make better use of available processing power. Good results can even be found increasing this number past the number of available processors as these threads may spend significant time in an I/O wait state when writing to external systems. Legal values for this parameter are positive integers.
+There are three configurable options in the pipeline, `--pipeline.workers`, `--pipeline.batch.size`, and `--pipeline.batch.delay`.
+The `--pipeline.workers` or `-w` parameter determines how many threads to run for filter and output processing. If you find that events are backing up, or that the CPU is not saturated, consider increasing the value of this parameter to make better use of available processing power. Good results can even be found increasing this number past the number of available processors as these threads may spend significant time in an I/O wait state when writing to external systems. Legal values for this parameter are positive integers.
 
-The `--pipeline-batch-size` or `-b` parameter defines the maximum number of events an individual worker thread collects before attempting to execute filters and outputs. Larger batch sizes are generally more efficient, but increase memory overhead. Some hardware configurations require you to increase JVM heap size by setting the `LS_HEAP_SIZE` variable to avoid performance degradation with this option. Values of this parameter in excess of the optimum range cause performance degradation due to frequent garbage collection or JVM crashes related to out-of-memory exceptions. Output plugins can process each batch as a logical unit. The Elasticsearch output, for example, issues https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html[bulk requests] for each batch received. Tuning the `-b` parameter adjusts the size of bulk requests sent to Elasticsearch.
+The `--pipeline.batch.size` or `-b` parameter defines the maximum number of events an individual worker thread collects before attempting to execute filters and outputs. Larger batch sizes are generally more efficient, but increase memory overhead. Some hardware configurations require you to increase JVM heap size by setting the `LS_HEAP_SIZE` variable to avoid performance degradation with this option. Values of this parameter in excess of the optimum range cause performance degradation due to frequent garbage collection or JVM crashes related to out-of-memory exceptions. Output plugins can process each batch as a logical unit. The Elasticsearch output, for example, issues https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html[bulk requests] for each batch received. Tuning the `-b` parameter adjusts the size of bulk requests sent to Elasticsearch.
 
-The `--pipeline-batch-delay` option rarely needs to be tuned. This option adjusts the latency of the Logstash pipeline. Pipeline batch delay is the maximum amount of time in milliseconds that Logstash waits for new messages after receiving an event in the current pipeline worker thread. After this time elapses, Logstash begins to execute filters and outputs.The maximum time that Logstash waits between receiving an event and processing that event in a filter is the product of the `pipeline_batch_delay` and  `pipeline_batch_size` settings.
+The `--pipeline.batch.delay` option rarely needs to be tuned. This option adjusts the latency of the Logstash pipeline. Pipeline batch delay is the maximum amount of time in milliseconds that Logstash waits for new messages after receiving an event in the current pipeline worker thread. After this time elapses, Logstash begins to execute filters and outputs.The maximum time that Logstash waits between receiving an event and processing that event in a filter is the product of the `pipeline_batch_delay` and  `pipeline_batch_size` settings.
 
 [float]
 ==== Notes on Pipeline Configuration and Performance
diff --git a/lib/bootstrap/environment.rb b/lib/bootstrap/environment.rb
index 66ed16093f0..ab73f5e37e4 100644
--- a/lib/bootstrap/environment.rb
+++ b/lib/bootstrap/environment.rb
@@ -56,7 +56,6 @@ def pattern_path(path)
   end
 end
 
-
 # when launched as a script, not require'd, (currently from bin/logstash and bin/logstash-plugin) the first
 # argument is the path of a Ruby file to require and a LogStash::Runner class is expected to be
 # defined and exposing the LogStash::Runner#main instance method which will be called with the current ARGV
@@ -64,12 +63,6 @@ def pattern_path(path)
 if $0 == __FILE__
   LogStash::Bundler.setup!({:without => [:build, :development]})
   require ARGV.shift
-  # TODO deprecate these arguments in the next major version. use -i only
-  if ARGV == ["irb"] || ARGV == ["pry"]
-    puts "Warn: option \"#{ARGV.first}\" is deprecated, use \"-i #{ARGV.first}\" or \"--interactive=#{ARGV.first}\" instead"
-    exit_status = LogStash::Runner.run("bin/logstash", ["--interactive", ARGV.first])
-  else
-    exit_status = LogStash::Runner.run("bin/logstash", ARGV)
-  end
+  exit_status = LogStash::Runner.run("bin/logstash", ARGV)
   exit(exit_status || 0)
 end
diff --git a/logstash-core/lib/logstash/agent.rb b/logstash-core/lib/logstash/agent.rb
index 09f2d21cb76..d1ff9e0570a 100644
--- a/logstash-core/lib/logstash/agent.rb
+++ b/logstash-core/lib/logstash/agent.rb
@@ -20,7 +20,8 @@
 class LogStash::Agent
   STARTED_AT = Time.now.freeze
 
-  attr_reader :metric, :node_name, :pipelines, :logger
+  attr_reader :metric, :node_name, :pipelines, :settings
+  attr_accessor :logger
 
   # initialize method for LogStash::Agent
   # @param params [Hash] potential parameters are:
@@ -28,21 +29,23 @@ class LogStash::Agent
   #   :auto_reload [Boolean] - enable reloading of pipelines
   #   :reload_interval [Integer] - reload pipelines every X seconds
   #   :logger [Cabin::Channel] - logger instance
-  def initialize(params)
-    @logger = params[:logger]
-    @auto_reload = params[:auto_reload]
+  def initialize(settings = LogStash::SETTINGS)
+    @settings = settings
+    @logger = Cabin::Channel.get(LogStash)
+    @auto_reload = setting("config.reload.auto")
 
     @pipelines = {}
-    @node_name = params[:node_name] || Socket.gethostname
-    @web_api_http_host = params[:web_api_http_host]
-    @web_api_http_port = params[:web_api_http_port]
+    @node_name = setting("node.name")
+    @web_api_http_host = setting("web_api.http.host")
+    @web_api_http_port = setting("web_api.http.port")
 
-    @config_loader = LogStash::Config::Loader.new(@logger, params[:debug_config])
-    @reload_interval = params[:reload_interval] || 3 # seconds
+    @config_loader = LogStash::Config::Loader.new(@logger)
+    @reload_interval = setting("config.reload.interval")
     @upgrade_mutex = Mutex.new
 
-    @collect_metric = params.fetch(:collect_metric, false)
-    setup_metric_collection
+    @collect_metric = setting("metric.collect")
+    @metric = create_metric_collector
+    @periodic_pollers = LogStash::Instrument::PeriodicPollers.new(metric)
   end
 
   def execute
@@ -74,9 +77,13 @@ def execute
   # @param pipeline_id [String] pipeline string identifier
   # @param settings [Hash] settings that will be passed when creating the pipeline.
   #   keys should be symbols such as :pipeline_workers and :pipeline_batch_delay
-  def register_pipeline(pipeline_id, settings)
-    pipeline = create_pipeline(settings.merge(:pipeline_id => pipeline_id, :metric => metric))
+  def register_pipeline(pipeline_id, settings = @settings)
+    pipeline_settings = settings.clone
+    pipeline_settings.set("pipeline.id", pipeline_id)
+
+    pipeline = create_pipeline(pipeline_settings)
     return unless pipeline.is_a?(LogStash::Pipeline)
+    pipeline.metric = @metric
     if @auto_reload && pipeline.non_reloadable_plugins.any?
       @logger.error(I18n.t("logstash.agent.non_reloadable_config_register"),
                     :pipeline_id => pipeline_id,
@@ -149,16 +156,14 @@ def stop_background_services
     end
   end
 
-  def setup_metric_collection
+  def create_metric_collector
     if collect_metrics?
       @logger.debug("Agent: Configuring metric collection")
       LogStash::Instrument::Collector.instance.agent = self
-      @metric = LogStash::Instrument::Metric.new
+      LogStash::Instrument::Metric.new
     else
-      @metric = LogStash::Instrument::NullMetric.new
+      LogStash::Instrument::NullMetric.new
     end
-
-    @periodic_pollers = LogStash::Instrument::PeriodicPollers.new(metric)
   end
 
   def collect_metrics?
@@ -185,21 +190,22 @@ def create_pipeline(settings, config=nil)
   end
 
   def fetch_config(settings)
-    @config_loader.format_config(settings[:config_path], settings[:config_string])
+    @config_loader.format_config(settings.get("config.path"), settings.get("config.string"))
   end
 
   # since this method modifies the @pipelines hash it is
   # wrapped in @upgrade_mutex in the parent call `reload_state!`
   def reload_pipeline!(id)
     old_pipeline = @pipelines[id]
-    new_config = fetch_config(old_pipeline.original_settings)
+    new_config = fetch_config(old_pipeline.settings)
     if old_pipeline.config_str == new_config
       @logger.debug("no configuration change for pipeline",
                     :pipeline => id, :config => new_config)
       return
     end
 
-    new_pipeline = create_pipeline(old_pipeline.original_settings, new_config)
+    new_pipeline = create_pipeline(old_pipeline.settings, new_config)
+
     return if new_pipeline.nil?
 
     if new_pipeline.non_reloadable_plugins.any?
@@ -270,4 +276,8 @@ def clean_state?
   def reset_collector
     LogStash::Instrument::Collector.instance.clear
   end
+
+  def setting(key)
+    @settings.get(key)
+  end
 end # class LogStash::Agent
diff --git a/logstash-core/lib/logstash/config/loader.rb b/logstash-core/lib/logstash/config/loader.rb
index 1cd0f3febaa..27575eda343 100644
--- a/logstash-core/lib/logstash/config/loader.rb
+++ b/logstash-core/lib/logstash/config/loader.rb
@@ -1,9 +1,9 @@
 require "logstash/config/defaults"
 
 module LogStash; module Config; class Loader
-  def initialize(logger, debug_config=false)
+  def initialize(logger)
     @logger = logger
-    @debug_config = debug_config
+    @debug_config = LogStash::SETTINGS.get_value("debug.config")
   end
 
   def format_config(config_path, config_string)
diff --git a/logstash-core/lib/logstash/environment.rb b/logstash-core/lib/logstash/environment.rb
index 79e7f24d86c..67a4241d814 100644
--- a/logstash-core/lib/logstash/environment.rb
+++ b/logstash-core/lib/logstash/environment.rb
@@ -1,7 +1,39 @@
 # encoding: utf-8
 require "logstash/errors"
+require "logstash/config/cpu_core_strategy"
+require "logstash/settings"
 
 module LogStash
+
+  [
+            Setting::String.new("node.name", Socket.gethostname),
+            Setting::String.new("config.path", nil, false),
+            Setting::String.new("config.string", nil, false),
+           Setting::Boolean.new("config.test", false),
+           Setting::Boolean.new("config.reload.auto", false),
+           Setting::Numeric.new("config.reload.interval", 3),
+           Setting::Boolean.new("metric.collect", true) {|v| v == true }, # metric collection cannot be disabled
+            Setting::String.new("settings.dir", ::File.join(Environment::LOGSTASH_HOME, "config")),
+            Setting::String.new("pipeline.id", "main"),
+           Setting::Numeric.new("pipeline.workers", LogStash::Config::CpuCoreStrategy.maximum),
+           Setting::Numeric.new("pipeline.output.workers", 1),
+           Setting::Numeric.new("pipeline.batch.size", 125),
+           Setting::Numeric.new("pipeline.batch.delay", 5), # in milliseconds
+           Setting::Boolean.new("pipeline.unsafe_shutdown", false),
+                    Setting.new("plugin.paths", Array, []),
+            Setting::String.new("interactive", nil, false),
+           Setting::Boolean.new("debug", false),
+           Setting::Boolean.new("debug.config", false),
+           Setting::Boolean.new("verbose", false),
+           Setting::Boolean.new("quiet", false),
+           Setting::Boolean.new("version", false),
+           Setting::Boolean.new("help", false),
+            Setting::String.new("log.path", nil, false),
+           Setting::Boolean.new("log.json", false),
+            Setting::String.new("web_api.http.host", "127.0.0.1"),
+              Setting::Port.new("web_api.http.port", 9600),
+  ].each {|setting| SETTINGS.register(setting) }
+
   module Environment
     extend self
 
diff --git a/logstash-core/lib/logstash/patches/clamp.rb b/logstash-core/lib/logstash/patches/clamp.rb
new file mode 100644
index 00000000000..0934157a9e3
--- /dev/null
+++ b/logstash-core/lib/logstash/patches/clamp.rb
@@ -0,0 +1,69 @@
+require 'clamp'
+require 'logstash/environment'
+
+module Clamp
+  module Attribute
+    class Instance
+      def default_from_environment
+        # we don't want uncontrolled var injection from the environment
+        # since we're establishing that settings can be pulled from only three places:
+        # 1. default settings
+        # 2. yaml file
+        # 3. cli arguments
+      end
+    end
+  end
+
+  module Option
+
+    module StrictDeclaration
+
+      include Clamp::Attribute::Declaration
+
+      # Instead of letting Clamp set up accessors for the options
+      # weŕe going to tightly controlling them through
+      # LogStash::SETTINGS
+      def define_simple_writer_for(option, &block)
+        LogStash::SETTINGS.get(option.attribute_name)
+        define_method(option.write_method) do |value|
+          value = instance_exec(value, &block) if block
+          LogStash::SETTINGS.set_value(option.attribute_name, value)
+        end
+      end
+
+      def define_reader_for(option)
+        define_method(option.read_method) do
+          LogStash::SETTINGS.get_value(option.attribute_name)
+        end
+      end
+
+    end
+
+    class Definition
+      # Allow boolean flags to optionally receive a true/false argument
+      # to explicitly set them, i.e.
+      # --long.flag.name       => sets flag to true
+      # --long.flag.name true  => sets flag to true
+      # --long.flag.name false => sets flag to false
+      # --long.flag.name=true  => sets flag to true
+      # --long.flag.name=false => sets flag to false
+      def extract_value(switch, arguments)
+        if flag? && (arguments.first.nil? || arguments.first.match("^-"))
+          flag_value(switch)
+        else
+          arguments.shift
+        end
+      end
+    end
+  end
+
+  # Create a subclass of Clamp::Command that enforces the use of
+  # LogStash::SETTINGS for setting validation
+  class StrictCommand < Command
+    class << self
+      include ::Clamp::Option::StrictDeclaration
+    end
+  end
+end
+
+
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 529ad6e887c..87a9805a41f 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -9,8 +9,6 @@
 require "logstash/filters/base"
 require "logstash/inputs/base"
 require "logstash/outputs/base"
-require "logstash/config/cpu_core_strategy"
-require "logstash/util/defaults_printer"
 require "logstash/shutdown_watcher"
 require "logstash/util/wrapped_synchronous_queue"
 require "logstash/pipeline_reporter"
@@ -22,7 +20,7 @@
 require "logstash/filter_delegator"
 
 module LogStash; class Pipeline
- attr_reader :inputs,
+  attr_reader :inputs,
     :filters,
     :outputs,
     :worker_threads,
@@ -30,36 +28,24 @@ module LogStash; class Pipeline
     :events_filtered,
     :reporter,
     :pipeline_id,
-    :metric,
     :logger,
     :started_at,
     :thread,
     :config_str,
-    :original_settings
-
-  DEFAULT_OUTPUT_WORKERS = 1
-
-  DEFAULT_SETTINGS = {
-    :default_pipeline_workers => LogStash::Config::CpuCoreStrategy.maximum,
-    :pipeline_batch_size => 125,
-    :pipeline_batch_delay => 5, # in milliseconds
-    :flush_interval => 5, # in seconds
-    :flush_timeout_interval => 60, # in seconds
-    :debug_config => false
-  }
+    :settings
+  attr_accessor :metric
+
   MAX_INFLIGHT_WARN_THRESHOLD = 10_000
 
   RELOAD_INCOMPATIBLE_PLUGINS = [
     "LogStash::Inputs::Stdin"
   ]
 
-  def initialize(config_str, settings = {})
+  def initialize(config_str, settings = LogStash::SETTINGS)
     @config_str = config_str
-    @original_settings = settings
     @logger = Cabin::Channel.get(LogStash)
-    @pipeline_id = settings[:pipeline_id] || self.object_id
-    @settings = DEFAULT_SETTINGS.clone
-    settings.each {|setting, value| configure(setting, value) }
+    @settings = settings
+    @pipeline_id = @settings.get_value("pipeline.id") || self.object_id
     @reporter = LogStash::PipelineReporter.new(@logger, self)
 
     @inputs = nil
@@ -74,9 +60,11 @@ def initialize(config_str, settings = {})
     # We also do this to make the changes backward compatible with previous testing of the
     # pipeline.
     #
-    # This need to be configured before we evaluate the code to make
+    # This needs to be configured before we evaluate the code to make
     # sure the metric instance is correctly send to the plugin.
-    @metric = settings.fetch(:metric, Instrument::NullMetric.new)
+    # NOTE: It is the responsibility of the Agent to set this externally with a setter
+    # if there's an intent of this not being a NullMetric
+    @metric = Instrument::NullMetric.new
 
     grammar = LogStashConfigParser.new
     @config = grammar.parse(config_str)
@@ -92,7 +80,7 @@ def initialize(config_str, settings = {})
     # The config code is hard to represent as a log message...
     # So just print it.
 
-    if @settings[:debug_config] && logger.debug?
+    if @settings.get("debug.config") && logger.debug?
       logger.debug("Compiled pipeline code", :code => code)
     end
 
@@ -121,38 +109,29 @@ def ready?
     @ready.value
   end
 
-  def configure(setting, value)
-    @settings[setting] = value
-  end
-
   def safe_pipeline_worker_count
-    default = DEFAULT_SETTINGS[:default_pipeline_workers]
-    thread_count = @settings[:pipeline_workers] #override from args "-w 8" or config
+    default = @settings.get_default("pipeline.workers")
+    pipeline_workers = @settings.get("pipeline.workers") #override from args "-w 8" or config
     safe_filters, unsafe_filters = @filters.partition(&:threadsafe?)
+    plugins = unsafe_filters.collect { |f| f.config_name }
 
-    if unsafe_filters.any?
-      plugins = unsafe_filters.collect { |f| f.config_name }
-      case thread_count
-      when nil
-        # user did not specify a worker thread count
-        # warn if the default is multiple
-
-        if default > 1
-          @logger.warn("Defaulting pipeline worker threads to 1 because there are some filters that might not work with multiple worker threads",
-                       :count_was => default, :filters => plugins)
-        end
+    return pipeline_workers if unsafe_filters.empty?
 
-        1 # can't allow the default value to propagate if there are unsafe filters
-      when 0, 1
-        1
-      else
+    if @settings.set?("pipeline.workers")
+      if pipeline_workers > 1
         @logger.warn("Warning: Manual override - there are filters that might not work with multiple worker threads",
-                     :worker_threads => thread_count, :filters => plugins)
-        thread_count # allow user to force this even if there are unsafe filters
+                     :worker_threads => pipeline_workers, :filters => plugins)
       end
     else
-      thread_count || default
+      # user did not specify a worker thread count
+      # warn if the default is multiple
+      if default > 1
+        @logger.warn("Defaulting pipeline worker threads to 1 because there are some filters that might not work with multiple worker threads",
+                     :count_was => default, :filters => plugins)
+        return 1 # can't allow the default value to propagate if there are unsafe filters
+      end
     end
+    pipeline_workers
   end
 
   def filters?
@@ -162,9 +141,8 @@ def filters?
   def run
     @started_at = Time.now
 
-    LogStash::Util.set_thread_name("[#{pipeline_id}]-pipeline-manager")
-    @logger.terminal(LogStash::Util::DefaultsPrinter.print(@settings))
     @thread = Thread.current
+    LogStash::Util.set_thread_name("[#{pipeline_id}]-pipeline-manager")
 
     start_workers
 
@@ -215,15 +193,15 @@ def start_workers
       @filters.each {|f| f.register }
 
       pipeline_workers = safe_pipeline_worker_count
-      batch_size = @settings[:pipeline_batch_size]
-      batch_delay = @settings[:pipeline_batch_delay]
+      batch_size = @settings.get("pipeline.batch.size")
+      batch_delay = @settings.get("pipeline.batch.delay")
       max_inflight = batch_size * pipeline_workers
       @logger.info("Starting pipeline",
-                   :id => self.pipeline_id,
-                   :pipeline_workers => pipeline_workers,
-                   :batch_size => batch_size,
-                   :batch_delay => batch_delay,
-                   :max_inflight => max_inflight)
+                   "id" => self.pipeline_id,
+                   "pipeline.workers" => pipeline_workers,
+                   "pipeline.batch.size" => batch_size,
+                   "pipeline.batch.delay" => batch_delay,
+                   "pipeline.max_inflight" => max_inflight)
       if max_inflight > MAX_INFLIGHT_WARN_THRESHOLD
         @logger.warn "CAUTION: Recommended inflight events max exceeded! Logstash will run with up to #{max_inflight} events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently #{batch_size}), or changing the number of pipeline workers (currently #{pipeline_workers})"
       end
@@ -457,7 +435,7 @@ def plugin(plugin_type, name, *args)
     klass = LogStash::Plugin.lookup(plugin_type, name)
 
     if plugin_type == "output"
-      LogStash::OutputDelegator.new(@logger, klass, DEFAULT_OUTPUT_WORKERS, pipeline_scoped_metric.namespace(:outputs), *args)
+      LogStash::OutputDelegator.new(@logger, klass, @settings.get("pipeline.output.workers"), pipeline_scoped_metric.namespace(:outputs), *args)
     elsif plugin_type == "filter"
       LogStash::FilterDelegator.new(@logger, klass, pipeline_scoped_metric.namespace(:filters), *args)
     else
diff --git a/logstash-core/lib/logstash/runner.rb b/logstash-core/lib/logstash/runner.rb
index a5e32e53b62..8400c128d77 100644
--- a/logstash-core/lib/logstash/runner.rb
+++ b/logstash-core/lib/logstash/runner.rb
@@ -3,7 +3,8 @@
 Encoding.default_external = Encoding::UTF_8
 $DEBUGLIST = (ENV["DEBUG"] || "").split(",")
 
-require "clamp" # gem 'clamp'
+require "clamp"
+require "cabin"
 require "net/http"
 require "logstash/environment"
 
@@ -12,125 +13,131 @@
 require "logstash/namespace"
 require "logstash/agent"
 require "logstash/config/defaults"
+require "logstash/shutdown_watcher"
+require "logstash/patches/clamp"
 
-class LogStash::Runner < Clamp::Command
+class LogStash::Runner < Clamp::StrictCommand
 
-  option ["-f", "--config"], "CONFIG_PATH",
+  # Node Settings
+  option ["-n", "--node.name"], "NAME",
+    I18n.t("logstash.runner.flag.node_name"),
+    :attribute_name => "node.name",
+    :default => LogStash::SETTINGS.get_default("node.name")
+
+  # Config Settings
+  option ["-f", "--config.path"], "CONFIG_PATH",
     I18n.t("logstash.runner.flag.config"),
-    :attribute_name => :config_path
+    :attribute_name => "config.path"
 
-  option "-e", "CONFIG_STRING",
+  option ["-e", "--config.string"], "CONFIG_STRING",
     I18n.t("logstash.runner.flag.config-string",
-           :default_input => LogStash::Config::Defaults.input,
-           :default_output => LogStash::Config::Defaults.output),
-    :default => nil, :attribute_name => :config_string
+      :default_input => LogStash::Config::Defaults.input,
+      :default_output => LogStash::Config::Defaults.output),
+    :default => LogStash::SETTINGS.get_default("config.string"),
+    :attribute_name => "config.string"
 
-  option ["-w", "--pipeline-workers"], "COUNT",
+  # Pipeline settings
+  option ["-w", "--pipeline.workers"], "COUNT",
     I18n.t("logstash.runner.flag.pipeline-workers"),
-    :attribute_name => :pipeline_workers,
-    :default => LogStash::Pipeline::DEFAULT_SETTINGS[:default_pipeline_workers]
+    :attribute_name => "pipeline.workers",
+    :default => LogStash::SETTINGS.get_default("pipeline.workers"), &:to_i
+
+  option ["-b", "--pipeline.batch.size"], "SIZE",
+    I18n.t("logstash.runner.flag.pipeline-batch-size"),
+    :attribute_name => "pipeline.batch.size",
+    :default => LogStash::SETTINGS.get_default("pipeline.batch.size"), &:to_i
 
-  option ["-b", "--pipeline-batch-size"], "SIZE",
-         I18n.t("logstash.runner.flag.pipeline-batch-size"),
-         :attribute_name => :pipeline_batch_size,
-         :default => LogStash::Pipeline::DEFAULT_SETTINGS[:pipeline_batch_size]
+  option ["-u", "--pipeline.batch.delay"], "DELAY_IN_MS",
+    I18n.t("logstash.runner.flag.pipeline-batch-delay"),
+    :attribute_name => "pipeline.batch.delay",
+    :default => LogStash::SETTINGS.get_default("pipeline.batch.delay"), &:to_i
+
+  option ["--pipeline.unsafe_shutdown"], :flag,
+    I18n.t("logstash.runner.flag.unsafe_shutdown"),
+    :attribute_name => "pipeline.unsafe_shutdown",
+    :default => LogStash::SETTINGS.get_default("pipeline.unsafe_shutdown")
 
-  option ["-u", "--pipeline-batch-delay"], "DELAY_IN_MS",
-         I18n.t("logstash.runner.flag.pipeline-batch-delay"),
-         :attribute_name => :pipeline_batch_delay,
-         :default => LogStash::Pipeline::DEFAULT_SETTINGS[:pipeline_batch_delay]
+  # Plugins Settings
+  option ["-p", "--plugin.paths"] , "PATH",
+    I18n.t("logstash.runner.flag.pluginpath"),
+    :multivalued => true, :attribute_name => "plugin.paths",
+    :default => LogStash::SETTINGS.get_default("plugin.paths")
 
-  option ["-l", "--log"], "FILE",
+  # Logging Settings
+  option ["-l", "--log.path"], "FILE",
     I18n.t("logstash.runner.flag.log"),
-    :attribute_name => :log_file
+    :attribute_name => "log.path"
 
-  # Old support for the '-v' flag'
-  option "-v", :flag,
-    I18n.t("logstash.runner.flag.verbosity"),
-    :attribute_name => :verbosity, :multivalued => true
+  option "--debug", :flag, I18n.t("logstash.runner.flag.debug"),
+    :default => LogStash::SETTINGS.get_default("debug")
+  option "--quiet", :flag, I18n.t("logstash.runner.flag.quiet"),
+    :default => LogStash::SETTINGS.get_default("quiet")
+  option "--verbose", :flag, I18n.t("logstash.runner.flag.verbose"),
+    :default => LogStash::SETTINGS.get_default("verbose")
 
-  option "--quiet", :flag, I18n.t("logstash.runner.flag.quiet")
-  option "--verbose", :flag, I18n.t("logstash.runner.flag.verbose")
-  option "--debug", :flag, I18n.t("logstash.runner.flag.debug")
+  option "--debug.config", :flag,
+    I18n.t("logstash.runner.flag.debug_config"),
+    :default => LogStash::SETTINGS.get_default("debug.config"),
+    :attribute_name => "debug.config"
 
-  option ["--debug-config"], :flag,
-         I18n.t("logstash.runner.flag.debug_config"),
-         :attribute_name => :debug_config, :default => false
+  # Other settings
+  option ["-i", "--interactive"], "SHELL",
+    I18n.t("logstash.runner.flag.rubyshell"),
+    :attribute_name => "interactive"
 
   option ["-V", "--version"], :flag,
     I18n.t("logstash.runner.flag.version")
 
-  option ["-p", "--pluginpath"] , "PATH",
-    I18n.t("logstash.runner.flag.pluginpath"),
-    :multivalued => true,
-    :attribute_name => :plugin_paths
-
-  option ["-t", "--configtest"], :flag,
+  option ["-t", "--config.test"], :flag,
     I18n.t("logstash.runner.flag.configtest"),
-    :attribute_name => :config_test
+    :attribute_name => "config.test",
+    :default => LogStash::SETTINGS.get_default("config.test")
 
-  option "--[no-]allow-unsafe-shutdown", :flag,
-    I18n.t("logstash.runner.flag.unsafe_shutdown"),
-    :attribute_name => :unsafe_shutdown,
-    :default => false
-
-  option ["-i", "--interactive"], "SHELL",
-    I18n.t("logstash.runner.flag.rubyshell"),
-    :attribute_name => :ruby_shell
-
-  option ["-n", "--node-name"], "NAME",
-    I18n.t("logstash.runner.flag.node_name"),
-    :attribute_name => :node_name
-
-  option ["-r", "--[no-]auto-reload"], :flag,
+  option ["-r", "--config.reload.auto"], :flag,
     I18n.t("logstash.runner.flag.auto_reload"),
-    :attribute_name => :auto_reload, :default => false
+    :attribute_name => "config.reload.auto",
+    :default => LogStash::SETTINGS.get_default("config.reload.auto")
 
-  option ["--reload-interval"], "RELOAD_INTERVAL",
+  option ["--config.reload.interval"], "RELOAD_INTERVAL",
     I18n.t("logstash.runner.flag.reload_interval"),
-    :attribute_name => :reload_interval, :default => 3, &:to_i
+    :attribute_name => "config.reload.interval",
+    :default => LogStash::SETTINGS.get_default("config.reload.interval"), &:to_i
 
-  option ["--http-host"], "WEB_API_HTTP_HOST",
+  option ["--web_api.http.host"], "WEB_API_HTTP_HOST",
     I18n.t("logstash.web_api.flag.http_host"),
-    :attribute_name => :web_api_http_host, :default => "127.0.0.1"
+    :attribute_name => "web_api.http.host",
+    :default => LogStash::SETTINGS.get_default("web_api.http.host")
 
-  option ["--http-port"], "WEB_API_HTTP_PORT",
+  option ["--web_api.http.port"], "WEB_API_HTTP_PORT",
     I18n.t("logstash.web_api.flag.http_port"),
-    :attribute_name => :web_api_http_port, :default => 9600
+    :attribute_name => "web_api.http.port",
+    :default => LogStash::SETTINGS.get_default("web_api.http.port"), &:to_i
 
-  option ["--[no-]log-in-json"], :flag,
+  option ["--log.json"], :flag,
     I18n.t("logstash.runner.flag.log-in-json"),
-    :default => false
-
-  def pipeline_workers=(pipeline_workers_value)
-    @pipeline_settings[:pipeline_workers] = validate_positive_integer(pipeline_workers_value)
-  end
-
-  def pipeline_batch_size=(pipeline_batch_size_value)
-    @pipeline_settings[:pipeline_batch_size] = validate_positive_integer(pipeline_batch_size_value)
-  end
-
-  def pipeline_batch_delay=(pipeline_batch_delay_value)
-    @pipeline_settings[:pipeline_batch_delay] = validate_positive_integer(pipeline_batch_delay_value)
-  end
-
-  def validate_positive_integer(str_arg)
-    int_arg = str_arg.to_i
-    if str_arg !~ /^\d+$/ || int_arg < 1
-      raise ArgumentError, "Expected a positive integer, got '#{str_arg}'"
-    end
+    :attribute_name => "log.json",
+    :default => LogStash::SETTINGS.get_default("log.json")
 
-    int_arg
-  end
+  option ["--settings.dir"], "SETTINGS_DIR",
+    I18n.t("logstash.runner.flag.settings-dir"),
+    :attribute_name => "settings.dir",
+    :default => LogStash::SETTINGS.get_default("settings.dir")
 
   attr_reader :agent
 
   def initialize(*args)
     @logger = Cabin::Channel.get(LogStash)
-    @pipeline_settings ||= { :pipeline_id => "main" }
+    @settings = LogStash::SETTINGS
     super(*args)
   end
 
+  def run(args)
+    settings_path = fetch_settings_path(args)
+    @settings.set("settings.dir", settings_path) if settings_path
+    LogStash::SETTINGS.from_yaml(LogStash::SETTINGS.get("settings.dir"))
+    super(*[args])
+  end
+
   def execute
     require "logstash/util"
     require "logstash/util/java_version"
@@ -140,7 +147,7 @@ def execute
 
     # Configure Logstash logging facility, this need to be done before everything else to
     # make sure the logger has the correct settings and the log level is correctly defined.
-    configure_logging(log_file)
+    configure_logging(setting("log.path"))
 
     LogStash::Util::set_thread_name(self.class.name)
 
@@ -154,32 +161,34 @@ def execute
     if LogStash::Util::JavaVersion.bad_java_version?(java_version)
       $stderr.puts "Java version 1.8.0 or later is required. (You are running: #{java_version})"
       return 1
-    end  
+    end
 
-    LogStash::ShutdownWatcher.unsafe_shutdown = unsafe_shutdown?
+    LogStash::ShutdownWatcher.unsafe_shutdown = setting("pipeline.unsafe_shutdown")
     LogStash::ShutdownWatcher.logger = @logger
 
-    configure
+    configure_plugin_paths(setting("plugin.paths"))
 
     if version?
       show_version
       return 0
     end
 
-    return start_shell(@ruby_shell, binding) if @ruby_shell
+    return start_shell(setting("interactive"), binding) if setting("interactive")
+
+    @settings.format_settings.each {|line| @logger.info(line) }
 
-    if config_string.nil? && config_path.nil?
+    if setting("config.string").nil? && setting("config.path").nil?
       fail(I18n.t("logstash.runner.missing-configuration"))
     end
 
-    if @auto_reload && config_path.nil?
+    if setting("config.reload.auto") && setting("config.path").nil?
       # there's nothing to reload
       signal_usage_error(I18n.t("logstash.runner.reload-without-config-path"))
     end
 
-    if config_test?
-      config_loader = LogStash::Config::Loader.new(@logger, @debug_config)
-      config_str = config_loader.format_config(config_path, config_string)
+    if setting("config.test")
+      config_loader = LogStash::Config::Loader.new(@logger)
+      config_str = config_loader.format_config(setting("config.path"), setting("config.string"))
       begin
         LogStash::Pipeline.new(config_str)
         @logger.terminal "Configuration OK"
@@ -190,21 +199,9 @@ def execute
       end
     end
 
-    @agent = create_agent(:logger => @logger,
-                          :auto_reload => @auto_reload,
-                          :reload_interval => @reload_interval,
-                          :collect_metric => true,
-                          :debug => debug?,
-                          :node_name => node_name,
-                          :debug_config => debug_config?,
-                          :web_api_http_host => @web_api_http_host,
-                          :web_api_http_port => @web_api_http_port)
-
-    @agent.register_pipeline("main", @pipeline_settings.merge({
-                          :config_string => config_string,
-                          :config_path => config_path,
-                          :debug_config => debug_config?
-                          }))
+    @agent = create_agent(@settings)
+
+    @agent.register_pipeline("main", @settings)
 
     # enable sigint/sigterm before starting the agent
     # to properly handle a stalled agent
@@ -239,10 +236,10 @@ def execute
   def show_version
     show_version_logstash
 
-    if [:info, :debug].include?(verbosity?) || debug? || verbose?
+    if debug? || verbose?
       show_version_ruby
       show_version_java if LogStash::Environment.jruby?
-      show_gems if [:debug].include?(verbosity?) || debug?
+      show_gems if debug?
     end
   end # def show_version
 
@@ -268,13 +265,6 @@ def show_gems
     end
   end # def show_gems
 
-  # Do any start-time configuration.
-  #
-  # Log file stuff, plugin path checking, etc.
-  def configure
-    configure_plugin_paths(plugin_paths)
-  end # def configure
-
   # add the given paths for ungemified/bare plugins lookups
   # @param paths [String, Array<String>] plugins path string or list of path strings to add
   def configure_plugin_paths(paths)
@@ -299,22 +289,10 @@ def configure_logging(path)
     elsif debug?
       @logger.level = :debug
     else
-      # Old support for the -v and -vv stuff.
-      if verbosity? && verbosity?.any?
-        # this is an array with length of how many times the flag is given
-        if verbosity?.length == 1
-          @logger.warn("The -v flag is deprecated and will be removed in a future release. You should use --verbose instead.")
-          @logger.level = :info
-        else
-          @logger.warn("The -vv flag is deprecated and will be removed in a future release. You should use --debug instead.")
-          @logger.level = :debug
-        end
-      else
-        @logger.level = :warn
-      end
+      @logger.level = :warn
     end
 
-    if log_file
+    if path
       # TODO(sissel): Implement file output/rotation in Cabin.
       # TODO(sissel): Catch exceptions, report sane errors.
       begin
@@ -325,7 +303,7 @@ def configure_logging(path)
                     :path => path, :error => e))
       end
 
-      if log_in_json?
+      if setting("log.json")
         @logger.subscribe(LogStash::Logging::JSON.new(STDOUT), :level => :fatal)
         @logger.subscribe(LogStash::Logging::JSON.new(@log_fd))
       else
@@ -334,14 +312,14 @@ def configure_logging(path)
       end
       @logger.terminal "Sending logstash logs to #{path}."
     else
-      if log_in_json?
+      if setting("log.json")
         @logger.subscribe(LogStash::Logging::JSON.new(STDOUT))
       else
         @logger.subscribe(STDOUT)
       end
     end
 
-    if debug_config? && @logger.level != :debug
+    if setting("debug.config") && @logger.level != :debug
       @logger.warn("--debug-config was specified, but log level was not set to --debug! No config info will be logged.")
     end
 
@@ -402,4 +380,26 @@ def trap_sigint
     end
   end
 
-end # class LogStash::Runner
+  def setting(key)
+    @settings.get_value(key)
+  end
+
+  # where can I find the logstash.yml file?
+  # 1. look for a "--settings.dir path"
+  # 2. look for a "--settings.dir=path"
+  # 3. check if the LS_SETTINGS_DIR environment variable is set
+  # 4. return nil if not found
+  def fetch_settings_path(cli_args)
+    if i=cli_args.find_index("--settings.dir")
+      cli_args[i+1]
+    elsif settings_arg = cli_args.find {|v| v.match(/--settings.dir=/) }
+      match = settings_arg.match(/--settings.dir=(.*)/)
+      match[1]
+    elsif ENV['LS_SETTINGS_DIR']
+      ENV['LS_SETTINGS_DIR']
+    else
+      nil
+    end
+  end
+
+end
diff --git a/logstash-core/lib/logstash/settings.rb b/logstash-core/lib/logstash/settings.rb
new file mode 100644
index 00000000000..ea92f080fb5
--- /dev/null
+++ b/logstash-core/lib/logstash/settings.rb
@@ -0,0 +1,252 @@
+# encoding: utf-8
+
+module LogStash
+  class Settings
+
+    def initialize
+      @settings = {}
+    end
+
+    def register(setting)
+      if @settings.key?(setting.name)
+        raise ArgumentError.new("Setting \"#{setting.name}\" has already been registered as #{setting.inspect}")
+      else
+        @settings[setting.name] = setting
+      end
+    end
+
+    def get_setting(setting_name)
+      setting = @settings[setting_name]
+      raise ArgumentError.new("Setting \"#{setting_name}\" hasn't been registered") if setting.nil?
+      setting
+    end
+
+    def get_subset(setting_regexp)
+      regexp = setting_regexp.is_a?(Regexp) ? setting_regexp : Regexp.new(setting_regexp)
+      settings = self.class.new
+      @settings.each do |setting_name, setting|
+        next unless setting_name.match(regexp)
+        settings.register(setting.clone)
+      end
+      settings
+    end
+
+    def set?(setting_name)
+      get_setting(setting_name).set?
+    end
+
+    def clone
+      get_subset(".*")
+    end
+
+    def get_default(setting_name)
+      get_setting(setting_name).default
+    end
+
+    def get_value(setting_name)
+      get_setting(setting_name).value
+    end
+    alias_method :get, :get_value
+
+    def set_value(setting_name, value)
+      get_setting(setting_name).set(value)
+    end
+    alias_method :set, :set_value
+
+    def to_hash
+      hash = {}
+      @settings.each do |name, setting|
+        hash[name] = setting.value
+      end
+      hash
+    end
+
+    def merge(hash)
+      hash.each {|key, value| set_value(key, value) }
+      self
+    end
+
+    def format_settings
+      output = []
+      output << "-------- Logstash Settings (* means modified) ---------"
+      @settings.each do |setting_name, setting|
+        value = setting.value
+        default_value = setting.default
+        if default_value == value # print setting and its default value
+          output << "#{setting_name}: #{value.inspect}" unless value.nil?
+        elsif default_value.nil? # print setting and warn it has been set
+          output << "*#{setting_name}: #{value.inspect}"
+        elsif value.nil? # default setting not set by user
+          output << "#{setting_name}: #{default_value.inspect}"
+        else # print setting, warn it has been set, and show default value
+          output << "*#{setting_name}: #{value.inspect} (default: #{default_value.inspect})"
+        end
+      end
+      output << "--------------- Logstash Settings -------------------"
+      output
+    end
+
+    def reset
+      @settings.values.each(&:reset)
+    end
+
+    def from_yaml(yaml_path)
+      settings = read_yaml(::File.join(yaml_path, "logstash.yml"))
+      self.merge(flatten_hash(settings))
+    end
+
+    private
+    def read_yaml(path)
+      YAML.safe_load(IO.read(path)) || {}
+    end
+
+    def flatten_hash(h,f="",g={})
+      return g.update({ f => h }) unless h.is_a? Hash
+      if f.empty?
+        h.each { |k,r| flatten_hash(r,k,g) }
+      else
+        h.each { |k,r| flatten_hash(r,"#{f}.#{k}",g) }
+      end
+      g
+    end
+  end
+
+  class Setting
+    attr_reader :name, :default
+
+    def initialize(name, klass, default=nil, strict=true, &validator_proc)
+      @name = name
+      unless klass.is_a?(Class)
+        raise ArgumentError.new("Setting \"#{@name}\" must be initialized with a class (received #{klass})")
+      end
+      @klass = klass
+      @validator_proc = validator_proc
+      @value = nil
+      @value_is_set = false
+
+      validate(default) if strict
+      @default = default
+    end
+
+    def value
+      @value_is_set ? @value : default
+    end
+
+    def set?
+      @value_is_set
+    end
+
+    def set(value)
+      validate(value)
+      @value = value
+      @value_is_set = true
+      @value
+    end
+
+    def reset
+      @value = nil
+      @value_is_set = false
+    end
+
+    def to_hash
+      {
+        "name" => @name,
+        "klass" => @klass,
+        "value" => @value,
+        "value_is_set" => @value_is_set,
+        "default" => @default,
+        # Proc#== will only return true if it's the same obj
+        # so no there's no point in comparing it
+        # also thereś no use case atm to return the proc
+        # so let's not expose it
+        #"validator_proc" => @validator_proc
+      }
+    end
+
+    def ==(other)
+      self.to_hash == other.to_hash
+    end
+
+    private
+    def validate(value)
+      if !value.is_a?(@klass)
+        raise ArgumentError.new("Setting \"#{@name}\" must be a #{@klass}. Received: #{value} (#{value.class})")
+      elsif @validator_proc && !@validator_proc.call(value)
+        raise ArgumentError.new("Failed to validate setting \"#{@name}\" with value: #{value}")
+      end
+    end
+
+    ### Specific settings #####
+
+    class Boolean < Setting
+      def initialize(name, default)
+        @name = name
+        @klass = Object
+        @value = nil
+        @value_is_set = false
+        @default = coerce(default)
+      end
+
+      def coerce(value)
+        case value
+        when TrueClass, "true"
+          true
+        when FalseClass, "false"
+          false
+        else
+          raise ArgumentError.new("could not coerce #{value} into a boolean")
+        end
+      end
+
+      def set(value)
+        @value = coerce(value)
+        @value_is_set = true
+        @value
+      end
+    end
+
+    class String < Setting
+      def initialize(name, default=nil, strict=true)
+        super(name, ::String, default, strict)
+      end
+    end
+
+    class Numeric < Setting
+      def initialize(name, default=nil, strict=true)
+        super(name, ::Numeric, default, strict)
+      end
+    end
+
+    class Port < Setting
+      def initialize(name, default=nil, strict=true)
+        super(name, ::Numeric, default, strict) {|value| value >= 1 && value <= 65535 }
+      end
+    end
+
+    class Validator < Setting
+      def initialize(name, default=nil, strict=true, validator_class=nil)
+        @validator_class = validator_class
+        super(name, ::Object, default, strict)
+      end
+
+      def validate(value)
+        @validator_class.validate(value)
+      end
+    end
+
+    class ExistingFilePath < Setting
+      def initialize(name, default=nil, strict=true)
+        super(name, ::String, default, strict) do |file_path|
+          if !::File.exists?(file_path)
+            raise ::ArgumentError.new("File \"#{file_path}\" must exist but was not found.")
+          else
+            true
+          end
+        end
+      end
+    end
+
+  end
+
+  SETTINGS = Settings.new
+end
diff --git a/logstash-core/lib/logstash/util/defaults_printer.rb b/logstash-core/lib/logstash/util/defaults_printer.rb
deleted file mode 100644
index 6dd850e1d50..00000000000
--- a/logstash-core/lib/logstash/util/defaults_printer.rb
+++ /dev/null
@@ -1,31 +0,0 @@
-# encoding: utf-8
-require "logstash/namespace"
-require "logstash/util"
-require "logstash/util/worker_threads_default_printer"
-
-
-# This class exists to format the settings for defaults used
-module LogStash module Util class DefaultsPrinter
-  def self.print(settings)
-    new(settings).print
-  end
-
-  def initialize(settings)
-    @settings = settings
-    @printers = [workers]
-  end
-
-  def print
-    collector = []
-    @printers.each do |printer|
-      printer.visit(collector)
-    end
-    "Settings: " + collector.join(', ')
-  end
-
-  private
-
-  def workers
-    WorkerThreadsDefaultPrinter.new(@settings)
-  end
-end end end
diff --git a/logstash-core/lib/logstash/util/worker_threads_default_printer.rb b/logstash-core/lib/logstash/util/worker_threads_default_printer.rb
index 43869162865..b35058ac24e 100644
--- a/logstash-core/lib/logstash/util/worker_threads_default_printer.rb
+++ b/logstash-core/lib/logstash/util/worker_threads_default_printer.rb
@@ -6,8 +6,8 @@
 module LogStash module Util class WorkerThreadsDefaultPrinter
 
   def initialize(settings)
-    @setting = settings.fetch(:pipeline_workers, 0)
-    @default = settings.fetch(:default_pipeline_workers, 0)
+    @setting = settings.fetch('pipeline.workers', 0)
+    @default = settings.fetch('default-pipeline-workers', 0)
   end
 
   def visit(collector)
diff --git a/logstash-core/locales/en.yml b/logstash-core/locales/en.yml
index f265cad81c4..1e4d86527a5 100644
--- a/logstash-core/locales/en.yml
+++ b/logstash-core/locales/en.yml
@@ -188,6 +188,9 @@ en:
         pipeline-batch-delay: |+
           When creating pipeline batches, how long to wait while polling
           for the next event.
+        settings-dir: |+
+          Directory containing logstash.yml file. This can also be
+          set through the LS_SETTINGS_DIR environment variable.
         auto_reload: |+
           Monitor configuration changes and reload
           whenever it is changed.
diff --git a/logstash-core/spec/api/spec_helper.rb b/logstash-core/spec/api/spec_helper.rb
index 90a1bb1e378..3a6befd8844 100644
--- a/logstash-core/spec/api/spec_helper.rb
+++ b/logstash-core/spec/api/spec_helper.rb
@@ -3,6 +3,7 @@
 
 require "logstash/devutils/rspec/spec_helper"
 
+require "logstash/settings"
 require 'rack/test'
 require 'rspec'
 require "json"
@@ -37,26 +38,24 @@ class LogStashRunner
   attr_reader :config_str, :agent, :pipeline_settings
 
   def initialize
-    args = [
-      :logger => Cabin::Channel.get(LogStash),
-      :auto_reload => false,
-      :collect_metric => true,
-      :debug => false,
-      :node_name => "test_agent",
-      :web_api_http_port => rand(9600..9700)
-    ]
-
     @config_str   = "input { generator {count => 0} } output { }"
-    @agent = LogStash::DummyAgent.new(*args)
-    @pipeline_settings ||= { :pipeline_id => "main",
-                             :config_str => config_str,
-                            :pipeline_batch_size => 1,
-                            :flush_interval => 1,
-                            :pipeline_workers => 1 }
+    args = {
+      "config.reload.auto" => false,
+      "metric.collect" => true,
+      "debug" => false,
+      "node.name" => "test_agent",
+      "web_api.http.port" => rand(9600..9700),
+      "config.string" => @config_str,
+      "pipeline.batch.size" => 1,
+      "pipeline.workers" => 1
+    }
+    @settings = ::LogStash::SETTINGS.clone.merge(args)
+
+    @agent = LogStash::DummyAgent.new(@settings)
   end
 
   def start
-    agent.register_pipeline("main", pipeline_settings)
+    agent.register_pipeline("main", @settings)
     @runner = Thread.new(agent) do |_agent|
       _agent.execute
     end
diff --git a/logstash-core/spec/logstash/agent_spec.rb b/logstash-core/spec/logstash/agent_spec.rb
index 60d28987f44..4777b7559ff 100644
--- a/logstash-core/spec/logstash/agent_spec.rb
+++ b/logstash-core/spec/logstash/agent_spec.rb
@@ -7,8 +7,14 @@
 describe LogStash::Agent do
 
   let(:logger) { double("logger") }
-  let(:agent_args) { { :logger => logger } }
-  subject { LogStash::Agent.new(agent_args) }
+  let(:agent_settings) { LogStash::SETTINGS }
+  let(:agent_args) { {} }
+  let(:pipeline_settings) { agent_settings.clone }
+  let(:pipeline_args) { {} }
+  let(:config_file) { Stud::Temporary.pathname }
+  let(:config_file_txt) { "input { generator { count => 100000 } } output { }" }
+
+  subject { LogStash::Agent.new(agent_settings) }
 
   before :each do
     [:info, :warn, :error, :fatal, :debug].each do |level|
@@ -17,46 +23,63 @@
     [:info?, :warn?, :error?, :fatal?, :debug?].each do |level|
       allow(logger).to receive(level)
     end
+    File.open(config_file, "w") { |f| f.puts config_file_txt }
+    agent_args.each do |key, value|
+      agent_settings.set(key, value)
+      pipeline_settings.set(key, value)
+    end
+    pipeline_args.each do |key, value|
+      pipeline_settings.set(key, value)
+    end
+    #subject.logger = logger
+  end
+
+  after :each do
+    LogStash::SETTINGS.reset
+    File.unlink(config_file)
+  end
+
+  it "fallback to hostname when no name is provided" do
+    expect(LogStash::Agent.new.node_name).to eq(Socket.gethostname)
   end
 
   describe "register_pipeline" do
     let(:pipeline_id) { "main" }
     let(:config_string) { "input { } filter { } output { }" }
-    let(:settings) { {
-      :config_string => config_string,
-      :pipeline_workers => 4
-    } }
-
-    let(:agent_args) { {
-      :logger => logger,
-      :auto_reload => false,
-      :reload_interval => 0.01
-    } }
+    let(:agent_args) do
+      { 
+        "config.string" => config_string,
+        "config.reload.auto" => true,
+        "config.reload.interval" => 0.01,
+	"pipeline.workers" => 4,
+      }
+    end
 
     it "should delegate settings to new pipeline" do
-      expect(LogStash::Pipeline).to receive(:new).with(settings[:config_string], hash_including(settings))
-      subject.register_pipeline(pipeline_id, settings)
+      expect(LogStash::Pipeline).to receive(:new) do |arg1, arg2|
+        expect(arg1).to eq(config_string)
+	expect(arg2.to_hash).to include(agent_args)
+      end
+      subject.register_pipeline(pipeline_id, agent_settings)
     end
   end
 
   describe "#execute" do
-    let(:sample_config) { "input { generator { count => 100000 } } output { }" }
-    let(:config_file) { Stud::Temporary.pathname }
+    let(:config_file_txt) { "input { generator { count => 100000 } } output { }" }
 
     before :each do
       allow(subject).to receive(:start_webserver).and_return(false)
       allow(subject).to receive(:stop_webserver).and_return(false)
-      File.open(config_file, "w") { |f| f.puts sample_config }
-    end
-
-    after :each do
-      File.unlink(config_file)
     end
 
     context "when auto_reload is false" do
-      let(:agent_args) { { :logger => logger, :auto_reload => false } }
+      let(:agent_args) do
+        {
+          "config.reload.auto" => false,
+          "config.path" => config_file
+        }
+      end
       let(:pipeline_id) { "main" }
-      let(:pipeline_settings) { { :config_path => config_file } }
 
       before(:each) do
         subject.register_pipeline(pipeline_id, pipeline_settings)
@@ -112,9 +135,14 @@
     end
 
     context "when auto_reload is true" do
-      let(:agent_args) { { :logger => logger, :auto_reload => true, :reload_interval => 0.01 } }
+      let(:agent_args) do
+        {
+          "config.reload.auto" => true,
+          "config.reload.interval" => 0.01,
+          "config.path" => config_file,
+        }
+      end
       let(:pipeline_id) { "main" }
-      let(:pipeline_settings) { { :config_path => config_file } }
 
       before(:each) do
         subject.register_pipeline(pipeline_id, pipeline_settings)
@@ -168,9 +196,9 @@
     let(:pipeline_id) { "main" }
     let(:first_pipeline_config) { "input { } filter { } output { }" }
     let(:second_pipeline_config) { "input { generator {} } filter { } output { }" }
-    let(:pipeline_settings) { {
-      :config_string => first_pipeline_config,
-      :pipeline_workers => 4
+    let(:pipeline_args) { {
+      "config.string" => first_pipeline_config,
+      "pipeline.workers" => 4
     } }
 
     before(:each) do
@@ -194,16 +222,13 @@
   end
 
   describe "Environment Variables In Configs" do
+    let(:pipeline_config) { "input { generator { message => '${FOO}-bar' } } filter { } output { }" }
     let(:agent_args) { {
-      :logger => logger,
-      :auto_reload => false,
-      :reload_interval => 0.01
+      "config.reload.auto" => false,
+      "config.reload.interval" => 0.01,
+      "config.string" => pipeline_config
     } }
     let(:pipeline_id) { "main" }
-    let(:pipeline_config) { "input { generator { message => '${FOO}-bar' } } filter { } output { }" }
-    let(:pipeline_settings) { {
-      :config_string => pipeline_config,
-    } }
 
     context "environment variable templating" do
       before :each do
@@ -216,7 +241,7 @@
       end
 
       it "doesn't upgrade the state" do
-        expect(subject).to receive(:fetch_config).and_return(pipeline_config)
+        allow(subject).to receive(:fetch_config).and_return(pipeline_config)
         subject.register_pipeline(pipeline_id, pipeline_settings)
         expect(subject.pipelines[pipeline_id].inputs.first.message).to eq("foo-bar")
       end
@@ -226,9 +251,9 @@
   describe "#upgrade_pipeline" do
     let(:pipeline_id) { "main" }
     let(:pipeline_config) { "input { } filter { } output { }" }
-    let(:pipeline_settings) { {
-      :config_string => pipeline_config,
-      :pipeline_workers => 4
+    let(:pipeline_args) { {
+      "config.string" => pipeline_config,
+      "pipeline.workers" => 4
     } }
     let(:new_pipeline_config) { "input { generator {} } output { }" }
 
@@ -275,23 +300,12 @@
   end
 
   describe "#fetch_config" do
-    let(:file_config) { "input { generator { count => 100 } } output { }" }
     let(:cli_config) { "filter { drop { } } " }
-    let(:tmp_config_path) { Stud::Temporary.pathname }
-    let(:agent_args) { { :logger => logger, :config_string => "filter { drop { } } ", :config_path => tmp_config_path } }
-
-    before :each do
-      IO.write(tmp_config_path, file_config)
-    end
-
-    after :each do
-      File.unlink(tmp_config_path)
-    end
+    let(:agent_args) { { "config.string" => cli_config, "config.path" => config_file } }
 
     it "should join the config string and config path content" do
-      settings = { :config_path => tmp_config_path, :config_string => cli_config }
-      fetched_config = subject.send(:fetch_config, settings)
-      expect(fetched_config.strip).to eq(cli_config + IO.read(tmp_config_path))
+      fetched_config = subject.send(:fetch_config, agent_settings)
+      expect(fetched_config.strip).to eq(cli_config + IO.read(config_file).strip)
     end
   end
 
@@ -319,13 +333,17 @@
       f.path
     end
     let(:interval) { 0.2 }
-    let(:pipeline_settings) { { :pipeline_workers => 4,
-                                :config_path => config_path } }
+    let(:pipeline_args) do
+      {
+        "pipeline.workers" => 4,
+        "config.path" => config_path
+      }
+    end
 
     let(:agent_args) do
-      super.merge({ :auto_reload => true,
-                    :reload_interval => interval,
-                    :collect_metric => true })
+      super.merge({ "config.reload.auto" => true,
+                    "config.reload.interval" => interval,
+                    "metric.collect" => true })
     end 
 
     before :each do
diff --git a/logstash-core/spec/logstash/pipeline_spec.rb b/logstash-core/spec/logstash/pipeline_spec.rb
index ea375570486..89fe7863aa3 100644
--- a/logstash-core/spec/logstash/pipeline_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_spec.rb
@@ -84,9 +84,21 @@ class TestPipeline < LogStash::Pipeline
 end
 
 describe LogStash::Pipeline do
-  let(:worker_thread_count)     { LogStash::Pipeline::DEFAULT_SETTINGS[:default_pipeline_workers] }
+  let(:worker_thread_count)     { 5 }
   let(:safe_thread_count)       { 1 }
   let(:override_thread_count)   { 42 }
+  let(:pipeline_settings_obj) { LogStash::SETTINGS }
+  let(:pipeline_settings) { {} }
+
+  before :each do
+    pipeline_workers_setting = LogStash::SETTINGS.get_setting("pipeline.workers")
+    allow(pipeline_workers_setting).to receive(:default).and_return(worker_thread_count)
+    pipeline_settings.each {|k, v| pipeline_settings_obj.set(k, v) }
+  end
+
+  after :each do
+    pipeline_settings_obj.reset
+  end
 
   describe "defaulting the pipeline workers based on thread safety" do
     before(:each) do
@@ -123,13 +135,15 @@ class TestPipeline < LogStash::Pipeline
         end
 
         it "should not receive a debug message with the compiled code" do
+          pipeline_settings_obj.set("debug.config", false)
           expect(logger).not_to receive(:debug).with(/Compiled pipeline/, anything)
           pipeline = TestPipeline.new(test_config_with_filters)
         end
 
         it "should print the compiled code if debug_config is set to true" do
+          pipeline_settings_obj.set("debug.config", true)
           expect(logger).to receive(:debug).with(/Compiled pipeline/, anything)
-          pipeline = TestPipeline.new(test_config_with_filters, :debug_config => true)
+          pipeline = TestPipeline.new(test_config_with_filters, pipeline_settings_obj)
         end
       end
 
@@ -145,12 +159,13 @@ class TestPipeline < LogStash::Pipeline
       end
 
       context "when there is command line -w N set" do
+        let(:pipeline_settings) { {"pipeline.workers" => override_thread_count } }
         it "starts multiple filter thread" do
-          msg = "Warning: Manual override - there are filters that might not work with multiple worker threads"
-          pipeline = TestPipeline.new(test_config_with_filters)
+          msg = "Warning: Manual override - there are filters that might" +
+                " not work with multiple worker threads"
+          pipeline = TestPipeline.new(test_config_with_filters, pipeline_settings_obj)
           expect(pipeline.logger).to receive(:warn).with(msg,
             {:worker_threads=> override_thread_count, :filters=>["dummyfilter"]})
-          pipeline.configure(:pipeline_workers, override_thread_count)
           pipeline.run
           expect(pipeline.worker_threads.size).to eq(override_thread_count)
         end
@@ -222,7 +237,7 @@ class TestPipeline < LogStash::Pipeline
         pipeline.run
 
         expect(pipeline.outputs.size ).to eq(1)
-        expect(pipeline.outputs.first.workers.size ).to eq(::LogStash::Pipeline::DEFAULT_OUTPUT_WORKERS)
+        expect(pipeline.outputs.first.workers.size ).to eq(::LogStash::SETTINGS.get("pipeline.output.workers"))
         expect(pipeline.outputs.first.workers.first.num_closes ).to eq(1)
       end
 
@@ -310,7 +325,8 @@ class TestPipeline < LogStash::Pipeline
   describe "max inflight warning" do
     let(:config) { "input { dummyinput {} } output { dummyoutput {} }" }
     let(:batch_size) { 1 }
-    let(:pipeline) { LogStash::Pipeline.new(config, :pipeline_batch_size => batch_size, :pipeline_workers => 1) }
+    let(:pipeline_settings) { { "pipeline.batch.size" => batch_size, "pipeline.workers" => 1 } }
+    let(:pipeline) { LogStash::Pipeline.new(config, pipeline_settings_obj) }
     let(:logger) { pipeline.logger }
     let(:warning_prefix) { /CAUTION: Recommended inflight events max exceeded!/ }
 
@@ -435,7 +451,7 @@ class TestPipeline < LogStash::Pipeline
 
     it "flushes the buffered contents of the filter" do
       Thread.abort_on_exception = true
-      pipeline = LogStash::Pipeline.new(config, { :flush_interval => 1 })
+      pipeline = LogStash::Pipeline.new(config, pipeline_settings_obj)
       Thread.new { pipeline.run }
       sleep 0.1 while !pipeline.ready?
       # give us a bit of time to flush the events
@@ -526,8 +542,9 @@ class TestPipeline < LogStash::Pipeline
   end
 
   context "when collecting metrics in the pipeline" do
-    subject { described_class.new(config, { :metric => metric, :pipeline_id => pipeline_id }) }
-    let(:pipeline_id) { :main }
+    let(:pipeline_settings) { { "pipeline.id" => pipeline_id } }
+    subject { described_class.new(config, pipeline_settings_obj) }
+    let(:pipeline_id) { "main" }
     let(:metric) { LogStash::Instrument::Metric.new }
     let(:number_of_events) { 1000 }
     let(:multiline_id) { "my-multiline" }
@@ -573,6 +590,7 @@ class TestPipeline < LogStash::Pipeline
       # Reset the metric store
       LogStash::Instrument::Collector.instance.clear
 
+      subject.metric = metric
       Thread.new { subject.run }
       # make sure we have received all the generated events
       sleep 1 while dummyoutput.events.size < number_of_events
diff --git a/logstash-core/spec/logstash/runner_spec.rb b/logstash-core/spec/logstash/runner_spec.rb
index d1ce6441dbf..f13b01663d5 100644
--- a/logstash-core/spec/logstash/runner_spec.rb
+++ b/logstash-core/spec/logstash/runner_spec.rb
@@ -19,16 +19,50 @@ def run(args); end
 
   before :each do
     allow(Cabin::Channel).to receive(:get).with(LogStash).and_return(channel)
-    allow(channel).to receive(:subscribe).with(any_args).and_call_original
+    allow(channel).to receive(:subscribe).with(any_args)
+    allow(channel).to receive(:log) {}
+    allow(LogStash::ShutdownWatcher).to receive(:logger).and_return(channel)
+  end
+
+  after :each do
+    LogStash::SETTINGS.reset
+  end
+
+  after :all do
+    LogStash::ShutdownWatcher.logger = nil
+  end
+
+  describe "argument precedence" do
+    let(:config) { "input {} output {}" }
+    let(:cli_args) { ["-e", config, "-w", "20"] }
+    let(:settings_yml_hash) { { "pipeline.workers" => 2 } }
+
+    before :each do
+      allow(LogStash::SETTINGS).to receive(:read_yaml).and_return(settings_yml_hash)
+    end
+
+    after :each do
+      LogStash::SETTINGS.reset
+    end
+
+    it "favors the last occurence of an option" do
+      expect(LogStash::Agent).to receive(:new) do |settings|
+        expect(settings.get("config.string")).to eq(config)
+        expect(settings.get("pipeline.workers")).to eq(20)
+      end
+      subject.run("bin/logstash", cli_args)
+    end
   end
 
   describe "argument parsing" do
     subject { LogStash::Runner.new("") }
+    before :each do
+      allow(Cabin::Channel.get(LogStash)).to receive(:terminal)
+    end
     context "when -e is given" do
 
       let(:args) { ["-e", "input {} output {}"] }
       let(:agent) { double("agent") }
-      let(:agent_logger) { double("agent logger") }
 
       before do
         allow(agent).to receive(:logger=).with(anything)
@@ -45,10 +79,9 @@ def run(args); end
 
     context "with no arguments" do
       let(:args) { [] }
-      let(:agent) { double("agent") }
 
       before(:each) do
-        allow(LogStash::Agent).to receive(:new).and_return(agent)        
+        allow(LogStash::Util::JavaVersion).to receive(:warn_on_bad_java_version)
       end
 
       it "should show help" do
@@ -98,10 +131,10 @@ def run(args); end
     end
   end
 
-  context "--log-in-json" do
+  context "--log.json" do
     subject { LogStash::Runner.new("") }
     let(:logfile) { Stud::Temporary.file }
-    let(:args) { [ "--log-in-json", "-l", logfile.path, "-e", "input {} output{}" ] }
+    let(:args) { [ "--log.json", "-l", logfile.path, "-e", "input {} output{}" ] }
 
     after do
       logfile.close
@@ -158,8 +191,9 @@ def run(args); end
 
     context "when :pipeline_workers is not defined by the user" do
       it "should not pass the value to the pipeline" do
-        expect(LogStash::Pipeline).to receive(:new).once.with(pipeline_string, hash_excluding(:pipeline_workers)).and_return(pipeline)
-
+        expect(LogStash::Agent).to receive(:new) do |settings|
+	  expect(settings.set?("pipeline.workers")).to be(false)
+        end
         args = ["-e", pipeline_string]
         subject.run("bin/logstash", args)
       end
@@ -167,8 +201,10 @@ def run(args); end
 
     context "when :pipeline_workers is defined by the user" do
       it "should pass the value to the pipeline" do
-        main_pipeline_settings[:pipeline_workers] = 2
-        expect(LogStash::Pipeline).to receive(:new).with(pipeline_string, hash_including(main_pipeline_settings)).and_return(pipeline)
+        expect(LogStash::Agent).to receive(:new) do |settings|
+	  expect(settings.set?("pipeline.workers")).to be(true)
+	  expect(settings.get("pipeline.workers")).to be(2)
+        end
 
         args = ["-w", "2", "-e", pipeline_string]
         subject.run("bin/logstash", args)
@@ -176,17 +212,19 @@ def run(args); end
     end
 
     describe "debug_config" do
-      it "should set 'debug_config' to false by default" do
-        expect(LogStash::Config::Loader).to receive(:new).with(anything, false).and_call_original
-        expect(LogStash::Pipeline).to receive(:new).with(pipeline_string, hash_including(:debug_config => false)).and_return(pipeline)
-        args = ["--debug", "-e", pipeline_string, "-l", "/dev/null", "--log-in-json"]
+      it "should set 'debug.config' to false by default" do
+        expect(LogStash::Agent).to receive(:new) do |settings|
+          expect(settings.get("debug.config")).to eq(false)
+        end
+        args = ["--debug", "-e", pipeline_string]
         subject.run("bin/logstash", args)
       end
 
-      it "should allow overriding debug_config" do
-        expect(LogStash::Config::Loader).to receive(:new).with(anything, true).and_call_original
-        expect(LogStash::Pipeline).to receive(:new).with(pipeline_string, hash_including(:debug_config => true)).and_return(pipeline)
-        args = ["--debug", "--debug-config",  "-e", pipeline_string, "-l", "/dev/null", "--log-in-json"]
+      it "should allow overriding debug.config" do
+        expect(LogStash::Agent).to receive(:new) do |settings|
+          expect(settings.get("debug.config")).to eq(true)
+        end
+        args = ["--debug", "--debug.config",  "-e", pipeline_string]
         subject.run("bin/logstash", args)
       end
     end
diff --git a/logstash-core/spec/logstash/setting_spec.rb b/logstash-core/spec/logstash/setting_spec.rb
new file mode 100644
index 00000000000..33d1572b256
--- /dev/null
+++ b/logstash-core/spec/logstash/setting_spec.rb
@@ -0,0 +1,130 @@
+# encoding: utf-8
+require "spec_helper"
+require "logstash/settings"
+
+describe LogStash::Setting do
+  let(:logger) { double("logger") }
+  describe "#value" do
+    context "when using a default value" do
+      context "when no value is set" do
+        subject { described_class.new("number", Numeric, 1) }
+        it "should return the default value" do
+          expect(subject.value).to eq(1)
+        end
+      end
+
+      context "when a value is set" do
+        subject { described_class.new("number", Numeric, 1) }
+        let(:new_value) { 2 }
+        before :each do
+          subject.set(new_value)
+        end
+        it "should return the set value" do
+          expect(subject.value).to eq(new_value)
+        end
+      end
+    end
+
+    context "when not using a default value" do
+      context "when no value is set" do
+        subject { described_class.new("number", Numeric, nil, false) }
+        it "should return the default value" do
+          expect(subject.value).to eq(nil)
+        end
+      end
+
+      context "when a value is set" do
+        subject { described_class.new("number", Numeric, nil, false) }
+        let(:new_value) { 2 }
+        before :each do
+          subject.set(new_value)
+        end
+        it "should return the set value" do
+          expect(subject.value).to eq(new_value)
+        end
+      end
+    end
+  end
+
+  describe "#set?" do
+    context "when there is not value set" do
+      subject { described_class.new("number", Numeric, 1) }
+      it "should return false" do
+        expect(subject.set?).to be(false)
+      end
+    end
+    context "when there is a value set" do
+      subject { described_class.new("number", Numeric, 1) }
+      before :each do
+        subject.set(2)
+      end
+      it "should return false" do
+        expect(subject.set?).to be(true)
+      end
+    end
+  end
+  describe "#set" do
+    subject { described_class.new("number", Numeric, 1) }
+    it "should change the value of a setting" do
+      expect(subject.value).to eq(1)
+      subject.set(4)
+      expect(subject.value).to eq(4)
+    end
+    context "when executed for the first time" do
+      it "should change the result of set?" do
+        expect(subject.set?).to eq(false)
+        subject.set(4)
+        expect(subject.set?).to eq(true)
+      end
+    end
+
+    context "when the argument's class does not match @klass" do
+      it "should throw an exception" do
+        expect { subject.set("not a number") }.to raise_error
+      end
+    end
+  end
+
+  describe "#reset" do
+    subject { described_class.new("number", Numeric, 1) }
+    context "if value is already set" do
+      before :each do
+        subject.set(2)
+      end
+      it "should reset value to default" do
+        subject.reset
+        expect(subject.value).to eq(1)
+      end
+      it "should reset set? to false" do
+        expect(subject.set?).to eq(true)
+        subject.reset
+        expect(subject.set?).to eq(false)
+      end
+    end
+  end
+
+  describe "validator_proc" do
+    let(:default_value) { "small text" }
+    subject { described_class.new("mytext", String, default_value) {|v| v.size < 20 } }
+    context "when validation fails" do
+      let(:new_value) { "very very very very very big text" }
+      it "should raise an exception" do
+        expect { subject.set(new_value) }.to raise_error
+      end
+      it "should not change the value" do
+        subject.set(new_value) rescue nil
+        expect(subject.value).to eq(default_value)
+      end
+    end
+    context "when validation is successful" do
+      let(:new_value) { "smaller text" }
+      it "should not raise an exception" do
+        expect { subject.set(new_value) }.to_not raise_error
+      end
+      it "should change the value" do
+        subject.set(new_value)
+        expect(subject.value).to eq(new_value)
+      end
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/settings_spec.rb b/logstash-core/spec/logstash/settings_spec.rb
new file mode 100644
index 00000000000..050da87f4ac
--- /dev/null
+++ b/logstash-core/spec/logstash/settings_spec.rb
@@ -0,0 +1,62 @@
+# encoding: utf-8
+require "spec_helper"
+require "logstash/settings"
+
+describe LogStash::Settings do
+  let(:numeric_setting_name) { "number" }
+  let(:numeric_setting) { LogStash::Setting.new(numeric_setting_name, Numeric, 1) }
+  describe "#register" do
+    context "if setting has already been registered" do
+      before :each do
+        subject.register(numeric_setting)
+      end
+      it "should raise an exception" do
+        expect { subject.register(numeric_setting) }.to raise_error
+      end
+    end
+    context "if setting hasn't been registered" do
+      it "should not raise an exception" do
+        expect { subject.register(numeric_setting) }.to_not raise_error
+      end
+    end
+  end
+  describe "#get_setting" do
+    context "if setting has been registered" do
+      before :each do
+        subject.register(numeric_setting)
+      end
+      it "should return the setting" do
+        expect(subject.get_setting(numeric_setting_name)).to eq(numeric_setting)
+      end
+    end
+    context "if setting hasn't been registered" do
+      it "should raise an exception" do
+        expect { subject.get_setting(numeric_setting_name) }.to raise_error
+      end
+    end
+  end
+  describe "#get_subset" do
+    let(:numeric_setting_1) { LogStash::Setting.new("num.1", Numeric, 1) }
+    let(:numeric_setting_2) { LogStash::Setting.new("num.2", Numeric, 2) }
+    let(:numeric_setting_3) { LogStash::Setting.new("num.3", Numeric, 3) }
+    let(:string_setting_1) { LogStash::Setting.new("string.1", String, "hello") }
+    before :each do
+      subject.register(numeric_setting_1)
+      subject.register(numeric_setting_2)
+      subject.register(numeric_setting_3)
+      subject.register(string_setting_1)
+    end
+
+    it "supports regex" do
+      expect(subject.get_subset(/num/).get_setting("num.3")).to eq(numeric_setting_3)
+      expect { subject.get_subset(/num/).get_setting("string.1") }.to raise_error
+    end
+
+    it "returns a copy of settings" do
+      subset = subject.get_subset(/num/)
+      subset.set("num.2", 1000)
+      expect(subject.get("num.2")).to eq(2)
+      expect(subset.get("num.2")).to eq(1000)
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/util/defaults_printer_spec.rb b/logstash-core/spec/logstash/util/defaults_printer_spec.rb
deleted file mode 100644
index b3f0576a3a9..00000000000
--- a/logstash-core/spec/logstash/util/defaults_printer_spec.rb
+++ /dev/null
@@ -1,50 +0,0 @@
-# encoding: utf-8
-require "spec_helper"
-require "logstash/util/defaults_printer"
-
-describe LogStash::Util::DefaultsPrinter do
-  shared_examples "a defaults printer" do
-    it 'the .print method returns a defaults description' do
-      expect(actual_block.call).to eq(expected)
-    end
-  end
-
-  let(:workers)  { 1 }
-  let(:expected) { "Settings: User set pipeline workers: #{workers}" }
-  let(:settings) { {} }
-
-  describe 'class methods API' do
-    let(:actual_block) do
-      -> {described_class.print(settings)}
-    end
-
-    context 'when the settings hash is empty' do
-      let(:expected) { "Settings: " }
-      it_behaves_like "a defaults printer"
-    end
-
-    context 'when the settings hash has content' do
-      let(:worker_queue) { 42 }
-      let(:settings) { {:pipeline_workers => workers} }
-      it_behaves_like "a defaults printer"
-    end
-  end
-
-  describe 'instance method API' do
-    let(:actual_block) do
-      -> {described_class.new(settings).print}
-    end
-
-    context 'when the settings hash is empty' do
-      let(:expected) { "Settings: " }
-      it_behaves_like "a defaults printer"
-    end
-
-    context 'when the settings hash has content' do
-      let(:workers) { 13 }
-      let(:settings) { {:pipeline_workers => workers} }
-
-      it_behaves_like "a defaults printer"
-    end
-  end
-end
diff --git a/logstash-core/spec/logstash/util/worker_threads_default_printer_spec.rb b/logstash-core/spec/logstash/util/worker_threads_default_printer_spec.rb
deleted file mode 100644
index 1842b4373ad..00000000000
--- a/logstash-core/spec/logstash/util/worker_threads_default_printer_spec.rb
+++ /dev/null
@@ -1,45 +0,0 @@
-# encoding: utf-8
-require "spec_helper"
-require "logstash/util/worker_threads_default_printer"
-
-describe LogStash::Util::WorkerThreadsDefaultPrinter do
-  let(:settings)  { {} }
-  let(:collector) { [] }
-
-  subject { described_class.new(settings) }
-
-  before { subject.visit(collector) }
-
-  describe "the #visit method" do
-    context 'when the settings hash is empty' do
-      it 'adds nothing to the collector' do
-        subject.visit(collector)
-        expect(collector).to eq([])
-      end
-    end
-
-    context 'when the settings hash has both user and default content' do
-      let(:settings) { {:pipeline_workers => 42, :default_pipeline_workers => 5} }
-
-      it 'adds two strings' do
-        expect(collector).to eq(["User set pipeline workers: 42", "Default pipeline workers: 5"])
-      end
-    end
-
-    context 'when the settings hash has only user content' do
-      let(:settings) { {:pipeline_workers => 42} }
-
-      it 'adds a string with user set pipeline workers' do
-        expect(collector.first).to eq("User set pipeline workers: 42")
-      end
-    end
-
-    context 'when the settings hash has only default content' do
-      let(:settings) { {:default_pipeline_workers => 5} }
-
-      it 'adds a string with default pipeline workers' do
-        expect(collector.first).to eq("Default pipeline workers: 5")
-      end
-    end
-  end
-end
diff --git a/rakelib/artifacts.rake b/rakelib/artifacts.rake
index e0fc2f57eb2..ad64e269780 100644
--- a/rakelib/artifacts.rake
+++ b/rakelib/artifacts.rake
@@ -13,6 +13,7 @@ namespace "artifact" do
       "lib/pluginmanager/**/*",
       "patterns/**/*",
       "vendor/??*/**/*",
+      "conf/logstash.yml",
       # To include ruby-maven's hidden ".mvn" directory, we need to
       # do add the line below. This directory contains a file called
       # "extensions.xml", which loads the ruby DSL for POMs.
diff --git a/spec/bootstrap/environment_spec.rb b/spec/bootstrap/environment_spec.rb
new file mode 100644
index 00000000000..f31cfcd38e8
--- /dev/null
+++ b/spec/bootstrap/environment_spec.rb
@@ -0,0 +1,6 @@
+# encoding: utf-8
+require "spec_helper"
+require "bootstrap/environment"
+
+describe LogStash::Environment do
+end
