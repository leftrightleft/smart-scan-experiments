diff --git a/logstash-core/lib/logstash/instrument/collector.rb b/logstash-core/lib/logstash/instrument/collector.rb
index 23827522e3e..1666810bf95 100644
--- a/logstash-core/lib/logstash/instrument/collector.rb
+++ b/logstash-core/lib/logstash/instrument/collector.rb
@@ -61,6 +61,9 @@ def push(namespaces_path, key, type, *metric_type_params)
       end
     end
 
+    def clear
+      @metric_store = MetricStore.new
+    end
 
     # Monitor the `Concurrent::TimerTask` this update is triggered on every successful or not
     # run of the task, TimerTask implement Observable and the collector acts as
diff --git a/logstash-core/lib/logstash/instrument/metric_store.rb b/logstash-core/lib/logstash/instrument/metric_store.rb
index 85371059408..1e0e27d5562 100644
--- a/logstash-core/lib/logstash/instrument/metric_store.rb
+++ b/logstash-core/lib/logstash/instrument/metric_store.rb
@@ -21,6 +21,10 @@ def initialize
       # We keep the structured cache to allow
       # the api to search the content of the differents nodes
       @store = Concurrent::Map.new
+
+      # This hash has only one dimension
+      # and allow fast retrieval of the metrics
+      @fast_lookup = Concurrent::Map.new
     end
 
     # This method use the namespace and key to search the corresponding value of
@@ -28,10 +32,32 @@ def initialize
     # path in the hash and return `new_value`
     #
     # @param [Array] The path where the values should be located
-    # @param [Object] The default object if the value is not found in the path
+    # @param [Symbol] The metric key
     # @return [Object] Return the new_value of the retrieve object in the tree
     def fetch_or_store(namespaces, key, default_value = nil)
-      fetch_or_store_namespaces(namespaces).fetch_or_store(key, block_given? ? yield(key) : default_value)
+      provided_value =  block_given? ? yield(key) : default_value
+
+      # We first check in the `@fast_lookup` store to see if we have already see that metrics before,
+      # This give us a `o(1)` access, which is faster than searching through the structured
+      # data store (Which is a `o(n)` operation where `n` is the number of element in the namespace and
+      # the value of the key). If the metric is already present in the `@fast_lookup`, the call to
+      # `#put_if_absent` will return the value. This value is send back directly to the caller.
+      #
+      # BUT. If the value is not present in the `@fast_lookup` the value will be inserted and
+      # `#puf_if_absent` will return nil. With this returned value of nil we assume that we don't
+      # have it in the `@metric_store` for structured search so we add it there too.
+      #
+      # The problem with only using the `@metric_store` directly all the time would require us
+      # to use the mutex around the structure since its a multi-level hash, without that it wont
+      # return a consistent value of the metric and this would slow down the code and would
+      # complixity the code.
+      if found_value = @fast_lookup.put_if_absent([namespaces, key], provided_value)
+        return found_value
+      else
+        # If we cannot find the value this mean we need to save it in the store.
+        fetch_or_store_namespaces(namespaces).fetch_or_store(key, provided_value)
+        return provided_value
+      end
     end
 
     # This method allow to retrieve values for a specific path,
@@ -80,7 +106,7 @@ def each(path = nil, &block)
 
     private
     def get_all
-      each_recursively(@store).flatten
+      @fast_lookup.values
     end
 
     def get_recursively(key_paths, map, new_hash)
diff --git a/logstash-core/spec/logstash/pipeline_spec.rb b/logstash-core/spec/logstash/pipeline_spec.rb
index d0eee0f2582..c3c3acc7eb6 100644
--- a/logstash-core/spec/logstash/pipeline_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_spec.rb
@@ -62,7 +62,7 @@ def initialize(params={})
 
   def register
   end
-  
+
   def receive(event)
     @events << event
   end
@@ -416,7 +416,7 @@ class TestPipeline < LogStash::Pipeline
         }
       }
       filter {
-        multiline { 
+        multiline {
           pattern => "^NeverMatch"
           negate => true
           what => "previous"
@@ -428,7 +428,7 @@ class TestPipeline < LogStash::Pipeline
       EOS
     end
     let(:output) { DummyOutput.new }
-    
+
     before do
       allow(DummyOutput).to receive(:new).with(any_args).and_return(output)
       allow(LogStash::Plugin).to receive(:lookup).with("input", "generator").and_return(LogStash::Inputs::Generator)
@@ -528,4 +528,59 @@ class TestPipeline < LogStash::Pipeline
       end
     end
   end
+
+  context "when collecting metric in the pipeline" do
+    subject { described_class.new(config, { :metric => metric, :pipeline_id => pipeline_id }) }
+    let(:pipeline_id) { :main }
+    let(:metric) { LogStash::Instrument::Metric.create }
+    let(:number_of_events) { 1000 }
+    let(:config) do
+      <<-EOS
+      input { generator { count => #{number_of_events}} }
+      filter {
+         multiline {
+              pattern => "hello"
+              what => next
+          }
+      }
+      output { dummyoutput {} }
+      EOS
+    end
+    let(:dummyoutput) { DummyOutput.new }
+
+    before do
+      allow(DummyOutput).to receive(:new).with(any_args).and_return(dummyoutput)
+      allow(LogStash::Plugin).to receive(:lookup).with("input", "generator").and_return(LogStash::Inputs::Generator)
+      allow(LogStash::Plugin).to receive(:lookup).with("codec", "plain").and_return(LogStash::Codecs::Plain)
+      allow(LogStash::Plugin).to receive(:lookup).with("filter", "multiline").and_return(LogStash::Filters::Multiline)
+      allow(LogStash::Plugin).to receive(:lookup).with("output", "dummyoutput").and_return(DummyOutput)
+
+      # Reset the metric store
+      LogStash::Instrument::Collector.instance.clear
+    end
+
+    it "populates the differents core metrics" do
+      t = Thread.new { subject.run }
+      # make sure we have received all the generated events
+      sleep 0.01 while dummyoutput.events.size < number_of_events
+
+      collected_metric = LogStash::Instrument::Collector.instance.snapshot_metric.metric_store.get_with_path("stats/events")
+
+      expect(collected_metric[:stats][:events][:in].value).to eq(number_of_events)
+      expect(collected_metric[:stats][:events][:filtered].value).to eq(number_of_events)
+      expect(collected_metric[:stats][:events][:out].value).to eq(number_of_events)
+    end
+
+    it "populates the pipelines core metrics" do
+      t = Thread.new { subject.run }
+      # make sure we have received all the generated events
+      sleep 0.01 while dummyoutput.events.size < number_of_events
+
+      collected_metric = LogStash::Instrument::Collector.instance.snapshot_metric.metric_store.get_with_path("stats/pipelines/")
+
+      expect(collected_metric[:stats][:pipelines][:main][:events][:in].value).to eq(number_of_events)
+      expect(collected_metric[:stats][:pipelines][:main][:events][:filtered].value).to eq(number_of_events)
+      expect(collected_metric[:stats][:pipelines][:main][:events][:out].value).to eq(number_of_events)
+    end
+  end
 end
