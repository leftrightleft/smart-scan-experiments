diff --git a/tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java b/tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java
index 3b827c6dc2d..534d8b449e7 100644
--- a/tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java
+++ b/tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java
@@ -24,7 +24,7 @@ final class JsUtil {
 
     private static final String[] SCRIPTS = {
         "shared", "date", "grok", "geoip", "gsub", "pipeline", "convert", "append", "json",
-        "rename", "lowercase"
+        "rename", "lowercase", "set"
     };
 
     private JsUtil() {
@@ -90,7 +90,7 @@ jsFunc, input(options.valueOf(input))
      * Retrieves the input Ingest JSON from a given {@link URI}.
      * @param uri {@link URI} of Ingest JSON
      * @return Json String
-     * @throws IOException On failure to load Ingest JSON 
+     * @throws IOException On failure to load Ingest JSON
      */
     private static String input(final URI uri) throws IOException {
         if ("file".equals(uri.getScheme())) {
diff --git a/tools/ingest-converter/src/main/java/org/logstash/ingest/Set.java b/tools/ingest-converter/src/main/java/org/logstash/ingest/Set.java
new file mode 100644
index 00000000000..7e7f11d8db9
--- /dev/null
+++ b/tools/ingest-converter/src/main/java/org/logstash/ingest/Set.java
@@ -0,0 +1,16 @@
+package org.logstash.ingest;
+
+import javax.script.ScriptException;
+
+/**
+ * Ingest Set DSL to Logstash mutate Transpiler.
+ */
+public class Set {
+    private Set() {
+        // Utility Wrapper for JS Script.
+    }
+
+    public static void main(final String... args) throws ScriptException, NoSuchMethodException {
+        JsUtil.convert(args, "ingest_set_to_logstash");
+    }
+}
diff --git a/tools/ingest-converter/src/main/resources/ingest-grok.js b/tools/ingest-converter/src/main/resources/ingest-grok.js
index c81c01bba2d..61f4fe3366e 100644
--- a/tools/ingest-converter/src/main/resources/ingest-grok.js
+++ b/tools/ingest-converter/src/main/resources/ingest-grok.js
@@ -1,6 +1,9 @@
 var IngestGrok = {
     has_grok: function (processor) {
-        return !!processor["grok"];
+        return !!processor[this.get_name()];
+    },
+    get_name: function () {
+        return "grok";
     },
     grok_hash: function (processor) {
 
diff --git a/tools/ingest-converter/src/main/resources/ingest-pipeline.js b/tools/ingest-converter/src/main/resources/ingest-pipeline.js
index d7c867c186d..235072cc8aa 100644
--- a/tools/ingest-converter/src/main/resources/ingest-pipeline.js
+++ b/tools/ingest-converter/src/main/resources/ingest-pipeline.js
@@ -3,13 +3,28 @@
  */
 function ingest_pipeline_to_logstash(json) {
 
+    function handle_on_failure_pipeline(on_failure_json, tag_name) {
+
+        return IngestConverter.create_tag_conditional(tag_name,
+            IngestConverter.join_hash_fields(on_failure_json.map(map_processor))
+        );
+    }
+
     function map_processor(processor) {
 
         var filter_blocks = [];
         if (IngestGrok.has_grok(processor)) {
             filter_blocks.push(
-                IngestConverter.create_hash("grok", IngestGrok.grok_hash(processor))
-            )
+                IngestConverter.create_hash(IngestGrok.get_name(), IngestGrok.grok_hash(processor))
+            );
+            if (IngestConverter.has_on_failure(processor, IngestGrok.get_name())) {
+                filter_blocks.push(
+                    handle_on_failure_pipeline(
+                        IngestConverter.get_on_failure(processor, IngestGrok.get_name()),
+                        "_grokparsefailure"
+                    )
+                );
+            }
         }
         if (IngestDate.has_date(processor)) {
             filter_blocks.push(
@@ -51,6 +66,11 @@ function ingest_pipeline_to_logstash(json) {
                 IngestConverter.create_hash("mutate", IngestLowercase.lowercase_hash(processor))
             );
         }
+        if (IngestSet.has_set(processor)) {
+            filter_blocks.push(
+                IngestConverter.create_hash("mutate", IngestSet.set_hash(processor))
+            );
+        }
         return IngestConverter.join_hash_fields(filter_blocks);
     }
 
diff --git a/tools/ingest-converter/src/main/resources/ingest-set.js b/tools/ingest-converter/src/main/resources/ingest-set.js
new file mode 100644
index 00000000000..5128bbc6157
--- /dev/null
+++ b/tools/ingest-converter/src/main/resources/ingest-set.js
@@ -0,0 +1,36 @@
+var IngestSet = {
+    has_set: function (processor) {
+        return !!processor["set"];
+    },
+    set_hash: function (processor) {
+        var set_json = processor["set"];
+        var value_contents;
+        var value = set_json["value"];
+        if (typeof value === 'string' || value instanceof String) {
+            value_contents = IngestConverter.quote_string(value);
+        } else {
+            value_contents = value;
+        }
+        var mutate_contents = IngestConverter.create_field(
+            IngestConverter.quote_string(IngestConverter.dots_to_square_brackets(set_json["field"])),
+            value_contents);
+        return IngestConverter.create_field("add_field", IngestConverter.wrap_in_curly(mutate_contents));
+    }
+};
+
+/**
+ * Converts Ingest Set JSON to LS mutate filter.
+ */
+function ingest_set_to_logstash(json) {
+
+    function map_processor(processor) {
+
+        return IngestConverter.filter_hash(
+            IngestConverter.create_hash(
+                "mutate", IngestSet.set_hash(processor)
+            )
+        );
+    }
+
+    return IngestConverter.filters_to_file(JSON.parse(json)["processors"].map(map_processor));
+}
diff --git a/tools/ingest-converter/src/main/resources/ingest-shared.js b/tools/ingest-converter/src/main/resources/ingest-shared.js
index c4c50329f77..9fa5389643b 100644
--- a/tools/ingest-converter/src/main/resources/ingest-shared.js
+++ b/tools/ingest-converter/src/main/resources/ingest-shared.js
@@ -86,8 +86,8 @@ var IngestConverter = {
      * @returns {string} Pattern array in LS formatting
      */
     create_pattern_array: function (patterns) {
-        return "[\n" 
-            + patterns.map(this.dots_to_square_brackets).map(this.quote_string).join(",\n") 
+        return "[\n"
+            + patterns.map(this.dots_to_square_brackets).map(this.quote_string).join(",\n")
             + "\n]";
     },
 
@@ -96,7 +96,7 @@ var IngestConverter = {
             + ingest_array.map(this.quote_string).join(",\n")
             + "\n]";
     },
-    
+
     /**
      * Converts Ingest/JSON style pattern array to LS pattern array or string if the given array
      * contains a single element only, performing necessary variable name and quote escaping
@@ -109,12 +109,38 @@ var IngestConverter = {
             ? this.quote_string(this.dots_to_square_brackets(patterns[0]))
             : this.create_pattern_array(patterns);
     },
-    
+
     filter_hash: function(contents) {
         return this.fix_indent(this.create_hash("filter", contents))
     },
-    
+
     filters_to_file: function(filters) {
         return filters.join("\n\n") + "\n";
+    },
+
+    /**
+     * Does it have an on_failure field?
+     * @param processor Json
+     * @param name Name of the processor
+     * @returns {boolean} True if has on failure
+     */
+    has_on_failure: function (processor, name) {
+        return !!processor[name]["on_failure"];
+    },
+
+    get_on_failure: function (processor, name) {
+        return processor[name]["on_failure"];
+    },
+
+    /**
+     * Creates an if clause with the tag name
+     * @param tag String tag name to find in [tags] field
+     * @param on_failure_pipeline The on failure pipeline converted to LS to tack on in the conditional
+     * @returns {string} a string representing a conditional logic
+     */
+    create_tag_conditional: function (tag, on_failure_pipeline) {
+        return "if " + this.quote_string(tag) + " in [tags] {\n" +
+                on_failure_pipeline + "\n" +
+                "}";
     }
 };
diff --git a/tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java b/tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java
index 12962c9e570..41f58633c8a 100644
--- a/tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java
+++ b/tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java
@@ -13,6 +13,8 @@ public static Iterable<String> data() {
         final Collection<String> cases = new ArrayList<>();
         cases.add("ComplexCase1");
         cases.add("ComplexCase2");
+        cases.add("ComplexCase3");
+        cases.add("ComplexCase4");
         GeoIpTest.data().forEach(cases::add);
         DateTest.data().forEach(cases::add);
         GrokTest.data().forEach(cases::add);
@@ -22,6 +24,7 @@ public static Iterable<String> data() {
         JsonTest.data().forEach(cases::add);
         RenameTest.data().forEach(cases::add);
         LowercaseTest.data().forEach(cases::add);
+        SetTest.data().forEach(cases::add);
         return cases;
     }
 
diff --git a/tools/ingest-converter/src/test/java/org/logstash/ingest/SetTest.java b/tools/ingest-converter/src/test/java/org/logstash/ingest/SetTest.java
new file mode 100644
index 00000000000..68af5e60cfa
--- /dev/null
+++ b/tools/ingest-converter/src/test/java/org/logstash/ingest/SetTest.java
@@ -0,0 +1,19 @@
+package org.logstash.ingest;
+
+import java.util.Arrays;
+import org.junit.Test;
+
+import static org.junit.runners.Parameterized.Parameters;
+
+public final class SetTest extends IngestTest {
+
+    @Parameters
+    public static Iterable<String> data() {
+        return Arrays.asList("Set", "DotsInSetField", "SetNumber");
+    }
+
+    @Test
+    public void convertsSetProcessorCorrectly() throws Exception {
+        assertCorrectConversion(Set.class);
+    }
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase3.json b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase3.json
new file mode 100644
index 00000000000..d059b3536de
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase3.json
@@ -0,0 +1,35 @@
+{
+  "description": "Pipeline to parse Apache logs",
+  "processors": [
+    {
+      "grok": {
+        "field": "message",
+        "patterns": ["%{COMBINEDAPACHELOG}"],
+        "on_failure" : [
+          {
+            "set" : {
+              "field" : "error",
+              "value" : "field does not exist"
+            }
+          }
+        ]
+      }
+    },
+    {
+      "date": {
+        "field": "timestamp",
+        "target_field": "@timestamp",
+        "formats": [
+          "dd/MMM/YYYY:HH:mm:ss Z"
+        ],
+        "locale": "en"
+      }
+    },
+    {
+      "geoip": {
+        "field": "clientip",
+        "target_field": "geo"
+      }
+    }
+  ]
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase4.json b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase4.json
new file mode 100644
index 00000000000..c63bda67333
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase4.json
@@ -0,0 +1,41 @@
+{
+  "description": "Pipeline to parse Apache logs",
+  "processors": [
+    {
+      "grok": {
+        "field": "message",
+        "patterns": ["%{COMBINEDAPACHELOG}"],
+        "on_failure" : [
+          {
+            "set" : {
+              "field" : "error",
+              "value" : "field does not exist"
+            }
+          },
+          {
+            "convert": {
+              "field" : "client.ip",
+              "type": "integer"
+            }
+          }
+        ]
+      }
+    },
+    {
+      "date": {
+        "field": "timestamp",
+        "target_field": "@timestamp",
+        "formats": [
+          "dd/MMM/YYYY:HH:mm:ss Z"
+        ],
+        "locale": "en"
+      }
+    },
+    {
+      "geoip": {
+        "field": "clientip",
+        "target_field": "geo"
+      }
+    }
+  ]
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestDotsInSetField.json b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestDotsInSetField.json
new file mode 100644
index 00000000000..7112b7131b5
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestDotsInSetField.json
@@ -0,0 +1,11 @@
+{
+  "description": "SetExample",
+  "processors": [
+    {
+      "set": {
+        "field": "foo.bar",
+        "value": "baz"
+      }
+    }
+  ]
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestSet.json b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestSet.json
new file mode 100644
index 00000000000..3ae6f3c3912
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestSet.json
@@ -0,0 +1,12 @@
+{
+  "description": "SetExample",
+  "processors": [
+    {
+      "set": {
+        "field": "field1",
+        "value": "bar"
+      }
+    }
+  ]
+}
+
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestSetNumber.json b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestSetNumber.json
new file mode 100644
index 00000000000..70558bd5255
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestSetNumber.json
@@ -0,0 +1,11 @@
+{
+  "description": "SetExample",
+  "processors": [
+    {
+      "set": {
+        "field": "field1",
+        "value": 5344.4
+      }
+    }
+  ]
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase3.conf b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase3.conf
new file mode 100644
index 00000000000..1b839472491
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase3.conf
@@ -0,0 +1,26 @@
+filter {
+   grok {
+      match => {
+         "message" => "%{COMBINEDAPACHELOG}"
+      }
+   }
+   if "_grokparsefailure" in [tags] {
+      mutate {
+         add_field => {
+            "error" => "field does not exist"
+         }
+      }
+   }
+   date {
+      match => [
+         "timestamp",
+         "dd/MMM/YYYY:HH:mm:ss Z"
+      ]
+      target => "@timestamp"
+      locale => "en"
+   }
+   geoip {
+      source => "clientip"
+      target => "geo"
+   }
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase4.conf b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase4.conf
new file mode 100644
index 00000000000..5c9c0ac1101
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase4.conf
@@ -0,0 +1,31 @@
+filter {
+   grok {
+      match => {
+         "message" => "%{COMBINEDAPACHELOG}"
+      }
+   }
+   if "_grokparsefailure" in [tags] {
+      mutate {
+         add_field => {
+            "error" => "field does not exist"
+         }
+      }
+      mutate {
+         convert => {
+            "[client][ip]" => "integer"
+         }
+      }
+   }
+   date {
+      match => [
+         "timestamp",
+         "dd/MMM/YYYY:HH:mm:ss Z"
+      ]
+      target => "@timestamp"
+      locale => "en"
+   }
+   geoip {
+      source => "clientip"
+      target => "geo"
+   }
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashDotsInSetField.conf b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashDotsInSetField.conf
new file mode 100644
index 00000000000..bdeaf929992
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashDotsInSetField.conf
@@ -0,0 +1,7 @@
+filter {
+   mutate {
+      add_field => {
+         "[foo][bar]" => "baz"
+      }
+   }
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashSet.conf b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashSet.conf
new file mode 100644
index 00000000000..149001e7c43
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashSet.conf
@@ -0,0 +1,7 @@
+filter {
+   mutate {
+      add_field => {
+         "field1" => "bar"
+      }
+   }
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashSetNumber.conf b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashSetNumber.conf
new file mode 100644
index 00000000000..f47c5b66c1b
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashSetNumber.conf
@@ -0,0 +1,7 @@
+filter {
+   mutate {
+      add_field => {
+         "field1" => 5344.4
+      }
+   }
+}
