diff --git a/logstash-core/lib/logstash/instrument/collector.rb b/logstash-core/lib/logstash/instrument/collector.rb
index 797dd471371..92ce5567d70 100644
--- a/logstash-core/lib/logstash/instrument/collector.rb
+++ b/logstash-core/lib/logstash/instrument/collector.rb
@@ -67,6 +67,19 @@ def get(namespaces_path, key, type)
       end
     end
 
+    def register?(namespaces_path, key, metric_instance)
+      registered = false
+
+      # Relies on MetricStore#fetch_or_store yielding the block
+      # EXACTLY ONCE to the winner in a race-condition.
+      @metric_store.fetch_or_store(namespaces_path, key) do
+        registered = true
+        metric_instance
+      end
+
+      registered
+    end
+
     # Snapshot the current Metric Store and return it immediately,
     # This is useful if you want to get access to the current metric store without
     # waiting for a periodic call.
diff --git a/logstash-core/lib/logstash/instrument/metric_store.rb b/logstash-core/lib/logstash/instrument/metric_store.rb
index eaac28a9c2b..1bb9c3e6ab5 100644
--- a/logstash-core/lib/logstash/instrument/metric_store.rb
+++ b/logstash-core/lib/logstash/instrument/metric_store.rb
@@ -51,11 +51,20 @@ def initialize
 
     # This method use the namespace and key to search the corresponding value of
     # the hash, if it doesn't exist it will create the appropriate namespaces
-    # path in the hash and return `new_value`
-    #
-    # @param [Array] The path where the values should be located
-    # @param [Symbol] The metric key
-    # @return [Object] Return the new_value of the retrieve object in the tree
+    # path in the hash and return `new_value`.
+    # @overload fetch_or_store(namespaces, key, default_value)
+    #   @param [Array<Symbol>] namespaces: The path where the values should be located
+    #   @param [Symbol] key: The metric key
+    #   @param [Metric] default_value: if no metric exists at this address, the
+    #                                  provided default_value will be stored
+    #   @return [Metric] the value as it exists in the tree after this operation
+    # @overload fetch_or_store(namespaces, key, &default_value_generator)
+    #   @param [Array<Symbol>] namespaces: The path where the values should be located
+    #   @param [Symbol] key: The metric key
+    #   @yield EXACTLY ONCE to the provided block IFF the metric does not exist
+    #   @yieldreturn [Metric] if no metric exists at this address, the result of yielding
+    #                         to the provided default_value_generator block will be stored.
+    #   @return [Metric] the value as it exists in the tree after this operation
     def fetch_or_store(namespaces, key, default_value = nil)
 
       # We first check in the `@fast_lookup` store to see if we have already see that metrics before,
@@ -63,20 +72,21 @@ def fetch_or_store(namespaces, key, default_value = nil)
       # data store (Which is a `o(n)` operation where `n` is the number of element in the namespace and
       # the value of the key). If the metric is already present in the `@fast_lookup`, then that value is sent
       # back directly to the caller.
-      #
-      # BUT. If the value is not present in the `@fast_lookup` the value will be inserted and we assume that we don't
-      # have it in the `@metric_store` for structured search so we add it there too.
-
-      value = @fast_lookup.get(namespaces.dup << key)
-      if value.nil?
-        value = block_given? ? yield(key) : default_value
-        @fast_lookup.put(namespaces.dup << key, value)
-        @structured_lookup_mutex.synchronize do
-            # If we cannot find the value this mean we need to save it in the store.
-          fetch_or_store_namespaces(namespaces).fetch_or_store(key, value)
+      fast_lookup_key = namespaces.dup << key
+      existing_value = @fast_lookup.get(fast_lookup_key)
+      return existing_value unless existing_value.nil?
+
+      # BUT. If the value was not present in the `@fast_lookup` we acquire the structured_lookup_lock
+      # before modifying _either_ the fast-lookup or the structured store.
+      @structured_lookup_mutex.synchronize do
+        # by using compute_if_absent, we ensure that we don't overwrite a value that was
+        # written by another thread that beat us to the @structured_lookup_mutex lock.
+        @fast_lookup.compute_if_absent(fast_lookup_key) do
+          generated_value = block_given? ? yield(key) : default_value
+          fetch_or_store_namespaces(namespaces).fetch_or_store(key, generated_value)
+          generated_value
         end
       end
-      return value;
     end
 
     # This method allow to retrieve values for a specific path,
@@ -298,36 +308,18 @@ def transform_to_hash(map, new_hash = Hash.new)
     # create it.
     #
     # @param [Array] The path where values should be located
-    # @raise [ConcurrentMapExpected] Raise if the retrieved object isn't a `Concurrent::Map`
+    # @raise [NamespacesExpectedError] Raise if the retrieved object isn't a `Concurrent::Map`
     # @return [Concurrent::Map] Map where the metrics should be saved
     def fetch_or_store_namespaces(namespaces_path)
-      path_map = fetch_or_store_namespace_recursively(@store, namespaces_path)
-
-      # This mean one of the namespace and key are colliding
-      # and we have to deal it upstream.
-      unless path_map.is_a?(Concurrent::Map)
-        raise NamespacesExpectedError, "Expecting a `Namespaces` but found class:  #{path_map.class.name} for namespaces_path: #{namespaces_path}"
-      end
-
-      return path_map
-    end
-
-    # Recursively fetch or create the namespace paths through the `MetricStove`
-    # This algorithm use an index to known which keys to search in the map.
-    # This doesn't cloning the array if we want to give a better feedback to the user
-    #
-    # @param [Concurrent::Map] Map to search for the key
-    # @param [Array] List of path to create
-    # @param [Integer] Which part from the list to create
-    #
-    def fetch_or_store_namespace_recursively(map, namespaces_path, idx = 0)
-      current = namespaces_path[idx]
+      namespaces_path.each_with_index.reduce(@store) do |memo, (current, index)|
+        node = memo.compute_if_absent(current) { Concurrent::Map.new }
 
-      # we are at the end of the namespace path, break out of the recursion
-      return map if current.nil?
+        unless node.kind_of?(Concurrent::Map)
+          raise NamespacesExpectedError, "Expecting a `Namespaces` but found class:  #{node.class.name} for namespaces_path: #{namespaces_path.first(index+1)}"
+        end
 
-      new_map = map.fetch_or_store(current) { Concurrent::Map.new }
-      return fetch_or_store_namespace_recursively(new_map, namespaces_path, idx + 1)
+        node
+      end
     end
 
     def delete_from_map(map, keys)
diff --git a/logstash-core/lib/logstash/instrument/metric_type.rb b/logstash-core/lib/logstash/instrument/metric_type.rb
index 395323658b8..1915e59a375 100644
--- a/logstash-core/lib/logstash/instrument/metric_type.rb
+++ b/logstash-core/lib/logstash/instrument/metric_type.rb
@@ -17,12 +17,14 @@
 
 require "logstash/instrument/metric_type/counter"
 require "logstash/instrument/metric_type/gauge"
+require "logstash/instrument/metric_type/uptime"
 
 module LogStash module Instrument
   module MetricType
     METRIC_TYPE_LIST = {
       :counter => LogStash::Instrument::MetricType::Counter,
-      :gauge => LogStash::Instrument::MetricType::Gauge
+      :gauge => LogStash::Instrument::MetricType::Gauge,
+      :uptime => LogStash::Instrument::MetricType::Uptime,
     }.freeze
 
     # Use the string to generate a concrete class for this metrics
diff --git a/logstash-core/lib/logstash/instrument/metric_type/uptime.rb b/logstash-core/lib/logstash/instrument/metric_type/uptime.rb
new file mode 100644
index 00000000000..0fe3803b9ac
--- /dev/null
+++ b/logstash-core/lib/logstash/instrument/metric_type/uptime.rb
@@ -0,0 +1,32 @@
+# Licensed to Elasticsearch B.V. under one or more contributor
+# license agreements. See the NOTICE file distributed with
+# this work for additional information regarding copyright
+# ownership. Elasticsearch B.V. licenses this file to you under
+# the Apache License, Version 2.0 (the "License"); you may
+# not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#  http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+
+java_import org.logstash.instrument.metrics.UptimeMetric
+
+module LogStash module Instrument module MetricType
+  class Uptime < UptimeMetric
+
+    def initialize(namespaces, key)
+      super(key.to_s)
+    end
+
+    def execute(action, value = nil)
+      fail("Unsupported operation `action` on Uptime Metric")
+    end
+
+  end
+end; end; end
diff --git a/logstash-core/lib/logstash/java_pipeline.rb b/logstash-core/lib/logstash/java_pipeline.rb
index 04063782faa..401daebf914 100644
--- a/logstash-core/lib/logstash/java_pipeline.rb
+++ b/logstash-core/lib/logstash/java_pipeline.rb
@@ -121,6 +121,7 @@ def start
     # this is useful in the context of pipeline reloading
     collect_stats
     collect_dlq_stats
+    initialize_flow_metrics
 
     @logger.debug("Starting pipeline", default_logging_keys)
 
@@ -533,6 +534,7 @@ def clear_pipeline_metrics
       # we want to keep other metrics like reload counts and error messages
       collector.clear("stats/pipelines/#{pipeline_id}/plugins")
       collector.clear("stats/pipelines/#{pipeline_id}/events")
+      collector.clear("stats/pipelines/#{pipeline_id}/flow")
     end
   end
 
diff --git a/logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java b/logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java
index ece0df7b7c2..b8debf753ef 100644
--- a/logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java
+++ b/logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java
@@ -33,6 +33,7 @@
 import java.util.Arrays;
 import java.util.List;
 import java.util.UUID;
+import java.util.concurrent.TimeUnit;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
@@ -69,8 +70,12 @@
 import org.logstash.ext.JRubyWrappedWriteClientExt;
 import org.logstash.instrument.metrics.AbstractMetricExt;
 import org.logstash.instrument.metrics.AbstractNamespacedMetricExt;
+import org.logstash.instrument.metrics.FlowMetric;
+import org.logstash.instrument.metrics.Metric;
 import org.logstash.instrument.metrics.MetricKeys;
 import org.logstash.instrument.metrics.NullMetricExt;
+import org.logstash.instrument.metrics.UptimeMetric;
+import org.logstash.instrument.metrics.counter.LongCounter;
 import org.logstash.plugins.ConfigVariableExpander;
 import org.logstash.secret.store.SecretStore;
 import org.logstash.secret.store.SecretStoreExt;
@@ -164,6 +169,8 @@ public class AbstractPipelineExt extends RubyBasicObject {
 
     private QueueReadClientBase filterQueueClient;
 
+    private ArrayList<FlowMetric> flowMetrics = new ArrayList<>();
+
     public AbstractPipelineExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);
     }
@@ -447,6 +454,102 @@ public final IRubyObject collectStats(final ThreadContext context) throws IOExce
         return context.nil;
     }
 
+    @JRubyMethod(name = "initialize_flow_metrics")
+    public final IRubyObject initializeFlowMetrics(final ThreadContext context) {
+        final UptimeMetric uptimeInMillis = initOrGetUptimeMetric(context, buildNamespace(), context.runtime.newSymbol("uptime_in_millis"));
+        final UptimeMetric uptimeInSeconds = uptimeInMillis.withTimeUnit("uptime_in_seconds", TimeUnit.SECONDS);
+
+        final RubySymbol flowKey = context.runtime.newSymbol("flow");
+        final RubySymbol[] flowNamespace = buildNamespace(flowKey);
+
+        final RubySymbol[] eventsNamespace = buildNamespace(MetricKeys.EVENTS_KEY);
+
+        final LongCounter eventsInCounter = initOrGetCounterMetric(context, eventsNamespace, MetricKeys.IN_KEY);
+        final FlowMetric inputThroughput = new FlowMetric("input_throughput", eventsInCounter, uptimeInSeconds);
+        this.flowMetrics.add(inputThroughput);
+        storeMetric(context, flowNamespace, inputThroughput);
+
+        final LongCounter eventsFilteredCounter = initOrGetCounterMetric(context, eventsNamespace, MetricKeys.FILTERED_KEY);
+        final FlowMetric filterThroughput = new FlowMetric("filter_throughput", eventsFilteredCounter, uptimeInSeconds);
+        this.flowMetrics.add(filterThroughput);
+        storeMetric(context, flowNamespace, filterThroughput);
+
+        final LongCounter eventsOutCounter = initOrGetCounterMetric(context, eventsNamespace, MetricKeys.OUT_KEY);
+        final FlowMetric outputThroughput = new FlowMetric("output_throughput", eventsOutCounter, uptimeInSeconds);
+        this.flowMetrics.add(outputThroughput);
+        storeMetric(context, flowNamespace, outputThroughput);
+
+        final LongCounter queuePushWaitInMillis = initOrGetCounterMetric(context, eventsNamespace, JRubyWrappedWriteClientExt.PUSH_DURATION_KEY);
+        final FlowMetric backpressureFlow = new FlowMetric("backpressure", queuePushWaitInMillis, uptimeInMillis);
+        this.flowMetrics.add(backpressureFlow);
+        storeMetric(context, flowNamespace, backpressureFlow);
+
+        final LongCounter durationInMillis = initOrGetCounterMetric(context, eventsNamespace, MetricKeys.DURATION_IN_MILLIS_KEY);
+        final FlowMetric concurrencyFlow = new FlowMetric("concurrency", durationInMillis, uptimeInMillis);
+        this.flowMetrics.add(concurrencyFlow);
+        storeMetric(context, flowNamespace, concurrencyFlow);
+
+        return context.nil;
+    }
+
+    @JRubyMethod(name = "collect_flow_metrics")
+    public final IRubyObject collectFlowMetrics(final ThreadContext context) {
+        this.flowMetrics.forEach(FlowMetric::capture);
+        return context.nil;
+    }
+
+    LongCounter initOrGetCounterMetric(final ThreadContext context,
+                                       final RubySymbol[] subPipelineNamespacePath,
+                                       final RubySymbol metricName) {
+        final IRubyObject collector = this.metric.collector(context);
+        final IRubyObject fullNamespace = RubyArray.newArray(context.runtime, fullNamespacePath(subPipelineNamespacePath));
+
+        final IRubyObject retrievedMetric = collector.callMethod(context, "get", new IRubyObject[]{fullNamespace, metricName, context.runtime.newSymbol("counter")});
+        return retrievedMetric.toJava(LongCounter.class);
+    }
+
+    UptimeMetric initOrGetUptimeMetric(final ThreadContext context,
+                                       final RubySymbol[] subPipelineNamespacePath,
+                                       final RubySymbol uptimeMetricName) {
+        final IRubyObject collector = this.metric.collector(context);
+        final IRubyObject fullNamespace = RubyArray.newArray(context.runtime, fullNamespacePath(subPipelineNamespacePath));
+
+        final IRubyObject retrievedMetric = collector.callMethod(context, "get", new IRubyObject[]{fullNamespace, uptimeMetricName, context.runtime.newSymbol("uptime")});
+        return retrievedMetric.toJava(UptimeMetric.class);
+    }
+
+
+    <T> void storeMetric(final ThreadContext context,
+                         final RubySymbol[] subPipelineNamespacePath,
+                         final Metric<T> metric) {
+        final IRubyObject collector = this.metric.collector(context);
+        final IRubyObject fullNamespace = RubyArray.newArray(context.runtime, fullNamespacePath(subPipelineNamespacePath));
+        final IRubyObject metricKey = context.runtime.newSymbol(metric.getName());
+
+        final IRubyObject wasRegistered = collector.callMethod(context, "register?", new IRubyObject[]{fullNamespace, metricKey, JavaUtil.convertJavaToUsableRubyObject(context.runtime, metric)});
+        if (!wasRegistered.toJava(Boolean.class)) {
+            LOGGER.warn(String.format("Metric registration error: `%s` could not be registered in namespace `%s`", metricKey, fullNamespace));
+        } else {
+            LOGGER.debug(String.format("Flow metric registered: `%s` in namespace `%s`", metricKey, fullNamespace));
+        }
+
+    }
+
+    RubySymbol[] fullNamespacePath(RubySymbol... subPipelineNamespacePath){
+        final RubySymbol[] pipelineNamespacePath = new RubySymbol[] { MetricKeys.STATS_KEY, MetricKeys.PIPELINES_KEY, pipelineId.asString().intern() };
+        if (subPipelineNamespacePath.length == 0) {
+            return pipelineNamespacePath;
+        }
+        final RubySymbol[] fullNamespacePath = Arrays.copyOf(pipelineNamespacePath, pipelineNamespacePath.length + subPipelineNamespacePath.length);
+        System.arraycopy(subPipelineNamespacePath, 0, fullNamespacePath, pipelineNamespacePath.length, subPipelineNamespacePath.length);
+        return fullNamespacePath;
+    }
+
+    RubySymbol[] buildNamespace(final RubySymbol... namespace) {
+        return namespace;
+    }
+
+
     @JRubyMethod(name = "input_queue_client")
     public final JRubyAbstractQueueWriteClientExt inputQueueClient() {
         return inputQueueClient;
diff --git a/logstash-core/src/main/java/org/logstash/ext/JRubyWrappedWriteClientExt.java b/logstash-core/src/main/java/org/logstash/ext/JRubyWrappedWriteClientExt.java
index 0c850e1964c..ad3e684624a 100644
--- a/logstash-core/src/main/java/org/logstash/ext/JRubyWrappedWriteClientExt.java
+++ b/logstash-core/src/main/java/org/logstash/ext/JRubyWrappedWriteClientExt.java
@@ -44,7 +44,7 @@ public final class JRubyWrappedWriteClientExt extends RubyObject implements Queu
 
     private static final long serialVersionUID = 1L;
 
-    private static final RubySymbol PUSH_DURATION_KEY =
+    public static final RubySymbol PUSH_DURATION_KEY =
         RubyUtil.RUBY.newSymbol("queue_push_duration_in_millis");
 
     private JRubyAbstractQueueWriteClientExt writeClient;
diff --git a/logstash-core/src/main/java/org/logstash/instrument/metrics/AbstractMetric.java b/logstash-core/src/main/java/org/logstash/instrument/metrics/AbstractMetric.java
index 8a3fe881de0..997275b8e8f 100644
--- a/logstash-core/src/main/java/org/logstash/instrument/metrics/AbstractMetric.java
+++ b/logstash-core/src/main/java/org/logstash/instrument/metrics/AbstractMetric.java
@@ -23,6 +23,8 @@
 
 import com.fasterxml.jackson.annotation.JsonValue;
 
+import java.util.Objects;
+
 /**
  * Abstract implementation of a {@link Metric}. All metrics should subclass this.
  *
@@ -48,8 +50,7 @@ protected AbstractMetric(final String name) {
 
     @Override
     public String toString() {
-        return String.format("%s -  name: %s value:%s", this.getClass().getName(), this.name, getValue() == null ? "null" :
-                getValue().toString());
+        return String.format("%s -  name: %s value:%s", this.getClass().getName(), this.name, Objects.requireNonNullElse(getValue(),"null"));
     }
 
     @Override
diff --git a/logstash-core/src/main/java/org/logstash/instrument/metrics/FlowMetric.java b/logstash-core/src/main/java/org/logstash/instrument/metrics/FlowMetric.java
new file mode 100644
index 00000000000..0d5c8556d44
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/instrument/metrics/FlowMetric.java
@@ -0,0 +1,95 @@
+package org.logstash.instrument.metrics;
+
+import java.math.BigDecimal;
+import java.math.RoundingMode;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Objects;
+import java.util.concurrent.atomic.AtomicReference;
+
+public class FlowMetric extends AbstractMetric<Map<String,Double>> {
+
+    // metric sources
+    private final Metric<? extends Number> numeratorMetric;
+    private final Metric<? extends Number> denominatorMetric;
+
+    // useful capture nodes for calculation
+    private final Capture baseline;
+
+    private final AtomicReference<Capture> head;
+    private final AtomicReference<Capture> instant = new AtomicReference<>();
+
+    static final String LIFETIME_KEY = "lifetime";
+    static final String CURRENT_KEY = "current";
+
+    public FlowMetric(final String name,
+                      final Metric<? extends Number> numeratorMetric,
+                      final Metric<? extends Number> denominatorMetric) {
+        super(name);
+        this.numeratorMetric = numeratorMetric;
+        this.denominatorMetric = denominatorMetric;
+
+        this.baseline = doCapture();
+        this.head = new AtomicReference<>(this.baseline);
+    }
+
+    public void capture() {
+        final Capture previousHead = head.getAndSet(doCapture());
+        instant.set(previousHead);
+    }
+
+    public Map<String,Double> getValue() {
+        final Capture headCapture = head.get();
+        if (Objects.isNull(headCapture)) {
+            return Map.of();
+        }
+
+        final Map<String, Double> rates = new HashMap<>();
+
+        final Double lifetimeRate = headCapture.calculateRate(baseline);
+
+        if (Objects.nonNull(lifetimeRate)) {
+            rates.put(LIFETIME_KEY, lifetimeRate);
+        }
+
+        final Capture instantCapture = instant.get();
+        final Double currentRate = headCapture.calculateRate(instantCapture);
+        if (Objects.nonNull(currentRate)) {
+            rates.put(CURRENT_KEY, currentRate);
+        }
+
+        return Map.copyOf(rates);
+    }
+
+    Capture doCapture() {
+        return new Capture(numeratorMetric.getValue(), denominatorMetric.getValue());
+    }
+
+    @Override
+    public MetricType getType() {
+        return MetricType.FLOW_RATES;
+    }
+
+    private static class Capture {
+        private final Number numerator;
+        private final Number denominator;
+
+        public Capture(final Number numerator, final Number denominator) {
+            this.numerator = numerator;
+            this.denominator = denominator;
+        }
+
+        Double calculateRate(final Capture baseline) {
+            if (Objects.isNull(baseline)) { return null; }
+            if (baseline == this) { return null; }
+
+            final double deltaNumerator = this.numerator.doubleValue() - baseline.numerator.doubleValue();
+            final double deltaDenominator = this.denominator.doubleValue() - baseline.denominator.doubleValue();
+
+            // To prevent the appearance of false-precision, we round to 3 decimal places.
+            return BigDecimal.valueOf(deltaNumerator)
+                    .divide(BigDecimal.valueOf(deltaDenominator), 3, RoundingMode.HALF_UP)
+                    .doubleValue();
+        }
+    }
+}
diff --git a/logstash-core/src/main/java/org/logstash/instrument/metrics/MetricType.java b/logstash-core/src/main/java/org/logstash/instrument/metrics/MetricType.java
index b6fcf2c6ba7..562881f5506 100644
--- a/logstash-core/src/main/java/org/logstash/instrument/metrics/MetricType.java
+++ b/logstash-core/src/main/java/org/logstash/instrument/metrics/MetricType.java
@@ -55,7 +55,13 @@ public enum MetricType {
     /**
      * A gauge backed by a {@link org.logstash.ext.JrubyTimestampExtLibrary.RubyTimestamp} type. Note - Java consumers should not use this, exist for legacy Ruby code.
      */
-    GAUGE_RUBYTIMESTAMP("gauge/rubytimestamp");
+    GAUGE_RUBYTIMESTAMP("gauge/rubytimestamp"),
+
+    /**
+     * A flow-rate {@link FlowMetric}, instantiated with one or more backing {@link Metric}{@code <Number>}.
+     */
+    FLOW_RATES("flow/rate"),
+    ;
 
     private final String type;
 
diff --git a/logstash-core/src/main/java/org/logstash/instrument/metrics/UptimeMetric.java b/logstash-core/src/main/java/org/logstash/instrument/metrics/UptimeMetric.java
new file mode 100644
index 00000000000..d01957ef3c4
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/instrument/metrics/UptimeMetric.java
@@ -0,0 +1,87 @@
+package org.logstash.instrument.metrics;
+
+import java.util.Objects;
+import java.util.concurrent.TimeUnit;
+import java.util.function.LongSupplier;
+
+/**
+ * The {@link UptimeMetric} is an auto-advancing {@link Metric} whose value
+ * represents the amount of time since instantiation. It can be made to track the
+ * advancement of the clock in one of several {@link TimeUnit}s.
+ */
+public class UptimeMetric extends AbstractMetric<Long> {
+    private final LongSupplier nanoTimeSupplier;
+    private final long startNanos;
+
+    private final TimeUnit timeUnit;
+
+    /**
+     * Constructs an {@link UptimeMetric} whose name is "uptime_in_millis" and whose units are milliseconds
+     */
+    public UptimeMetric() {
+        this("uptime_in_millis");
+    }
+
+    public UptimeMetric(final String name) {
+        this(name, TimeUnit.MILLISECONDS);
+    }
+
+    /**
+     * Constructs an {@link UptimeMetric} with the provided name and units.
+     * @param name the name of the metric, which is used by our metric store, API retrieval, etc.
+     * @param timeUnit the units in which to keep track of uptime (millis, seconds, etc.)
+     */
+    public UptimeMetric(final String name, final TimeUnit timeUnit) {
+        this(name, timeUnit, System::nanoTime);
+    }
+
+    UptimeMetric(final String name, final TimeUnit timeUnit, final LongSupplier nanoTimeSupplier) {
+        this(name, timeUnit, nanoTimeSupplier, nanoTimeSupplier.getAsLong());
+    }
+
+    UptimeMetric(final String name, final TimeUnit timeUnit, final LongSupplier nanoTimeSupplier, final long startNanos) {
+        super(Objects.requireNonNull(name, "name"));
+        this.nanoTimeSupplier = Objects.requireNonNull(nanoTimeSupplier, "nanoTimeSupplier");
+        this.timeUnit = Objects.requireNonNull(timeUnit, "timeUnit");
+        this.startNanos = Objects.requireNonNull(startNanos, "startNanos");
+    }
+
+    /**
+     * @return the number of {@link TimeUnit}s that have elapsed
+     *         since this {@link UptimeMetric} was instantiated
+     */
+    @Override
+    public Long getValue() {
+        final long elapsedNanos = this.nanoTimeSupplier.getAsLong() - this.startNanos;
+
+        return this.timeUnit.convert(elapsedNanos, TimeUnit.NANOSECONDS);
+    }
+
+    /**
+     * @return the {@link MetricType}{@code .COUNTER_LONG} associated with
+     *         long-valued metrics that only-increment, for use in Monitoring data structuring.
+     */
+    @Override
+    public MetricType getType() {
+        return MetricType.COUNTER_LONG;
+    }
+
+    /**
+     * @return the {@link TimeUnit} associated with this {@link UptimeMetric}.
+     */
+    public TimeUnit getTimeUnit() {
+        return timeUnit;
+    }
+
+    /**
+     * Constructs a _copy_ of this {@link UptimeMetric} with a new name and timeUnit, but whose
+     * uptime is tracking from the same instant as this instance.
+     *
+     * @param name the new metric's name (typically includes units)
+     * @param timeUnit the new metric's units
+     * @return a _copy_ of this {@link UptimeMetric}.
+     */
+    public UptimeMetric withTimeUnit(final String name, final TimeUnit timeUnit) {
+        return new UptimeMetric(name, timeUnit, this.nanoTimeSupplier, this.startNanos);
+    }
+}
diff --git a/logstash-core/src/test/java/org/logstash/instrument/metrics/FlowMetricTest.java b/logstash-core/src/test/java/org/logstash/instrument/metrics/FlowMetricTest.java
new file mode 100644
index 00000000000..901d2e15f81
--- /dev/null
+++ b/logstash-core/src/test/java/org/logstash/instrument/metrics/FlowMetricTest.java
@@ -0,0 +1,54 @@
+package org.logstash.instrument.metrics;
+
+import org.junit.Test;
+import org.logstash.instrument.metrics.counter.LongCounter;
+
+import java.time.Duration;
+import java.time.Instant;
+import java.time.temporal.ChronoUnit;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.TimeUnit;
+
+import static org.junit.Assert.*;
+import static org.logstash.instrument.metrics.FlowMetric.CURRENT_KEY;
+import static org.logstash.instrument.metrics.FlowMetric.LIFETIME_KEY;
+
+public class FlowMetricTest {
+    @Test
+    public void testBaselineFunctionality() {
+        final ManualAdvanceClock clock = new ManualAdvanceClock(Instant.now());
+        final LongCounter numeratorMetric = new LongCounter("events");
+        final Metric<Long> denominatorMetric = new UptimeMetric("uptime", TimeUnit.SECONDS, clock::nanoTime);
+        final FlowMetric instance = new FlowMetric("flow", numeratorMetric, denominatorMetric);
+
+        final Map<String, Double> ratesBeforeCaptures = instance.getValue();
+        assertTrue(ratesBeforeCaptures.isEmpty());
+
+        // 5 seconds pass, during which 1000 events are processed
+        clock.advance(Duration.ofSeconds(5));
+        numeratorMetric.increment(1000);
+        instance.capture();
+        final Map<String, Double> ratesAfterFirstCapture = instance.getValue();
+        assertFalse(ratesAfterFirstCapture.isEmpty());
+        assertEquals(Map.of(LIFETIME_KEY, 200.0, CURRENT_KEY, 200.0), ratesAfterFirstCapture);
+
+        // 5 more seconds pass, during which 2000 more events are processed
+        clock.advance(Duration.ofSeconds(5));
+        numeratorMetric.increment(2000);
+        instance.capture();
+        final Map<String, Double> ratesAfterSecondCapture = instance.getValue();
+        assertFalse(ratesAfterSecondCapture.isEmpty());
+        assertEquals(Map.of(LIFETIME_KEY, 300.0, CURRENT_KEY, 400.0), ratesAfterSecondCapture);
+
+        // 30 seconds pass, during which 11700 more events are seen by our numerator
+        for (Integer eventCount : List.of(1883, 2117, 1901, 2299, 1608, 1892)) {
+            clock.advance(Duration.ofSeconds(5));
+            numeratorMetric.increment(eventCount);
+            instance.capture();
+        }
+        final Map<String, Double> ratesAfterNthCapture = instance.getValue();
+        assertFalse(ratesAfterNthCapture.isEmpty());
+        assertEquals(Map.of(LIFETIME_KEY, 367.5, CURRENT_KEY, 378.4), ratesAfterNthCapture);
+    }
+}
diff --git a/logstash-core/src/test/java/org/logstash/instrument/metrics/ManualAdvanceClock.java b/logstash-core/src/test/java/org/logstash/instrument/metrics/ManualAdvanceClock.java
new file mode 100644
index 00000000000..e1df9568be0
--- /dev/null
+++ b/logstash-core/src/test/java/org/logstash/instrument/metrics/ManualAdvanceClock.java
@@ -0,0 +1,63 @@
+package org.logstash.instrument.metrics;
+
+import java.time.Clock;
+import java.time.Duration;
+import java.time.Instant;
+import java.time.ZoneId;
+import java.time.temporal.ChronoUnit;
+import java.util.Objects;
+import java.util.concurrent.atomic.AtomicReference;
+
+class ManualAdvanceClock extends Clock {
+    private final ZoneId zoneId;
+    private final AtomicReference<Instant> currentInstant;
+    private final Instant zeroInstant;
+
+    public ManualAdvanceClock(final Instant currentInstant, final ZoneId zoneId) {
+        this(currentInstant, new AtomicReference<>(currentInstant), zoneId);
+    }
+
+    public ManualAdvanceClock(final Instant currentInstant) {
+        this(currentInstant, null);
+    }
+
+    private ManualAdvanceClock(final Instant zeroInstant, final AtomicReference<Instant> currentInstant, final ZoneId zoneId) {
+        this.zeroInstant = zeroInstant;
+        this.currentInstant = currentInstant;
+        this.zoneId = Objects.requireNonNullElseGet(zoneId, ZoneId::systemDefault);
+    }
+
+    @Override
+    public ZoneId getZone() {
+        return this.zoneId;
+    }
+
+    @Override
+    public Clock withZone(ZoneId zone) {
+        return new ManualAdvanceClock(this.zeroInstant, this.currentInstant, zone);
+    }
+
+    @Override
+    public Instant instant() {
+        return currentInstant.get();
+    }
+
+    /**
+     * @return an only-incrementing long value, meant as a drop-in replacement
+     *         for {@link System#nanoTime()}, using this {@link ManualAdvanceClock}
+     *         as the time source, and carrying the same constraints.
+     */
+    public long nanoTime() {
+        return zeroInstant.until(instant(), ChronoUnit.NANOS);
+    }
+
+    public void advance(final Duration duration) {
+        if (duration.isZero()) {
+            return;
+        }
+        if (duration.isNegative()) {
+            throw new IllegalArgumentException("duration must not be negative");
+        }
+        this.currentInstant.updateAndGet(previous -> previous.plus(duration));
+    }
+}
diff --git a/logstash-core/src/test/java/org/logstash/instrument/metrics/UptimeMetricTest.java b/logstash-core/src/test/java/org/logstash/instrument/metrics/UptimeMetricTest.java
new file mode 100644
index 00000000000..a7b7de05f05
--- /dev/null
+++ b/logstash-core/src/test/java/org/logstash/instrument/metrics/UptimeMetricTest.java
@@ -0,0 +1,63 @@
+package org.logstash.instrument.metrics;
+
+import org.junit.Test;
+
+import java.time.Duration;
+import java.time.Instant;
+import java.util.concurrent.TimeUnit;
+
+import static org.junit.Assert.assertEquals;
+
+public class UptimeMetricTest {
+
+    @Test
+    public void testDefaultConstructor() {
+        final UptimeMetric defaultConstructorUptimeMetric = new UptimeMetric();
+        assertEquals("uptime_in_millis", defaultConstructorUptimeMetric.getName());
+        assertEquals(TimeUnit.MILLISECONDS, defaultConstructorUptimeMetric.getTimeUnit());
+    }
+
+    @Test
+    public void getNameExplicit() {
+        final String customName = "custom_uptime_name";
+        assertEquals(customName, new UptimeMetric(customName, TimeUnit.MILLISECONDS).getName());
+    }
+
+    @Test
+    public void getType() {
+        assertEquals(MetricType.COUNTER_LONG, new UptimeMetric().getType());
+    }
+
+    @Test
+    public void getValue() {
+        final ManualAdvanceClock clock = new ManualAdvanceClock(Instant.now());
+        final UptimeMetric uptimeMetric = new UptimeMetric("up", TimeUnit.MILLISECONDS, clock::nanoTime);
+        assertEquals(Long.valueOf(0L), uptimeMetric.getValue());
+
+        clock.advance(Duration.ofMillis(123));
+        assertEquals(Long.valueOf(123L), uptimeMetric.getValue());
+
+        clock.advance(Duration.ofMillis(456));
+        assertEquals(Long.valueOf(579L), uptimeMetric.getValue());
+
+        clock.advance(Duration.ofMinutes(15));
+        assertEquals(Long.valueOf(900579L), uptimeMetric.getValue());
+
+        clock.advance(Duration.ofHours(712));
+        assertEquals(Long.valueOf(2564100579L), uptimeMetric.getValue());
+    }
+
+    @Test
+    public void withTemporalUnit() {
+        final ManualAdvanceClock clock = new ManualAdvanceClock(Instant.now());
+        final UptimeMetric uptimeMetric = new UptimeMetric("up_millis", TimeUnit.MILLISECONDS, clock::nanoTime);
+        clock.advance(Duration.ofMillis(1_000_000_000));
+
+        // set-up: ensure advancing nanos reflects in our milli-based uptime
+        assertEquals(Long.valueOf(1_000_000_000), uptimeMetric.getValue());
+
+        final UptimeMetric secondsBasedCopy = uptimeMetric.withTimeUnit("up_seconds", TimeUnit.SECONDS);
+        assertEquals(Long.valueOf(1_000_000), secondsBasedCopy.getValue());
+    }
+
+}
\ No newline at end of file
