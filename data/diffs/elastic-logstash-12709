diff --git a/logstash-core/logstash-core.gemspec b/logstash-core/logstash-core.gemspec
index 03748524e51..f1925100044 100644
--- a/logstash-core/logstash-core.gemspec
+++ b/logstash-core/logstash-core.gemspec
@@ -73,4 +73,10 @@ Gem::Specification.new do |gem|
 
   gem.add_runtime_dependency "elasticsearch", "~> 5"
   gem.add_runtime_dependency "manticore", '~> 0.6'
+
+  # xpack geoip database service
+  gem.add_dependency 'faraday' #(MIT license)
+  gem.add_dependency 'down', '~> 5.2.0' #(MIT license)
+  gem.add_dependency 'tzinfo-data' #(MIT license)
+  gem.add_dependency 'rufus-scheduler' #(MIT license)
 end
diff --git a/rakelib/plugins-metadata.json b/rakelib/plugins-metadata.json
index b8daea5aa4d..35f7f70266a 100644
--- a/rakelib/plugins-metadata.json
+++ b/rakelib/plugins-metadata.json
@@ -133,6 +133,7 @@
   },
   "logstash-filter-geoip": {
     "default-plugins": true,
+    "core-specs": true,
     "skip-list": false
   },
   "logstash-filter-grok": {
diff --git a/tools/dependencies-report/src/main/resources/licenseMapping.csv b/tools/dependencies-report/src/main/resources/licenseMapping.csv
index 1504ffde392..1e475d59bfc 100644
--- a/tools/dependencies-report/src/main/resources/licenseMapping.csv
+++ b/tools/dependencies-report/src/main/resources/licenseMapping.csv
@@ -145,3 +145,4 @@ dependency,dependencyUrl,licenseOverride,copyright,sourceURL
 "unf:",https://github.com/knu/ruby-unf,BSD-2-Clause
 "webhdfs:",https://github.com/kzk/webhdfs,Apache-2.0
 "xml-simple:",https://github.com/maik/xml-simple,BSD-2-Clause
+"down",https://github.com/janko/down,MIT
diff --git a/tools/dependencies-report/src/main/resources/notices/down-NOTICE.txt b/tools/dependencies-report/src/main/resources/notices/down-NOTICE.txt
new file mode 100644
index 00000000000..12ad42a8be7
--- /dev/null
+++ b/tools/dependencies-report/src/main/resources/notices/down-NOTICE.txt
@@ -0,0 +1,21 @@
+The MIT License (MIT)
+
+Copyright (c) 2015 Janko MarohniÄ‡
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in
+all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+THE SOFTWARE.
\ No newline at end of file
diff --git a/x-pack/build.gradle b/x-pack/build.gradle
index 5c978f55642..6ea1d5908ca 100644
--- a/x-pack/build.gradle
+++ b/x-pack/build.gradle
@@ -16,17 +16,34 @@ buildscript {
   }
 }
 
+configurations {
+  geolite2
+}
+
 dependencies {
   testImplementation project(':logstash-core')
   testImplementation 'org.assertj:assertj-core:3.8.0'
   testImplementation 'junit:junit:4.12'
+
+  geolite2('org.elasticsearch:geolite2-databases:20191119') {
+    transitive = false
+  }
 }
 
 test {
   exclude '/**'
 }
 
+tasks.register("unzipGeolite", Copy) {
+  from(zipTree(configurations.geolite2.singleFile)) {
+    include "GeoLite2-ASN.mmdb"
+    include "GeoLite2-City.mmdb"
+  }
+  into file("${projectDir}/spec/filters/geoip/vendor")
+}
+
 tasks.register("rubyTests", Test) {
+  dependsOn unzipGeolite
   inputs.files fileTree("${projectDir}/spec")
   inputs.files fileTree("${projectDir}/lib")
   inputs.files fileTree("${projectDir}/modules")
diff --git a/x-pack/lib/filters/geoip/database_manager.rb b/x-pack/lib/filters/geoip/database_manager.rb
new file mode 100644
index 00000000000..c9c151a8ade
--- /dev/null
+++ b/x-pack/lib/filters/geoip/database_manager.rb
@@ -0,0 +1,147 @@
+# Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+# or more contributor license agreements. Licensed under the Elastic License;
+# you may not use this file except in compliance with the Elastic License.
+
+require "logstash/util/loggable"
+require_relative "util"
+require_relative "database_metadata"
+require_relative "download_manager"
+require "faraday"
+require "json"
+require "zlib"
+require "stud/try"
+require "down"
+require "rufus/scheduler"
+require "date"
+
+# The mission of DatabaseManager is to ensure the plugin running an up-to-date MaxMind database and
+#   thus users are compliant with EULA.
+# DatabaseManager does a daily checking by calling an endpoint to notice a version update.
+# DatabaseMetadata records the update timestamp and md5 of the database in the metadata file
+#   to keep track of versions and the number of days disconnects to the endpoint.
+# Once a new database version release, DownloadManager downloads it, and GeoIP Filter uses it on-the-fly.
+# If the last update timestamp is 25 days ago, a warning message shows in the log;
+# if it was 30 days ago, the GeoIP Filter should shutdown in order to be compliant.
+# There are online mode and offline mode in DatabaseManager. `online` is for automatic database update
+#   while `offline` is for static database path provided by users
+
+module LogStash module Filters module Geoip class DatabaseManager
+  include LogStash::Util::Loggable
+  include LogStash::Filters::Geoip::Util
+
+  def initialize(geoip, database_path, database_type, vendor_path)
+    @vendor_path = vendor_path
+    @geoip = geoip
+    @mode = database_path.nil? ? :online : :offline
+    @database_type = database_type
+    @database_path = patch_database_path(database_path)
+
+    if @mode == :online
+      logger.info "By using `online` mode, you accepted and agreed MaxMind EULA. "\
+                  "For more details please visit https://www.maxmind.com/en/geolite2/eula"
+
+      setup
+      clean_up_database
+      execute_download_job
+
+      # check database update periodically. trigger `call` method
+      @scheduler = Rufus::Scheduler.new({:max_work_threads => 1})
+      @scheduler.every('24h', self)
+    else
+      logger.info "GeoIP plugin is in offline mode. Logstash points to static database files and will not check for update. "\
+                  "Keep in mind that if you are not using the database shipped with this plugin, "\
+                  "please go to https://www.maxmind.com/en/geolite2/eula to accept and agree the terms and conditions."
+    end
+  end
+
+  DEFAULT_DATABASE_FILENAME = ["GeoLite2-ASN.mmdb", "GeoLite2-City.mmdb"].freeze
+
+  public
+
+  def execute_download_job
+    begin
+      has_update, new_database_path = @download_manager.fetch_database
+      @database_path = new_database_path if has_update
+      @metadata.save_timestamp(@database_path)
+      has_update
+    rescue => e
+      logger.error(e.message, :cause => e.cause, :backtrace => e.backtrace)
+      check_age
+      false
+    end
+  end
+
+  # scheduler callback
+  def call(job, time)
+    logger.debug "scheduler runs database update check"
+
+    begin
+      if execute_download_job
+        @geoip.setup_filter(database_path)
+        clean_up_database
+      end
+    rescue DatabaseExpiryError => e
+      logger.error(e.message, :cause => e.cause, :backtrace => e.backtrace)
+      @geoip.terminate_filter
+    end
+  end
+
+  def close
+    @scheduler.every_jobs.each(&:unschedule) if @scheduler
+  end
+
+  def database_path
+    @database_path
+  end
+
+  protected
+  # return a valid database path or default database path
+  def patch_database_path(database_path)
+    return database_path if file_exist?(database_path)
+    return database_path if database_path = get_file_path("GeoLite2-#{@database_type}.mmdb") and file_exist?(database_path)
+    raise "You must specify 'database => ...' in your geoip filter (I looked for '#{database_path}')"
+  end
+
+  def check_age
+    days_without_update = (Date.today - Time.at(@metadata.updated_at).to_date).to_i
+
+    case
+    when days_without_update >= 30
+      raise DatabaseExpiryError, "The MaxMind database has been used for more than 30 days. Logstash is unable to get newer version from internet. "\
+      "According to EULA, GeoIP plugin needs to stop in order to be compliant. "\
+      "Please check the network settings and allow Logstash accesses the internet to download the latest database, "\
+      "or switch to offline mode (:database => PATH_TO_YOUR_DATABASE) to use a self-managed database which you can download from https://dev.maxmind.com/geoip/geoip2/geolite2/ "
+    when days_without_update >= 25
+      logger.warn("The MaxMind database has been used for #{days_without_update} days without update. "\
+      "Logstash will stop the GeoIP plugin in #{30 - days_without_update} days. "\
+      "Please check the network settings and allow Logstash accesses the internet to download the latest database ")
+    else
+      logger.debug("The MaxMind database hasn't updated", :days_without_update => days_without_update)
+    end
+  end
+
+  # Clean up files .mmdb, .gz which are not mentioned in metadata and not default database
+  def clean_up_database
+    if @metadata.exist?
+      protected_filenames = (@metadata.database_filenames + DEFAULT_DATABASE_FILENAME).uniq
+      existing_filenames = ::Dir.glob(get_file_path('*.{mmdb,gz}')).map { |path| path.split("/").last }
+
+      (existing_filenames - protected_filenames).each do |filename|
+        ::File.delete(get_file_path(filename))
+        logger.debug("old database #{filename} is deleted")
+      end
+    end
+  end
+
+  def setup
+    @metadata = DatabaseMetadata.new(@database_type, @vendor_path)
+    @metadata.save_timestamp(@database_path) unless @metadata.exist?
+
+    @database_path = @metadata.database_path || @database_path
+
+    @download_manager = DownloadManager.new(@database_type, @metadata, @vendor_path)
+  end
+
+  class DatabaseExpiryError < StandardError
+  end
+end end end end
\ No newline at end of file
diff --git a/x-pack/lib/filters/geoip/database_metadata.rb b/x-pack/lib/filters/geoip/database_metadata.rb
new file mode 100644
index 00000000000..c71c296517c
--- /dev/null
+++ b/x-pack/lib/filters/geoip/database_metadata.rb
@@ -0,0 +1,78 @@
+# Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+# or more contributor license agreements. Licensed under the Elastic License;
+# you may not use this file except in compliance with the Elastic License.
+
+require "logstash/util/loggable"
+require_relative "util"
+require "csv"
+require "date"
+
+module LogStash module Filters module Geoip class DatabaseMetadata
+  include LogStash::Util::Loggable
+  include LogStash::Filters::Geoip::Util
+
+  def initialize(database_type, vendor_path)
+    @vendor_path = vendor_path
+    @metadata_path = get_file_path("metadata.csv")
+    @database_type = database_type
+  end
+
+  public
+
+  # csv format: database_type, update_at, gz_md5, md5, filename
+  def save_timestamp(database_path)
+    metadata = get_metadata(false)
+    metadata << [@database_type, Time.now.to_i, md5(database_path + '.gz'), md5(database_path), database_path.split("/").last]
+
+    ::CSV.open @metadata_path, 'w' do |csv|
+      metadata.each { |row| csv << row }
+    end
+
+    logger.debug("metadata updated", :metadata => metadata)
+  end
+
+  def get_all
+    file_exist?(@metadata_path)? ::CSV.read(@metadata_path, headers: false) : Array.new
+  end
+
+  # Give rows of metadata in default database type, or empty array
+  def get_metadata(match_type = true)
+    get_all.select { |row| row[Column::DATABASE_TYPE].eql?(@database_type) == match_type }
+  end
+
+  # Return database path which has valid md5
+  def database_path
+    get_metadata.map { |metadata| [metadata, get_file_path(metadata[Column::FILENAME])] }
+                .select { |metadata, path| file_exist?(path) && (md5(path) == metadata[Column::MD5]) }
+                .map { |metadata, path| path }
+                .last
+  end
+
+  def gz_md5
+    get_metadata.map { |metadata| metadata[Column::GZ_MD5] }
+                .last || ''
+  end
+
+  def updated_at
+    (get_metadata.map { |metadata| metadata[Column::UPDATE_AT] }
+                 .last || 0).to_i
+  end
+
+  # Return database related filenames in .mmdb .gz
+  def database_filenames
+    get_all.flat_map { |metadata| [metadata[Column::FILENAME], metadata[Column::FILENAME] + '.gz'] }
+  end
+  
+  def exist?
+    file_exist?(@metadata_path)
+  end
+
+  class Column
+    DATABASE_TYPE = 0
+    UPDATE_AT     = 1
+    GZ_MD5        = 2
+    MD5           = 3
+    FILENAME      = 4
+  end
+
+end end end end
\ No newline at end of file
diff --git a/x-pack/lib/filters/geoip/download_manager.rb b/x-pack/lib/filters/geoip/download_manager.rb
new file mode 100644
index 00000000000..fe237d2da39
--- /dev/null
+++ b/x-pack/lib/filters/geoip/download_manager.rb
@@ -0,0 +1,96 @@
+# Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+# or more contributor license agreements. Licensed under the Elastic License;
+# you may not use this file except in compliance with the Elastic License.
+
+require "logstash/util/loggable"
+require_relative "util"
+require_relative "database_metadata"
+require "logstash-filter-geoip_jars"
+require "faraday"
+require "json"
+require "zlib"
+require "stud/try"
+require "down"
+
+module LogStash module Filters module Geoip class DownloadManager
+  include LogStash::Util::Loggable
+  include LogStash::Filters::Geoip::Util
+
+  def initialize(database_type, metadata, vendor_path)
+    @vendor_path = vendor_path
+    @database_type = database_type
+    @metadata = metadata
+  end
+
+  GEOIP_HOST = "https://paisano.elastic.dev".freeze
+  GEOIP_ENDPOINT = "#{GEOIP_HOST}/v1/geoip/database/".freeze
+
+  public
+  # Check available update and download it. Unzip and validate the file.
+  # return [has_update, new_database_path]
+  def fetch_database
+    has_update, database_info = check_update
+
+    if has_update
+      new_database_path = unzip download_database(database_info)
+      assert_database!(new_database_path)
+      return [true, new_database_path]
+    end
+
+    [false, nil]
+  end
+
+  private
+  # Call infra endpoint to get md5 of latest database and verify with metadata
+  # return [has_update, server db info]
+  def check_update
+    uuid = get_uuid
+    res = rest_client.get("#{GEOIP_ENDPOINT}?key=#{uuid}&elastic_geoip_service_tos=agree")
+    logger.debug("check update", :endpoint => GEOIP_ENDPOINT, :response => res.status)
+
+    dbs = JSON.parse(res.body)
+    target_db = dbs.select { |db| db['name'].include?(@database_type) }.first
+    has_update = @metadata.gz_md5 != target_db['md5_hash']
+    logger.info "new database version detected? #{has_update}"
+
+    [has_update, target_db]
+  end
+
+  def download_database(server_db)
+    Stud.try(3.times) do
+      new_database_zip_path = get_file_path("GeoLite2-#{@database_type}_#{Time.now.to_i}.mmdb.gz")
+      Down.download(server_db['url'], destination: new_database_zip_path)
+      raise "the new download has wrong checksum" if md5(new_database_zip_path) != server_db['md5_hash']
+
+      logger.debug("new database downloaded in ", :path => new_database_zip_path)
+      new_database_zip_path
+    end
+  end
+
+  def unzip(zip_path)
+    database_path = zip_path[0...-3]
+    Zlib::GzipReader.open(zip_path) do |gz|
+      ::File.open(database_path, "wb") do |f|
+        f.print gz.read
+      end
+    end
+    database_path
+  end
+
+  # Make sure the path has usable database
+  def assert_database!(database_path)
+    raise "failed to load database #{database_path}" unless org.logstash.filters.GeoIPFilter.database_valid?(database_path)
+  end
+
+  def rest_client
+    @client ||= Faraday.new do |conn|
+      conn.use Faraday::Response::RaiseError
+      conn.adapter :net_http
+    end
+  end
+
+  def get_uuid
+    @uuid ||= ::File.read(::File.join(LogStash::SETTINGS.get("path.data"), "uuid"))
+  end
+
+end end end end
diff --git a/x-pack/lib/filters/geoip/util.rb b/x-pack/lib/filters/geoip/util.rb
new file mode 100644
index 00000000000..4dfe7899acb
--- /dev/null
+++ b/x-pack/lib/filters/geoip/util.rb
@@ -0,0 +1,22 @@
+# Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+# or more contributor license agreements. Licensed under the Elastic License;
+# you may not use this file except in compliance with the Elastic License.
+
+require "digest"
+
+
+module LogStash module Filters module Geoip module Util
+
+  def get_file_path(filename)
+    ::File.join(@vendor_path, filename)
+  end
+
+  def file_exist?(path)
+    !path.nil? && ::File.exist?(path) && !::File.empty?(path)
+  end
+
+  def md5(file_path)
+    file_exist?(file_path) ? Digest::MD5.hexdigest(::File.read(file_path)): ""
+  end
+
+end end end end
\ No newline at end of file
diff --git a/x-pack/spec/filters/geoip/database_manager_spec.rb b/x-pack/spec/filters/geoip/database_manager_spec.rb
new file mode 100644
index 00000000000..86ab9aae766
--- /dev/null
+++ b/x-pack/spec/filters/geoip/database_manager_spec.rb
@@ -0,0 +1,216 @@
+# Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+# or more contributor license agreements. Licensed under the Elastic License;
+# you may not use this file except in compliance with the Elastic License.
+
+require_relative 'test_helper'
+require "filters/geoip/database_manager"
+
+module LogStash module Filters module Geoip
+
+  describe DatabaseManager, :aggregate_failures do
+    let(:mock_geoip_plugin)  { double("geoip_plugin") }
+    let(:mock_metadata)  { double("database_metadata") }
+    let(:mock_download_manager)  { double("download_manager") }
+    let(:mock_scheduler)  { double("scheduler") }
+    let(:db_manager) do
+      manager = DatabaseManager.new(mock_geoip_plugin, DEFAULT_CITY_DB_PATH, "City", get_vendor_path)
+      manager.instance_variable_set(:@metadata, mock_metadata)
+      manager.instance_variable_set(:@download_manager, mock_download_manager)
+      manager.instance_variable_set(:@scheduler, mock_scheduler)
+      manager
+    end
+    let(:logger) { double("Logger") }
+
+    context "patch database" do
+      it "use input path" do
+        path = db_manager.send(:patch_database_path, DEFAULT_ASN_DB_PATH)
+        expect(path).to eq(DEFAULT_ASN_DB_PATH)
+      end
+
+      it "use CC license database as default" do
+        path = db_manager.send(:patch_database_path, "")
+        expect(path).to eq(DEFAULT_CITY_DB_PATH)
+      end
+
+      it "failed when default database is missing" do
+        expect(db_manager).to receive(:file_exist?).and_return(false, false)
+        expect { db_manager.send(:patch_database_path, "") }.to raise_error /I looked for/
+      end
+    end
+
+    context "md5" do
+      it "return md5 if file exists" do
+        str = db_manager.send(:md5, DEFAULT_CITY_DB_PATH)
+        expect(str).not_to eq("")
+        expect(str).not_to be_nil
+      end
+
+      it "return empty str if file not exists" do
+        file = Stud::Temporary.file.path + "/invalid"
+        str = db_manager.send(:md5, file)
+        expect(str).to eq("")
+      end
+    end
+
+    context "check age" do
+      it "should raise error when 30 days has passed" do
+        expect(mock_metadata).to receive(:updated_at).and_return((Time.now - (60 * 60 * 24 * 33)).to_i)
+        expect{ db_manager.send(:check_age) }.to raise_error /be compliant/
+      end
+
+      it "should give warning after 25 days" do
+        expect(mock_metadata).to receive(:updated_at).and_return((Time.now - (60 * 60 * 24 * 26)).to_i)
+        expect(mock_geoip_plugin).to receive(:terminate_filter).never
+        expect(DatabaseManager).to receive(:logger).at_least(:once).and_return(logger)
+        expect(logger).to receive(:warn)
+        expect(logger).to receive(:info)
+
+        db_manager.send(:check_age)
+      end
+    end
+
+    context "execute download job" do
+      it "should be false if no update" do
+        original = db_manager.instance_variable_get(:@database_path)
+        expect(mock_download_manager).to receive(:fetch_database).and_return([false, nil])
+        allow(mock_metadata).to receive(:save_timestamp)
+
+        expect(db_manager.send(:execute_download_job)).to be_falsey
+        expect(db_manager.instance_variable_get(:@database_path)).to eq(original)
+      end
+
+      it "should return true if update" do
+        original = db_manager.instance_variable_get(:@database_path)
+        expect(mock_download_manager).to receive(:fetch_database).and_return([true, "NEW_PATH"])
+        allow(mock_metadata).to receive(:save_timestamp)
+
+        expect(db_manager.send(:execute_download_job)).to be_truthy
+        expect(db_manager.instance_variable_get(:@database_path)).not_to eq(original)
+      end
+
+      it "should raise error when 30 days has passed" do
+        allow(mock_download_manager).to receive(:fetch_database).and_raise("boom")
+        expect(mock_metadata).to receive(:updated_at).and_return((Time.now - (60 * 60 * 24 * 33)).to_i)
+
+        expect{ db_manager.send(:execute_download_job) }.to raise_error /be compliant/
+      end
+
+
+      it "should return false when 25 days has passed" do
+        allow(mock_download_manager).to receive(:fetch_database).and_raise("boom")
+
+        expect(mock_metadata).to receive(:updated_at).and_return((Time.now - (60 * 60 * 24 * 25)).to_i)
+
+        expect(db_manager.send(:execute_download_job)).to be_falsey
+      end
+    end
+
+    context "scheduler call" do
+      it "should call plugin termination when raise error and last update > 30 days" do
+        allow(mock_download_manager).to receive(:fetch_database).and_raise("boom")
+        expect(mock_metadata).to receive(:updated_at).and_return((Time.now - (60 * 60 * 24 * 33)).to_i)
+        expect(mock_geoip_plugin).to receive(:terminate_filter)
+        db_manager.send(:call, nil, nil)
+      end
+
+      it "should not call plugin setup when database is up to date" do
+        allow(mock_download_manager).to receive(:fetch_database).and_return([false, nil])
+        expect(mock_metadata).to receive(:save_timestamp)
+        allow(mock_geoip_plugin).to receive(:setup_filter).never
+        db_manager.send(:call, nil, nil)
+      end
+
+      it "should call scheduler when has update" do
+        allow(db_manager).to receive(:execute_download_job).and_return(true)
+        allow(mock_geoip_plugin).to receive(:setup_filter).once
+        allow(db_manager).to receive(:clean_up_database).once
+        db_manager.send(:call, nil, nil)
+      end
+    end
+
+    context "clean up database" do
+      let(:asn00) { get_file_path("GeoLite2-ASN_000000000.mmdb") }
+      let(:asn00gz) { get_file_path("GeoLite2-ASN_000000000.gz") }
+      let(:city00) { get_file_path("GeoLite2-City_000000000.mmdb") }
+      let(:city00gz) { get_file_path("GeoLite2-City_000000000.gz") }
+      let(:city44) { get_file_path("GeoLite2-City_4444444444.mmdb") }
+      let(:city44gz) { get_file_path("GeoLite2-City_4444444444.gz") }
+
+      before(:each) do
+        [asn00, asn00gz, city00, city00gz, city44, city44gz].each { |file_path| ::File.delete(file_path) if ::File.exist?(file_path) }
+      end
+
+      it "should not delete when metadata file doesn't exist" do
+        expect(mock_metadata).to receive(:exist?).and_return(false)
+        allow(mock_geoip_plugin).to receive(:database_filenames).never
+
+        db_manager.send(:clean_up_database)
+      end
+
+      it "should delete file which is not in metadata" do
+        [asn00, asn00gz, city00, city00gz, city44, city44gz].each { |file_path| FileUtils.touch(file_path) }
+        expect(mock_metadata).to receive(:exist?).and_return(true)
+        expect(mock_metadata).to receive(:database_filenames).and_return(["GeoLite2-City_4444444444.mmdb"])
+
+        db_manager.send(:clean_up_database)
+        [asn00, asn00gz, city00, city00gz, city44gz].each { |file_path| expect(::File.exist?(file_path)).to be_falsey }
+        [DEFAULT_CITY_DB_PATH, DEFAULT_ASN_DB_PATH, city44].each { |file_path| expect(::File.exist?(file_path)).to be_truthy }
+      end
+
+      it "should keep the default database" do
+        expect(mock_metadata).to receive(:exist?).and_return(true)
+        expect(mock_metadata).to receive(:database_filenames).and_return(["GeoLite2-City_4444444444.mmdb"])
+
+        db_manager.send(:clean_up_database)
+        [DEFAULT_CITY_DB_PATH, DEFAULT_ASN_DB_PATH].each { |file_path| expect(::File.exist?(file_path)).to be_truthy }
+      end
+    end
+
+    context "setup metadata" do
+      let(:db_metadata) do
+        dbm = DatabaseMetadata.new("City", get_vendor_path)
+        dbm.instance_variable_set(:@metadata_path, Stud::Temporary.file.path)
+        dbm
+      end
+
+      let(:temp_metadata_path) { db_metadata.instance_variable_get(:@metadata_path) }
+
+      before(:each) do
+        expect(::File.empty?(temp_metadata_path)).to be_truthy
+        allow(DatabaseMetadata).to receive(:new).and_return(db_metadata)
+      end
+
+      after(:each) do
+        ::File.delete(SECOND_CITY_DB_PATH) if ::File.exist?(SECOND_CITY_DB_PATH)
+      end
+
+      it "create metadata when file is missing" do
+        db_manager.send(:setup)
+        expect(db_manager.instance_variable_get(:@database_path)).to eql(DEFAULT_CITY_DB_PATH)
+        expect(db_metadata.database_path).to eql(DEFAULT_CITY_DB_PATH)
+        expect(::File.exist?(temp_metadata_path)).to be_truthy
+        expect(::File.empty?(temp_metadata_path)).to be_falsey
+      end
+
+      it "manager should use database path in metadata" do
+        write_temp_metadata(temp_metadata_path, city2_metadata)
+        copy_city_database(SECOND_CITY_DB_NAME)
+        expect(db_metadata).to receive(:save_timestamp).never
+
+        db_manager.send(:setup)
+        filename = db_manager.instance_variable_get(:@database_path).split('/').last
+        expect(filename).to match /#{SECOND_CITY_DB_NAME}/
+      end
+
+      it "ignore database_path in metadata if md5 does not match" do
+        write_temp_metadata(temp_metadata_path, ["City","","","INVALID_MD5",SECOND_CITY_DB_NAME])
+        copy_city_database(SECOND_CITY_DB_NAME)
+        expect(db_metadata).to receive(:save_timestamp).never
+
+        db_manager.send(:setup)
+        filename = db_manager.instance_variable_get(:@database_path).split('/').last
+        expect(filename).to match /#{DEFAULT_CITY_DB_NAME}/
+      end
+    end
+  end
+end end end
\ No newline at end of file
diff --git a/x-pack/spec/filters/geoip/database_metadata_spec.rb b/x-pack/spec/filters/geoip/database_metadata_spec.rb
new file mode 100644
index 00000000000..307fd48d804
--- /dev/null
+++ b/x-pack/spec/filters/geoip/database_metadata_spec.rb
@@ -0,0 +1,149 @@
+# # Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+# # or more contributor license agreements. Licensed under the Elastic License;
+# # you may not use this file except in compliance with the Elastic License.
+
+require_relative 'test_helper'
+require "filters/geoip/database_metadata"
+require "stud/temporary"
+
+module LogStash module Filters module Geoip
+
+  describe DatabaseMetadata, :aggregate_failures do
+    let(:dbm) do
+      dbm = DatabaseMetadata.new("City", get_vendor_path)
+      dbm.instance_variable_set(:@metadata_path, Stud::Temporary.file.path)
+      dbm
+    end
+    let(:temp_metadata_path) { dbm.instance_variable_get(:@metadata_path) }
+    let(:logger) { double("Logger") }
+
+    context "get all" do
+      it "return multiple rows" do
+        write_temp_metadata(temp_metadata_path, city2_metadata)
+
+        expect(dbm.get_all.size).to eq(3)
+      end
+    end
+
+    context "get metadata" do
+      it "return metadata" do
+        write_temp_metadata(temp_metadata_path, city2_metadata)
+
+        city = dbm.get_metadata
+        expect(city.size).to eq(2)
+
+        asn = dbm.get_metadata(false)
+        expect(asn.size).to eq(1)
+      end
+
+      it "return empty array when file is missing" do
+        metadata = dbm.get_metadata
+        expect(metadata.size).to eq(0)
+      end
+
+      it "return empty array when an empty file exist" do
+        FileUtils.touch(temp_metadata_path)
+
+        metadata = dbm.get_metadata
+        expect(metadata.size).to eq(0)
+      end
+    end
+
+    context "save timestamp" do
+      it "write the current time" do
+        dbm.save_timestamp(DEFAULT_CITY_DB_PATH)
+
+        metadata = dbm.get_metadata.last
+        expect(metadata[DatabaseMetadata::Column::DATABASE_TYPE]).to eq("City")
+        past = metadata[DatabaseMetadata::Column::UPDATE_AT]
+        expect(Time.now.to_i - past.to_i).to be < 100
+        expect(metadata[DatabaseMetadata::Column::GZ_MD5]).to eq('')
+        expect(metadata[DatabaseMetadata::Column::MD5]).to eq(DEFAULT_CITY_DB_MD5)
+        expect(metadata[DatabaseMetadata::Column::FILENAME]).to eq(DEFAULT_CITY_DB_NAME)
+      end
+    end
+
+    context "database path" do
+      it "return the default city database path" do
+        write_temp_metadata(temp_metadata_path)
+
+        expect(dbm.database_path).to eq(DEFAULT_CITY_DB_PATH)
+      end
+
+      it "return the last database path with valid md5" do
+        write_temp_metadata(temp_metadata_path, city2_metadata)
+
+        expect(dbm.database_path).to eq(DEFAULT_CITY_DB_PATH)
+      end
+
+      context "with ASN database type" do
+        let(:dbm) do
+          dbm = DatabaseMetadata.new("ASN", get_vendor_path)
+          dbm.instance_variable_set(:@metadata_path, Stud::Temporary.file.path)
+          dbm
+        end
+
+        it "return the default asn database path" do
+          write_temp_metadata(temp_metadata_path)
+
+          expect(dbm.database_path).to eq(DEFAULT_ASN_DB_PATH)
+        end
+      end
+
+      context "with invalid database type" do
+        let(:dbm) do
+          dbm = DatabaseMetadata.new("???", get_vendor_path)
+          dbm.instance_variable_set(:@metadata_path, Stud::Temporary.file.path)
+          dbm
+        end
+
+        it "return nil if md5 not matched" do
+          write_temp_metadata(temp_metadata_path)
+
+          expect(dbm.database_path).to be_nil
+        end
+      end
+    end
+
+    context "gz md5" do
+      it "should give the last gz md5" do
+        write_temp_metadata(temp_metadata_path, ["City","","SOME_GZ_MD5","SOME_MD5",SECOND_CITY_DB_NAME])
+        expect(dbm.gz_md5).to eq("SOME_GZ_MD5")
+      end
+
+      it "should give empty string if metadata is empty" do
+        expect(dbm.gz_md5).to eq("")
+      end
+    end
+
+    context "updated at" do
+      it "should give the last update timestamp" do
+        write_temp_metadata(temp_metadata_path, ["City","1611690807","SOME_GZ_MD5","SOME_MD5",SECOND_CITY_DB_NAME])
+        expect(dbm.updated_at).to eq(1611690807)
+      end
+
+      it "should give 0 if metadata is empty" do
+        expect(dbm.updated_at).to eq(0)
+      end
+    end
+
+    context "database filenames" do
+      it "should give filename in .mmdb .gz" do
+        write_temp_metadata(temp_metadata_path)
+        expect(dbm.database_filenames).to match_array([DEFAULT_CITY_DB_NAME, DEFAULT_ASN_DB_NAME, 'GeoLite2-City.mmdb.gz', 'GeoLite2-ASN.mmdb.gz'])
+      end
+    end
+
+    context "exist" do
+      it "should be false because Stud create empty temp file" do
+        expect(dbm.exist?).to be_falsey
+      end
+
+      it "should be true if temp file has content" do
+        ::File.open(temp_metadata_path, "w") { |f| f.write("something") }
+
+        expect(dbm.exist?).to be_truthy
+      end
+    end
+  end
+end end end
\ No newline at end of file
diff --git a/x-pack/spec/filters/geoip/download_manager_spec.rb b/x-pack/spec/filters/geoip/download_manager_spec.rb
new file mode 100644
index 00000000000..f57b057f207
--- /dev/null
+++ b/x-pack/spec/filters/geoip/download_manager_spec.rb
@@ -0,0 +1,148 @@
+# Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+# or more contributor license agreements. Licensed under the Elastic License;
+# you may not use this file except in compliance with the Elastic License.
+
+require_relative 'test_helper'
+require "filters/geoip/download_manager"
+
+module LogStash module Filters module Geoip
+
+  describe DownloadManager, :aggregate_failures do
+    let(:mock_metadata)  { double("database_metadata") }
+    let(:download_manager) do
+      manager = DownloadManager.new( "City", mock_metadata, get_vendor_path)
+      manager
+    end
+    let(:logger) { double("Logger") }
+
+
+    context "rest client" do
+      it "can call endpoint" do
+        conn = download_manager.send(:rest_client)
+        res = conn.get("#{GEOIP_STAGING_ENDPOINT}?key=#{SecureRandom.uuid}")
+        expect(res.status).to eq(200)
+      end
+
+      it "should raise error when endpoint response 4xx" do
+        conn = download_manager.send(:rest_client)
+        expect { conn.get("#{GEOIP_STAGING_HOST}?key=#{SecureRandom.uuid}") }.to raise_error /404/
+      end
+    end
+
+    context "check update" do
+      before(:each) do
+        expect(download_manager).to receive(:get_uuid).and_return(SecureRandom.uuid)
+        mock_resp = double("geoip_endpoint", :body => ::File.read(::File.expand_path("./fixtures/normal_resp.json", ::File.dirname(__FILE__))), :status => 200)
+        allow(download_manager).to receive_message_chain("rest_client.get").and_return(mock_resp)
+      end
+
+      it "should return has_update and db info when md5 does not match" do
+        expect(mock_metadata).to receive(:gz_md5).and_return("")
+
+        has_update, info = download_manager.send(:check_update)
+        expect(has_update).to be_truthy
+        expect(info).to have_key("md5_hash")
+        expect(info).to have_key("name")
+        expect(info).to have_key("provider")
+        expect(info).to have_key("updated")
+        expect(info).to have_key("url")
+        expect(info["name"]).to include("City")
+      end
+
+      it "should return false when md5 is the same" do
+        expect(mock_metadata).to receive(:gz_md5).and_return("4013dc17343af52a841bca2a8bad7e5e")
+
+        has_update, info = download_manager.send(:check_update)
+        expect(has_update).to be_falsey
+      end
+
+      it "should return true when md5 does not match" do
+        expect(mock_metadata).to receive(:gz_md5).and_return("bca2a8bad7e5e4013dc17343af52a841")
+
+        has_update, info = download_manager.send(:check_update)
+        expect(has_update).to be_truthy
+      end
+    end
+
+    context "download database" do
+      let(:db_info) do
+        {
+          "md5_hash" => md5_hash,
+          "name" => filename,
+          "provider" => "maxmind",
+          "updated" => 1609891257,
+          "url" => "https://github.com/logstash-plugins/logstash-filter-geoip/archive/master.zip"
+        }
+      end
+      let(:md5_hash) { SecureRandom.hex }
+      let(:filename) { "GeoLite2-City.mmdb.gz"}
+
+      it "should raise error if md5 does not match" do
+        allow(Down).to receive(:download)
+        expect{ download_manager.send(:download_database, db_info) }.to raise_error /wrong checksum/
+      end
+
+      it "should download file and return zip path" do
+        expect(download_manager).to receive(:md5).and_return(md5_hash)
+
+        path = download_manager.send(:download_database, db_info)
+        expect(path).to match /GeoLite2-City_\d+\.mmdb\.gz/
+        expect(::File.exist?(path)).to be_truthy
+        ::File.delete(path) if ::File.exist?(path)
+      end
+    end
+
+    context "unzip" do
+      before(:each) do
+        file_path = ::File.expand_path("./fixtures/sample", ::File.dirname(__FILE__))
+        ::File.delete(file_path) if ::File.exist?(file_path)
+      end
+
+      it "gz file" do
+        path = ::File.expand_path("./fixtures/sample.gz", ::File.dirname(__FILE__))
+        unzip_path = download_manager.send(:unzip, path)
+        expect(::File.exist?(unzip_path)).to be_truthy
+      end
+    end
+
+    context "assert database" do
+      it "should raise error if file is invalid" do
+        expect{ download_manager.send(:assert_database!, "Gemfile") }.to raise_error /failed to load database/
+      end
+
+      it "should pass validation" do
+        expect(download_manager.send(:assert_database!, DEFAULT_CITY_DB_PATH)).to be_nil
+      end
+    end
+
+    context "fetch database" do
+      it "should be false if no update" do
+        expect(download_manager).to receive(:check_update).and_return([false, {}])
+
+        has_update, new_database_path = download_manager.send(:fetch_database)
+
+        expect(has_update).to be_falsey
+        expect(new_database_path).to be_nil
+      end
+
+      it "should raise error" do
+        expect(download_manager).to receive(:check_update).and_return([true, {}])
+        expect(download_manager).to receive(:download_database).and_raise('boom')
+
+        expect { download_manager.send(:fetch_database) }.to raise_error
+      end
+
+      it "should be true if got update" do
+        expect(download_manager).to receive(:check_update).and_return([true, {}])
+        allow(download_manager).to receive(:download_database)
+        allow(download_manager).to receive(:unzip)
+        allow(download_manager).to receive(:assert_database!)
+
+        has_update, new_database_path = download_manager.send(:fetch_database)
+
+        expect(has_update).to be_truthy
+      end
+    end
+
+  end
+end end end
\ No newline at end of file
diff --git a/x-pack/spec/filters/geoip/fixtures/normal_resp.json b/x-pack/spec/filters/geoip/fixtures/normal_resp.json
new file mode 100644
index 00000000000..ca7aada9274
--- /dev/null
+++ b/x-pack/spec/filters/geoip/fixtures/normal_resp.json
@@ -0,0 +1,23 @@
+[
+  {
+    "md5_hash": "865cda8a8dda3178cacd9011b5ff43b3",
+    "name": "GeoLite2-ASN.mmdb.gz",
+    "provider": "maxmind",
+    "updated": 1609840452,
+    "url": "https://storage.googleapis.com/elastic-paisano-production/maxmind/GeoLite2-ASN.mmdb.gz?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=elastic-paisano-production%40elastic-apps-163815.iam.gserviceaccount.com%2F20210107%2Fhenk%2Fstorage%2Fgoog4_request&X-Goog-Date=20210107T135955Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=8362fd6001d6e6aca53bb968e77dbb2366a9ef65140e8a1e926974a690308e6328e9ccd82e53c6ea58cec9c58d4a77b16cb94b98a80f7d20969b3ce403ea6d3305771fb091d6505f5dee0e4597b6c6785adfec8e8708cfac75489d16297ac67edad81fd51e4a948ac2ede0bc0dea636e89443aed453815e9c4c557fea486304d15356fb6f32d8a168cbf58b5b31571c39e0ecbf877beb4b101f3e07cff667d952eaf5ad01bf90bed94469ac1e1046782b445db8c119cc7c01eaad5f7565932a6d40f5da182532d9032e6848ec916c24f18069bbb75e3ae50830023dc711d59eca8ec767f3701b45cbf3b358c9ca5ead763c9897792353cfdd12468a788311337"
+  },
+  {
+    "md5_hash": "4013dc17343af52a841bca2a8bad7e5e",
+    "name": "GeoLite2-City.mmdb.gz",
+    "provider": "maxmind",
+    "updated": 1609891257,
+    "url": "https://storage.googleapis.com/elastic-paisano-production/maxmind/GeoLite2-City.mmdb.gz?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=elastic-paisano-production%40elastic-apps-163815.iam.gserviceaccount.com%2F20210107%2Fhenk%2Fstorage%2Fgoog4_request&X-Goog-Date=20210107T135955Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=7e03e8ea5dfd2edfab99bd471105009479754e379248f173b61d1f55cc4cac2f7fadfc76bb1da062bebe530b6b1f482a83305a27bd5ab0be2eec9d5801f5690f2c05c2c333ce312b7e739090956a78c3ee1a54382b8b94edd3bd83fdabd4ae4d722fed0aad078e3c0cd920b7f9467f84969df0a3dcde569eb2763e4f0b96a739891efb5180d150aac41375697cb94d88018d1aa9877f98937003cdba6c5770b40334b5d43ba302eb12f5765c67c49269418512127d4ee5315c3d8dd8c07a4261ff04477e230e96cb5a622fab944b2cc98f83eb532708f8ec42fa23e47a62ba800bd939bf29d6bf2afc20a6835500f67b7a2063663c4bb53a6a2f3d982a1822bc"
+  },
+  {
+    "md5_hash": "1b94cc12c605c33b21ad3ea1ffa2a6a9",
+    "name": "GeoLite2-Country.mmdb.gz",
+    "provider": "maxmind",
+    "updated": 1609891257,
+    "url": "https://storage.googleapis.com/elastic-paisano-production/maxmind/GeoLite2-Country.mmdb.gz?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=elastic-paisano-production%40elastic-apps-163815.iam.gserviceaccount.com%2F20210107%2Fhenk%2Fstorage%2Fgoog4_request&X-Goog-Date=20210107T135955Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=8cfcdbc08b2894fe5ec59f7231c4e0be187256216c6a1a89319cae8bb0bc87d1cfe1e946ce57553310a22116f930b4d1b21c1621f89b69e44180457231fe0c5dfa0795184ab5153989027e24a6a96a466f7d72c45d5bf83f81158272c2909f7ac6ec39dea292a8500e410f8e07c68710b7888f267a8622a130876f4a21ee676aed0e104f992dcb074fbe3b7f1f7182343af6aee16c0b70b0dda9316401b67c932df76470d7be9b685d15509d9fc936e0d934ff03ac25264c5c996a4d82d9cab42dc3b2a02c30bf97ea0cb03564d21417544532c553ab70d4ec5a64613fb60468a05e914e40fbb14842fc89a802b4a27d18180045f147d7f3dc6c5eb78607f2a9"
+  }
+]
\ No newline at end of file
diff --git a/x-pack/spec/filters/geoip/fixtures/sample.gz b/x-pack/spec/filters/geoip/fixtures/sample.gz
new file mode 100644
index 00000000000..1b30dad7022
Binary files /dev/null and b/x-pack/spec/filters/geoip/fixtures/sample.gz differ
diff --git a/x-pack/spec/filters/geoip/test_helper.rb b/x-pack/spec/filters/geoip/test_helper.rb
new file mode 100644
index 00000000000..966c6aa92ec
--- /dev/null
+++ b/x-pack/spec/filters/geoip/test_helper.rb
@@ -0,0 +1,61 @@
+# Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+# or more contributor license agreements. Licensed under the Elastic License;
+# you may not use this file except in compliance with the Elastic License.
+
+require 'spec_helper'
+require "digest"
+
+def get_vendor_path
+  ::File.expand_path("./vendor/", ::File.dirname(__FILE__))
+end
+
+def get_file_path(filename)
+  ::File.join(get_vendor_path, filename)
+end
+
+def md5(file_path)
+  ::File.exist?(file_path) ? Digest::MD5.hexdigest(::File.read(file_path)) : ''
+end
+
+DEFAULT_CITY_DB_PATH = get_file_path("GeoLite2-City.mmdb")
+DEFAULT_ASN_DB_PATH = get_file_path("GeoLite2-ASN.mmdb")
+METADATA_PATH = get_file_path("metadata.csv")
+DEFAULT_CITY_DB_NAME = "GeoLite2-City.mmdb"
+DEFAULT_ASN_DB_NAME = "GeoLite2-ASN.mmdb"
+SECOND_CITY_DB_NAME = "GeoLite2-City_20200220.mmdb"
+SECOND_CITY_DB_PATH = get_file_path("GeoLite2-City_20200220.mmdb")
+DEFAULT_CITY_DB_MD5 = md5(DEFAULT_CITY_DB_PATH)
+DEFAULT_ASN_DB_MD5 = md5(DEFAULT_ASN_DB_PATH)
+GEOIP_STAGING_HOST = "https://paisano-staging.elastic.dev"
+GEOIP_STAGING_ENDPOINT = "#{GEOIP_STAGING_HOST}/v1/geoip/database/"
+
+def write_temp_metadata(temp_file_path, row = nil)
+  now = Time.now.to_i
+  city = md5(DEFAULT_CITY_DB_PATH)
+  asn = md5(DEFAULT_ASN_DB_PATH)
+
+  metadata = []
+  metadata << ["ASN",now,"",asn,DEFAULT_ASN_DB_NAME]
+  metadata << ["City",now,"",city,DEFAULT_CITY_DB_NAME]
+  metadata << row if row
+  CSV.open temp_file_path, 'w' do |csv|
+    metadata.each { |row| csv << row }
+  end
+end
+
+def city2_metadata
+  ["City",Time.now.to_i,"",md5(DEFAULT_CITY_DB_PATH),SECOND_CITY_DB_NAME]
+end
+
+def copy_city_database(filename)
+  new_path = DEFAULT_CITY_DB_PATH.gsub(DEFAULT_CITY_DB_NAME, filename)
+  FileUtils.cp(DEFAULT_CITY_DB_PATH, new_path)
+end
+
+def delete_file(*filepaths)
+  filepaths.map { |filepath| ::File.delete(filepath) if ::File.exist?(filepath) }
+end
+
+def get_metadata_database_name
+  ::File.exist?(METADATA_PATH) ? ::File.read(METADATA_PATH).split(",").last[0..-2] : nil
+end
\ No newline at end of file
