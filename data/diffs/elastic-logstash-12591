diff --git a/config/log4j2.properties b/config/log4j2.properties
index 18e655840ab..cd6f3159314 100644
--- a/config/log4j2.properties
+++ b/config/log4j2.properties
@@ -26,11 +26,7 @@ appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
 appender.rolling.policies.size.size = 100MB
 appender.rolling.strategy.type = DefaultRolloverStrategy
 appender.rolling.strategy.max = 30
-appender.rolling.avoid_pipelined_filter.type = ScriptFilter
-appender.rolling.avoid_pipelined_filter.script.type = Script
-appender.rolling.avoid_pipelined_filter.script.name = filter_no_pipelined
-appender.rolling.avoid_pipelined_filter.script.language = JavaScript
-appender.rolling.avoid_pipelined_filter.script.scriptText = ${sys:ls.pipeline.separate_logs} == false || !(logEvent.getContextData().containsKey("pipeline.id"))
+appender.rolling.avoid_pipelined_filter.type = PipelineRoutingFilter
 
 appender.json_rolling.type = RollingFile
 appender.json_rolling.name = json_rolling
@@ -47,34 +43,20 @@ appender.json_rolling.policies.size.type = SizeBasedTriggeringPolicy
 appender.json_rolling.policies.size.size = 100MB
 appender.json_rolling.strategy.type = DefaultRolloverStrategy
 appender.json_rolling.strategy.max = 30
-appender.json_rolling.avoid_pipelined_filter.type = ScriptFilter
-appender.json_rolling.avoid_pipelined_filter.script.type = Script
-appender.json_rolling.avoid_pipelined_filter.script.name = filter_no_pipelined
-appender.json_rolling.avoid_pipelined_filter.script.language = JavaScript
-appender.json_rolling.avoid_pipelined_filter.script.scriptText = ${sys:ls.pipeline.separate_logs} == false || !(logEvent.getContextData().containsKey("pipeline.id"))
+appender.json_rolling.avoid_pipelined_filter.type = PipelineRoutingFilter
 
-appender.routing.type = Routing
+appender.routing.type = PipelineRouting
 appender.routing.name = pipeline_routing_appender
-appender.routing.routes.type = Routes
-appender.routing.routes.script.type = Script
-appender.routing.routes.script.name = routing_script
-appender.routing.routes.script.language = JavaScript
-appender.routing.routes.script.scriptText = logEvent.getContextData().containsKey("pipeline.id") ? logEvent.getContextData().getValue("pipeline.id") : "sink";
-appender.routing.routes.route_pipelines.type = Route
-appender.routing.routes.route_pipelines.rolling.type = RollingFile
-appender.routing.routes.route_pipelines.rolling.name = appender-${ctx:pipeline.id}
-appender.routing.routes.route_pipelines.rolling.fileName = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.log
-appender.routing.routes.route_pipelines.rolling.filePattern = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.%i.log.gz
-appender.routing.routes.route_pipelines.rolling.layout.type = PatternLayout
-appender.routing.routes.route_pipelines.rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %m%n
-appender.routing.routes.route_pipelines.rolling.policy.type = SizeBasedTriggeringPolicy
-appender.routing.routes.route_pipelines.rolling.policy.size = 100MB
-appender.routing.routes.route_pipelines.strategy.type = DefaultRolloverStrategy
-appender.routing.routes.route_pipelines.strategy.max = 30
-appender.routing.routes.route_sink.type = Route
-appender.routing.routes.route_sink.key = sink
-appender.routing.routes.route_sink.null.type = Null
-appender.routing.routes.route_sink.null.name = drop-appender
+appender.routing.pipeline.type = RollingFile
+appender.routing.pipeline.name = appender-${ctx:pipeline.id}
+appender.routing.pipeline.fileName = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.log
+appender.routing.pipeline.filePattern = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.%i.log.gz
+appender.routing.pipeline.layout.type = PatternLayout
+appender.routing.pipeline.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %m%n
+appender.routing.pipeline.policy.type = SizeBasedTriggeringPolicy
+appender.routing.pipeline.policy.size = 100MB
+appender.routing.pipeline.strategy.type = DefaultRolloverStrategy
+appender.routing.pipeline.strategy.max = 30
 
 rootLogger.level = ${sys:ls.log.level}
 rootLogger.appenderRef.console.ref = ${sys:ls.log.format}_console
diff --git a/logstash-core/benchmarks/src/main/resources/log4j2-with-script.properties b/logstash-core/benchmarks/src/main/resources/log4j2-with-script.properties
index 7c326d5fba2..fe2de91e93e 100644
--- a/logstash-core/benchmarks/src/main/resources/log4j2-with-script.properties
+++ b/logstash-core/benchmarks/src/main/resources/log4j2-with-script.properties
@@ -15,34 +15,20 @@ appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
 appender.rolling.policies.size.size = 100MB
 appender.rolling.strategy.type = DefaultRolloverStrategy
 appender.rolling.strategy.max = 30
-appender.rolling.avoid_pipelined_filter.type = ScriptFilter
-appender.rolling.avoid_pipelined_filter.script.type = Script
-appender.rolling.avoid_pipelined_filter.script.name = filter_no_pipelined
-appender.rolling.avoid_pipelined_filter.script.language = JavaScript
-appender.rolling.avoid_pipelined_filter.script.scriptText = ${sys:ls.pipeline.separate_logs} == false || !(logEvent.getContextData().containsKey("pipeline.id"))
+appender.rolling.avoid_pipelined_filter.type = PipelineRoutingFilter
 
-appender.routing.type = Routing
+appender.routing.type = PipelineRouting
 appender.routing.name = pipeline_routing_appender
-appender.routing.routes.type = Routes
-appender.routing.routes.script.type = Script
-appender.routing.routes.script.name = routing_script
-appender.routing.routes.script.language = JavaScript
-appender.routing.routes.script.scriptText = logEvent.getContextData().containsKey("pipeline.id") ? logEvent.getContextData().getValue("pipeline.id") : "sink";
-appender.routing.routes.route_pipelines.type = Route
-appender.routing.routes.route_pipelines.rolling.type = RollingFile
-appender.routing.routes.route_pipelines.rolling.name = appender-${ctx:pipeline.id}
-appender.routing.routes.route_pipelines.rolling.fileName = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.log
-appender.routing.routes.route_pipelines.rolling.filePattern = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.%i.log.gz
-appender.routing.routes.route_pipelines.rolling.layout.type = PatternLayout
-appender.routing.routes.route_pipelines.rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %-.10000m%n
-appender.routing.routes.route_pipelines.rolling.policy.type = SizeBasedTriggeringPolicy
-appender.routing.routes.route_pipelines.rolling.policy.size = 100MB
-appender.routing.routes.route_pipelines.strategy.type = DefaultRolloverStrategy
-appender.routing.routes.route_pipelines.strategy.max = 30
-appender.routing.routes.route_sink.type = Route
-appender.routing.routes.route_sink.key = sink
-appender.routing.routes.route_sink.null.type = Null
-appender.routing.routes.route_sink.null.name = drop-appender
+appender.routing.pipeline.type = RollingFile
+appender.routing.pipeline.name = appender-${ctx:pipeline.id}
+appender.routing.pipeline.fileName = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.log
+appender.routing.pipeline.filePattern = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.%i.log.gz
+appender.routing.pipeline.layout.type = PatternLayout
+appender.routing.pipeline.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %m%n
+appender.routing.pipeline.policy.type = SizeBasedTriggeringPolicy
+appender.routing.pipeline.policy.size = 100MB
+appender.routing.pipeline.strategy.type = DefaultRolloverStrategy
+appender.routing.pipeline.strategy.max = 30
 
 rootLogger.level = INFO
 rootLogger.appenderRef.rolling.ref = ${sys:ls.log.format}_rolling
diff --git a/logstash-core/lib/logstash/runner.rb b/logstash-core/lib/logstash/runner.rb
index 9a0cf1bcf56..7ed06ccad83 100644
--- a/logstash-core/lib/logstash/runner.rb
+++ b/logstash-core/lib/logstash/runner.rb
@@ -296,6 +296,10 @@ def execute
     # override log level that may have been introduced from a custom log4j config file
     LogStash::Logging::Logger::configure_logging(setting("log.level"))
 
+    if log_configuration_contains_javascript_usage?
+      logger.warn("Logging configuration uses appender or filter with scripting language JavaScript, which will be removed in a future major release of Logstash.")
+    end
+
     if setting("config.debug") && !logger.debug?
       logger.warn("--config.debug was specified, but log.level was not set to \'debug\'! No config info will be logged.")
     end
@@ -437,6 +441,18 @@ def execute
     @log_fd.close if @log_fd
   end # def self.main
 
+  def log_configuration_contains_javascript_usage?
+     context = LoggerContext.getContext(false)
+     config = context.configuration
+     config_file = config.configuration_source.file
+     # no config file so nothing to check
+     return false if config_file.nil?
+
+     logger.info("Log4j configuration path used is: #{config_file.path}")
+     log_config = File.open(config_file.absolute_path).read
+     (log_config =~ /^[^#]+script\.language\s*=\s*JavaScript/) != nil
+  end
+
   def show_version
     show_version_logstash
 
diff --git a/logstash-core/src/main/java/org/logstash/Logstash.java b/logstash-core/src/main/java/org/logstash/Logstash.java
index 7d387bfd5e9..e2afce899c0 100644
--- a/logstash-core/src/main/java/org/logstash/Logstash.java
+++ b/logstash-core/src/main/java/org/logstash/Logstash.java
@@ -62,7 +62,6 @@ public static void main(final String... args) {
                     "LS_HOME environment variable must be set. This is likely a bug that should be reported."
             );
         }
-        configureNashornDeprecationSwitchForJavaAbove11();
         installGlobalUncaughtExceptionHandler();
 
         final Path home = Paths.get(lsHome).toAbsolutePath();
@@ -93,15 +92,6 @@ public static void main(final String... args) {
         System.exit(0);
     }
 
-    private static void configureNashornDeprecationSwitchForJavaAbove11() {
-        final String javaVersion = System.getProperty("java.version");
-        // match version 1.x.y, 9.x.y and 10.x.y
-        if (!javaVersion.matches("^1\\.\\d\\..*") && !javaVersion.matches("^(9|10)\\.\\d\\..*")) {
-            // Avoid Nashorn deprecation logs in JDK >= 11
-            System.setProperty("nashorn.args", "--no-deprecation-warning");
-        }
-    }
-
     private static void installGlobalUncaughtExceptionHandler() {
         Thread.setDefaultUncaughtExceptionHandler((thread, e) -> {
             if (e instanceof Error) {
diff --git a/logstash-core/src/main/java/org/logstash/log/PipelineRoutingAppender.java b/logstash-core/src/main/java/org/logstash/log/PipelineRoutingAppender.java
new file mode 100644
index 00000000000..4f8ffccaf92
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/log/PipelineRoutingAppender.java
@@ -0,0 +1,155 @@
+package org.logstash.log;
+
+import org.apache.logging.log4j.core.Appender;
+import org.apache.logging.log4j.core.Core;
+import org.apache.logging.log4j.core.LogEvent;
+import org.apache.logging.log4j.core.appender.AbstractAppender;
+import org.apache.logging.log4j.core.config.AppenderControl;
+import org.apache.logging.log4j.core.config.Configuration;
+import org.apache.logging.log4j.core.config.Node;
+import org.apache.logging.log4j.core.config.Property;
+import org.apache.logging.log4j.core.config.plugins.Plugin;
+import org.apache.logging.log4j.core.config.plugins.PluginBuilderFactory;
+import org.apache.logging.log4j.core.config.plugins.PluginNode;
+
+import java.util.Collections;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+
+/**
+ * Appender customization to separate logs per pipeline.
+ *
+ * It instantiates subappenders, starting from a definition.
+ *
+ * Sample of XML configuration:
+ * <pre>{@code
+ *  <PipelineRouting name="a_name">
+ *      <RollingFile
+ *            name="appender-${ctx:pipeline.id}"
+ *            fileName="${sys:ls.logs}/pipeline_${ctx:pipeline.id}.log"
+ *            filePattern="${sys:ls.logs}/pipeline_${ctx:pipeline.id}.%i.log.gz">
+ *          <PatternLayout>
+ *            <pattern>[%d{ISO8601}][%-5p][%-25c] %m%n</pattern>
+ *          </PatternLayout>
+ *          <SizeBasedTriggeringPolicy size="100MB" />
+ *          <DefaultRolloverStrategy max="30" />
+ *        </RollingFile>
+ *  </PipelineRouting>
+ *  }
+ * </pre>
+ * */
+@Plugin(name = "PipelineRouting", category = Core.CATEGORY_NAME, elementType = Appender.ELEMENT_TYPE, printObject = true, deferChildren = true)
+public class PipelineRoutingAppender extends AbstractAppender {
+
+    /**
+     * Builder for {@link PipelineRoutingAppender} instances
+     * */
+    public static class Builder<B extends PipelineRoutingAppender.Builder<B>> extends AbstractAppender.Builder<B>
+            implements org.apache.logging.log4j.core.util.Builder<PipelineRoutingAppender> {
+
+        @PluginNode
+        private Node appenderNode;
+
+        @Override
+        public PipelineRoutingAppender build() {
+            final String name = getName();
+            if (name == null) {
+                LOGGER.error("No name defined for this RoutingAppender");
+                return null;
+            }
+            return new PipelineRoutingAppender(name, appenderNode, getConfiguration());
+        }
+    }
+
+    /**
+     * Factory method to instantiate the appender
+     * */
+    @PluginBuilderFactory
+    public static <B extends PipelineRoutingAppender.Builder<B>> B newBuilder() {
+        return new PipelineRoutingAppender.Builder<B>().asBuilder();
+    }
+
+    private final Node appenderNode;
+    private final Configuration configuration;
+    private final ConcurrentMap<String, AppenderControl> createdAppenders = new ConcurrentHashMap<>();
+    private final Map<String, AppenderControl> createdAppendersUnmodifiableView =
+            Collections.unmodifiableMap(createdAppenders);
+
+    protected PipelineRoutingAppender(String name, Node appenderNode, Configuration configuration) {
+        super(name, null, null, false, new Property[0]);
+        this.appenderNode = appenderNode;
+        this.configuration = configuration;
+    }
+
+    /**
+     * Returns an unmodifiable view of the appenders created by this {@link PipelineRoutingAppender}.
+     */
+    public Map<String, AppenderControl> getAppenders() {
+        return createdAppendersUnmodifiableView;
+    }
+
+    /**
+     * Core method to apply the logic of routing.
+     * */
+    @Override
+    public void append(LogEvent event) {
+        AppenderControl appenderControl = getControl(event);
+
+        if (appenderControl != null) {
+            appenderControl.callAppender(event);
+        }
+    }
+
+    /**
+     * Create or retrieve the sub appender for the pipeline.id provided into the event
+     * */
+    private AppenderControl getControl(LogEvent event) {
+        String key = event.getContextData().getValue("pipeline.id");
+        if (key == null) {
+            error("Unable to find the pipeline.id in event's context data");
+            key = "sink";
+        }
+
+        AppenderControl appenderControl = createdAppenders.get(key);
+        if (appenderControl == null) {
+            synchronized (this) {
+                appenderControl = createdAppenders.get(key);
+                if (appenderControl == null) {
+                    //create new appender and control
+                    final Appender app = createAppender(event);
+                    if (app == null) {
+                        return null;
+                    }
+                    AppenderControl created = new AppenderControl(app, null, null);
+                    appenderControl = created;
+                    createdAppenders.put(key, created);
+                }
+            }
+        }
+        return appenderControl;
+    }
+
+
+    /**
+     * Used by @{@link #getControl(LogEvent)} to create new subappenders for not yet encountered pipelines.
+     * */
+    private Appender createAppender(final LogEvent event) {
+        for (final Node node : appenderNode.getChildren()) {
+            if (node.getType().getElementName().equals(Appender.ELEMENT_TYPE)) {
+                final Node appNode = new Node(node);
+                configuration.createConfiguration(appNode, event);
+                if (appNode.getObject() instanceof Appender) {
+                    final Appender app = appNode.getObject();
+                    app.start();
+                    return app;
+                }
+                error("Unable to create Appender of type " + node.getName());
+                return null;
+            }
+        }
+        error("No Appender was configured for  " + getName());
+        return null;
+    }
+
+}
diff --git a/logstash-core/src/main/java/org/logstash/log/PipelineRoutingFilter.java b/logstash-core/src/main/java/org/logstash/log/PipelineRoutingFilter.java
new file mode 100644
index 00000000000..544065fe5b0
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/log/PipelineRoutingFilter.java
@@ -0,0 +1,50 @@
+package org.logstash.log;
+
+import org.apache.logging.log4j.core.Appender;
+import org.apache.logging.log4j.core.Core;
+import org.apache.logging.log4j.core.LogEvent;
+import org.apache.logging.log4j.core.config.plugins.Plugin;
+import org.apache.logging.log4j.core.config.plugins.PluginFactory;
+import org.apache.logging.log4j.core.filter.AbstractFilter;
+
+/**
+ * Custom filter to avoid that pipeline tagged log events goes in global appender.
+ * */
+@Plugin(name = "PipelineRoutingFilter", category = Core.CATEGORY_NAME, elementType = Appender.ELEMENT_TYPE, printObject = true)
+public final class PipelineRoutingFilter extends AbstractFilter {
+
+    private boolean isSeparateLogs;
+
+    /**
+     * Factory method to instantiate the filter
+     * */
+    @PluginFactory
+    public static PipelineRoutingFilter createFilter() {
+        return new PipelineRoutingFilter();
+    }
+
+    /**
+     * Avoid direct instantiation of the filter
+     * */
+    private PipelineRoutingFilter() {
+        isSeparateLogs = Boolean.getBoolean("ls.pipeline.separate_logs");
+    }
+
+    /**
+     * Contains the main logic to execute in filtering.
+     *
+     * Deny the logging of an event when separate logs feature is enabled and the event is fish tagged with a
+     * pipeline id.
+     *
+     * @param event the log to filter.
+     * */
+    @Override
+    public Result filter(LogEvent event) {
+        final boolean directedToPipelineLog = isSeparateLogs &&
+                event.getContextData().containsKey("pipeline.id");
+        if (directedToPipelineLog) {
+            return Result.DENY;
+        }
+        return Result.NEUTRAL;
+    }
+}
diff --git a/logstash-core/src/test/java/org/logstash/log/LogstashConfigurationFactoryTest.java b/logstash-core/src/test/java/org/logstash/log/LogstashConfigurationFactoryTest.java
index 0d1495df958..6bb5dedb9ac 100644
--- a/logstash-core/src/test/java/org/logstash/log/LogstashConfigurationFactoryTest.java
+++ b/logstash-core/src/test/java/org/logstash/log/LogstashConfigurationFactoryTest.java
@@ -90,7 +90,7 @@ public void testAppenderPerPipelineIsCreatedAfterLogLine() {
     private void verifyPipelineReceived(String pipelineSubAppenderName, String expectedMessage) {
         LoggerContext context = LoggerContext.getContext(false);
         final Configuration config = context.getConfiguration();
-        RoutingAppender routingApp = config.getAppender(LogstashConfigurationFactory.PIPELINE_ROUTING_APPENDER_NAME);
+        PipelineRoutingAppender routingApp = config.getAppender(LogstashConfigurationFactory.PIPELINE_ROUTING_APPENDER_NAME);
         Map<String, AppenderControl> appenders = routingApp.getAppenders();
         assertNotNull("Routing appenders MUST be defined", appenders);
         AppenderControl appenderControl = appenders.get(pipelineSubAppenderName);
diff --git a/logstash-core/src/test/java/org/logstash/log/PipelineRoutingAppenderTest.java b/logstash-core/src/test/java/org/logstash/log/PipelineRoutingAppenderTest.java
new file mode 100644
index 00000000000..5b930992771
--- /dev/null
+++ b/logstash-core/src/test/java/org/logstash/log/PipelineRoutingAppenderTest.java
@@ -0,0 +1,67 @@
+package org.logstash.log;
+
+import org.apache.logging.log4j.EventLogger;
+import org.apache.logging.log4j.core.LogEvent;
+import org.apache.logging.log4j.core.LoggerContext;
+import org.apache.logging.log4j.core.config.AppenderControl;
+import org.apache.logging.log4j.core.config.Configuration;
+import org.apache.logging.log4j.junit.LoggerContextRule;
+import org.apache.logging.log4j.message.StructuredDataMessage;
+import org.apache.logging.log4j.test.appender.ListAppender;
+import org.junit.After;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.RuleChain;
+
+import java.util.List;
+import java.util.Map;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertTrue;
+
+public class PipelineRoutingAppenderTest {
+
+    private static final String CONFIG = "log4j-pipeline-routing.xml";
+
+    private ListAppender app;
+
+    private final LoggerContextRule loggerContextRule = new LoggerContextRule(CONFIG);
+
+    // this is needed to initialize log context
+    @Rule
+    public RuleChain rules = loggerContextRule.withCleanFilesRule();
+
+    @After
+    public void tearDown() {
+        this.app.clear();
+        this.loggerContextRule.getLoggerContext().stop();
+    }
+
+    @Test
+    public void routingTest() {
+        final String pipelineId = "test_pipeline";
+        StructuredDataMessage msg = new StructuredDataMessage("Test", "This is a test", "Service");
+        org.apache.logging.log4j.ThreadContext.put("pipeline.id", pipelineId);
+        EventLogger.logEvent(msg);
+
+        this.app = findListAppender(pipelineId);
+        assertEquals("appender-" + pipelineId, app.getName());
+
+        final List<LogEvent> list = app.getEvents();
+        assertNotNull("No events generated", list);
+        assertEquals("Incorrect number of events. Expected 1, got " + list.size(), 1, list.size());
+    }
+
+    private ListAppender findListAppender(String pipelineId) {
+        LoggerContext context = LoggerContext.getContext(false);
+        final Configuration config = context.getConfiguration();
+        PipelineRoutingAppender routingApp = config.getAppender("pipeline_routing");
+        assertNotNull("Can't find pipeline routing appender", routingApp);
+        Map<String, AppenderControl> appenders = routingApp.getAppenders();
+        assertTrue("Subappender must exists with id " + pipelineId, appenders.containsKey(pipelineId));
+        final AppenderControl appenderControl = appenders.get(pipelineId);
+        return (ListAppender) appenderControl.getAppender();
+    }
+
+}
\ No newline at end of file
diff --git a/logstash-core/src/test/java/org/logstash/log/PipelineRoutingFilterTest.java b/logstash-core/src/test/java/org/logstash/log/PipelineRoutingFilterTest.java
new file mode 100644
index 00000000000..a5ed4cea1e9
--- /dev/null
+++ b/logstash-core/src/test/java/org/logstash/log/PipelineRoutingFilterTest.java
@@ -0,0 +1,62 @@
+package org.logstash.log;
+
+import org.apache.logging.log4j.Level;
+import org.apache.logging.log4j.MarkerManager;
+import org.apache.logging.log4j.core.Filter;
+import org.apache.logging.log4j.core.LogEvent;
+import org.apache.logging.log4j.core.config.Property;
+import org.apache.logging.log4j.core.impl.Log4jLogEvent;
+import org.apache.logging.log4j.message.SimpleMessage;
+import org.junit.After;
+import org.junit.Test;
+
+import java.util.Collections;
+
+import static org.junit.Assert.assertEquals;
+
+public class PipelineRoutingFilterTest {
+
+    @After
+    public void tearDown() {
+        System.clearProperty(LogstashConfigurationFactory.PIPELINE_SEPARATE_LOGS);
+    }
+
+    @Test
+    public void testShouldLetEventFlowIfSeparateLogFeatureIsDisabled() {
+        final PipelineRoutingFilter sut = PipelineRoutingFilter.createFilter();
+
+        LogEvent log = new Log4jLogEvent();
+        final Filter.Result res = sut.filter(log);
+
+        assertEquals("When ls.pipeline.separate_logs is false the filter MUST be neutral", Filter.Result.NEUTRAL, res);
+    }
+
+    @Test
+    public void testShouldLetEventFlowIfSeparateLogFeatureIsEnabledAndTheEventIsNotPipelineTagged() {
+        System.setProperty(LogstashConfigurationFactory.PIPELINE_SEPARATE_LOGS, "true");
+        final PipelineRoutingFilter sut = PipelineRoutingFilter.createFilter();
+
+        LogEvent log = new Log4jLogEvent();
+        final Filter.Result res = sut.filter(log);
+
+        assertEquals("When ls.pipeline.separate_logs is enabled and log event is not tagged the filter MUST be neutral",
+                Filter.Result.NEUTRAL, res);
+    }
+
+    @Test
+    public void testDenyEventFlowIfSeparateLogFeatureIsEnabledAndTheEventIsPipelineTagged() {
+        System.setProperty(LogstashConfigurationFactory.PIPELINE_SEPARATE_LOGS, "true");
+        final PipelineRoutingFilter sut = PipelineRoutingFilter.createFilter();
+
+        final Property prop = Property.createProperty("pipeline.id", "test_pipeline");
+
+        LogEvent log = new Log4jLogEvent("logstash.test.filer",
+                new MarkerManager.Log4jMarker("marker"), "a", Level.DEBUG,
+                new SimpleMessage("test message"), Collections.singletonList(prop), null);
+        final Filter.Result res = sut.filter(log);
+
+        assertEquals("When ls.pipeline.separate_logs is enabled and log event is tagged the filter MUST deny the flowing",
+                Filter.Result.DENY, res);
+    }
+
+}
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/log4j-pipeline-routing.xml b/logstash-core/src/test/resources/log4j-pipeline-routing.xml
new file mode 100644
index 00000000000..7ed55a706d6
--- /dev/null
+++ b/logstash-core/src/test/resources/log4j-pipeline-routing.xml
@@ -0,0 +1,46 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+
+-->
+<Configuration status="OFF" name="RoutingTest">
+  <Properties>
+    <Property name="filename">build/routing1/routingtest-$${sd:type}.log</Property>
+  </Properties>
+  <ThresholdFilter level="debug"/>
+
+  <Appenders>
+    <Console name="STDOUT">
+      <PatternLayout pattern="%m%n"/>
+    </Console>
+    <PipelineRouting name="pipeline_routing">
+      <List name="appender-${ctx:pipeline.id}">
+        <ThresholdFilter level="debug"/>
+      </List>
+    </PipelineRouting>
+  </Appenders>
+
+  <Loggers>
+    <Logger name="EventLogger" level="info" additivity="false">
+      <AppenderRef ref="pipeline_routing"/>
+    </Logger>
+
+    <Root level="error">
+      <AppenderRef ref="STDOUT"/>
+    </Root>
+  </Loggers>
+
+</Configuration>
\ No newline at end of file
diff --git a/logstash-core/src/test/resources/log4j2-log-pipeline-test.properties b/logstash-core/src/test/resources/log4j2-log-pipeline-test.properties
index 782af7dc606..49d019840bd 100644
--- a/logstash-core/src/test/resources/log4j2-log-pipeline-test.properties
+++ b/logstash-core/src/test/resources/log4j2-log-pipeline-test.properties
@@ -16,16 +16,10 @@ appender.rolling.policies.size.size = 100MB
 appender.rolling.strategy.type = DefaultRolloverStrategy
 appender.rolling.strategy.max = 30
 
-appender.routing.type = Routing
+appender.routing.type = PipelineRouting
 appender.routing.name = pipeline_routing_appender
-appender.routing.routes.type = Routes
-appender.routing.routes.script.type = Script
-appender.routing.routes.script.name = routing_script
-appender.routing.routes.script.language = JavaScript
-appender.routing.routes.script.scriptText = logEvent.getContextMap().get("pipeline.id")
-appender.routing.routes.route1.type = Route
-appender.routing.routes.route1.list.type = List
-appender.routing.routes.route1.list.name = appender-${mdc:pipeline.id}
+appender.routing.pipeline.type = List
+appender.routing.pipeline.name = appender-${mdc:pipeline.id}
 
 rootLogger.level = DEBUG
 rootLogger.appenderRef.routing.ref = pipeline_routing_appender
diff --git a/qa/integration/fixtures/persistent_queues/log4j2.properties b/qa/integration/fixtures/persistent_queues/log4j2.properties
index dffe516fed7..1132e88a82a 100644
--- a/qa/integration/fixtures/persistent_queues/log4j2.properties
+++ b/qa/integration/fixtures/persistent_queues/log4j2.properties
@@ -26,11 +26,7 @@ appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
 appender.rolling.policies.size.size = 100MB
 appender.rolling.strategy.type = DefaultRolloverStrategy
 appender.rolling.strategy.max = 30
-appender.rolling.avoid_pipelined_filter.type = ScriptFilter
-appender.rolling.avoid_pipelined_filter.script.type = Script
-appender.rolling.avoid_pipelined_filter.script.name = filter_no_pipelined
-appender.rolling.avoid_pipelined_filter.script.language = JavaScript
-appender.rolling.avoid_pipelined_filter.script.scriptText = ${sys:ls.pipeline.separate_logs} == false || !(logEvent.getContextData().containsKey("pipeline.id"))
+appender.rolling.avoid_pipelined_filter.type = PipelineRoutingFilter
 
 appender.json_rolling.type = RollingFile
 appender.json_rolling.name = json_rolling
@@ -47,34 +43,20 @@ appender.json_rolling.policies.size.type = SizeBasedTriggeringPolicy
 appender.json_rolling.policies.size.size = 100MB
 appender.json_rolling.strategy.type = DefaultRolloverStrategy
 appender.json_rolling.strategy.max = 30
-appender.json_rolling.avoid_pipelined_filter.type = ScriptFilter
-appender.json_rolling.avoid_pipelined_filter.script.type = Script
-appender.json_rolling.avoid_pipelined_filter.script.name = filter_no_pipelined
-appender.json_rolling.avoid_pipelined_filter.script.language = JavaScript
-appender.json_rolling.avoid_pipelined_filter.script.scriptText = ${sys:ls.pipeline.separate_logs} == false || !(logEvent.getContextData().containsKey("pipeline.id"))
+appender.json_rolling.avoid_pipelined_filter.type = PipelineRoutingFilter
 
-appender.routing.type = Routing
+appender.routing.type = PipelineRouting
 appender.routing.name = pipeline_routing_appender
-appender.routing.routes.type = Routes
-appender.routing.routes.script.type = Script
-appender.routing.routes.script.name = routing_script
-appender.routing.routes.script.language = JavaScript
-appender.routing.routes.script.scriptText = logEvent.getContextData().containsKey("pipeline.id") ? logEvent.getContextData().getValue("pipeline.id") : "sink";
-appender.routing.routes.route_pipelines.type = Route
-appender.routing.routes.route_pipelines.rolling.type = RollingFile
-appender.routing.routes.route_pipelines.rolling.name = appender-${ctx:pipeline.id}
-appender.routing.routes.route_pipelines.rolling.fileName = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.log
-appender.routing.routes.route_pipelines.rolling.filePattern = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.%i.log.gz
-appender.routing.routes.route_pipelines.rolling.layout.type = PatternLayout
-appender.routing.routes.route_pipelines.rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %m%n
-appender.routing.routes.route_pipelines.rolling.policy.type = SizeBasedTriggeringPolicy
-appender.routing.routes.route_pipelines.rolling.policy.size = 100MB
-appender.routing.routes.route_pipelines.strategy.type = DefaultRolloverStrategy
-appender.routing.routes.route_pipelines.strategy.max = 30
-appender.routing.routes.route_sink.type = Route
-appender.routing.routes.route_sink.key = sink
-appender.routing.routes.route_sink.null.type = Null
-appender.routing.routes.route_sink.null.name = drop-appender
+appender.routing.pipeline.type = RollingFile
+appender.routing.pipeline.name = appender-${ctx:pipeline.id}
+appender.routing.pipeline.fileName = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.log
+appender.routing.pipeline.filePattern = ${sys:ls.logs}/pipeline_${ctx:pipeline.id}.%i.log.gz
+appender.routing.pipeline.layout.type = PatternLayout
+appender.routing.pipeline.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %m%n
+appender.routing.pipeline.policy.type = SizeBasedTriggeringPolicy
+appender.routing.pipeline.policy.size = 100MB
+appender.routing.pipeline.strategy.type = DefaultRolloverStrategy
+appender.routing.pipeline.strategy.max = 30
 
 rootLogger.level = ${sys:ls.log.level}
 rootLogger.appenderRef.console.ref = ${sys:ls.log.format}_console
