diff --git a/logstash-core/lib/logstash/agent.rb b/logstash-core/lib/logstash/agent.rb
index 840aec14050..a12e3cf7f64 100644
--- a/logstash-core/lib/logstash/agent.rb
+++ b/logstash-core/lib/logstash/agent.rb
@@ -25,7 +25,7 @@ class LogStash::Agent
   include LogStash::Util::Loggable
   STARTED_AT = Time.now.freeze
 
-  attr_reader :metric, :name, :settings, :webserver, :dispatcher, :ephemeral_id
+  attr_reader :metric, :name, :settings, :webserver, :dispatcher, :ephemeral_id, :pipelines
   attr_accessor :logger
 
   # initialize method for LogStash::Agent
@@ -40,8 +40,7 @@ def initialize(settings = LogStash::SETTINGS, source_loader = nil)
     @ephemeral_id = SecureRandom.uuid
 
     # Do not use @pipelines directly. Use #with_pipelines which does locking
-    @pipelines = {}
-    @pipelines_lock = java.util.concurrent.locks.ReentrantLock.new
+    @pipelines = java.util.concurrent.ConcurrentHashMap.new();
 
     @name = setting("node.name")
     @http_host = setting("http.host")
@@ -133,17 +132,6 @@ def stopped?
     !@running.value
   end
 
-  # Safely perform an operation on the pipelines hash
-  # Using the correct synchronization
-  def with_pipelines
-    begin
-      @pipelines_lock.lock
-      yield @pipelines
-    ensure
-      @pipelines_lock.unlock
-    end
-  end
-
   def converge_state_and_update
     results = @source_loader.fetch
 
@@ -161,11 +149,9 @@ def converge_state_and_update
     converge_result = nil
 
     # we don't use the variable here, but we want the locking
-    with_pipelines do |pipelines|
-      pipeline_actions = resolve_actions(results.response)
-      converge_result = converge_state(pipeline_actions)
-      update_metrics(converge_result)
-    end
+    pipeline_actions = resolve_actions(results.response)
+    converge_result = converge_state(pipeline_actions)
+    update_metrics(converge_result)
 
     report_currently_running_pipelines(converge_result)
     dispatch_events(converge_result)
@@ -229,21 +215,19 @@ def id_path
   end
 
   def get_pipeline(pipeline_id)
-    with_pipelines do |pipelines|
-      pipelines[pipeline_id]
-    end
+    pipelines.get(pipeline_id)
   end
 
   def pipelines_count
-    with_pipelines do |pipelines|
-      pipelines.size
-    end
+    pipelines.size
+  end
+
+  def running_pipelines
+    pipelines.select {|id,pipeline| running_pipeline?(id) }
   end
 
   def with_running_pipelines
-    with_pipelines do |pipelines|
-      yield pipelines.select {|pipeline_id, _| running_pipeline?(pipeline_id) }
-    end
+    yield running_pipelines
   end
 
   def running_pipelines?
@@ -251,25 +235,19 @@ def running_pipelines?
   end
 
   def running_pipelines_count
-    with_running_pipelines do |pipelines|
-      pipelines.size
-    end
+    running_pipelines.size
   end
 
   def running_user_defined_pipelines?
-    with_running_user_defined_pipelines do |pipelines|
-      pipelines.size > 0
-    end
+    !running_user_defined_pipelines.empty?
   end
 
-  def with_running_user_defined_pipelines
-    with_pipelines do |pipelines|
-      found = pipelines.select do |_, pipeline|
-        pipeline.running? && !pipeline.system?
-      end
+  def running_user_defined_pipelines
+    pipelines.select {|id, pipeline| running_pipeline?(id) && !pipeline.system? }
+  end
 
-      yield found
-    end
+  def with_running_user_defined_pipelines
+    yield running_user_defined_pipelines
   end
 
   private
@@ -296,29 +274,31 @@ def converge_state(pipeline_actions)
 
     converge_result = LogStash::ConvergeResult.new(pipeline_actions.size)
 
+    threads = []
     pipeline_actions.each do |action|
-      # We execute every task we need to converge the current state of pipelines
-      # for every task we will record the action result, that will help us
-      # the results of all the task will determine if the converge was successful or not
-      #
-      # The ConvergeResult#add, will accept the following values
-      #  - boolean
-      #  - FailedAction
-      #  - SuccessfulAction
-      #  - Exception
-      #
-      # This give us a bit more extensibility with the current startup/validation model
-      # that we currently have.
-      with_pipelines do |pipelines|
-        begin
+      threads << Thread.new do
+        java.lang.Thread.currentThread().setName("Converge #{action}");
+        # We execute every task we need to converge the current state of pipelines
+        # for every task we will record the action result, that will help us
+        # the results of all the task will determine if the converge was successful or not
+        #
+        # The ConvergeResult#add, will accept the following values
+        #  - boolean
+        #  - FailedAction
+        #  - SuccessfulAction
+        #  - Exception
+        #
+        # This give us a bit more extensibility with the current startup/validation model
+        # that we currently have.
+        var = begin
           logger.debug("Executing action", :action => action)
-            action_result = action.execute(self, pipelines)
+          action_result = action.execute(self, pipelines)
           converge_result.add(action, action_result)
 
           unless action_result.successful?
             logger.error("Failed to execute action", :id => action.pipeline_id,
-                        :action_type => action_result.class, :message => action_result.message,
-                        :backtrace => action_result.backtrace)
+                         :action_type => action_result.class, :message => action_result.message,
+                         :backtrace => action_result.backtrace)
           end
         rescue SystemExit => e
           converge_result.add(action, e)
@@ -326,8 +306,10 @@ def converge_state(pipeline_actions)
           logger.error("Failed to execute action", :action => action, :exception => e.class.name, :message => e.message, :backtrace => e.backtrace)
           converge_result.add(action, e)
         end
+        var
       end
     end
+    threads.each(&:join)
 
     if logger.trace?
       logger.trace("Converge results", :success => converge_result.success?,
@@ -339,14 +321,12 @@ def converge_state(pipeline_actions)
   end
 
   def resolve_actions(pipeline_configs)
-    with_pipelines do |pipelines|
-      @state_resolver.resolve(pipelines, pipeline_configs)
-    end
+    @state_resolver.resolve(@pipelines, pipeline_configs)
   end
 
   def report_currently_running_pipelines(converge_result)
     if converge_result.success? && converge_result.total > 0
-      with_running_pipelines do |pipelines|
+      running_pipelines do |pipelines|
         number_of_running_pipeline = pipelines.size
         logger.info("Pipelines running", :count => number_of_running_pipeline, :pipelines => pipelines.values.collect(&:pipeline_id) )
       end
@@ -413,21 +393,19 @@ def shutdown_pipelines
     # In this context I could just call shutdown, but I've decided to
     # use the stop action implementation for that so we have the same code.
     # This also give us some context into why a shutdown is failing
-    with_pipelines do |pipelines|
-      pipeline_actions = resolve_actions([]) # We stop all the pipeline, so we converge to a empty state
-      converge_state(pipeline_actions)
-    end
+    pipeline_actions = resolve_actions([]) # We stop all the pipeline, so we converge to a empty state
+    converge_state(pipeline_actions)
   end
 
   def running_pipeline?(pipeline_id)
-    thread = get_pipeline(pipeline_id).thread
+    pipeline = get_pipeline(pipeline_id)
+    return false unless pipeline
+    thread = pipeline.thread
     thread.is_a?(Thread) && thread.alive?
   end
 
   def clean_state?
-    with_pipelines do |pipelines|
-      pipelines.empty?
-    end
+    pipelines.empty?
   end
 
   def setting(key)
diff --git a/logstash-core/lib/logstash/converge_result.rb b/logstash-core/lib/logstash/converge_result.rb
index 805339ef07e..d0dc0e1c4a4 100644
--- a/logstash-core/lib/logstash/converge_result.rb
+++ b/logstash-core/lib/logstash/converge_result.rb
@@ -60,7 +60,7 @@ def successful?
 
     def initialize(expected_actions_count)
       @expected_actions_count = expected_actions_count
-      @actions = {}
+      @actions = java.util.concurrent.ConcurrentHashMap.new
     end
 
     def add(action, action_result)
diff --git a/logstash-core/lib/logstash/pipeline_action/create.rb b/logstash-core/lib/logstash/pipeline_action/create.rb
index 1e932cd0a48..541f042b3b4 100644
--- a/logstash-core/lib/logstash/pipeline_action/create.rb
+++ b/logstash-core/lib/logstash/pipeline_action/create.rb
@@ -40,13 +40,19 @@ def execute(agent, pipelines)
           LogStash::Pipeline.new(@pipeline_config, @metric, agent)
         end
 
-      status = pipeline.start # block until the pipeline is correctly started or crashed
-
-      if status
-        pipelines[pipeline_id] = pipeline # The pipeline is successfully started we can add it to the hash
+      status = nil
+      pipelines.compute(pipeline_id) do |id,value|
+        status = pipeline.start # block until the pipeline is correctly started or crashed
+        pipeline # The pipeline is successfully started we can add it to the hash
       end
 
+
       LogStash::ConvergeResult::ActionResult.create(self, status)
     end
+
+
+    def to_s
+      "PipelineAction::Create<#{pipeline_id}>"
+    end
   end
 end end
diff --git a/logstash-core/lib/logstash/pipeline_action/reload.rb b/logstash-core/lib/logstash/pipeline_action/reload.rb
index 80eee756b45..bcdf216a629 100644
--- a/logstash-core/lib/logstash/pipeline_action/reload.rb
+++ b/logstash-core/lib/logstash/pipeline_action/reload.rb
@@ -19,6 +19,10 @@ def pipeline_id
       @pipeline_config.pipeline_id
     end
 
+    def to_s
+      "PipelineAction::Reload<#{pipeline_id}>"
+    end
+
     def execute(agent, pipelines)
       old_pipeline = pipelines[pipeline_id]
 
@@ -42,12 +46,16 @@ def execute(agent, pipelines)
       end
 
       logger.info("Reloading pipeline", "pipeline.id" => pipeline_id)
-      status = Stop.new(pipeline_id).execute(agent, pipelines)
 
-      if status
-        return Create.new(@pipeline_config, @metric).execute(agent, pipelines)
-      else
-        return status
+      pipelines.compute(pipeline_id) do |k,pipeline|
+        status = Stop.new(pipeline_id).execute(agent, pipelines)
+
+        if status
+          return Create.new(@pipeline_config, @metric).execute(agent, pipelines)
+        else
+          return status
+        end
+        pipeline
       end
     end
   end
diff --git a/logstash-core/lib/logstash/pipeline_action/stop.rb b/logstash-core/lib/logstash/pipeline_action/stop.rb
index 7ee45f76af1..b14d5c75b81 100644
--- a/logstash-core/lib/logstash/pipeline_action/stop.rb
+++ b/logstash-core/lib/logstash/pipeline_action/stop.rb
@@ -12,13 +12,19 @@ def initialize(pipeline_id)
     end
 
     def execute(agent, pipelines)
-      pipeline = pipelines[pipeline_id]
-      pipeline.shutdown { LogStash::ShutdownWatcher.start(pipeline) }
-      pipeline.thread.join
-      pipelines.delete(pipeline_id)
+      pipelines.compute(pipeline_id) do |k,pipeline|
+        pipeline.shutdown { LogStash::ShutdownWatcher.start(pipeline) }
+        pipeline.thread.join
+        pipelines.delete(pipeline_id)
+        pipeline
+      end
       # If we reach this part of the code we have succeeded because
       # the shutdown call will block.
       return LogStash::ConvergeResult::SuccessfulAction.new
     end
+
+    def to_s
+      "PipelineAction::Stop<#{pipeline_id}>"
+    end
   end
 end end
diff --git a/logstash-core/lib/logstash/plugins/registry.rb b/logstash-core/lib/logstash/plugins/registry.rb
index c784442594b..f9301b12e99 100644
--- a/logstash-core/lib/logstash/plugins/registry.rb
+++ b/logstash-core/lib/logstash/plugins/registry.rb
@@ -97,13 +97,16 @@ def register(hooks, settings)
     attr_reader :hooks
 
     def initialize
-      @registry = {}
+      @mutex = Mutex.new
+      @registry = java.util.concurrent.ConcurrentHashMap.new
       @hooks = HooksRegistry.new
     end
 
     def setup!
-      load_available_plugins
-      execute_universal_plugins
+      @mutex.synchronize do
+        load_available_plugins
+        execute_universal_plugins
+      end
     end
 
     def execute_universal_plugins
@@ -134,17 +137,21 @@ def load_available_plugins
     end
 
     def lookup(type, plugin_name, &block)
-      plugin = get(type, plugin_name)
-      # Assume that we have a legacy plugin
-      if plugin.nil?
-        plugin = legacy_lookup(type, plugin_name)
-      end
+      @mutex.synchronize do
+        plugin_spec = get(type, plugin_name)
+        # Assume that we have a legacy plugin
+        if plugin_spec.nil?
+          plugin_spec = legacy_lookup(type, plugin_name)
+        end
 
-      if block_given? # if provided pass a block to do validation
-        raise LoadError, "Block validation fails for plugin named #{plugin_name} of type #{type}," unless block.call(plugin.klass, plugin_name)
-      end
+        raise LoadError, "No plugin found with name '#{plugin_name}'" unless plugin_spec
 
-      return plugin.klass
+        if block_given? # if provided pass a block to do validation
+          raise LoadError, "Block validation fails for plugin named #{plugin_name} of type #{type}," unless block.call(plugin_spec.klass, plugin_name)
+        end
+
+        return plugin_spec.klass
+      end
     end
 
     # The legacy_lookup method uses the 1.5->5.0 file structure to find and match
diff --git a/logstash-core/spec/logstash/agent_spec.rb b/logstash-core/spec/logstash/agent_spec.rb
index e9fdf4e78cf..6588347ae7b 100644
--- a/logstash-core/spec/logstash/agent_spec.rb
+++ b/logstash-core/spec/logstash/agent_spec.rb
@@ -134,7 +134,7 @@
           it "does not upgrade the new config" do
             t = Thread.new { subject.execute }
             Timeout.timeout(timeout) do
-              sleep(0.01) until subject.with_pipelines {|pipelines| subject.running_pipelines? && pipelines.values.first.ready? }
+              sleep(0.01) until subject.running_pipelines? && subject.pipelines.values.first.ready?
             end
             expect(subject.converge_state_and_update).not_to be_a_successful_converge
             expect(subject).to have_running_pipeline?(mock_config_pipeline)
@@ -154,7 +154,7 @@
           it "does upgrade the new config" do
             t = Thread.new { subject.execute }
             Timeout.timeout(timeout) do
-              sleep(0.01) until subject.with_pipelines {|pipelines| subject.pipelines_count > 0 && pipelines.values.first.ready? }
+              sleep(0.01) until subject.pipelines_count > 0 && subject.pipelines.values.first.ready?
             end
 
             expect(subject.converge_state_and_update).to be_a_successful_converge
@@ -178,7 +178,7 @@
           it "does not try to reload the pipeline" do
             t = Thread.new { subject.execute }
             Timeout.timeout(timeout) do
-              sleep(0.01) until subject.with_pipelines {|pipelines| subject.running_pipelines? && pipelines.values.first.running? }
+              sleep(0.01) until subject.running_pipelines? && subject.pipelines.values.first.running?
             end
             expect(subject.converge_state_and_update).not_to be_a_successful_converge
             expect(subject).to have_running_pipeline?(mock_config_pipeline)
@@ -198,7 +198,7 @@
           it "tries to reload the pipeline" do
             t = Thread.new { subject.execute }
             Timeout.timeout(timeout) do
-              sleep(0.01) until subject.with_pipelines {|pipelines| subject.running_pipelines? && pipelines.values.first.running? }
+              sleep(0.01) until subject.running_pipelines? && subject.pipelines.values.first.running?
             end
 
             expect(subject.converge_state_and_update).to be_a_successful_converge
diff --git a/logstash-core/spec/logstash/pipeline_action/create_spec.rb b/logstash-core/spec/logstash/pipeline_action/create_spec.rb
index b5918813014..8e67b9cbdaa 100644
--- a/logstash-core/spec/logstash/pipeline_action/create_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_action/create_spec.rb
@@ -9,7 +9,7 @@
 describe LogStash::PipelineAction::Create do
   let(:metric) { LogStash::Instrument::NullMetric.new(LogStash::Instrument::Collector.new) }
   let(:pipeline_config) { mock_pipeline_config(:main, "input { generator { id => '123' } } output { null {} }") }
-  let(:pipelines) {  Hash.new }
+  let(:pipelines) { java.util.concurrent.ConcurrentHashMap.new }
   let(:agent) { double("agent") }
 
   before do
diff --git a/logstash-core/spec/logstash/pipeline_action/reload_spec.rb b/logstash-core/spec/logstash/pipeline_action/reload_spec.rb
index 60bb59686d8..98c71d92d9f 100644
--- a/logstash-core/spec/logstash/pipeline_action/reload_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_action/reload_spec.rb
@@ -11,7 +11,7 @@
   let(:new_pipeline_config) { mock_pipeline_config(pipeline_id, "input { generator { id => 'new' } } output { null {} }", { "pipeline.reloadable" => true}) }
   let(:pipeline_config) { "input { generator {} } output { null {} }" }
   let(:pipeline) { mock_pipeline_from_string(pipeline_config, mock_settings("pipeline.reloadable" => true)) }
-  let(:pipelines) { { pipeline_id => pipeline } }
+  let(:pipelines) { chm = java.util.concurrent.ConcurrentHashMap.new; chm[pipeline_id] = pipeline; chm }
   let(:agent) { double("agent") }
 
   subject { described_class.new(new_pipeline_config, metric) }
diff --git a/logstash-core/spec/logstash/pipeline_action/stop_spec.rb b/logstash-core/spec/logstash/pipeline_action/stop_spec.rb
index e4971ec3352..b8a6f06bd61 100644
--- a/logstash-core/spec/logstash/pipeline_action/stop_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_action/stop_spec.rb
@@ -9,7 +9,7 @@
   let(:pipeline_config) { "input { generator {} } output { null {} }" }
   let(:pipeline_id) { :main }
   let(:pipeline) { mock_pipeline_from_string(pipeline_config) }
-  let(:pipelines) { { :main => pipeline } }
+  let(:pipelines) { chm = java.util.concurrent.ConcurrentHashMap.new; chm[:main] = pipeline; chm }
   let(:agent) { double("agent") }
 
   subject { described_class.new(pipeline_id) }
diff --git a/logstash-core/spec/support/shared_contexts.rb b/logstash-core/spec/support/shared_contexts.rb
index 690821ba2dd..0dbc75ad218 100644
--- a/logstash-core/spec/support/shared_contexts.rb
+++ b/logstash-core/spec/support/shared_contexts.rb
@@ -26,7 +26,7 @@
     @agent.execute
     pipeline_config = mock_pipeline_config(:main, "input { generator { id => '123' } } output { null {} }")
     pipeline_creator =  LogStash::PipelineAction::Create.new(pipeline_config, @agent.metric)
-    @pipelines = Hash.new
+    @pipelines = java.util.concurrent.ConcurrentHashMap.new
     expect(pipeline_creator.execute(@agent, @pipelines)).to be_truthy
   end
 
diff --git a/logstash-core/src/main/java/org/logstash/Logstash.java b/logstash-core/src/main/java/org/logstash/Logstash.java
index 262abd90d50..a77af33c4b4 100644
--- a/logstash-core/src/main/java/org/logstash/Logstash.java
+++ b/logstash-core/src/main/java/org/logstash/Logstash.java
@@ -139,6 +139,6 @@ private static String safePath(final Path home, final String... subs) {
     }
 
     private static void uncleanShutdown(final Exception ex) {
-        throw new IllegalStateException("Logstash stopped processing because of an error:", ex);
+        throw new IllegalStateException("Logstash stopped processing because of an error: " + ex.getMessage(), ex);
     }
 }
