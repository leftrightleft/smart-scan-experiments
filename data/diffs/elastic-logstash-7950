diff --git a/logstash-core/lib/logstash/compiler/lscl.rb b/logstash-core/lib/logstash/compiler/lscl.rb
index 6bbba9c8ea1..d4ee27fcc90 100644
--- a/logstash-core/lib/logstash/compiler/lscl.rb
+++ b/logstash-core/lib/logstash/compiler/lscl.rb
@@ -101,12 +101,15 @@ def expr_attributes
         else
           [k,v]
         end
-      }.reduce({}) do |hash,kv|
-        k,v = kv
-        hash[k] = v
+      }.reduce({}) do |hash, kv|
+        k, v = kv
+        if hash[k].nil?
+          hash[k] = v
+        else
+          hash[k] += v
+        end
         hash
       end
-
     end
   end
 
@@ -327,8 +330,12 @@ def jconvert(sexpr)
       case op
       when :and
         return jdsl.eAnd(left, right);
+      when :nand
+        return jdsl.eNand(left, right);
       when :or
         return jdsl.eOr(left, right);
+      when :xor
+        return jdsl.eXor(left, right);
       else
         raise "Unknown op #{jop}"
       end
@@ -511,8 +518,12 @@ def expr
       case self.text_value
       when "and"
         AND_METHOD
+      when "nand"
+        NAND_METHOD
       when "or"
         OR_METHOD
+      when "xor"
+        XOR_METHOD
       else
         raise "Unknown operator #{self.text_value}"
       end
diff --git a/logstash-core/lib/logstash/compiler/lscl/helpers.rb b/logstash-core/lib/logstash/compiler/lscl/helpers.rb
index b9f2bf029f6..baac2afcbc1 100644
--- a/logstash-core/lib/logstash/compiler/lscl/helpers.rb
+++ b/logstash-core/lib/logstash/compiler/lscl/helpers.rb
@@ -50,6 +50,8 @@ def self.jdsl
     end
     
     AND_METHOD = jdsl.method(:eAnd)
+    NAND_METHOD = jdsl.method(:eNand)
     OR_METHOD = jdsl.method(:eOr)
+    XOR_METHOD = jdsl.method(:eXor)
   end
-end; end; end; end; end
\ No newline at end of file
+end; end; end; end; end
diff --git a/logstash-core/lib/logstash/config/file.rb b/logstash-core/lib/logstash/config/file.rb
deleted file mode 100644
index 6b5ae954675..00000000000
--- a/logstash-core/lib/logstash/config/file.rb
+++ /dev/null
@@ -1,37 +0,0 @@
-# encoding: utf-8
-require "logstash/namespace"
-require "logstash/config/grammar"
-require "logstash/config/config_ast"
-require "logstash/errors"
-require "logger"
-
-class LogStash::Config::File
-  include Enumerable
-  include LogStash::Util::Loggable
-
-  public
-  def initialize(text)
-    @text = text
-    @config = parse(text)
-  end # def initialize
-
-  def parse(text)
-    grammar = LogStashConfigParser.new
-    result = grammar.parse(text)
-    if result.nil?
-      raise LogStash::ConfigurationError, grammar.failure_reason
-    end
-    return result
-  end # def parse
-
-  def plugin(plugin_type, name, *args)
-    klass = LogStash::Plugin.lookup(plugin_type, name)
-    return klass.new(*args)
-  end
-
-  def each
-    @config.recursive_select(LogStash::Config::AST::Plugin)
-  end
-end #  class LogStash::Config::Parser
-
-#agent.config(cfg)
diff --git a/logstash-core/lib/logstash/config/grammar.rb b/logstash-core/lib/logstash/config/grammar.rb
deleted file mode 100644
index af56cf3a16a..00000000000
--- a/logstash-core/lib/logstash/config/grammar.rb
+++ /dev/null
@@ -1,3503 +0,0 @@
-# Autogenerated from a Treetop grammar. Edits may be lost.
-
-
-require "treetop"
-require "logstash/config/config_ast"
-
-module LogStashConfig
-  include Treetop::Runtime
-
-  def root
-    @root ||= :config
-  end
-
-  module Config0
-    def _
-      elements[0]
-    end
-
-    def plugin_section
-      elements[1]
-    end
-  end
-
-  module Config1
-    def _1
-      elements[0]
-    end
-
-    def plugin_section
-      elements[1]
-    end
-
-    def _2
-      elements[2]
-    end
-
-    def _3
-      elements[4]
-    end
-  end
-
-  def _nt_config
-    start_index = index
-    if node_cache[:config].has_key?(index)
-      cached = node_cache[:config][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt__
-    s0 << r1
-    if r1
-      r2 = _nt_plugin_section
-      s0 << r2
-      if r2
-        r3 = _nt__
-        s0 << r3
-        if r3
-          s4, i4 = [], index
-          loop do
-            i5, s5 = index, []
-            r6 = _nt__
-            s5 << r6
-            if r6
-              r7 = _nt_plugin_section
-              s5 << r7
-            end
-            if s5.last
-              r5 = instantiate_node(SyntaxNode,input, i5...index, s5)
-              r5.extend(Config0)
-            else
-              @index = i5
-              r5 = nil
-            end
-            if r5
-              s4 << r5
-            else
-              break
-            end
-          end
-          r4 = instantiate_node(SyntaxNode,input, i4...index, s4)
-          s0 << r4
-          if r4
-            r8 = _nt__
-            s0 << r8
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Config,input, i0...index, s0)
-      r0.extend(Config1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:config][start_index] = r0
-
-    r0
-  end
-
-  module Comment0
-  end
-
-  def _nt_comment
-    start_index = index
-    if node_cache[:comment].has_key?(index)
-      cached = node_cache[:comment][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    s0, i0 = [], index
-    loop do
-      i1, s1 = index, []
-      r3 = _nt_whitespace
-      if r3
-        r2 = r3
-      else
-        r2 = instantiate_node(SyntaxNode,input, index...index)
-      end
-      s1 << r2
-      if r2
-        if has_terminal?("#", false, index)
-          r4 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure("#")
-          r4 = nil
-        end
-        s1 << r4
-        if r4
-          s5, i5 = [], index
-          loop do
-            if has_terminal?('\G[^\\r\\n]', true, index)
-              r6 = true
-              @index += 1
-            else
-              r6 = nil
-            end
-            if r6
-              s5 << r6
-            else
-              break
-            end
-          end
-          r5 = instantiate_node(SyntaxNode,input, i5...index, s5)
-          s1 << r5
-          if r5
-            if has_terminal?("\r", false, index)
-              r8 = instantiate_node(SyntaxNode,input, index...(index + 1))
-              @index += 1
-            else
-              terminal_parse_failure("\r")
-              r8 = nil
-            end
-            if r8
-              r7 = r8
-            else
-              r7 = instantiate_node(SyntaxNode,input, index...index)
-            end
-            s1 << r7
-            if r7
-              if has_terminal?("\n", false, index)
-                r9 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                @index += 1
-              else
-                terminal_parse_failure("\n")
-                r9 = nil
-              end
-              s1 << r9
-            end
-          end
-        end
-      end
-      if s1.last
-        r1 = instantiate_node(SyntaxNode,input, i1...index, s1)
-        r1.extend(Comment0)
-      else
-        @index = i1
-        r1 = nil
-      end
-      if r1
-        s0 << r1
-      else
-        break
-      end
-    end
-    if s0.empty?
-      @index = i0
-      r0 = nil
-    else
-      r0 = instantiate_node(LogStash::Config::AST::Comment,input, i0...index, s0)
-    end
-
-    node_cache[:comment][start_index] = r0
-
-    r0
-  end
-
-  def _nt__
-    start_index = index
-    if node_cache[:_].has_key?(index)
-      cached = node_cache[:_][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    s0, i0 = [], index
-    loop do
-      i1 = index
-      r2 = _nt_comment
-      if r2
-        r1 = r2
-      else
-        r3 = _nt_whitespace
-        if r3
-          r1 = r3
-        else
-          @index = i1
-          r1 = nil
-        end
-      end
-      if r1
-        s0 << r1
-      else
-        break
-      end
-    end
-    r0 = instantiate_node(LogStash::Config::AST::Whitespace,input, i0...index, s0)
-
-    node_cache[:_][start_index] = r0
-
-    r0
-  end
-
-  def _nt_whitespace
-    start_index = index
-    if node_cache[:whitespace].has_key?(index)
-      cached = node_cache[:whitespace][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    s0, i0 = [], index
-    loop do
-      if has_terminal?('\G[ \\t\\r\\n]', true, index)
-        r1 = true
-        @index += 1
-      else
-        r1 = nil
-      end
-      if r1
-        s0 << r1
-      else
-        break
-      end
-    end
-    if s0.empty?
-      @index = i0
-      r0 = nil
-    else
-      r0 = instantiate_node(LogStash::Config::AST::Whitespace,input, i0...index, s0)
-    end
-
-    node_cache[:whitespace][start_index] = r0
-
-    r0
-  end
-
-  module PluginSection0
-    def branch_or_plugin
-      elements[0]
-    end
-
-    def _
-      elements[1]
-    end
-  end
-
-  module PluginSection1
-    def plugin_type
-      elements[0]
-    end
-
-    def _1
-      elements[1]
-    end
-
-    def _2
-      elements[3]
-    end
-
-  end
-
-  def _nt_plugin_section
-    start_index = index
-    if node_cache[:plugin_section].has_key?(index)
-      cached = node_cache[:plugin_section][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_plugin_type
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        if has_terminal?("{", false, index)
-          r3 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure("{")
-          r3 = nil
-        end
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            s5, i5 = [], index
-            loop do
-              i6, s6 = index, []
-              r7 = _nt_branch_or_plugin
-              s6 << r7
-              if r7
-                r8 = _nt__
-                s6 << r8
-              end
-              if s6.last
-                r6 = instantiate_node(SyntaxNode,input, i6...index, s6)
-                r6.extend(PluginSection0)
-              else
-                @index = i6
-                r6 = nil
-              end
-              if r6
-                s5 << r6
-              else
-                break
-              end
-            end
-            r5 = instantiate_node(SyntaxNode,input, i5...index, s5)
-            s0 << r5
-            if r5
-              if has_terminal?("}", false, index)
-                r9 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                @index += 1
-              else
-                terminal_parse_failure("}")
-                r9 = nil
-              end
-              s0 << r9
-            end
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::PluginSection,input, i0...index, s0)
-      r0.extend(PluginSection1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:plugin_section][start_index] = r0
-
-    r0
-  end
-
-  def _nt_branch_or_plugin
-    start_index = index
-    if node_cache[:branch_or_plugin].has_key?(index)
-      cached = node_cache[:branch_or_plugin][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    r1 = _nt_branch
-    if r1
-      r0 = r1
-    else
-      r2 = _nt_plugin
-      if r2
-        r0 = r2
-      else
-        @index = i0
-        r0 = nil
-      end
-    end
-
-    node_cache[:branch_or_plugin][start_index] = r0
-
-    r0
-  end
-
-  def _nt_plugin_type
-    start_index = index
-    if node_cache[:plugin_type].has_key?(index)
-      cached = node_cache[:plugin_type][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    if has_terminal?("input", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 5))
-      @index += 5
-    else
-      terminal_parse_failure("input")
-      r1 = nil
-    end
-    if r1
-      r0 = r1
-    else
-      if has_terminal?("filter", false, index)
-        r2 = instantiate_node(SyntaxNode,input, index...(index + 6))
-        @index += 6
-      else
-        terminal_parse_failure("filter")
-        r2 = nil
-      end
-      if r2
-        r0 = r2
-      else
-        if has_terminal?("output", false, index)
-          r3 = instantiate_node(SyntaxNode,input, index...(index + 6))
-          @index += 6
-        else
-          terminal_parse_failure("output")
-          r3 = nil
-        end
-        if r3
-          r0 = r3
-        else
-          @index = i0
-          r0 = nil
-        end
-      end
-    end
-
-    node_cache[:plugin_type][start_index] = r0
-
-    r0
-  end
-
-  module Plugins0
-    def _
-      elements[0]
-    end
-
-    def plugin
-      elements[1]
-    end
-  end
-
-  module Plugins1
-    def plugin
-      elements[0]
-    end
-
-  end
-
-  def _nt_plugins
-    start_index = index
-    if node_cache[:plugins].has_key?(index)
-      cached = node_cache[:plugins][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i1, s1 = index, []
-    r2 = _nt_plugin
-    s1 << r2
-    if r2
-      s3, i3 = [], index
-      loop do
-        i4, s4 = index, []
-        r5 = _nt__
-        s4 << r5
-        if r5
-          r6 = _nt_plugin
-          s4 << r6
-        end
-        if s4.last
-          r4 = instantiate_node(SyntaxNode,input, i4...index, s4)
-          r4.extend(Plugins0)
-        else
-          @index = i4
-          r4 = nil
-        end
-        if r4
-          s3 << r4
-        else
-          break
-        end
-      end
-      r3 = instantiate_node(SyntaxNode,input, i3...index, s3)
-      s1 << r3
-    end
-    if s1.last
-      r1 = instantiate_node(SyntaxNode,input, i1...index, s1)
-      r1.extend(Plugins1)
-    else
-      @index = i1
-      r1 = nil
-    end
-    if r1
-      r0 = r1
-    else
-      r0 = instantiate_node(SyntaxNode,input, index...index)
-    end
-
-    node_cache[:plugins][start_index] = r0
-
-    r0
-  end
-
-  module Plugin0
-    def whitespace
-      elements[0]
-    end
-
-    def _
-      elements[1]
-    end
-
-    def attribute
-      elements[2]
-    end
-  end
-
-  module Plugin1
-    def attribute
-      elements[0]
-    end
-
-  end
-
-  module Plugin2
-    def name
-      elements[0]
-    end
-
-    def _1
-      elements[1]
-    end
-
-    def _2
-      elements[3]
-    end
-
-    def attributes
-      elements[4]
-    end
-
-    def _3
-      elements[5]
-    end
-
-  end
-
-  def _nt_plugin
-    start_index = index
-    if node_cache[:plugin].has_key?(index)
-      cached = node_cache[:plugin][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_name
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        if has_terminal?("{", false, index)
-          r3 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure("{")
-          r3 = nil
-        end
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            i6, s6 = index, []
-            r7 = _nt_attribute
-            s6 << r7
-            if r7
-              s8, i8 = [], index
-              loop do
-                i9, s9 = index, []
-                r10 = _nt_whitespace
-                s9 << r10
-                if r10
-                  r11 = _nt__
-                  s9 << r11
-                  if r11
-                    r12 = _nt_attribute
-                    s9 << r12
-                  end
-                end
-                if s9.last
-                  r9 = instantiate_node(SyntaxNode,input, i9...index, s9)
-                  r9.extend(Plugin0)
-                else
-                  @index = i9
-                  r9 = nil
-                end
-                if r9
-                  s8 << r9
-                else
-                  break
-                end
-              end
-              r8 = instantiate_node(SyntaxNode,input, i8...index, s8)
-              s6 << r8
-            end
-            if s6.last
-              r6 = instantiate_node(SyntaxNode,input, i6...index, s6)
-              r6.extend(Plugin1)
-            else
-              @index = i6
-              r6 = nil
-            end
-            if r6
-              r5 = r6
-            else
-              r5 = instantiate_node(SyntaxNode,input, index...index)
-            end
-            s0 << r5
-            if r5
-              r13 = _nt__
-              s0 << r13
-              if r13
-                if has_terminal?("}", false, index)
-                  r14 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                  @index += 1
-                else
-                  terminal_parse_failure("}")
-                  r14 = nil
-                end
-                s0 << r14
-              end
-            end
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Plugin,input, i0...index, s0)
-      r0.extend(Plugin2)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:plugin][start_index] = r0
-
-    r0
-  end
-
-  def _nt_name
-    start_index = index
-    if node_cache[:name].has_key?(index)
-      cached = node_cache[:name][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    s1, i1 = [], index
-    loop do
-      if has_terminal?('\G[A-Za-z0-9_-]', true, index)
-        r2 = true
-        @index += 1
-      else
-        r2 = nil
-      end
-      if r2
-        s1 << r2
-      else
-        break
-      end
-    end
-    if s1.empty?
-      @index = i1
-      r1 = nil
-    else
-      r1 = instantiate_node(LogStash::Config::AST::Name,input, i1...index, s1)
-    end
-    if r1
-      r0 = r1
-    else
-      r3 = _nt_string
-      if r3
-        r0 = r3
-      else
-        @index = i0
-        r0 = nil
-      end
-    end
-
-    node_cache[:name][start_index] = r0
-
-    r0
-  end
-
-  module Attribute0
-    def name
-      elements[0]
-    end
-
-    def _1
-      elements[1]
-    end
-
-    def _2
-      elements[3]
-    end
-
-    def value
-      elements[4]
-    end
-  end
-
-  def _nt_attribute
-    start_index = index
-    if node_cache[:attribute].has_key?(index)
-      cached = node_cache[:attribute][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_name
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        if has_terminal?("=>", false, index)
-          r3 = instantiate_node(SyntaxNode,input, index...(index + 2))
-          @index += 2
-        else
-          terminal_parse_failure("=>")
-          r3 = nil
-        end
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            r5 = _nt_value
-            s0 << r5
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Attribute,input, i0...index, s0)
-      r0.extend(Attribute0)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:attribute][start_index] = r0
-
-    r0
-  end
-
-  def _nt_value
-    start_index = index
-    if node_cache[:value].has_key?(index)
-      cached = node_cache[:value][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    r1 = _nt_plugin
-    if r1
-      r0 = r1
-    else
-      r2 = _nt_bareword
-      if r2
-        r0 = r2
-      else
-        r3 = _nt_string
-        if r3
-          r0 = r3
-        else
-          r4 = _nt_number
-          if r4
-            r0 = r4
-          else
-            r5 = _nt_array
-            if r5
-              r0 = r5
-            else
-              r6 = _nt_hash
-              if r6
-                r0 = r6
-              else
-                @index = i0
-                r0 = nil
-              end
-            end
-          end
-        end
-      end
-    end
-
-    node_cache[:value][start_index] = r0
-
-    r0
-  end
-
-  def _nt_array_value
-    start_index = index
-    if node_cache[:array_value].has_key?(index)
-      cached = node_cache[:array_value][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    r1 = _nt_bareword
-    if r1
-      r0 = r1
-    else
-      r2 = _nt_string
-      if r2
-        r0 = r2
-      else
-        r3 = _nt_number
-        if r3
-          r0 = r3
-        else
-          r4 = _nt_array
-          if r4
-            r0 = r4
-          else
-            r5 = _nt_hash
-            if r5
-              r0 = r5
-            else
-              @index = i0
-              r0 = nil
-            end
-          end
-        end
-      end
-    end
-
-    node_cache[:array_value][start_index] = r0
-
-    r0
-  end
-
-  module Bareword0
-  end
-
-  def _nt_bareword
-    start_index = index
-    if node_cache[:bareword].has_key?(index)
-      cached = node_cache[:bareword][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?('\G[A-Za-z_]', true, index)
-      r1 = true
-      @index += 1
-    else
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      s2, i2 = [], index
-      loop do
-        if has_terminal?('\G[A-Za-z0-9_]', true, index)
-          r3 = true
-          @index += 1
-        else
-          r3 = nil
-        end
-        if r3
-          s2 << r3
-        else
-          break
-        end
-      end
-      if s2.empty?
-        @index = i2
-        r2 = nil
-      else
-        r2 = instantiate_node(SyntaxNode,input, i2...index, s2)
-      end
-      s0 << r2
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Bareword,input, i0...index, s0)
-      r0.extend(Bareword0)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:bareword][start_index] = r0
-
-    r0
-  end
-
-  module DoubleQuotedString0
-  end
-
-  module DoubleQuotedString1
-  end
-
-  def _nt_double_quoted_string
-    start_index = index
-    if node_cache[:double_quoted_string].has_key?(index)
-      cached = node_cache[:double_quoted_string][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?('"', false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 1))
-      @index += 1
-    else
-      terminal_parse_failure('"')
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      s2, i2 = [], index
-      loop do
-        i3 = index
-        if has_terminal?('\"', false, index)
-          r4 = instantiate_node(SyntaxNode,input, index...(index + 2))
-          @index += 2
-        else
-          terminal_parse_failure('\"')
-          r4 = nil
-        end
-        if r4
-          r3 = r4
-        else
-          i5, s5 = index, []
-          i6 = index
-          if has_terminal?('"', false, index)
-            r7 = instantiate_node(SyntaxNode,input, index...(index + 1))
-            @index += 1
-          else
-            terminal_parse_failure('"')
-            r7 = nil
-          end
-          if r7
-            r6 = nil
-          else
-            @index = i6
-            r6 = instantiate_node(SyntaxNode,input, index...index)
-          end
-          s5 << r6
-          if r6
-            if index < input_length
-              r8 = instantiate_node(SyntaxNode,input, index...(index + 1))
-              @index += 1
-            else
-              terminal_parse_failure("any character")
-              r8 = nil
-            end
-            s5 << r8
-          end
-          if s5.last
-            r5 = instantiate_node(SyntaxNode,input, i5...index, s5)
-            r5.extend(DoubleQuotedString0)
-          else
-            @index = i5
-            r5 = nil
-          end
-          if r5
-            r3 = r5
-          else
-            @index = i3
-            r3 = nil
-          end
-        end
-        if r3
-          s2 << r3
-        else
-          break
-        end
-      end
-      r2 = instantiate_node(SyntaxNode,input, i2...index, s2)
-      s0 << r2
-      if r2
-        if has_terminal?('"', false, index)
-          r9 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure('"')
-          r9 = nil
-        end
-        s0 << r9
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::String,input, i0...index, s0)
-      r0.extend(DoubleQuotedString1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:double_quoted_string][start_index] = r0
-
-    r0
-  end
-
-  module SingleQuotedString0
-  end
-
-  module SingleQuotedString1
-  end
-
-  def _nt_single_quoted_string
-    start_index = index
-    if node_cache[:single_quoted_string].has_key?(index)
-      cached = node_cache[:single_quoted_string][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?("'", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 1))
-      @index += 1
-    else
-      terminal_parse_failure("'")
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      s2, i2 = [], index
-      loop do
-        i3 = index
-        if has_terminal?("\\'", false, index)
-          r4 = instantiate_node(SyntaxNode,input, index...(index + 2))
-          @index += 2
-        else
-          terminal_parse_failure("\\'")
-          r4 = nil
-        end
-        if r4
-          r3 = r4
-        else
-          i5, s5 = index, []
-          i6 = index
-          if has_terminal?("'", false, index)
-            r7 = instantiate_node(SyntaxNode,input, index...(index + 1))
-            @index += 1
-          else
-            terminal_parse_failure("'")
-            r7 = nil
-          end
-          if r7
-            r6 = nil
-          else
-            @index = i6
-            r6 = instantiate_node(SyntaxNode,input, index...index)
-          end
-          s5 << r6
-          if r6
-            if index < input_length
-              r8 = instantiate_node(SyntaxNode,input, index...(index + 1))
-              @index += 1
-            else
-              terminal_parse_failure("any character")
-              r8 = nil
-            end
-            s5 << r8
-          end
-          if s5.last
-            r5 = instantiate_node(SyntaxNode,input, i5...index, s5)
-            r5.extend(SingleQuotedString0)
-          else
-            @index = i5
-            r5 = nil
-          end
-          if r5
-            r3 = r5
-          else
-            @index = i3
-            r3 = nil
-          end
-        end
-        if r3
-          s2 << r3
-        else
-          break
-        end
-      end
-      r2 = instantiate_node(SyntaxNode,input, i2...index, s2)
-      s0 << r2
-      if r2
-        if has_terminal?("'", false, index)
-          r9 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure("'")
-          r9 = nil
-        end
-        s0 << r9
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::String,input, i0...index, s0)
-      r0.extend(SingleQuotedString1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:single_quoted_string][start_index] = r0
-
-    r0
-  end
-
-  def _nt_string
-    start_index = index
-    if node_cache[:string].has_key?(index)
-      cached = node_cache[:string][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    r1 = _nt_double_quoted_string
-    if r1
-      r0 = r1
-    else
-      r2 = _nt_single_quoted_string
-      if r2
-        r0 = r2
-      else
-        @index = i0
-        r0 = nil
-      end
-    end
-
-    node_cache[:string][start_index] = r0
-
-    r0
-  end
-
-  module Regexp0
-  end
-
-  module Regexp1
-  end
-
-  def _nt_regexp
-    start_index = index
-    if node_cache[:regexp].has_key?(index)
-      cached = node_cache[:regexp][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?('/', false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 1))
-      @index += 1
-    else
-      terminal_parse_failure('/')
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      s2, i2 = [], index
-      loop do
-        i3 = index
-        if has_terminal?('\/', false, index)
-          r4 = instantiate_node(SyntaxNode,input, index...(index + 2))
-          @index += 2
-        else
-          terminal_parse_failure('\/')
-          r4 = nil
-        end
-        if r4
-          r3 = r4
-        else
-          i5, s5 = index, []
-          i6 = index
-          if has_terminal?('/', false, index)
-            r7 = instantiate_node(SyntaxNode,input, index...(index + 1))
-            @index += 1
-          else
-            terminal_parse_failure('/')
-            r7 = nil
-          end
-          if r7
-            r6 = nil
-          else
-            @index = i6
-            r6 = instantiate_node(SyntaxNode,input, index...index)
-          end
-          s5 << r6
-          if r6
-            if index < input_length
-              r8 = instantiate_node(SyntaxNode,input, index...(index + 1))
-              @index += 1
-            else
-              terminal_parse_failure("any character")
-              r8 = nil
-            end
-            s5 << r8
-          end
-          if s5.last
-            r5 = instantiate_node(SyntaxNode,input, i5...index, s5)
-            r5.extend(Regexp0)
-          else
-            @index = i5
-            r5 = nil
-          end
-          if r5
-            r3 = r5
-          else
-            @index = i3
-            r3 = nil
-          end
-        end
-        if r3
-          s2 << r3
-        else
-          break
-        end
-      end
-      r2 = instantiate_node(SyntaxNode,input, i2...index, s2)
-      s0 << r2
-      if r2
-        if has_terminal?('/', false, index)
-          r9 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure('/')
-          r9 = nil
-        end
-        s0 << r9
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::RegExp,input, i0...index, s0)
-      r0.extend(Regexp1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:regexp][start_index] = r0
-
-    r0
-  end
-
-  module Number0
-  end
-
-  module Number1
-  end
-
-  def _nt_number
-    start_index = index
-    if node_cache[:number].has_key?(index)
-      cached = node_cache[:number][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?("-", false, index)
-      r2 = instantiate_node(SyntaxNode,input, index...(index + 1))
-      @index += 1
-    else
-      terminal_parse_failure("-")
-      r2 = nil
-    end
-    if r2
-      r1 = r2
-    else
-      r1 = instantiate_node(SyntaxNode,input, index...index)
-    end
-    s0 << r1
-    if r1
-      s3, i3 = [], index
-      loop do
-        if has_terminal?('\G[0-9]', true, index)
-          r4 = true
-          @index += 1
-        else
-          r4 = nil
-        end
-        if r4
-          s3 << r4
-        else
-          break
-        end
-      end
-      if s3.empty?
-        @index = i3
-        r3 = nil
-      else
-        r3 = instantiate_node(SyntaxNode,input, i3...index, s3)
-      end
-      s0 << r3
-      if r3
-        i6, s6 = index, []
-        if has_terminal?(".", false, index)
-          r7 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure(".")
-          r7 = nil
-        end
-        s6 << r7
-        if r7
-          s8, i8 = [], index
-          loop do
-            if has_terminal?('\G[0-9]', true, index)
-              r9 = true
-              @index += 1
-            else
-              r9 = nil
-            end
-            if r9
-              s8 << r9
-            else
-              break
-            end
-          end
-          r8 = instantiate_node(SyntaxNode,input, i8...index, s8)
-          s6 << r8
-        end
-        if s6.last
-          r6 = instantiate_node(SyntaxNode,input, i6...index, s6)
-          r6.extend(Number0)
-        else
-          @index = i6
-          r6 = nil
-        end
-        if r6
-          r5 = r6
-        else
-          r5 = instantiate_node(SyntaxNode,input, index...index)
-        end
-        s0 << r5
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Number,input, i0...index, s0)
-      r0.extend(Number1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:number][start_index] = r0
-
-    r0
-  end
-
-  module Array0
-    def _1
-      elements[0]
-    end
-
-    def _2
-      elements[2]
-    end
-
-    def value
-      elements[3]
-    end
-  end
-
-  module Array1
-    def value
-      elements[0]
-    end
-
-  end
-
-  module Array2
-    def _1
-      elements[1]
-    end
-
-    def _2
-      elements[3]
-    end
-
-  end
-
-  def _nt_array
-    start_index = index
-    if node_cache[:array].has_key?(index)
-      cached = node_cache[:array][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?("[", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 1))
-      @index += 1
-    else
-      terminal_parse_failure("[")
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        i4, s4 = index, []
-        r5 = _nt_value
-        s4 << r5
-        if r5
-          s6, i6 = [], index
-          loop do
-            i7, s7 = index, []
-            r8 = _nt__
-            s7 << r8
-            if r8
-              if has_terminal?(",", false, index)
-                r9 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                @index += 1
-              else
-                terminal_parse_failure(",")
-                r9 = nil
-              end
-              s7 << r9
-              if r9
-                r10 = _nt__
-                s7 << r10
-                if r10
-                  r11 = _nt_value
-                  s7 << r11
-                end
-              end
-            end
-            if s7.last
-              r7 = instantiate_node(SyntaxNode,input, i7...index, s7)
-              r7.extend(Array0)
-            else
-              @index = i7
-              r7 = nil
-            end
-            if r7
-              s6 << r7
-            else
-              break
-            end
-          end
-          r6 = instantiate_node(SyntaxNode,input, i6...index, s6)
-          s4 << r6
-        end
-        if s4.last
-          r4 = instantiate_node(SyntaxNode,input, i4...index, s4)
-          r4.extend(Array1)
-        else
-          @index = i4
-          r4 = nil
-        end
-        if r4
-          r3 = r4
-        else
-          r3 = instantiate_node(SyntaxNode,input, index...index)
-        end
-        s0 << r3
-        if r3
-          r12 = _nt__
-          s0 << r12
-          if r12
-            if has_terminal?("]", false, index)
-              r13 = instantiate_node(SyntaxNode,input, index...(index + 1))
-              @index += 1
-            else
-              terminal_parse_failure("]")
-              r13 = nil
-            end
-            s0 << r13
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Array,input, i0...index, s0)
-      r0.extend(Array2)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:array][start_index] = r0
-
-    r0
-  end
-
-  module Hash0
-    def _1
-      elements[1]
-    end
-
-    def _2
-      elements[3]
-    end
-
-  end
-
-  def _nt_hash
-    start_index = index
-    if node_cache[:hash].has_key?(index)
-      cached = node_cache[:hash][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?("{", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 1))
-      @index += 1
-    else
-      terminal_parse_failure("{")
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        r4 = _nt_hashentries
-        if r4
-          r3 = r4
-        else
-          r3 = instantiate_node(SyntaxNode,input, index...index)
-        end
-        s0 << r3
-        if r3
-          r5 = _nt__
-          s0 << r5
-          if r5
-            if has_terminal?("}", false, index)
-              r6 = instantiate_node(SyntaxNode,input, index...(index + 1))
-              @index += 1
-            else
-              terminal_parse_failure("}")
-              r6 = nil
-            end
-            s0 << r6
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Hash,input, i0...index, s0)
-      r0.extend(Hash0)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:hash][start_index] = r0
-
-    r0
-  end
-
-  module Hashentries0
-    def whitespace
-      elements[0]
-    end
-
-    def hashentry
-      elements[1]
-    end
-  end
-
-  module Hashentries1
-    def hashentry
-      elements[0]
-    end
-
-  end
-
-  def _nt_hashentries
-    start_index = index
-    if node_cache[:hashentries].has_key?(index)
-      cached = node_cache[:hashentries][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_hashentry
-    s0 << r1
-    if r1
-      s2, i2 = [], index
-      loop do
-        i3, s3 = index, []
-        r4 = _nt_whitespace
-        s3 << r4
-        if r4
-          r5 = _nt_hashentry
-          s3 << r5
-        end
-        if s3.last
-          r3 = instantiate_node(SyntaxNode,input, i3...index, s3)
-          r3.extend(Hashentries0)
-        else
-          @index = i3
-          r3 = nil
-        end
-        if r3
-          s2 << r3
-        else
-          break
-        end
-      end
-      r2 = instantiate_node(SyntaxNode,input, i2...index, s2)
-      s0 << r2
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::HashEntries,input, i0...index, s0)
-      r0.extend(Hashentries1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:hashentries][start_index] = r0
-
-    r0
-  end
-
-  module Hashentry0
-    def name
-      elements[0]
-    end
-
-    def _1
-      elements[1]
-    end
-
-    def _2
-      elements[3]
-    end
-
-    def value
-      elements[4]
-    end
-  end
-
-  def _nt_hashentry
-    start_index = index
-    if node_cache[:hashentry].has_key?(index)
-      cached = node_cache[:hashentry][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    i1 = index
-    r2 = _nt_number
-    if r2
-      r1 = r2
-    else
-      r3 = _nt_bareword
-      if r3
-        r1 = r3
-      else
-        r4 = _nt_string
-        if r4
-          r1 = r4
-        else
-          @index = i1
-          r1 = nil
-        end
-      end
-    end
-    s0 << r1
-    if r1
-      r5 = _nt__
-      s0 << r5
-      if r5
-        if has_terminal?("=>", false, index)
-          r6 = instantiate_node(SyntaxNode,input, index...(index + 2))
-          @index += 2
-        else
-          terminal_parse_failure("=>")
-          r6 = nil
-        end
-        s0 << r6
-        if r6
-          r7 = _nt__
-          s0 << r7
-          if r7
-            r8 = _nt_value
-            s0 << r8
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::HashEntry,input, i0...index, s0)
-      r0.extend(Hashentry0)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:hashentry][start_index] = r0
-
-    r0
-  end
-
-  module Branch0
-    def _
-      elements[0]
-    end
-
-    def else_if
-      elements[1]
-    end
-  end
-
-  module Branch1
-    def _
-      elements[0]
-    end
-
-    def else
-      elements[1]
-    end
-  end
-
-  module Branch2
-    def if
-      elements[0]
-    end
-
-  end
-
-  def _nt_branch
-    start_index = index
-    if node_cache[:branch].has_key?(index)
-      cached = node_cache[:branch][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_if
-    s0 << r1
-    if r1
-      s2, i2 = [], index
-      loop do
-        i3, s3 = index, []
-        r4 = _nt__
-        s3 << r4
-        if r4
-          r5 = _nt_else_if
-          s3 << r5
-        end
-        if s3.last
-          r3 = instantiate_node(SyntaxNode,input, i3...index, s3)
-          r3.extend(Branch0)
-        else
-          @index = i3
-          r3 = nil
-        end
-        if r3
-          s2 << r3
-        else
-          break
-        end
-      end
-      r2 = instantiate_node(SyntaxNode,input, i2...index, s2)
-      s0 << r2
-      if r2
-        i7, s7 = index, []
-        r8 = _nt__
-        s7 << r8
-        if r8
-          r9 = _nt_else
-          s7 << r9
-        end
-        if s7.last
-          r7 = instantiate_node(SyntaxNode,input, i7...index, s7)
-          r7.extend(Branch1)
-        else
-          @index = i7
-          r7 = nil
-        end
-        if r7
-          r6 = r7
-        else
-          r6 = instantiate_node(SyntaxNode,input, index...index)
-        end
-        s0 << r6
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Branch,input, i0...index, s0)
-      r0.extend(Branch2)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:branch][start_index] = r0
-
-    r0
-  end
-
-  module If0
-    def branch_or_plugin
-      elements[0]
-    end
-
-    def _
-      elements[1]
-    end
-  end
-
-  module If1
-    def _1
-      elements[1]
-    end
-
-    def condition
-      elements[2]
-    end
-
-    def _2
-      elements[3]
-    end
-
-    def _3
-      elements[5]
-    end
-
-  end
-
-  def _nt_if
-    start_index = index
-    if node_cache[:if].has_key?(index)
-      cached = node_cache[:if][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?("if", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 2))
-      @index += 2
-    else
-      terminal_parse_failure("if")
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        r3 = _nt_condition
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            if has_terminal?("{", false, index)
-              r5 = instantiate_node(SyntaxNode,input, index...(index + 1))
-              @index += 1
-            else
-              terminal_parse_failure("{")
-              r5 = nil
-            end
-            s0 << r5
-            if r5
-              r6 = _nt__
-              s0 << r6
-              if r6
-                s7, i7 = [], index
-                loop do
-                  i8, s8 = index, []
-                  r9 = _nt_branch_or_plugin
-                  s8 << r9
-                  if r9
-                    r10 = _nt__
-                    s8 << r10
-                  end
-                  if s8.last
-                    r8 = instantiate_node(SyntaxNode,input, i8...index, s8)
-                    r8.extend(If0)
-                  else
-                    @index = i8
-                    r8 = nil
-                  end
-                  if r8
-                    s7 << r8
-                  else
-                    break
-                  end
-                end
-                r7 = instantiate_node(SyntaxNode,input, i7...index, s7)
-                s0 << r7
-                if r7
-                  if has_terminal?("}", false, index)
-                    r11 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                    @index += 1
-                  else
-                    terminal_parse_failure("}")
-                    r11 = nil
-                  end
-                  s0 << r11
-                end
-              end
-            end
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::If,input, i0...index, s0)
-      r0.extend(If1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:if][start_index] = r0
-
-    r0
-  end
-
-  module ElseIf0
-    def branch_or_plugin
-      elements[0]
-    end
-
-    def _
-      elements[1]
-    end
-  end
-
-  module ElseIf1
-    def _1
-      elements[1]
-    end
-
-    def _2
-      elements[3]
-    end
-
-    def condition
-      elements[4]
-    end
-
-    def _3
-      elements[5]
-    end
-
-    def _4
-      elements[7]
-    end
-
-  end
-
-  def _nt_else_if
-    start_index = index
-    if node_cache[:else_if].has_key?(index)
-      cached = node_cache[:else_if][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?("else", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 4))
-      @index += 4
-    else
-      terminal_parse_failure("else")
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        if has_terminal?("if", false, index)
-          r3 = instantiate_node(SyntaxNode,input, index...(index + 2))
-          @index += 2
-        else
-          terminal_parse_failure("if")
-          r3 = nil
-        end
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            r5 = _nt_condition
-            s0 << r5
-            if r5
-              r6 = _nt__
-              s0 << r6
-              if r6
-                if has_terminal?("{", false, index)
-                  r7 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                  @index += 1
-                else
-                  terminal_parse_failure("{")
-                  r7 = nil
-                end
-                s0 << r7
-                if r7
-                  r8 = _nt__
-                  s0 << r8
-                  if r8
-                    s9, i9 = [], index
-                    loop do
-                      i10, s10 = index, []
-                      r11 = _nt_branch_or_plugin
-                      s10 << r11
-                      if r11
-                        r12 = _nt__
-                        s10 << r12
-                      end
-                      if s10.last
-                        r10 = instantiate_node(SyntaxNode,input, i10...index, s10)
-                        r10.extend(ElseIf0)
-                      else
-                        @index = i10
-                        r10 = nil
-                      end
-                      if r10
-                        s9 << r10
-                      else
-                        break
-                      end
-                    end
-                    r9 = instantiate_node(SyntaxNode,input, i9...index, s9)
-                    s0 << r9
-                    if r9
-                      if has_terminal?("}", false, index)
-                        r13 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                        @index += 1
-                      else
-                        terminal_parse_failure("}")
-                        r13 = nil
-                      end
-                      s0 << r13
-                    end
-                  end
-                end
-              end
-            end
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Elsif,input, i0...index, s0)
-      r0.extend(ElseIf1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:else_if][start_index] = r0
-
-    r0
-  end
-
-  module Else0
-    def branch_or_plugin
-      elements[0]
-    end
-
-    def _
-      elements[1]
-    end
-  end
-
-  module Else1
-    def _1
-      elements[1]
-    end
-
-    def _2
-      elements[3]
-    end
-
-  end
-
-  def _nt_else
-    start_index = index
-    if node_cache[:else].has_key?(index)
-      cached = node_cache[:else][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?("else", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 4))
-      @index += 4
-    else
-      terminal_parse_failure("else")
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        if has_terminal?("{", false, index)
-          r3 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure("{")
-          r3 = nil
-        end
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            s5, i5 = [], index
-            loop do
-              i6, s6 = index, []
-              r7 = _nt_branch_or_plugin
-              s6 << r7
-              if r7
-                r8 = _nt__
-                s6 << r8
-              end
-              if s6.last
-                r6 = instantiate_node(SyntaxNode,input, i6...index, s6)
-                r6.extend(Else0)
-              else
-                @index = i6
-                r6 = nil
-              end
-              if r6
-                s5 << r6
-              else
-                break
-              end
-            end
-            r5 = instantiate_node(SyntaxNode,input, i5...index, s5)
-            s0 << r5
-            if r5
-              if has_terminal?("}", false, index)
-                r9 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                @index += 1
-              else
-                terminal_parse_failure("}")
-                r9 = nil
-              end
-              s0 << r9
-            end
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Else,input, i0...index, s0)
-      r0.extend(Else1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:else][start_index] = r0
-
-    r0
-  end
-
-  module Condition0
-    def _1
-      elements[0]
-    end
-
-    def boolean_operator
-      elements[1]
-    end
-
-    def _2
-      elements[2]
-    end
-
-    def expression
-      elements[3]
-    end
-  end
-
-  module Condition1
-    def expression
-      elements[0]
-    end
-
-  end
-
-  def _nt_condition
-    start_index = index
-    if node_cache[:condition].has_key?(index)
-      cached = node_cache[:condition][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_expression
-    s0 << r1
-    if r1
-      s2, i2 = [], index
-      loop do
-        i3, s3 = index, []
-        r4 = _nt__
-        s3 << r4
-        if r4
-          r5 = _nt_boolean_operator
-          s3 << r5
-          if r5
-            r6 = _nt__
-            s3 << r6
-            if r6
-              r7 = _nt_expression
-              s3 << r7
-            end
-          end
-        end
-        if s3.last
-          r3 = instantiate_node(SyntaxNode,input, i3...index, s3)
-          r3.extend(Condition0)
-        else
-          @index = i3
-          r3 = nil
-        end
-        if r3
-          s2 << r3
-        else
-          break
-        end
-      end
-      r2 = instantiate_node(SyntaxNode,input, i2...index, s2)
-      s0 << r2
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::Condition,input, i0...index, s0)
-      r0.extend(Condition1)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:condition][start_index] = r0
-
-    r0
-  end
-
-  module Expression0
-    def _1
-      elements[1]
-    end
-
-    def condition
-      elements[2]
-    end
-
-    def _2
-      elements[3]
-    end
-
-  end
-
-  def _nt_expression
-    start_index = index
-    if node_cache[:expression].has_key?(index)
-      cached = node_cache[:expression][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    i1, s1 = index, []
-    if has_terminal?("(", false, index)
-      r2 = instantiate_node(SyntaxNode,input, index...(index + 1))
-      @index += 1
-    else
-      terminal_parse_failure("(")
-      r2 = nil
-    end
-    s1 << r2
-    if r2
-      r3 = _nt__
-      s1 << r3
-      if r3
-        r4 = _nt_condition
-        s1 << r4
-        if r4
-          r5 = _nt__
-          s1 << r5
-          if r5
-            if has_terminal?(")", false, index)
-              r6 = instantiate_node(SyntaxNode,input, index...(index + 1))
-              @index += 1
-            else
-              terminal_parse_failure(")")
-              r6 = nil
-            end
-            s1 << r6
-          end
-        end
-      end
-    end
-    if s1.last
-      r1 = instantiate_node(SyntaxNode,input, i1...index, s1)
-      r1.extend(Expression0)
-    else
-      @index = i1
-      r1 = nil
-    end
-    if r1
-      r0 = r1
-      r0.extend(LogStash::Config::AST::Expression)
-    else
-      r7 = _nt_negative_expression
-      if r7
-        r0 = r7
-        r0.extend(LogStash::Config::AST::Expression)
-      else
-        r8 = _nt_in_expression
-        if r8
-          r0 = r8
-          r0.extend(LogStash::Config::AST::Expression)
-        else
-          r9 = _nt_not_in_expression
-          if r9
-            r0 = r9
-            r0.extend(LogStash::Config::AST::Expression)
-          else
-            r10 = _nt_compare_expression
-            if r10
-              r0 = r10
-              r0.extend(LogStash::Config::AST::Expression)
-            else
-              r11 = _nt_regexp_expression
-              if r11
-                r0 = r11
-                r0.extend(LogStash::Config::AST::Expression)
-              else
-                r12 = _nt_rvalue
-                if r12
-                  r0 = r12
-                  r0.extend(LogStash::Config::AST::Expression)
-                else
-                  @index = i0
-                  r0 = nil
-                end
-              end
-            end
-          end
-        end
-      end
-    end
-
-    node_cache[:expression][start_index] = r0
-
-    r0
-  end
-
-  module NegativeExpression0
-    def _1
-      elements[1]
-    end
-
-    def _2
-      elements[3]
-    end
-
-    def condition
-      elements[4]
-    end
-
-    def _3
-      elements[5]
-    end
-
-  end
-
-  module NegativeExpression1
-    def _
-      elements[1]
-    end
-
-    def selector
-      elements[2]
-    end
-  end
-
-  def _nt_negative_expression
-    start_index = index
-    if node_cache[:negative_expression].has_key?(index)
-      cached = node_cache[:negative_expression][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    i1, s1 = index, []
-    if has_terminal?("!", false, index)
-      r2 = instantiate_node(SyntaxNode,input, index...(index + 1))
-      @index += 1
-    else
-      terminal_parse_failure("!")
-      r2 = nil
-    end
-    s1 << r2
-    if r2
-      r3 = _nt__
-      s1 << r3
-      if r3
-        if has_terminal?("(", false, index)
-          r4 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure("(")
-          r4 = nil
-        end
-        s1 << r4
-        if r4
-          r5 = _nt__
-          s1 << r5
-          if r5
-            r6 = _nt_condition
-            s1 << r6
-            if r6
-              r7 = _nt__
-              s1 << r7
-              if r7
-                if has_terminal?(")", false, index)
-                  r8 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                  @index += 1
-                else
-                  terminal_parse_failure(")")
-                  r8 = nil
-                end
-                s1 << r8
-              end
-            end
-          end
-        end
-      end
-    end
-    if s1.last
-      r1 = instantiate_node(SyntaxNode,input, i1...index, s1)
-      r1.extend(NegativeExpression0)
-    else
-      @index = i1
-      r1 = nil
-    end
-    if r1
-      r0 = r1
-      r0.extend(LogStash::Config::AST::NegativeExpression)
-    else
-      i9, s9 = index, []
-      if has_terminal?("!", false, index)
-        r10 = instantiate_node(SyntaxNode,input, index...(index + 1))
-        @index += 1
-      else
-        terminal_parse_failure("!")
-        r10 = nil
-      end
-      s9 << r10
-      if r10
-        r11 = _nt__
-        s9 << r11
-        if r11
-          r12 = _nt_selector
-          s9 << r12
-        end
-      end
-      if s9.last
-        r9 = instantiate_node(SyntaxNode,input, i9...index, s9)
-        r9.extend(NegativeExpression1)
-      else
-        @index = i9
-        r9 = nil
-      end
-      if r9
-        r0 = r9
-        r0.extend(LogStash::Config::AST::NegativeExpression)
-      else
-        @index = i0
-        r0 = nil
-      end
-    end
-
-    node_cache[:negative_expression][start_index] = r0
-
-    r0
-  end
-
-  module InExpression0
-    def rvalue1
-      elements[0]
-    end
-
-    def _1
-      elements[1]
-    end
-
-    def in_operator
-      elements[2]
-    end
-
-    def _2
-      elements[3]
-    end
-
-    def rvalue2
-      elements[4]
-    end
-  end
-
-  def _nt_in_expression
-    start_index = index
-    if node_cache[:in_expression].has_key?(index)
-      cached = node_cache[:in_expression][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_rvalue
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        r3 = _nt_in_operator
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            r5 = _nt_rvalue
-            s0 << r5
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::InExpression,input, i0...index, s0)
-      r0.extend(InExpression0)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:in_expression][start_index] = r0
-
-    r0
-  end
-
-  module NotInExpression0
-    def rvalue1
-      elements[0]
-    end
-
-    def _1
-      elements[1]
-    end
-
-    def not_in_operator
-      elements[2]
-    end
-
-    def _2
-      elements[3]
-    end
-
-    def rvalue2
-      elements[4]
-    end
-  end
-
-  def _nt_not_in_expression
-    start_index = index
-    if node_cache[:not_in_expression].has_key?(index)
-      cached = node_cache[:not_in_expression][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_rvalue
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        r3 = _nt_not_in_operator
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            r5 = _nt_rvalue
-            s0 << r5
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::NotInExpression,input, i0...index, s0)
-      r0.extend(NotInExpression0)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:not_in_expression][start_index] = r0
-
-    r0
-  end
-
-  def _nt_in_operator
-    start_index = index
-    if node_cache[:in_operator].has_key?(index)
-      cached = node_cache[:in_operator][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    if has_terminal?("in", false, index)
-      r0 = instantiate_node(SyntaxNode,input, index...(index + 2))
-      @index += 2
-    else
-      terminal_parse_failure("in")
-      r0 = nil
-    end
-
-    node_cache[:in_operator][start_index] = r0
-
-    r0
-  end
-
-  module NotInOperator0
-    def _
-      elements[1]
-    end
-
-  end
-
-  def _nt_not_in_operator
-    start_index = index
-    if node_cache[:not_in_operator].has_key?(index)
-      cached = node_cache[:not_in_operator][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?("not ", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 4))
-      @index += 4
-    else
-      terminal_parse_failure("not ")
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        if has_terminal?("in", false, index)
-          r3 = instantiate_node(SyntaxNode,input, index...(index + 2))
-          @index += 2
-        else
-          terminal_parse_failure("in")
-          r3 = nil
-        end
-        s0 << r3
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(SyntaxNode,input, i0...index, s0)
-      r0.extend(NotInOperator0)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:not_in_operator][start_index] = r0
-
-    r0
-  end
-
-  def _nt_rvalue
-    start_index = index
-    if node_cache[:rvalue].has_key?(index)
-      cached = node_cache[:rvalue][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    r1 = _nt_string
-    if r1
-      r0 = r1
-    else
-      r2 = _nt_number
-      if r2
-        r0 = r2
-      else
-        r3 = _nt_selector
-        if r3
-          r0 = r3
-        else
-          r4 = _nt_array
-          if r4
-            r0 = r4
-          else
-            r5 = _nt_method_call
-            if r5
-              r0 = r5
-            else
-              r6 = _nt_regexp
-              if r6
-                r0 = r6
-              else
-                @index = i0
-                r0 = nil
-              end
-            end
-          end
-        end
-      end
-    end
-
-    node_cache[:rvalue][start_index] = r0
-
-    r0
-  end
-
-  module MethodCall0
-    def _1
-      elements[0]
-    end
-
-    def _2
-      elements[2]
-    end
-
-    def rvalue
-      elements[3]
-    end
-  end
-
-  module MethodCall1
-    def rvalue
-      elements[0]
-    end
-
-  end
-
-  module MethodCall2
-    def method
-      elements[0]
-    end
-
-    def _1
-      elements[1]
-    end
-
-    def _2
-      elements[3]
-    end
-
-    def _3
-      elements[5]
-    end
-
-  end
-
-  def _nt_method_call
-    start_index = index
-    if node_cache[:method_call].has_key?(index)
-      cached = node_cache[:method_call][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_method
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        if has_terminal?("(", false, index)
-          r3 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure("(")
-          r3 = nil
-        end
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            i6, s6 = index, []
-            r7 = _nt_rvalue
-            s6 << r7
-            if r7
-              s8, i8 = [], index
-              loop do
-                i9, s9 = index, []
-                r10 = _nt__
-                s9 << r10
-                if r10
-                  if has_terminal?(",", false, index)
-                    r11 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                    @index += 1
-                  else
-                    terminal_parse_failure(",")
-                    r11 = nil
-                  end
-                  s9 << r11
-                  if r11
-                    r12 = _nt__
-                    s9 << r12
-                    if r12
-                      r13 = _nt_rvalue
-                      s9 << r13
-                    end
-                  end
-                end
-                if s9.last
-                  r9 = instantiate_node(SyntaxNode,input, i9...index, s9)
-                  r9.extend(MethodCall0)
-                else
-                  @index = i9
-                  r9 = nil
-                end
-                if r9
-                  s8 << r9
-                else
-                  break
-                end
-              end
-              r8 = instantiate_node(SyntaxNode,input, i8...index, s8)
-              s6 << r8
-            end
-            if s6.last
-              r6 = instantiate_node(SyntaxNode,input, i6...index, s6)
-              r6.extend(MethodCall1)
-            else
-              @index = i6
-              r6 = nil
-            end
-            if r6
-              r5 = r6
-            else
-              r5 = instantiate_node(SyntaxNode,input, index...index)
-            end
-            s0 << r5
-            if r5
-              r14 = _nt__
-              s0 << r14
-              if r14
-                if has_terminal?(")", false, index)
-                  r15 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                  @index += 1
-                else
-                  terminal_parse_failure(")")
-                  r15 = nil
-                end
-                s0 << r15
-              end
-            end
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::MethodCall,input, i0...index, s0)
-      r0.extend(MethodCall2)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:method_call][start_index] = r0
-
-    r0
-  end
-
-  def _nt_method
-    start_index = index
-    if node_cache[:method].has_key?(index)
-      cached = node_cache[:method][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    r0 = _nt_bareword
-
-    node_cache[:method][start_index] = r0
-
-    r0
-  end
-
-  module CompareExpression0
-    def rvalue1
-      elements[0]
-    end
-
-    def _1
-      elements[1]
-    end
-
-    def compare_operator
-      elements[2]
-    end
-
-    def _2
-      elements[3]
-    end
-
-    def rvalue2
-      elements[4]
-    end
-  end
-
-  def _nt_compare_expression
-    start_index = index
-    if node_cache[:compare_expression].has_key?(index)
-      cached = node_cache[:compare_expression][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_rvalue
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        r3 = _nt_compare_operator
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            r5 = _nt_rvalue
-            s0 << r5
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::ComparisonExpression,input, i0...index, s0)
-      r0.extend(CompareExpression0)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:compare_expression][start_index] = r0
-
-    r0
-  end
-
-  def _nt_compare_operator
-    start_index = index
-    if node_cache[:compare_operator].has_key?(index)
-      cached = node_cache[:compare_operator][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    if has_terminal?("==", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 2))
-      @index += 2
-    else
-      terminal_parse_failure("==")
-      r1 = nil
-    end
-    if r1
-      r0 = r1
-      r0.extend(LogStash::Config::AST::ComparisonOperator)
-    else
-      if has_terminal?("!=", false, index)
-        r2 = instantiate_node(SyntaxNode,input, index...(index + 2))
-        @index += 2
-      else
-        terminal_parse_failure("!=")
-        r2 = nil
-      end
-      if r2
-        r0 = r2
-        r0.extend(LogStash::Config::AST::ComparisonOperator)
-      else
-        if has_terminal?("<=", false, index)
-          r3 = instantiate_node(SyntaxNode,input, index...(index + 2))
-          @index += 2
-        else
-          terminal_parse_failure("<=")
-          r3 = nil
-        end
-        if r3
-          r0 = r3
-          r0.extend(LogStash::Config::AST::ComparisonOperator)
-        else
-          if has_terminal?(">=", false, index)
-            r4 = instantiate_node(SyntaxNode,input, index...(index + 2))
-            @index += 2
-          else
-            terminal_parse_failure(">=")
-            r4 = nil
-          end
-          if r4
-            r0 = r4
-            r0.extend(LogStash::Config::AST::ComparisonOperator)
-          else
-            if has_terminal?("<", false, index)
-              r5 = instantiate_node(SyntaxNode,input, index...(index + 1))
-              @index += 1
-            else
-              terminal_parse_failure("<")
-              r5 = nil
-            end
-            if r5
-              r0 = r5
-              r0.extend(LogStash::Config::AST::ComparisonOperator)
-            else
-              if has_terminal?(">", false, index)
-                r6 = instantiate_node(SyntaxNode,input, index...(index + 1))
-                @index += 1
-              else
-                terminal_parse_failure(">")
-                r6 = nil
-              end
-              if r6
-                r0 = r6
-                r0.extend(LogStash::Config::AST::ComparisonOperator)
-              else
-                @index = i0
-                r0 = nil
-              end
-            end
-          end
-        end
-      end
-    end
-
-    node_cache[:compare_operator][start_index] = r0
-
-    r0
-  end
-
-  module RegexpExpression0
-    def rvalue
-      elements[0]
-    end
-
-    def _1
-      elements[1]
-    end
-
-    def regexp_operator
-      elements[2]
-    end
-
-    def _2
-      elements[3]
-    end
-
-  end
-
-  def _nt_regexp_expression
-    start_index = index
-    if node_cache[:regexp_expression].has_key?(index)
-      cached = node_cache[:regexp_expression][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    r1 = _nt_rvalue
-    s0 << r1
-    if r1
-      r2 = _nt__
-      s0 << r2
-      if r2
-        r3 = _nt_regexp_operator
-        s0 << r3
-        if r3
-          r4 = _nt__
-          s0 << r4
-          if r4
-            i5 = index
-            r6 = _nt_string
-            if r6
-              r5 = r6
-            else
-              r7 = _nt_regexp
-              if r7
-                r5 = r7
-              else
-                @index = i5
-                r5 = nil
-              end
-            end
-            s0 << r5
-          end
-        end
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::RegexpExpression,input, i0...index, s0)
-      r0.extend(RegexpExpression0)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:regexp_expression][start_index] = r0
-
-    r0
-  end
-
-  def _nt_regexp_operator
-    start_index = index
-    if node_cache[:regexp_operator].has_key?(index)
-      cached = node_cache[:regexp_operator][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    if has_terminal?("=~", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 2))
-      @index += 2
-    else
-      terminal_parse_failure("=~")
-      r1 = nil
-    end
-    if r1
-      r0 = r1
-      r0.extend(LogStash::Config::AST::RegExpOperator)
-    else
-      if has_terminal?("!~", false, index)
-        r2 = instantiate_node(SyntaxNode,input, index...(index + 2))
-        @index += 2
-      else
-        terminal_parse_failure("!~")
-        r2 = nil
-      end
-      if r2
-        r0 = r2
-        r0.extend(LogStash::Config::AST::RegExpOperator)
-      else
-        @index = i0
-        r0 = nil
-      end
-    end
-
-    node_cache[:regexp_operator][start_index] = r0
-
-    r0
-  end
-
-  def _nt_boolean_operator
-    start_index = index
-    if node_cache[:boolean_operator].has_key?(index)
-      cached = node_cache[:boolean_operator][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0 = index
-    if has_terminal?("and", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 3))
-      @index += 3
-    else
-      terminal_parse_failure("and")
-      r1 = nil
-    end
-    if r1
-      r0 = r1
-      r0.extend(LogStash::Config::AST::BooleanOperator)
-    else
-      if has_terminal?("or", false, index)
-        r2 = instantiate_node(SyntaxNode,input, index...(index + 2))
-        @index += 2
-      else
-        terminal_parse_failure("or")
-        r2 = nil
-      end
-      if r2
-        r0 = r2
-        r0.extend(LogStash::Config::AST::BooleanOperator)
-      else
-        if has_terminal?("xor", false, index)
-          r3 = instantiate_node(SyntaxNode,input, index...(index + 3))
-          @index += 3
-        else
-          terminal_parse_failure("xor")
-          r3 = nil
-        end
-        if r3
-          r0 = r3
-          r0.extend(LogStash::Config::AST::BooleanOperator)
-        else
-          if has_terminal?("nand", false, index)
-            r4 = instantiate_node(SyntaxNode,input, index...(index + 4))
-            @index += 4
-          else
-            terminal_parse_failure("nand")
-            r4 = nil
-          end
-          if r4
-            r0 = r4
-            r0.extend(LogStash::Config::AST::BooleanOperator)
-          else
-            @index = i0
-            r0 = nil
-          end
-        end
-      end
-    end
-
-    node_cache[:boolean_operator][start_index] = r0
-
-    r0
-  end
-
-  def _nt_selector
-    start_index = index
-    if node_cache[:selector].has_key?(index)
-      cached = node_cache[:selector][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    s0, i0 = [], index
-    loop do
-      r1 = _nt_selector_element
-      if r1
-        s0 << r1
-      else
-        break
-      end
-    end
-    if s0.empty?
-      @index = i0
-      r0 = nil
-    else
-      r0 = instantiate_node(LogStash::Config::AST::Selector,input, i0...index, s0)
-    end
-
-    node_cache[:selector][start_index] = r0
-
-    r0
-  end
-
-  module SelectorElement0
-  end
-
-  def _nt_selector_element
-    start_index = index
-    if node_cache[:selector_element].has_key?(index)
-      cached = node_cache[:selector_element][index]
-      if cached
-        cached = SyntaxNode.new(input, index...(index + 1)) if cached == true
-        @index = cached.interval.end
-      end
-      return cached
-    end
-
-    i0, s0 = index, []
-    if has_terminal?("[", false, index)
-      r1 = instantiate_node(SyntaxNode,input, index...(index + 1))
-      @index += 1
-    else
-      terminal_parse_failure("[")
-      r1 = nil
-    end
-    s0 << r1
-    if r1
-      s2, i2 = [], index
-      loop do
-        if has_terminal?('\G[^\\],]', true, index)
-          r3 = true
-          @index += 1
-        else
-          r3 = nil
-        end
-        if r3
-          s2 << r3
-        else
-          break
-        end
-      end
-      if s2.empty?
-        @index = i2
-        r2 = nil
-      else
-        r2 = instantiate_node(SyntaxNode,input, i2...index, s2)
-      end
-      s0 << r2
-      if r2
-        if has_terminal?("]", false, index)
-          r4 = instantiate_node(SyntaxNode,input, index...(index + 1))
-          @index += 1
-        else
-          terminal_parse_failure("]")
-          r4 = nil
-        end
-        s0 << r4
-      end
-    end
-    if s0.last
-      r0 = instantiate_node(LogStash::Config::AST::SelectorElement,input, i0...index, s0)
-      r0.extend(SelectorElement0)
-    else
-      @index = i0
-      r0 = nil
-    end
-
-    node_cache[:selector_element][start_index] = r0
-
-    r0
-  end
-
-end
-
-class LogStashConfigParser < Treetop::Runtime::CompiledParser
-  include LogStashConfig
-end
-
diff --git a/logstash-core/lib/logstash/config/grammar.treetop b/logstash-core/lib/logstash/config/grammar.treetop
deleted file mode 100644
index e46fc55307a..00000000000
--- a/logstash-core/lib/logstash/config/grammar.treetop
+++ /dev/null
@@ -1,241 +0,0 @@
-require "treetop"
-require "logstash/config/config_ast"
-
-grammar LogStashConfig
-  rule config
-    _ plugin_section _ (_ plugin_section)* _ <LogStash::Config::AST::Config>
-  end
-
-  rule comment
-    (whitespace? "#" [^\r\n]* "\r"? "\n")+ <LogStash::Config::AST::Comment>
-  end
-
-  rule _
-    (comment / whitespace)* <LogStash::Config::AST::Whitespace>
-  end
-
-  rule whitespace
-    [ \t\r\n]+ <LogStash::Config::AST::Whitespace>
-  end
-
-  rule plugin_section
-    plugin_type _ "{"
-      _ (branch_or_plugin _)*
-    "}"
-    <LogStash::Config::AST::PluginSection>
-  end
-
-  rule branch_or_plugin
-    branch / plugin
-  end
-
-  rule plugin_type
-    ("input" / "filter" / "output")
-  end
-
-  rule plugins
-    (plugin (_ plugin)*)?
-    <LogStash::Config::AST::Plugins>
-  end
-
-  rule plugin
-    name _ "{"
-      _
-      attributes:( attribute (whitespace _ attribute)*)?
-      _
-    "}"
-    <LogStash::Config::AST::Plugin>
-  end
-
-  rule name
-    (
-      ([A-Za-z0-9_-]+ <LogStash::Config::AST::Name>)
-      / string
-    )
-  end
-
-  rule attribute
-    name _ "=>" _ value
-    <LogStash::Config::AST::Attribute>
-  end
-
-  rule value
-    plugin / bareword / string / number / array / hash
-  end
-
-  rule array_value
-    bareword / string / number / array / hash
-  end
-
-  rule bareword
-    [A-Za-z_] [A-Za-z0-9_]+
-    <LogStash::Config::AST::Bareword>
-  end
-
-  rule double_quoted_string
-    ( '"' ( '\"' / !'"' . )* '"' <LogStash::Config::AST::String>)
-  end
-
-  rule single_quoted_string
-    ( "'" ( "\\'" / !"'" . )* "'" <LogStash::Config::AST::String>)
-  end
-
-  rule string
-    double_quoted_string / single_quoted_string
-  end
-
-  rule regexp
-    ( '/' ( '\/' / !'/' . )* '/'  <LogStash::Config::AST::RegExp>)
-  end
-
-  rule number
-    "-"? [0-9]+ ("." [0-9]*)?
-    <LogStash::Config::AST::Number>
-  end
-
-  rule array
-    "["
-    _
-    (
-      value (_ "," _ value)*
-    )?
-    _
-    "]"
-    <LogStash::Config::AST::Array>
-  end
-
-  rule hash
-    "{"
-      _
-      hashentries?
-      _
-    "}"
-    <LogStash::Config::AST::Hash>
-  end
-
-  rule hashentries
-    hashentry (whitespace hashentry)*
-    <LogStash::Config::AST::HashEntries>
-  end
-
-  rule hashentry
-    name:(number / bareword / string) _ "=>" _ value
-    <LogStash::Config::AST::HashEntry>
-  end
-
-  # Conditions
-  rule branch
-    if (_ else_if)* (_ else)?
-    <LogStash::Config::AST::Branch>
-  end
-
-  rule if
-    "if" _ condition _ "{" _ (branch_or_plugin _)* "}"
-    <LogStash::Config::AST::If>
-  end
-
-  rule else_if
-    "else" _ "if" _ condition _ "{" _ ( branch_or_plugin _)* "}"
-    <LogStash::Config::AST::Elsif>
-  end
-
-  rule else
-    "else" _ "{" _ (branch_or_plugin _)* "}"
-    <LogStash::Config::AST::Else>
-  end
-
-  rule condition
-    expression (_ boolean_operator _ expression)*
-    <LogStash::Config::AST::Condition>
-  end
-
-  rule expression
-    (
-        ("(" _ condition _ ")")
-      / negative_expression
-      / in_expression
-      / not_in_expression
-      / compare_expression
-      / regexp_expression
-      / rvalue
-    ) <LogStash::Config::AST::Expression>
-  end
-
-  rule negative_expression
-    (
-        ("!" _ "(" _ condition _ ")")
-      / ("!" _ selector)
-    ) <LogStash::Config::AST::NegativeExpression>
-  end
-
-  rule in_expression
-    rvalue _ in_operator _ rvalue
-    <LogStash::Config::AST::InExpression>
-  end
-
-  rule not_in_expression
-    rvalue _ not_in_operator _ rvalue
-    <LogStash::Config::AST::NotInExpression>
-  end
-
-  rule in_operator
-    "in"
-  end
-
-  rule not_in_operator
-    "not " _ "in"
-  end
-
-  rule rvalue
-    string / number / selector / array / method_call / regexp
-  end
-
-  rule method_call
-      method _ "(" _
-        (
-          rvalue ( _ "," _ rvalue )*
-        )?
-      _ ")"
-    <LogStash::Config::AST::MethodCall>
-  end
-
-  rule method
-    bareword
-  end
-
-  rule compare_expression
-    rvalue _ compare_operator _ rvalue
-    <LogStash::Config::AST::ComparisonExpression>
-  end
-  
-  rule compare_operator 
-    ("==" / "!=" / "<=" / ">=" / "<" / ">") 
-    <LogStash::Config::AST::ComparisonOperator>
-  end
-
-  rule regexp_expression
-    rvalue _  regexp_operator _ (string / regexp)
-    <LogStash::Config::AST::RegexpExpression>
-  end
-
-  rule regexp_operator
-    ("=~" / "!~") <LogStash::Config::AST::RegExpOperator>
-  end
-
-
-  rule boolean_operator
-    ("and" / "or" / "xor" / "nand")
-    <LogStash::Config::AST::BooleanOperator>
-  end
-
-  rule selector
-    selector_element+
-    <LogStash::Config::AST::Selector>
-  end
-
-  rule selector_element
-    "[" [^\],]+ "]"
-    <LogStash::Config::AST::SelectorElement>
-  end
-
-end
diff --git a/logstash-core/lib/logstash/filter_delegator.rb b/logstash-core/lib/logstash/filter_delegator.rb
index 9040482ddd4..ac0ca7b1d09 100644
--- a/logstash-core/lib/logstash/filter_delegator.rb
+++ b/logstash-core/lib/logstash/filter_delegator.rb
@@ -2,6 +2,7 @@
 #
 module LogStash
   class FilterDelegator
+    include org.logstash.config.ir.compiler.RubyIntegration::Filter
     extend Forwardable
     DELEGATED_METHODS = [
       :register,
@@ -34,7 +35,7 @@ def initialize(logger, klass, metric, execution_context, plugin_args)
       namespaced_metric.gauge(:name, config_name)
 
       # Not all the filters will do bufferings
-      define_flush_method if @filter.respond_to?(:flush)
+      @flushes = @filter.respond_to?(:flush)
     end
 
     def config_name
@@ -55,19 +56,20 @@ def multi_filter(events)
       @metric_events_out.increment(c) if c > 0
       new_events
     end
+    
+    def has_flush
+      @flushes
+    end
 
-    private
-    def define_flush_method
-      define_singleton_method(:flush) do |options = {}|
-        # we also need to trace the number of events
-        # coming from a specific filters.
-        new_events = @filter.flush(options)
+    def flush(options = {})
+      # we also need to trace the number of events
+      # coming from a specific filters.
+      new_events = @filter.flush(options)
 
-        # Filter plugins that does buffering or spooling of events like the
-        # `Logstash-filter-aggregates` can return `NIL` and will flush on the next flush ticks.
-        @metric_events_out.increment(new_events.size) if new_events && new_events.size > 0
-        new_events
-      end
+      # Filter plugins that does buffering or spooling of events like the
+      # `Logstash-filter-aggregates` can return `NIL` and will flush on the next flush ticks.
+      @metric_events_out.increment(new_events.size) if new_events && new_events.size > 0
+      new_events
     end
   end
 end
diff --git a/logstash-core/lib/logstash/output_delegator.rb b/logstash-core/lib/logstash/output_delegator.rb
index 2ce8a8abaa0..b1fb8b75e4c 100644
--- a/logstash-core/lib/logstash/output_delegator.rb
+++ b/logstash-core/lib/logstash/output_delegator.rb
@@ -5,6 +5,7 @@
 require "logstash/output_delegator_strategies/legacy"
 
 module LogStash class OutputDelegator
+  include org.logstash.config.ir.compiler.RubyIntegration::Output
   attr_reader :metric, :metric_events, :strategy, :namespaced_metric, :metric_events, :id
 
   def initialize(logger, output_class, metric, execution_context, strategy_registry, plugin_args)
@@ -44,11 +45,12 @@ def register
   end
 
   def multi_receive(events)
-    @in_counter.increment(events.length)
+    count = events.size
+    @in_counter.increment(count)
     start_time = java.lang.System.nano_time
     @strategy.multi_receive(events)
     @time_metric.increment((java.lang.System.nano_time - start_time) / 1_000_000)
-    @out_counter.increment(events.length)
+    @out_counter.increment(count)
   end
 
   def do_close
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 9b1671b9f0b..0775bec5cad 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -6,7 +6,6 @@
 require "logstash/errors"
 require "logstash-core/logstash-core"
 require "logstash/event"
-require "logstash/config/file"
 require "logstash/filters/base"
 require "logstash/inputs/base"
 require "logstash/outputs/base"
@@ -29,8 +28,10 @@
 java_import org.logstash.common.DeadLetterQueueFactory
 java_import org.logstash.common.SourceWithMetadata
 java_import org.logstash.common.io.DeadLetterQueueWriter
+java_import org.logstash.config.ir.CompiledPipeline
 
 module LogStash; class BasePipeline
+  include org.logstash.config.ir.compiler.RubyIntegration::Pipeline 
   include LogStash::Util::Loggable
 
   attr_reader :settings, :config_str, :config_hash, :inputs, :filters, :outputs, :pipeline_id, :lir, :execution_context, :ephemeral_id
@@ -56,33 +57,17 @@ def initialize(pipeline_config, namespaced_metric = nil, agent = nil)
 
     # A list of plugins indexed by id
     @plugins_by_id = {}
-    @inputs = nil
-    @filters = nil
-    @outputs = nil
     @agent = agent
 
     @dlq_writer = dlq_writer
 
-    grammar = LogStashConfigParser.new
-    parsed_config = grammar.parse(config_str)
-    raise(ConfigurationError, grammar.failure_reason) if parsed_config.nil?
-
-    parsed_config.process_escape_sequences = settings.get_value("config.support_escapes")
-    config_code = parsed_config.compile
-
-    # config_code = BasePipeline.compileConfig(config_str)
-
+    @lir_execution = CompiledPipeline.new(@lir, self)
     if settings.get_value("config.debug") && @logger.debug?
-      @logger.debug("Compiled pipeline code", default_logging_keys(:code => config_code))
-    end
-
-    # Evaluate the config compiled code that will initialize all the plugins and define the
-    # filter and output methods.
-    begin
-      eval(config_code)
-    rescue => e
-      raise e
+      @logger.debug("Compiled pipeline code", default_logging_keys(:code => @lir.get_graph.to_string))
     end
+    @inputs = @lir_execution.inputs
+    @filters = @lir_execution.filters
+    @outputs = @lir_execution.outputs
   end
 
   def dlq_writer
@@ -106,6 +91,22 @@ def compile_lir
     ]
     LogStash::Compiler.compile_sources(sources_with_metadata, @settings)
   end
+   
+  def buildOutput(name, line, column, *args)
+    plugin("output", name, line, column, *args)
+  end
+
+  def buildFilter(name, line, column, *args)
+    plugin("filter", name, line, column, *args)
+  end
+               
+  def buildInput(name, line, column, *args)
+    plugin("input", name, line, column, *args)
+  end
+
+  def buildCodec(name, *args)
+   plugin("codec", name, 0, 0, *args)
+  end
 
   def plugin(plugin_type, name, line, column, *args)
     @plugin_counter += 1
@@ -232,7 +233,6 @@ def initialize(pipeline_config, namespaced_metric = nil, agent = nil)
     )
     @drain_queue =  @settings.get_value("queue.drain")
 
-
     @events_filtered = Concurrent::AtomicFixnum.new(0)
     @events_consumed = Concurrent::AtomicFixnum.new(0)
 
@@ -242,6 +242,7 @@ def initialize(pipeline_config, namespaced_metric = nil, agent = nil)
     @running = Concurrent::AtomicBoolean.new(false)
     @flushing = Concurrent::AtomicReference.new(false)
     @outputs_registered = Concurrent::AtomicBoolean.new(false)
+    @finished_execution = Concurrent::AtomicBoolean.new(false)
   end # def initialize
 
   def ready?
@@ -273,7 +274,7 @@ def safe_pipeline_worker_count
   end
 
   def filters?
-    return @filters.any?
+    @filters.any?
   end
 
   def start
@@ -284,7 +285,7 @@ def start
 
     @logger.debug("Starting pipeline", default_logging_keys)
 
-    @finished_execution = Concurrent::AtomicBoolean.new(false)
+    @finished_execution.make_false
 
     @thread = Thread.new do
       begin
@@ -314,7 +315,7 @@ def wait_until_started
       # because the execution of the thread was successful and complete
       if @finished_execution.true?
         return true
-      elsif !thread.alive?
+      elsif thread.nil? || !thread.alive?
         return false
       elsif running?
         return true
@@ -380,22 +381,11 @@ def system?
     settings.get_value("pipeline.system")
   end
 
-  # register_plugin simply calls the plugin #register method and catches & logs any error
-  # @param plugin [Plugin] the plugin to register
-  # @return [Plugin] the registered plugin
-  def register_plugin(plugin)
-    plugin.register
-    plugin
-  rescue => e
-    @logger.error("Error registering plugin", default_logging_keys(:plugin => plugin.inspect, :error => e.message))
-    raise e
-  end
-
   # register_plugins calls #register_plugin on the plugins list and upon exception will call Plugin#do_close on all registered plugins
   # @param plugins [Array[Plugin]] the list of plugins to register
   def register_plugins(plugins)
     registered = []
-    plugins.each { |plugin| registered << register_plugin(plugin) }
+    plugins.each { |plugin| registered << @lir_execution.registerPlugin(plugin) }
   rescue => e
     registered.each(&:do_close)
     raise e
@@ -431,10 +421,13 @@ def start_workers
       if max_inflight > MAX_INFLIGHT_WARN_THRESHOLD
         @logger.warn("CAUTION: Recommended inflight events max exceeded! Logstash will run with up to #{max_inflight} events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently #{batch_size}), or changing the number of pipeline workers (currently #{pipeline_workers})", default_logging_keys)
       end
+      
+      @filter_queue_client.set_batch_dimensions(batch_size, batch_delay)
 
       pipeline_workers.times do |t|
-        thread = Thread.new(batch_size, batch_delay, self) do |_b_size, _b_delay, _pipeline|
-          _pipeline.worker_loop(_b_size, _b_delay)
+        batched_execution = @lir_execution.buildExecution
+        thread = Thread.new(self, batched_execution) do |_pipeline, _batched_execution|
+          _pipeline.worker_loop(_batched_execution)
         end
         thread.name="[#{pipeline_id}]>worker#{t}"
         @worker_threads << thread
@@ -462,25 +455,16 @@ def dlq_enabled?
 
   # Main body of what a worker thread does
   # Repeatedly takes batches off the queue, filters, then outputs them
-  def worker_loop(batch_size, batch_delay)
+  def worker_loop(batched_execution)
     shutdown_requested = false
-
-    @filter_queue_client.set_batch_dimensions(batch_size, batch_delay)
-
     while true
       signal = @signal_queue.poll || NO_SIGNAL
       shutdown_requested |= signal.shutdown? # latch on shutdown signal
 
       batch = @filter_queue_client.read_batch # metrics are started in read_batch
-      if batch.size > 0
-        @events_consumed.increment(batch.size)
-        filter_batch(batch)
-      end
-      flush_filters_to_batch(batch, :final => false) if signal.flush?
-      if batch.size > 0
-        output_batch(batch)
-        @filter_queue_client.close_batch(batch)
-      end
+      @events_consumed.increment(batch.size)
+      execute_batch(batched_execution, batch, signal.flush?)
+      @filter_queue_client.close_batch(batch)
       # keep break at end of loop, after the read_batch operation, some pipeline specs rely on this "final read_batch" before shutdown.
       break if (shutdown_requested && !draining_queue?)
     end
@@ -489,56 +473,10 @@ def worker_loop(batch_size, batch_delay)
     # for this we need to create a new empty batch to contain the final flushed events
     batch = @filter_queue_client.new_batch
     @filter_queue_client.start_metrics(batch) # explicitly call start_metrics since we dont do a read_batch here
-    flush_filters_to_batch(batch, :final => true)
-    output_batch(batch)
+    batched_execution.compute(batch, true, true)
     @filter_queue_client.close_batch(batch)
   end
 
-  def filter_batch(batch)
-    batch.each do |event|
-      filter_func(event).each do |e|
-        #these are both original and generated events
-        batch.merge(e) unless e.cancelled?
-      end
-    end
-    @filter_queue_client.add_filtered_metrics(batch)
-    @events_filtered.increment(batch.size)
-  rescue Exception => e
-    # Plugins authors should manage their own exceptions in the plugin code
-    # but if an exception is raised up to the worker thread they are considered
-    # fatal and logstash will not recover from this situation.
-    #
-    # Users need to check their configuration or see if there is a bug in the
-    # plugin.
-    @logger.error("Exception in pipelineworker, the pipeline stopped processing new events, please check your filter configuration and restart Logstash.",
-                  default_logging_keys("exception" => e.message, "backtrace" => e.backtrace))
-
-    raise e
-  end
-
-  # Take an array of events and send them to the correct output
-  def output_batch(batch)
-    # Build a mapping of { output_plugin => [events...]}
-    output_events_map = Hash.new { |h, k| h[k] = [] }
-    batch.each do |event|
-      # We ask the AST to tell us which outputs to send each event to
-      # Then, we stick it in the correct bin
-
-      # output_func should never return anything other than an Array but we have lots of legacy specs
-      # that monkeypatch it and return nil. We can deprecate  "|| []" after fixing these specs
-      (output_func(event) || []).each do |output|
-        output_events_map[output].push(event)
-      end
-    end
-    # Now that we have our output to event mapping we can just invoke each output
-    # once with its list of events
-    output_events_map.each do |output, events|
-      output.multi_receive(events)
-    end
-
-    @filter_queue_client.add_output_metrics(batch)
-  end
-
   def wait_inputs
     @input_threads.each(&:join)
   end
@@ -648,22 +586,13 @@ def shutdown_workers
   end
 
   # for backward compatibility in devutils for the rspec helpers, this method is not used
-  # in the pipeline anymore.
+  # anymore and just here to not break TestPipeline that inherits this class.
   def filter(event, &block)
-    maybe_setup_out_plugins
-    # filter_func returns all filtered events, including cancelled ones
-    filter_func(event).each {|e| block.call(e)}
   end
 
-  # perform filters flush and yield flushed event to the passed block
-  # @param options [Hash]
-  # @option options [Boolean] :final => true to signal a final shutdown flush
+  # for backward compatibility in devutils for the rspec helpers, this method is not used
+  # anymore and just here to not break TestPipeline that inherits this class.
   def flush_filters(options = {}, &block)
-    flushers = options[:final] ? @shutdown_flushers : @periodic_flushers
-
-    flushers.each do |flusher|
-      flusher.call(options, &block)
-    end
   end
 
   def start_flusher
@@ -697,21 +626,6 @@ def uptime
     ((Time.now.to_f - started_at.to_f) * 1000.0).to_i
   end
 
-  # perform filters flush into the output queue
-  #
-  # @param batch [ReadClient::ReadBatch]
-  # @param options [Hash]
-  def flush_filters_to_batch(batch, options = {})
-    flush_filters(options) do |event|
-      unless event.cancelled?
-        @logger.debug? and @logger.debug("Pushing flushed events", default_logging_keys(:event => event))
-        batch.merge(event)
-      end
-    end
-
-    @flushing.set(false)
-  end # flush_filters_to_batch
-
   def plugin_threads_info
     input_threads = @input_threads.select {|t| t.alive? }
     worker_threads = @worker_threads.select {|t| t.alive? }
@@ -786,6 +700,24 @@ def inspect
 
   private
 
+  def execute_batch(batched_execution, batch, flush)
+    batched_execution.compute(batch, flush, false)
+    @filter_queue_client.add_output_metrics(batch)
+    @filter_queue_client.add_filtered_metrics(batch)
+    @events_filtered.increment(batch.size)
+  rescue Exception => e
+    # Plugins authors should manage their own exceptions in the plugin code
+    # but if an exception is raised up to the worker thread they are considered
+    # fatal and logstash will not recover from this situation.
+    #
+    # Users need to check their configuration or see if there is a bug in the
+    # plugin.
+    @logger.error("Exception in pipelineworker, the pipeline stopped processing new events, please check your filter configuration and restart Logstash.",
+                  default_logging_keys("exception" => e.message, "backtrace" => e.backtrace))
+
+    raise e
+  end
+
   def maybe_setup_out_plugins
     if @outputs_registered.make_true
       register_plugins(@outputs)
diff --git a/logstash-core/lib/logstash/util/wrapped_acked_queue.rb b/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
index 4536545724e..24f91e6c209 100644
--- a/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
+++ b/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
@@ -238,6 +238,7 @@ def add_output_metrics(batch)
     end
 
     class ReadBatch
+      include org.logstash.config.ir.compiler.RubyIntegration::Batch
       def initialize(queue, size, wait)
         @queue = queue
         @size = size
@@ -285,6 +286,12 @@ def cancel(event)
         # @cancelled[event] = true
       end
 
+      def to_a
+        events = []
+        each {|e| events << e}
+        events
+      end
+
       def each(&blk)
         # take care not to cause @originals or @generated to change during iteration
 
diff --git a/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb b/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
index ef984e58924..698f8348ec1 100644
--- a/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
+++ b/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
@@ -171,6 +171,7 @@ def add_output_metrics(batch)
     end
 
     class ReadBatch
+      include org.logstash.config.ir.compiler.RubyIntegration::Batch
       def initialize(queue, size, wait)
         @queue = queue.queue
         @size = size
@@ -204,6 +205,12 @@ def cancel(event)
         # @cancelled[event] = true
       end
 
+      def to_a
+        events = []
+        each {|e| events << e}
+        events
+      end
+
       def each(&blk)
         # take care not to cause @originals or @generated to change during iteration
         @is_iterating = true
diff --git a/logstash-core/spec/conditionals_spec.rb b/logstash-core/spec/conditionals_spec.rb
index 80a4bd7bf25..b6f587ab453 100644
--- a/logstash-core/spec/conditionals_spec.rb
+++ b/logstash-core/spec/conditionals_spec.rb
@@ -1,7 +1,9 @@
 # encoding: utf-8
 require 'spec_helper'
+require 'support/pipeline/pipeline_helpers'
 
 module ConditionalFanciness
+  include PipelineHelpers
   def description
     return self.metadata[:description]
   end
@@ -76,21 +78,21 @@ def multi_receive(events)
       }
     CONFIG
 
-    sample({"foo" => "bar"}) do
+    sample_one({"foo" => "bar"}) do
       expect(subject.get("always")).to eq("awesome")
       expect(subject.get("hello")).to eq("world")
       expect(subject.get("fancy")).to be_nil
       expect(subject.get("free")).to be_nil
     end
 
-    sample({"notfoo" => "bar"}) do
+    sample_one({"notfoo" => "bar"}) do
       expect(subject.get("always")).to eq("awesome")
       expect(subject.get("hello")).to be_nil
       expect(subject.get("fancy")).to be_nil
       expect(subject.get("free")).to eq("hugs")
     end
 
-    sample({"bar" => "baz"}) do
+    sample_one({"bar" => "baz"}) do
       expect(subject.get("always")).to eq("awesome")
       expect(subject.get("hello")).to be_nil
       expect(subject.get("fancy")).to eq("pants")
@@ -114,28 +116,28 @@ def multi_receive(events)
       }
     CONFIG
 
-    sample("foo" => "bar", "nest" => 124) do
+    sample_one("foo" => "bar", "nest" => 124) do
       expect(subject.get("always")).to be_nil
       expect(subject.get("hello")).to be_nil
       expect(subject.get("fancy")).to be_nil
       expect(subject.get("free")).to be_nil
     end
 
-    sample("foo" => "bar", "nest" => 123) do
+    sample_one("foo" => "bar", "nest" => 123) do
       expect(subject.get("always")).to eq("awesome")
       expect(subject.get("hello")).to eq("world")
       expect(subject.get("fancy")).to be_nil
       expect(subject.get("free")).to be_nil
     end
 
-    sample("notfoo" => "bar", "nest" => 123) do
+    sample_one("notfoo" => "bar", "nest" => 123) do
       expect(subject.get("always")).to eq("awesome")
       expect(subject.get("hello")).to be_nil
       expect(subject.get("fancy")).to be_nil
       expect(subject.get("free")).to eq("hugs")
     end
 
-    sample("bar" => "baz", "nest" => 123) do
+    sample_one("bar" => "baz", "nest" => 123) do
       expect(subject.get("always")).to eq("awesome")
       expect(subject.get("hello")).to be_nil
       expect(subject.get("fancy")).to eq("pants")
@@ -152,7 +154,7 @@ def multi_receive(events)
       }
     CONFIG
 
-    sample("foo" => 123, "bar" => 123) do
+    sample_one("foo" => 123, "bar" => 123) do
       expect(subject.get("tags") ).to include("woot")
     end
   end
@@ -181,7 +183,7 @@ def multi_receive(events)
       }
     CONFIG
 
-    sample("foo" => "foo", "foobar" => "foobar", "greeting" => "hello world") do
+    sample_one("foo" => "foo", "foobar" => "foobar", "greeting" => "hello world") do
       expect(subject.get("tags")).to include("field in field")
       expect(subject.get("tags")).to include("field in string")
       expect(subject.get("tags")).to include("string in field")
@@ -203,7 +205,7 @@ def multi_receive(events)
       }
     CONFIG
 
-    sample("foo" => "foo", "somelist" => [ "one", "two" ], "foobar" => "foobar", "greeting" => "hello world", "tags" => [ "fancypantsy" ]) do
+    sample_one("foo" => "foo", "somelist" => [ "one", "two" ], "foobar" => "foobar", "greeting" => "hello world", "tags" => [ "fancypantsy" ]) do
       # verify the original exists
       expect(subject.get("tags")).to include("fancypantsy")
 
@@ -218,94 +220,156 @@ def multi_receive(events)
 
   describe "operators" do
     conditional "[message] == 'sample'" do
-      sample("sample") { expect(subject.get("tags") ).to include("success") }
-      sample("different") { expect(subject.get("tags") ).to include("failure") }
+      sample_one("sample") { expect(subject.get("tags") ).to include("success") }
+      sample_one("different") { expect(subject.get("tags") ).to include("failure") }
+    end
+
+    conditional "'sample' == [message]" do
+      sample_one("sample") {expect(subject.get("tags")).to include("success")}
+      sample_one("different") {expect(subject.get("tags")).to include("failure")}
+    end
+
+    conditional "'value' == 'value'" do
+      sample_one("sample") {expect(subject.get("tags")).to include("success")}
+    end
+
+    conditional "'value' == 'other'" do
+      sample_one("sample") {expect(subject.get("tags")).to include("failure")}
     end
 
     conditional "[message] != 'sample'" do
-      sample("sample") { expect(subject.get("tags") ).to include("failure") }
-      sample("different") { expect(subject.get("tags") ).to include("success") }
+      sample_one("sample") { expect(subject.get("tags") ).to include("failure") }
+      sample_one("different") { expect(subject.get("tags") ).to include("success") }
     end
 
     conditional "[message] < 'sample'" do
-      sample("apple") { expect(subject.get("tags") ).to include("success") }
-      sample("zebra") { expect(subject.get("tags") ).to include("failure") }
+      sample_one("apple") { expect(subject.get("tags") ).to include("success") }
+      sample_one("zebra") { expect(subject.get("tags") ).to include("failure") }
     end
 
     conditional "[message] > 'sample'" do
-      sample("zebra") { expect(subject.get("tags") ).to include("success") }
-      sample("apple") { expect(subject.get("tags") ).to include("failure") }
+      sample_one("zebra") { expect(subject.get("tags") ).to include("success") }
+      sample_one("apple") { expect(subject.get("tags") ).to include("failure") }
     end
 
     conditional "[message] <= 'sample'" do
-      sample("apple") { expect(subject.get("tags") ).to include("success") }
-      sample("zebra") { expect(subject.get("tags") ).to include("failure") }
-      sample("sample") { expect(subject.get("tags") ).to include("success") }
+      sample_one("apple") { expect(subject.get("tags") ).to include("success") }
+      sample_one("zebra") { expect(subject.get("tags") ).to include("failure") }
+      sample_one("sample") { expect(subject.get("tags") ).to include("success") }
     end
 
     conditional "[message] >= 'sample'" do
-      sample("zebra") { expect(subject.get("tags") ).to include("success") }
-      sample("sample") { expect(subject.get("tags") ).to include("success") }
-      sample("apple") { expect(subject.get("tags") ).to include("failure") }
+      sample_one("zebra") { expect(subject.get("tags") ).to include("success") }
+      sample_one("sample") { expect(subject.get("tags") ).to include("success") }
+      sample_one("apple") { expect(subject.get("tags") ).to include("failure") }
+    end
+
+    conditional "[message] == 5" do
+      sample_one("message" => 5) {expect(subject.get("tags")).to include("success")}
+      sample_one("message" => 3) {expect(subject.get("tags")).to include("failure")}
+    end
+
+    conditional "5 == [message]" do
+      sample_one("message" => 5) {expect(subject.get("tags")).to include("success")}
+      sample_one("message" => 3) {expect(subject.get("tags")).to include("failure")}
+    end
+
+    conditional "7 == 7" do
+      sample_one("message" => 7) {expect(subject.get("tags")).to include("success")}
+      sample_one("message" => 3) {expect(subject.get("tags")).to include("success")}
+    end
+
+    conditional "5 == 7" do
+      sample_one("message" => 3) {expect(subject.get("tags")).to include("failure")}
+      sample_one("message" => 2) {expect(subject.get("tags")).to include("failure")}
+    end
+
+    conditional "[message] != 5" do
+      sample_one("message" => 5) {expect(subject.get("tags")).to include("failure")}
+      sample_one("message" => 3) {expect(subject.get("tags")).to include("success")}
+    end
+
+    conditional "[message] < 5" do
+      sample_one("message" => 3) {expect(subject.get("tags")).to include("success")}
+      sample_one("message" => 5) {expect(subject.get("tags")).to include("failure")}
+      sample_one("message" => 9) {expect(subject.get("tags")).to include("failure")}
+    end
+
+    conditional "[message] > 5" do
+      sample_one("message" => 9) {expect(subject.get("tags")).to include("success")}
+      sample_one("message" => 5) {expect(subject.get("tags")).to include("failure")}
+      sample_one("message" => 4) {expect(subject.get("tags")).to include("failure")}
+    end
+
+    conditional "[message] <= 5" do
+      sample_one("message" => 9) {expect(subject.get("tags")).to include("failure")}
+      sample_one("message" => 5) {expect(subject.get("tags")).to include("success")}
+      sample_one("message" => 3) {expect(subject.get("tags")).to include("success")}
+    end
+
+    conditional "[message] >= 5" do
+      sample_one("message" => 5) {expect(subject.get("tags")).to include("success")}
+      sample_one("message" => 7) {expect(subject.get("tags")).to include("success")}
+      sample_one("message" => 3) {expect(subject.get("tags")).to include("failure")}
     end
 
     conditional "[message] =~ /sample/" do
-      sample("apple") { expect(subject.get("tags") ).to include("failure") }
-      sample("sample") { expect(subject.get("tags") ).to include("success") }
-      sample("some sample") { expect(subject.get("tags") ).to include("success") }
+      sample_one("apple") { expect(subject.get("tags") ).to include("failure") }
+      sample_one("sample") { expect(subject.get("tags") ).to include("success") }
+      sample_one("some sample") { expect(subject.get("tags") ).to include("success") }
     end
 
     conditional "[message] !~ /sample/" do
-      sample("apple") { expect(subject.get("tags")).to include("success") }
-      sample("sample") { expect(subject.get("tags")).to include("failure") }
-      sample("some sample") { expect(subject.get("tags")).to include("failure") }
+      sample_one("apple") { expect(subject.get("tags")).to include("success") }
+      sample_one("sample") { expect(subject.get("tags")).to include("failure") }
+      sample_one("some sample") { expect(subject.get("tags")).to include("failure") }
     end
 
   end
 
   describe "negated expressions" do
     conditional "!([message] == 'sample')" do
-      sample("sample") { expect(subject.get("tags")).not_to include("success") }
-      sample("different") { expect(subject.get("tags")).not_to include("failure") }
+      sample_one("sample") { expect(subject.get("tags")).not_to include("success") }
+      sample_one("different") { expect(subject.get("tags")).not_to include("failure") }
     end
 
     conditional "!([message] != 'sample')" do
-      sample("sample") { expect(subject.get("tags")).not_to include("failure") }
-      sample("different") { expect(subject.get("tags")).not_to include("success") }
+      sample_one("sample") { expect(subject.get("tags")).not_to include("failure") }
+      sample_one("different") { expect(subject.get("tags")).not_to include("success") }
     end
 
     conditional "!([message] < 'sample')" do
-      sample("apple") { expect(subject.get("tags")).not_to include("success") }
-      sample("zebra") { expect(subject.get("tags")).not_to include("failure") }
+      sample_one("apple") { expect(subject.get("tags")).not_to include("success") }
+      sample_one("zebra") { expect(subject.get("tags")).not_to include("failure") }
     end
 
     conditional "!([message] > 'sample')" do
-      sample("zebra") { expect(subject.get("tags")).not_to include("success") }
-      sample("apple") { expect(subject.get("tags")).not_to include("failure") }
+      sample_one("zebra") { expect(subject.get("tags")).not_to include("success") }
+      sample_one("apple") { expect(subject.get("tags")).not_to include("failure") }
     end
 
     conditional "!([message] <= 'sample')" do
-      sample("apple") { expect(subject.get("tags")).not_to include("success") }
-      sample("zebra") { expect(subject.get("tags")).not_to include("failure") }
-      sample("sample") { expect(subject.get("tags")).not_to include("success")}
+      sample_one("apple") { expect(subject.get("tags")).not_to include("success") }
+      sample_one("zebra") { expect(subject.get("tags")).not_to include("failure") }
+      sample_one("sample") { expect(subject.get("tags")).not_to include("success")}
     end
 
     conditional "!([message] >= 'sample')" do
-      sample("zebra") { expect(subject.get("tags")).not_to include("success") }
-      sample("sample") { expect(subject.get("tags")).not_to include("success") }
-      sample("apple") { expect(subject.get("tags")).not_to include("failure") }
+      sample_one("zebra") { expect(subject.get("tags")).not_to include("success") }
+      sample_one("sample") { expect(subject.get("tags")).not_to include("success") }
+      sample_one("apple") { expect(subject.get("tags")).not_to include("failure") }
     end
 
     conditional "!([message] =~ /sample/)" do
-      sample("apple") { expect(subject.get("tags")).not_to include("failure") }
-      sample("sample") { expect(subject.get("tags")).not_to include("success") }
-      sample("some sample") { expect(subject.get("tags")).not_to include("success") }
+      sample_one("apple") { expect(subject.get("tags")).not_to include("failure") }
+      sample_one("sample") { expect(subject.get("tags")).not_to include("success") }
+      sample_one("some sample") { expect(subject.get("tags")).not_to include("success") }
     end
 
     conditional "!([message] !~ /sample/)" do
-      sample("apple") { expect(subject.get("tags")).not_to include("success") }
-      sample("sample") { expect(subject.get("tags")).not_to include("failure") }
-      sample("some sample") { expect(subject.get("tags")).not_to include("failure") }
+      sample_one("apple") { expect(subject.get("tags")).not_to include("success") }
+      sample_one("sample") { expect(subject.get("tags")).not_to include("failure") }
+      sample_one("some sample") { expect(subject.get("tags")).not_to include("failure") }
     end
 
   end
@@ -313,66 +377,96 @@ def multi_receive(events)
   describe "value as an expression" do
     # testing that a field has a value should be true.
     conditional "[message]" do
-      sample("apple") { expect(subject.get("tags")).to include("success") }
-      sample("sample") { expect(subject.get("tags")).to include("success") }
-      sample("some sample") { expect(subject.get("tags")).to include("success") }
+      sample_one("apple") { expect(subject.get("tags")).to include("success") }
+      sample_one("sample") { expect(subject.get("tags")).to include("success") }
+      sample_one("some sample") { expect(subject.get("tags")).to include("success") }
     end
 
     # testing that a missing field has a value should be false.
     conditional "[missing]" do
-      sample("apple") { expect(subject.get("tags")).to include("failure") }
-      sample("sample") { expect(subject.get("tags")).to include("failure") }
-      sample("some sample") { expect(subject.get("tags")).to include("failure") }
+      sample_one("apple") { expect(subject.get("tags")).to include("failure") }
+      sample_one("sample") { expect(subject.get("tags")).to include("failure") }
+      sample_one("some sample") { expect(subject.get("tags")).to include("failure") }
     end
   end
 
   describe "logic operators" do
     describe "and" do
       conditional "[message] and [message]" do
-        sample("whatever") { expect(subject.get("tags")).to include("success") }
+        sample_one("whatever") { expect(subject.get("tags")).to include("success") }
       end
       conditional "[message] and ![message]" do
-        sample("whatever") { expect(subject.get("tags")).to include("failure") }
+        sample_one("whatever") { expect(subject.get("tags")).to include("failure") }
       end
       conditional "![message] and [message]" do
-        sample("whatever") { expect(subject.get("tags")).to include("failure") }
+        sample_one("whatever") { expect(subject.get("tags")).to include("failure") }
       end
       conditional "![message] and ![message]" do
-        sample("whatever") { expect(subject.get("tags")).to include("failure") }
+        sample_one("whatever") { expect(subject.get("tags")).to include("failure") }
+      end
+    end
+
+    describe "nand" do
+      conditional "[message] nand [message]" do
+        sample_one("whatever") { expect(subject.get("tags")).to include("failure") }
+      end
+      conditional "[message] nand ![message]" do
+        sample_one("whatever") { expect(subject.get("tags")).to include("success") }
+      end
+      conditional "![message] nand [message]" do
+        sample_one("whatever") { expect(subject.get("tags")).to include("success") }
+      end
+      conditional "![message] nand ![message]" do
+        sample_one("whatever") { expect(subject.get("tags")).to include("success") }
+      end
+    end
+
+    describe "xor" do
+      conditional "[message] xor [message]" do
+        sample_one("whatever") { expect(subject.get("tags")).to include("failure") }
+      end
+      conditional "[message] xor ![message]" do
+        sample_one("whatever") { expect(subject.get("tags")).to include("success") }
+      end
+      conditional "![message] xor [message]" do
+        sample_one("whatever") { expect(subject.get("tags")).to include("success") }
+      end
+      conditional "![message] xor ![message]" do
+        sample_one("whatever") { expect(subject.get("tags")).to include("failure") }
       end
     end
 
     describe "or" do
       conditional "[message] or [message]" do
-        sample("whatever") { expect(subject.get("tags")).to include("success") }
+        sample_one("whatever") { expect(subject.get("tags")).to include("success") }
       end
       conditional "[message] or ![message]" do
-        sample("whatever") { expect(subject.get("tags")).to include("success") }
+        sample_one("whatever") { expect(subject.get("tags")).to include("success") }
       end
       conditional "![message] or [message]" do
-        sample("whatever") { expect(subject.get("tags")).to include("success") }
+        sample_one("whatever") { expect(subject.get("tags")).to include("success") }
       end
       conditional "![message] or ![message]" do
-        sample("whatever") { expect(subject.get("tags")).to include("failure") }
+        sample_one("whatever") { expect(subject.get("tags")).to include("failure") }
       end
     end
   end
 
   describe "field references" do
     conditional "[field with space]" do
-      sample("field with space" => "hurray") do
+      sample_one("field with space" => "hurray") do
         expect(subject.get("tags")).to include("success")
       end
     end
 
     conditional "[field with space] == 'hurray'" do
-      sample("field with space" => "hurray") do
+      sample_one("field with space" => "hurray") do
         expect(subject.get("tags")).to include("success")
       end
     end
 
     conditional "[nested field][reference with][some spaces] == 'hurray'" do
-      sample({"nested field" => { "reference with" => { "some spaces" => "hurray" } } }) do
+      sample_one({"nested field" => { "reference with" => { "some spaces" => "hurray" } } }) do
         expect(subject.get("tags")).to include("success")
       end
     end
@@ -394,15 +488,16 @@ def multi_receive(events)
       }
     CONFIG
 
-    sample({"type" => "original"}) do
+    sample_one({"type" => "original"}) do
       expect(subject).to be_an(Array)
       expect(subject.length).to eq(2)
+      subject.sort! {|a, b| a.get("type") <=> b.get("type")}
 
-      expect(subject[0].get("type")).to eq("original")
-      expect(subject[0].get("cond1")).to eq("true")
-      expect(subject[0].get("cond2")).to eq(nil)
+      expect(subject[1].get("type")).to eq("original")
+      expect(subject[1].get("cond1")).to eq("true")
+      expect(subject[1].get("cond2")).to eq(nil)
 
-      expect(subject[1].get("type")).to eq("clone")
+      expect(subject[0].get("type")).to eq("clone")
       # expect(subject[1].get("cond1")).to eq(nil)
       # expect(subject[1].get("cond2")).to eq("true")
     end
@@ -424,18 +519,78 @@ def multi_receive(events)
       }
     CONFIG
 
-    sample({"type" => "original"}) do
-      # puts subject.inspect
-      expect(subject[0].get("cond1")).to eq(nil)
+    sample_one({"type" => "original"}) do
+      expect(subject.length).to eq(3)
+      subject.sort! {|a, b| a.get("type") <=> b.get("type")}
+
+      expect(subject[0].get("type")).to eq("clone1")
+      expect(subject[0].get("cond1")).to eq("true")
       expect(subject[0].get("cond2")).to eq(nil)
 
-      expect(subject[1].get("type")).to eq("clone1")
-      expect(subject[1].get("cond1")).to eq("true")
-      expect(subject[1].get("cond2")).to eq(nil)
+      expect(subject[1].get("type")).to eq("clone2")
+      expect(subject[1].get("cond1")).to eq(nil)
+      expect(subject[1].get("cond2")).to eq("true")
 
-      expect(subject[2].get("type")).to eq("clone2")
+      expect(subject[2].get("type")).to eq("original")
       expect(subject[2].get("cond1")).to eq(nil)
-      expect(subject[2].get("cond2")).to eq("true")
+      expect(subject[2].get("cond2")).to eq(nil)
+    end
+  end
+
+  describe "complex case" do
+    config <<-CONFIG
+      filter {
+        if ("foo" in [tags]) {
+          mutate { id => addbar add_tag => bar }
+      
+          if ("bar" in [tags]) {
+            mutate { id => addbaz  add_tag => baz }
+          }
+      
+          if ("baz" in [tags]) {
+            mutate { id => addbot add_tag => bot }
+      
+            if ("bot" in [tags]) {
+              mutate { id => addbonk add_tag => bonk }
+            }
+          }
+        }
+      
+        if ("bot" in [tags]) {
+          mutate { id => addwat add_tag => wat }
+        }
+      
+        mutate { id => addprev add_tag => prev }
+      
+        mutate { id => addfinal add_tag => final }
+      
+      }
+    CONFIG
+
+    sample_one("tags" => ["bot"]) do
+      tags = subject.get("tags")
+      expect(tags[0]).to eq("bot")
+      expect(tags[1]).to eq("wat")
+      expect(tags[2]).to eq("prev")
+      expect(tags[3]).to eq("final")
+    end
+
+    sample_one("tags" => ["foo"]) do
+      tags = subject.get("tags")
+      expect(tags[0]).to eq("foo")
+      expect(tags[1]).to eq("bar")
+      expect(tags[2]).to eq("baz")
+      expect(tags[3]).to eq("bot")
+      expect(tags[4]).to eq("bonk")
+      expect(tags[5]).to eq("wat")
+      expect(tags[6]).to eq("prev")
+      expect(tags[7]).to eq("final")
+    end
+    
+    sample_one("type" => "original") do
+      tags = subject.get("tags")
+      expect(tags[0]).to eq("prev")
+      expect(tags[1]).to eq("final")
     end
   end
 end
diff --git a/logstash-core/spec/logstash/config/config_ast_spec.rb b/logstash-core/spec/logstash/config/config_ast_spec.rb
deleted file mode 100644
index 769cb0a8bb1..00000000000
--- a/logstash-core/spec/logstash/config/config_ast_spec.rb
+++ /dev/null
@@ -1,263 +0,0 @@
-# encoding: utf-8
-# config syntax tests
-#
-require "spec_helper"
-require "logstash/config/grammar"
-require "logstash/config/config_ast"
-
-describe LogStashConfigParser do
-  let(:settings) { mock_settings({}) }
-
-  context '#parse' do
-    context "valid configuration" do
-      it "should permit single-quoted attribute names" do
-        parser = LogStashConfigParser.new
-        config = parser.parse(%q(
-          input {
-            example {
-              'foo' => 'bar'
-              test => { 'bar' => 'baz' }
-            }
-          }
-          ))
-
-        expect(config).not_to be_nil
-      end
-
-      it "should permit empty plugin sections" do
-        parser = LogStashConfigParser.new
-        config = parser.parse(%q(
-          filter {
-          }
-          ))
-
-        expect(config).not_to be_nil
-      end
-
-      it 'permits hash to contains array' do
-        parser = LogStashConfigParser.new
-        config = parser.parse(%q(
-          input{
-            example {
-              match => {
-                "message"=> ["pattern1", "pattern2", "pattern3"]
-              }
-            }
-          }))
-        expect(config).not_to be_nil
-      end
-    end
-  end
-
-  context "#compile" do
-    context "if with multiline conditionals" do
-      let(:config) { <<-CONFIG }
-        filter {
-          if [something]
-             or [anotherthing]
-             or [onemorething] {
-          }
-        }
-      CONFIG
-      subject { LogStashConfigParser.new }
-         
-      it "should compile successfully" do
-        result = subject.parse(config)
-        expect(result).not_to(be_nil)
-        expect { eval(result.compile) }.not_to(raise_error)
-      end
-    end
-
-    context "elsif with multiline conditionals" do
-      let(:config) { <<-CONFIG }
-        filter {
-          if [notathing] {
-          } else if [something]
-                or [anotherthing]
-                or [onemorething] {
-          }
-        }
-      CONFIG
-      subject { LogStashConfigParser.new }
-
-      it "should compile successfully" do
-        result = subject.parse(config)
-        expect(result).not_to(be_nil)
-        expect { eval(result.compile) }.not_to(raise_error)
-      end
-    end
-
-
-    context "invalid configuration" do
-      it "rejects duplicate hash key" do
-        parser = LogStashConfigParser.new
-        config = parser.parse(%q(
-          input {
-            example {
-              match => {
-                "message"=> "pattern1"
-                "message"=> "pattern2"
-                "message"=> "pattern3"
-              }
-            }
-          }
-        ))
-
-        expect { config.compile }.to raise_error(LogStash::ConfigurationError, /Duplicate keys found in your configuration: \["message"\]/)
-      end
-
-      it "rejects duplicate keys in nested hash" do
-        parser = LogStashConfigParser.new
-        config = parser.parse(%q(
-          input {
-            example {
-              match => {
-                "message"=> "pattern1"
-                "more" => {
-                  "cool" => true
-                  "cool" => true
-                }
-              }
-            }
-          }
-        ))
-
-        expect { config.compile }.to raise_error(LogStash::ConfigurationError, /Duplicate keys found in your configuration: \["cool"\]/)
-      end
-
-      it "rejects a key with multiple double quotes" do
-        parser = LogStashConfigParser.new
-        config = parser.parse(%q(
-          input {
-            example {
-              match => {
-                "message"=> "pattern1"
-                ""more"" => {
-                  "cool" => true
-                  "cool" => true
-                }
-              }
-            }
-          }
-        ))
-
-        expect(config).to be_nil
-      end
-    end
-
-    context "when config.support_escapes" do
-      let(:parser) { LogStashConfigParser.new }
-
-      let(:processed_value)  { 'The computer says, "No"' }
-
-      let(:config) {
-        parser.parse(%q(
-          input {
-            foo {
-              bar => "The computer says, \"No\""
-            }
-          }
-        ))
-      }
-
-      let(:compiled_string) { eval(config.recursive_select(LogStash::Config::AST::String).first.compile) }
-
-      before do
-        config.process_escape_sequences = escapes
-      end
-
-      context "is enabled" do
-        let(:escapes) { true }
-
-        it "should process escape sequences" do
-          expect(compiled_string).to be == processed_value
-        end
-      end
-
-      context "is false" do
-        let(:escapes) { false }
-
-        it "should not process escape sequences" do
-          expect(compiled_string).not_to be == processed_value
-        end
-      end
-    end
-  end
-
-  context "when using two plugin sections of the same type" do
-    let(:pipeline_klass) do
-      Class.new do
-        def initialize(config, settings)
-          grammar = LogStashConfigParser.new
-          @config = grammar.parse(config)
-          @code = @config.compile
-          eval(@code)
-        end
-        def plugin(*args);end
-      end
-    end
-    context "(filters)" do
-      let(:config_string) {
-        "input { generator { } }
-         filter { filter1 { } }
-         filter { filter1 { } }
-         output { output1 { } }"
-      }
-
-
-      it "should create a pipeline with both sections" do
-        generated_objects = pipeline_klass.new(config_string, settings).instance_variable_get("@generated_objects")
-        filters = generated_objects.keys.map(&:to_s).select {|obj_name| obj_name.match(/^filter.+?_\d+$/) }
-        expect(filters.size).to eq(2)
-      end
-    end
-
-    context "(filters)" do
-      let(:config_string) {
-        "input { generator { } }
-         output { output1 { } }
-         output { output1 { } }"
-      }
-
-
-      it "should create a pipeline with both sections" do
-        generated_objects = pipeline_klass.new(config_string, settings).instance_variable_get("@generated_objects")
-        outputs = generated_objects.keys.map(&:to_s).select {|obj_name| obj_name.match(/^output.+?_\d+$/) }
-        expect(outputs.size).to eq(2)
-      end
-    end
-  end
-  context "when creating two instances of the same configuration" do
-    let(:config_string) {
-      "input { generator { } }
-       filter {
-         if [type] == 'test' { filter1 { } }
-       }
-       output {
-         output1 { }
-       }"
-    }
-
-    let(:pipeline_klass) do
-      Class.new do
-        def initialize(config, settings)
-          grammar = LogStashConfigParser.new
-          @config = grammar.parse(config)
-          @code = @config.compile
-          eval(@code)
-        end
-        def plugin(*args);end
-      end
-    end
-
-    describe "generated conditional functionals" do
-      it "should be created per instance" do
-        instance_1 = pipeline_klass.new(config_string, settings)
-        instance_2 = pipeline_klass.new(config_string, settings)
-        generated_method_1 = instance_1.instance_variable_get("@generated_objects")[:cond_func_1]
-        generated_method_2 = instance_2.instance_variable_get("@generated_objects")[:cond_func_1]
-        expect(generated_method_1).to_not be(generated_method_2)
-      end
-    end
-  end
-end
diff --git a/logstash-core/spec/logstash/filter_delegator_spec.rb b/logstash-core/spec/logstash/filter_delegator_spec.rb
index b64ac834e4a..98d9420158c 100644
--- a/logstash-core/spec/logstash/filter_delegator_spec.rb
+++ b/logstash-core/spec/logstash/filter_delegator_spec.rb
@@ -146,7 +146,7 @@ def filter(event)
     end
 
     it "doesnt define a flush method" do
-      expect(subject.respond_to?(:flush)).to be_falsey
+      expect(subject.has_flush).to be_falsey
     end
 
     it "increments the in/out of the metric" do
diff --git a/logstash-core/spec/logstash/filters/base_spec.rb b/logstash-core/spec/logstash/filters/base_spec.rb
index 31ec7fb2de6..e03348fbf5e 100644
--- a/logstash-core/spec/logstash/filters/base_spec.rb
+++ b/logstash-core/spec/logstash/filters/base_spec.rb
@@ -1,6 +1,7 @@
 # encoding: utf-8
 require "spec_helper"
 require "logstash/json"
+require 'support/pipeline/pipeline_helpers'
 
 # use a dummy NOOP filter to test Filters::Base
 class LogStash::Filters::NOOP < LogStash::Filters::Base
@@ -50,6 +51,7 @@ def filter(event)
 end
 
 describe LogStash::Filters::NOOP do
+  extend PipelineHelpers
 
   describe "adding multiple values to one field" do
     config <<-CONFIG
@@ -61,7 +63,7 @@ def filter(event)
     }
     CONFIG
 
-    sample "example" do
+    sample_one("example") do
       insist { subject.get("new_field") } == ["new_value", "new_value_2"]
     end
   end
@@ -75,7 +77,7 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop") do
+    sample_one("type" => "noop") do
       insist { subject.get("tags") } == ["test"]
     end
   end
@@ -89,11 +91,11 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop") do
+    sample_one("type" => "noop") do
       insist { subject.get("tags") } == ["test"]
     end
 
-    sample("type" => "noop", "tags" => ["t1", "t2"]) do
+    sample_one("type" => "noop", "tags" => ["t1", "t2"]) do
       insist { subject.get("tags") } == ["t1", "t2", "test"]
     end
   end
@@ -107,11 +109,11 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop") do
+    sample_one("type" => "noop") do
       insist { subject.get("tags") } == ["bar"]
     end
 
-    sample("type" => "noop", "tags" => "foo") do
+    sample_one("type" => "noop", "tags" => "foo") do
       insist { subject.get("tags") } == ["foo", "bar"]
     end
   end
@@ -125,7 +127,7 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop", "tags" => "foo") do
+    sample_one("type" => "noop", "tags" => "foo") do
       # this is completely weird but seems to be already expected in other specs
       insist { subject.get("tags") } == ["foo", "foo"]
     end
@@ -140,19 +142,19 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop") do
+    sample_one("type" => "noop") do
       insist { subject.get("tags") } == ["test"]
     end
 
-    sample("type" => "noop", "tags" => ["t1"]) do
+    sample_one("type" => "noop", "tags" => ["t1"]) do
       insist { subject.get("tags") } == ["t1", "test"]
     end
 
-    sample("type" => "noop", "tags" => ["t1", "t2"]) do
+    sample_one("type" => "noop", "tags" => ["t1", "t2"]) do
       insist { subject.get("tags") } == ["t1", "t2", "test"]
     end
 
-    sample("type" => "noop", "tags" => ["t1", "t2", "t3"]) do
+    sample_one("type" => "noop", "tags" => ["t1", "t2", "t3"]) do
       insist { subject.get("tags") } == ["t1", "t2", "t3", "test"]
     end
   end
@@ -166,39 +168,39 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop", "tags" => "foo") do
+    sample_one("type" => "noop", "tags" => "foo") do
       insist { subject.get("tags") } == ["foo"]
     end
 
-    sample("type" => "noop", "tags" => "t2") do
+    sample_one("type" => "noop", "tags" => "t2") do
       insist { subject.get("tags") } == []
     end
 
-    sample("type" => "noop", "tags" => ["t2"]) do
+    sample_one("type" => "noop", "tags" => ["t2"]) do
       insist { subject.get("tags") } == []
     end
 
-    sample("type" => "noop", "tags" => ["t4"]) do
+    sample_one("type" => "noop", "tags" => ["t4"]) do
       insist { subject.get("tags") } == ["t4"]
     end
 
-    sample("type" => "noop", "tags" => ["t1", "t2", "t3"]) do
+    sample_one("type" => "noop", "tags" => ["t1", "t2", "t3"]) do
       insist { subject.get("tags") } == ["t1"]
     end
 
     # also test from Json deserialized data to test the handling of native Java collections by JrJackson
     # see https://github.com/elastic/logstash/issues/2261
-    sample(LogStash::Json.load("{\"type\":\"noop\", \"tags\":[\"t1\", \"t2\", \"t3\"]}")) do
+    sample_one(LogStash::Json.load("{\"type\":\"noop\", \"tags\":[\"t1\", \"t2\", \"t3\"]}")) do
       insist { subject.get("tags") } == ["t1"]
     end
 
-    sample("type" => "noop", "tags" => ["t1", "t2"]) do
+    sample_one("type" => "noop", "tags" => ["t1", "t2"]) do
       insist { subject.get("tags") } == ["t1"]
     end
 
     # also test from Json deserialized data to test the handling of native Java collections by JrJackson
     # see https://github.com/elastic/logstash/issues/2261
-    sample(LogStash::Json.load("{\"type\":\"noop\", \"tags\":[\"t1\", \"t2\"]}")) do
+    sample_one(LogStash::Json.load("{\"type\":\"noop\", \"tags\":[\"t1\", \"t2\"]}")) do
       insist { subject.get("tags") } == ["t1"]
     end
   end
@@ -212,13 +214,13 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop", "tags" => ["t1", "goaway", "t3"], "blackhole" => "goaway") do
+    sample_one("type" => "noop", "tags" => ["t1", "goaway", "t3"], "blackhole" => "goaway") do
       insist { subject.get("tags") } == ["t1", "t3"]
     end
 
     # also test from Json deserialized data to test the handling of native Java collections by JrJackson
     # see https://github.com/elastic/logstash/issues/2261
-    sample(LogStash::Json.load("{\"type\":\"noop\", \"tags\":[\"t1\", \"goaway\", \"t3\"], \"blackhole\":\"goaway\"}")) do
+    sample_one(LogStash::Json.load("{\"type\":\"noop\", \"tags\":[\"t1\", \"goaway\", \"t3\"], \"blackhole\":\"goaway\"}")) do
       insist { subject.get("tags") } == ["t1", "t3"]
     end
   end
@@ -232,17 +234,17 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop", "t4" => "four") do
+    sample_one("type" => "noop", "t4" => "four") do
       insist { subject }.include?("t4")
     end
 
-    sample("type" => "noop", "t1" => "one", "t2" => "two", "t3" => "three") do
+    sample_one("type" => "noop", "t1" => "one", "t2" => "two", "t3" => "three") do
       insist { subject }.include?("t1")
       reject { subject }.include?("t2")
       reject { subject }.include?("t3")
     end
 
-    sample("type" => "noop", "t1" => "one", "t2" => "two") do
+    sample_one("type" => "noop", "t1" => "one", "t2" => "two") do
       insist { subject }.include?("t1")
       reject { subject }.include?("t2")
     end
@@ -257,7 +259,7 @@ def filter(event)
     }
     CONFIG
 
-    sample("tags" => "foo") do
+    sample_one("tags" => "foo") do
       reject { subject }.include?("tags")
     end
   end
@@ -271,7 +273,7 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop", "t1" => {"t2" => "two", "t3" => "three"}) do
+    sample_one("type" => "noop", "t1" => {"t2" => "two", "t3" => "three"}) do
       insist { subject }.include?("t1")
       reject { subject }.include?("[t1][t2]")
       insist { subject }.include?("[t1][t3]")
@@ -287,7 +289,7 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop", "t1" => ["t2", "t3"]) do
+    sample_one("type" => "noop", "t1" => ["t2", "t3"]) do
       insist { subject }.include?("t1")
       insist { subject.get("[t1][0]") } == "t3"
     end
@@ -302,7 +304,7 @@ def filter(event)
     }
     CONFIG
 
-    sample("type" => "noop", "blackhole" => "go", "go" => "away") do
+    sample_one("type" => "noop", "blackhole" => "go", "go" => "away") do
       insist { subject }.include?("blackhole")
       reject { subject }.include?("go")
     end
diff --git a/logstash-core/spec/logstash/pipeline_spec.rb b/logstash-core/spec/logstash/pipeline_spec.rb
index 5be9567dba3..e2188380d20 100644
--- a/logstash-core/spec/logstash/pipeline_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_spec.rb
@@ -5,6 +5,7 @@
 require_relative "../support/mocks_classes"
 require_relative "../support/helpers"
 require_relative "../logstash/pipeline_reporter_spec" # for DummyOutput class
+require 'support/pipeline/pipeline_helpers'
 require "stud/try"
 require 'timeout'
 
@@ -388,6 +389,7 @@ class TestPipeline < LogStash::Pipeline
   end
 
   context "compiled flush function" do
+    extend PipelineHelpers
     describe "flusher thread" do
       before(:each) do
         allow(LogStash::Plugin).to receive(:lookup).with("input", "dummyinput").and_return(DummyInput)
@@ -415,7 +417,7 @@ class TestPipeline < LogStash::Pipeline
         }
       CONFIG
 
-      sample("hello") do
+      sample_one("hello") do
         expect(subject).to eq(nil)
       end
     end
@@ -428,7 +430,8 @@ class TestPipeline < LogStash::Pipeline
           }
         }
       CONFIG
-      sample(["foo", "bar"]) do
+
+      sample_one(["foo", "bar"]) do
         expect(subject.size).to eq(4)
       end
     end
@@ -474,6 +477,7 @@ class TestPipeline < LogStash::Pipeline
 
   context "compiled filter functions" do
     context "new events should propagate down the filters" do
+      extend PipelineHelpers
       config <<-CONFIG
         filter {
           clone {
@@ -485,7 +489,7 @@ class TestPipeline < LogStash::Pipeline
         }
       CONFIG
 
-      sample("hello") do
+      sample_one("hello") do
         expect(subject.size).to eq(3)
 
         expect(subject[0].get("message")).to eq("hello")
@@ -592,38 +596,6 @@ class TestPipeline < LogStash::Pipeline
     end
   end
 
-  context "Multiples pipelines" do
-    before do
-      allow(LogStash::Plugin).to receive(:lookup).with("input", "dummyinputgenerator").and_return(DummyInputGenerator)
-      allow(LogStash::Plugin).to receive(:lookup).with("codec", "plain").and_return(DummyCodec)
-      allow(LogStash::Plugin).to receive(:lookup).with("filter", "dummyfilter").and_return(DummyFilter)
-      allow(LogStash::Plugin).to receive(:lookup).with("output", "dummyoutput").and_return(::LogStash::Outputs::DummyOutput)
-      allow(LogStash::Plugin).to receive(:lookup).with("output", "dummyoutputmore").and_return(DummyOutputMore)
-    end
-
-    # multiple pipelines cannot be instantiated using the same PQ settings, force memory queue
-    before :each do
-      pipeline_workers_setting = LogStash::SETTINGS.get_setting("queue.type")
-      allow(pipeline_workers_setting).to receive(:value).and_return("memory")
-      pipeline_settings.each {|k, v| pipeline_settings_obj.set(k, v) }
-    end
-
-    let(:pipeline1) { mock_pipeline_from_string("input { dummyinputgenerator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
-    let(:pipeline2) { mock_pipeline_from_string("input { dummyinputgenerator {} } filter { dummyfilter {} } output { dummyoutputmore {}}") }
-
-    after  do
-      pipeline1.close
-      pipeline2.close
-    end
-
-    it "should handle evaluating different config" do
-      expect(pipeline1.output_func(LogStash::Event.new)).not_to include(nil)
-      expect(pipeline1.filter_func(LogStash::Event.new)).not_to include(nil)
-      expect(pipeline2.output_func(LogStash::Event.new)).not_to include(nil)
-      expect(pipeline1.filter_func(LogStash::Event.new)).not_to include(nil)
-    end
-  end
-
   context "Periodic Flush" do
     let(:config) do
       <<-EOS
@@ -670,42 +642,6 @@ class TestPipeline < LogStash::Pipeline
     end
   end
 
-  context "Multiple pipelines" do
-    before do
-      allow(LogStash::Plugin).to receive(:lookup).with("input", "generator").and_return(LogStash::Inputs::Generator)
-      allow(LogStash::Plugin).to receive(:lookup).with("codec", "plain").and_return(DummyCodec)
-      allow(LogStash::Plugin).to receive(:lookup).with("filter", "dummyfilter").and_return(DummyFilter)
-      allow(LogStash::Plugin).to receive(:lookup).with("output", "dummyoutput").and_return(::LogStash::Outputs::DummyOutput)
-    end
-
-    let(:pipeline1) { mock_pipeline_from_string("input { generator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
-    let(:pipeline2) { mock_pipeline_from_string("input { generator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
-
-    # multiple pipelines cannot be instantiated using the same PQ settings, force memory queue
-    before :each do
-      pipeline_workers_setting = LogStash::SETTINGS.get_setting("queue.type")
-      allow(pipeline_workers_setting).to receive(:value).and_return("memory")
-      pipeline_settings.each {|k, v| pipeline_settings_obj.set(k, v) }
-    end
-
-    it "should handle evaluating different config" do
-      # When the functions are compiled from the AST it will generate instance
-      # variables that are unique to the actual config, the instances are pointing
-      # to conditionals and/or plugins.
-      #
-      # Before the `defined_singleton_method`, the definition of the method was
-      # not unique per class, but the `instance variables` were unique per class.
-      #
-      # So the methods were trying to access instance variables that did not exist
-      # in the current instance and was returning an array containing nil values for
-      # the match.
-      expect(pipeline1.output_func(LogStash::Event.new)).not_to include(nil)
-      expect(pipeline1.filter_func(LogStash::Event.new)).not_to include(nil)
-      expect(pipeline2.output_func(LogStash::Event.new)).not_to include(nil)
-      expect(pipeline1.filter_func(LogStash::Event.new)).not_to include(nil)
-    end
-  end
-
   context "#started_at" do
     # use a run limiting count to shutdown the pipeline automatically
     let(:config) do
diff --git a/logstash-core/spec/support/pipeline/pipeline_helpers.rb b/logstash-core/spec/support/pipeline/pipeline_helpers.rb
new file mode 100644
index 00000000000..1f0e6982063
--- /dev/null
+++ b/logstash-core/spec/support/pipeline/pipeline_helpers.rb
@@ -0,0 +1,97 @@
+require "logstash/agent"
+require "logstash/pipeline"
+require "logstash/event"
+require "stud/try"
+require "rspec/expectations"
+require "thread"
+
+java_import org.logstash.common.SourceWithMetadata
+
+module PipelineHelpers
+
+  class SpecSamplerInput < LogStash::Inputs::Base
+    config_name "spec_sampler_input"
+
+    def register
+    end
+
+    def run(queue)
+      unless @@event.nil?
+        queue.push_batch(@@event)
+        @@event = nil
+      end
+    end
+
+    def close
+      @@event = nil
+    end
+
+    def self.set_event(event)
+      @@event = event
+    end
+  end
+
+  class SpecSamplerOutput < LogStash::Outputs::Base
+    config_name "spec_sampler_output"
+
+    def register
+      @@seen = []
+    end
+
+    def multi_receive(events)
+      @@seen += events
+    end
+
+    def self.seen
+      @@seen
+    end
+  end
+
+  def sample_one(sample_event, &block)
+    name = sample_event.is_a?(String) ? sample_event : LogStash::Json.dump(sample_event)
+    name = name[0..50] + "..." if name.length > 50
+
+    before do
+      LogStash::PLUGIN_REGISTRY.add(:input, "spec_sampler_input", SpecSamplerInput)
+      LogStash::PLUGIN_REGISTRY.add(:output, "spec_sampler_output", SpecSamplerOutput)
+    end
+
+    describe "\"#{name}\"" do
+      let(:pipeline) do
+        settings = ::LogStash::SETTINGS.clone
+        settings.set_value("queue.drain", true)
+        settings.set_value("pipeline.workers", 1)
+        LogStash::Pipeline.new(
+          LogStash::Config::PipelineConfig.new(
+            LogStash::Config::Source::Local, :main,
+            SourceWithMetadata.new(
+              "config_string", "config_string",
+              "input { spec_sampler_input {} }\n" + config + "\noutput { spec_sampler_output {} }"
+            ), settings
+          )
+        )
+      end
+      let(:event) do
+        sample_event = [sample_event] unless sample_event.is_a?(Array)
+        next sample_event.collect do |e|
+          e = { "message" => e } if e.is_a?(String)
+          next LogStash::Event.new(e)
+        end
+      end
+
+      let(:results) do
+        SpecSamplerInput.set_event event
+        pipeline.run
+        SpecSamplerOutput.seen
+      end
+
+      after do
+        pipeline.close
+      end
+
+      subject {results.length > 1 ? results : results.first}
+
+      it("when processed", &block)
+    end
+  end
+end
diff --git a/logstash-core/src/main/java/org/logstash/ObjectMappers.java b/logstash-core/src/main/java/org/logstash/ObjectMappers.java
index ff284804764..8e7b4a91f34 100644
--- a/logstash-core/src/main/java/org/logstash/ObjectMappers.java
+++ b/logstash-core/src/main/java/org/logstash/ObjectMappers.java
@@ -23,6 +23,7 @@
 import org.jruby.RubyString;
 import org.jruby.RubySymbol;
 import org.jruby.ext.bigdecimal.RubyBigDecimal;
+import org.jruby.util.ByteList;
 import org.logstash.ext.JrubyTimestampExtLibrary;
 
 public final class ObjectMappers {
@@ -40,7 +41,8 @@ public final class ObjectMappers {
     private static final SimpleModule CBOR_DESERIALIZERS =
         new SimpleModule("CborRubyDeserializers")
             .addDeserializer(RubyBigDecimal.class, new RubyBigDecimalDeserializer())
-            .addDeserializer(RubyBignum.class, new RubyBignumDeserializer());
+            .addDeserializer(RubyBignum.class, new RubyBignumDeserializer())
+            .addDeserializer(RubyString.class, new RubyStringDeserializer());
 
     public static final ObjectMapper JSON_MAPPER = 
         new ObjectMapper().registerModule(RUBY_SERIALIZERS);
@@ -63,8 +65,7 @@ private ObjectMappers() {
      * Serializer for {@link RubyString} since Jackson can't handle that type natively, so we
      * simply serialize it as if it were a {@link String}.
      */
-    private static final class RubyStringSerializer
-        extends NonTypedScalarSerializerBase<RubyString> {
+    private static final class RubyStringSerializer extends StdSerializer<RubyString> {
 
         RubyStringSerializer() {
             super(RubyString.class, true);
@@ -76,6 +77,28 @@ public void serialize(final RubyString value, final JsonGenerator generator,
             throws IOException {
             generator.writeString(value.asJavaString());
         }
+
+        @Override
+        public void serializeWithType(final RubyString value, final JsonGenerator jgen,
+            final SerializerProvider serializers, final TypeSerializer typeSer) throws IOException {
+            typeSer.writeTypePrefixForScalar(value, jgen, RubyString.class);
+            final ByteList bytes = value.getByteList();
+            jgen.writeBinary(bytes.getUnsafeBytes(), 0, bytes.length());
+            typeSer.writeTypeSuffixForScalar(value, jgen);
+        }
+    }
+
+    public static final class RubyStringDeserializer extends StdDeserializer<RubyString> {
+
+        RubyStringDeserializer() {
+            super(RubyString.class);
+        }
+
+        @Override
+        public RubyString deserialize(final JsonParser p, final DeserializationContext ctxt)
+            throws IOException {
+            return RubyString.newString(RubyUtil.RUBY, p.getBinaryValue());
+        }
     }
 
     /**
@@ -91,8 +114,7 @@ private static final class RubySymbolSerializer
 
         @Override
         public void serialize(final RubySymbol value, final JsonGenerator generator,
-            final SerializerProvider provider)
-            throws IOException {
+            final SerializerProvider provider) throws IOException {
             generator.writeString(value.asJavaString());
         }
     }
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/CompiledPipeline.java b/logstash-core/src/main/java/org/logstash/config/ir/CompiledPipeline.java
new file mode 100644
index 00000000000..e9b3d3d2ffc
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/config/ir/CompiledPipeline.java
@@ -0,0 +1,382 @@
+package org.logstash.config.ir;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.Objects;
+import java.util.stream.Collectors;
+import org.jruby.RubyHash;
+import org.jruby.runtime.builtin.IRubyObject;
+import org.logstash.RubyUtil;
+import org.logstash.Rubyfier;
+import org.logstash.common.SourceWithMetadata;
+import org.logstash.config.ir.compiler.Dataset;
+import org.logstash.config.ir.compiler.EventCondition;
+import org.logstash.config.ir.compiler.RubyIntegration;
+import org.logstash.config.ir.graph.IfVertex;
+import org.logstash.config.ir.graph.PluginVertex;
+import org.logstash.config.ir.graph.Vertex;
+import org.logstash.config.ir.imperative.PluginStatement;
+import org.logstash.ext.JrubyEventExtLibrary;
+
+/**
+ * <h3>Compiled Logstash Pipeline Configuration.</h3>
+ * This class represents an executable pipeline, compiled from the configured topology that is
+ * learnt from {@link PipelineIR}.
+ * Each compiled pipeline consists in graph of {@link Dataset} that represent either a
+ * {@code filter}, {@code output} or an {@code if} condition.
+ */
+public final class CompiledPipeline {
+
+    /**
+     * Configured inputs.
+     */
+    private final Collection<IRubyObject> inputs;
+
+    /**
+     * Configured Filters, indexed by their ID as returned by {@link PluginVertex#getId()}.
+     */
+    private final Map<String, RubyIntegration.Filter> filters;
+
+    /**
+     * Immutable collection of filters that flush on shutdown.
+     */
+    private final Collection<RubyIntegration.Filter> shutdownFlushes;
+
+    /**
+     * Immutable collection of filters that flush periodically.
+     */
+    private final Collection<RubyIntegration.Filter> periodicFlushes;
+
+    /**
+     * Configured outputs.
+     */
+    private final Map<String, RubyIntegration.Output> outputs;
+
+    /**
+     * Parsed pipeline configuration graph.
+     */
+    private final PipelineIR pipelineIR;
+
+    /**
+     * Ruby pipeline object.
+     */
+    private final RubyIntegration.Pipeline pipeline;
+
+    public CompiledPipeline(final PipelineIR pipelineIR, final RubyIntegration.Pipeline pipeline) {
+        this.pipelineIR = pipelineIR;
+        this.pipeline = pipeline;
+        inputs = setupInputs();
+        filters = setupFilters();
+        outputs = setupOutputs();
+        shutdownFlushes = Collections.unmodifiableList(
+            filters.values().stream().filter(RubyIntegration.Filter::hasFlush)
+                .collect(Collectors.toList())
+        );
+        periodicFlushes = Collections.unmodifiableList(
+            shutdownFlushes.stream().filter(RubyIntegration.Filter::periodicFlush)
+                .collect(Collectors.toList())
+        );
+    }
+
+    public Collection<RubyIntegration.Filter> shutdownFlushers() {
+        return shutdownFlushes;
+    }
+
+    public Collection<RubyIntegration.Filter> periodicFlushers() {
+        return periodicFlushes;
+    }
+
+    public Collection<RubyIntegration.Output> outputs() {
+        return Collections.unmodifiableCollection(outputs.values());
+    }
+
+    public Collection<RubyIntegration.Filter> filters() {
+        return Collections.unmodifiableCollection(filters.values());
+    }
+
+    public Collection<IRubyObject> inputs() {
+        return inputs;
+    }
+
+    public RubyIntegration.Plugin registerPlugin(final RubyIntegration.Plugin plugin) {
+        plugin.register();
+        return plugin;
+    }
+
+    /**
+     * This method contains the actual compilation of the {@link Dataset} representing the
+     * underlying pipeline from the Queue to the outputs.
+     * @return Compiled {@link Dataset} representation of the underlying {@link PipelineIR} topology
+     */
+    public Dataset buildExecution() {
+        return new CompiledPipeline.CompiledExecution().toDataset();
+    }
+
+    /**
+     * Sets up all Ruby outputs learnt from {@link PipelineIR}.
+     */
+    private Map<String, RubyIntegration.Output> setupOutputs() {
+        final Collection<PluginVertex> outs = pipelineIR.getOutputPluginVertices();
+        final Map<String, RubyIntegration.Output> res = new HashMap<>(outs.size());
+        outs.forEach(v -> {
+            final PluginDefinition def = v.getPluginDefinition();
+            final SourceWithMetadata source = v.getSourceWithMetadata();
+            res.put(v.getId(), pipeline.buildOutput(
+                RubyUtil.RUBY.newString(def.getName()), RubyUtil.RUBY.newFixnum(source.getLine()),
+                RubyUtil.RUBY.newFixnum(source.getColumn()), convertArgs(def)
+            ));
+        });
+        return res;
+    }
+
+    /**
+     * Sets up all Ruby filters learnt from {@link PipelineIR}.
+     */
+    private Map<String, RubyIntegration.Filter> setupFilters() {
+        final Collection<PluginVertex> filterPlugins = pipelineIR.getFilterPluginVertices();
+        final Map<String, RubyIntegration.Filter> res =
+            new HashMap<>(filterPlugins.size(), 1.0F);
+        for (final PluginVertex plugin : filterPlugins) {
+            res.put(plugin.getId(), buildFilter(plugin));
+        }
+        return res;
+    }
+
+    /**
+     * Sets up all Ruby inputs learnt from {@link PipelineIR}.
+     */
+    private Collection<IRubyObject> setupInputs() {
+        final Collection<PluginVertex> vertices = pipelineIR.getInputPluginVertices();
+        final Collection<IRubyObject> nodes = new HashSet<>(vertices.size());
+        vertices.forEach(v -> {
+            final PluginDefinition def = v.getPluginDefinition();
+            final SourceWithMetadata source = v.getSourceWithMetadata();
+            nodes.add(pipeline.buildInput(
+                RubyUtil.RUBY.newString(def.getName()), RubyUtil.RUBY.newFixnum(source.getLine()),
+                RubyUtil.RUBY.newFixnum(source.getColumn()), convertArgs(def)
+            ));
+        });
+        return nodes;
+    }
+
+    /**
+     * Converts plugin arguments from the format provided by {@link PipelineIR} into coercible
+     * Ruby types.
+     * @param def PluginDefinition as provided by {@link PipelineIR}
+     * @return RubyHash of plugin arguments as understood by {@link RubyIntegration.Pipeline}
+     * methods
+     */
+    private RubyHash convertArgs(final PluginDefinition def) {
+        final RubyHash converted = RubyHash.newHash(RubyUtil.RUBY);
+        for (final Map.Entry<String, Object> entry : def.getArguments().entrySet()) {
+            final Object value = entry.getValue();
+            final String key = entry.getKey();
+            final Object toput;
+            if (value instanceof PluginStatement) {
+                final PluginDefinition codec = ((PluginStatement) value).getPluginDefinition();
+                toput = pipeline.buildCodec(
+                    RubyUtil.RUBY.newString(codec.getName()),
+                    Rubyfier.deep(RubyUtil.RUBY, codec.getArguments())
+                );
+            } else {
+                toput = value;
+            }
+            converted.put(key, toput);
+        }
+        return converted;
+    }
+
+    /**
+     * Compiles a {@link RubyIntegration.Filter} from a given {@link PluginVertex}.
+     * @param vertex Filter {@link PluginVertex}
+     * @return Compiled {@link RubyIntegration.Filter}
+     */
+    private RubyIntegration.Filter buildFilter(final PluginVertex vertex) {
+        final PluginDefinition def = vertex.getPluginDefinition();
+        final SourceWithMetadata source = vertex.getSourceWithMetadata();
+        return pipeline.buildFilter(
+            RubyUtil.RUBY.newString(def.getName()), RubyUtil.RUBY.newFixnum(source.getLine()),
+            RubyUtil.RUBY.newFixnum(source.getColumn()), convertArgs(def)
+        );
+    }
+
+    /**
+     * Checks if a certain {@link Vertex} represents a {@link RubyIntegration.Filter}.
+     * @param vertex Vertex to check
+     * @return True iff {@link Vertex} represents a {@link RubyIntegration.Filter}
+     */
+    private boolean isFilter(final Vertex vertex) {
+        return filters.containsKey(vertex.getId());
+    }
+
+    /**
+     * Checks if a certain {@link Vertex} represents a {@link RubyIntegration.Output}.
+     * @param vertex Vertex to check
+     * @return True iff {@link Vertex} represents a {@link RubyIntegration.Output}
+     */
+    private boolean isOutput(final Vertex vertex) {
+        return outputs.containsKey(vertex.getId());
+    }
+
+    /**
+     * Compiles an {@link IfVertex} into an {@link EventCondition}.
+     * @param iff IfVertex to build condition for
+     * @return EventCondition for given {@link IfVertex}
+     */
+    private static EventCondition buildCondition(final IfVertex iff) {
+        return EventCondition.Compiler.buildCondition(iff.getBooleanExpression());
+    }
+
+    /**
+     * Instances of this class represent a fully compiled pipeline execution. Note that this class
+     * has a separate lifecycle from {@link CompiledPipeline} because it holds per (worker-thread) 
+     * state and thus needs to be instantiated once per thread.
+     */
+    private final class CompiledExecution {
+
+        /**
+         * Compiled {@link IfVertex, indexed by their ID as returned by {@link Vertex#getId()}.
+         */
+        private final Map<String, Dataset.SplitDataset> iffs = new HashMap<>(5);
+
+        /**
+         * Cached {@link Dataset} compiled from {@link PluginVertex} indexed by their ID as returned
+         * by {@link Vertex#getId()} to avoid duplicate computations.
+         */
+        private final Map<String, Dataset> plugins = new HashMap<>(5);
+
+        private final Dataset compiled;
+
+        CompiledExecution() {
+            compiled = compile();
+        }
+
+        Dataset toDataset() {
+            return compiled;
+        }
+
+        /**
+         * Instantiates the graph of compiled {@link Dataset}.
+         * @return Compiled {@link Dataset} representing the pipeline.
+         */
+        private Dataset compile() {
+            final Collection<Dataset> datasets = new ArrayList<>();
+            pipelineIR.getGraph()
+                .allLeaves()
+                .filter(CompiledPipeline.this::isOutput)
+                .forEach(leaf -> datasets.add(
+                    outputDataset(leaf.getId(), flatten(Dataset.ROOT_DATASETS, leaf))
+                    )
+                );
+            return Dataset.TerminalDataset.from(datasets);
+        }
+
+        /**
+         * Build a {@link Dataset} representing the {@link JrubyEventExtLibrary.RubyEvent}s after
+         * the application of the given filter.
+         * @param vertex Vertex Id of the filter to create this {@link Dataset} for
+         * @param datasets All the datasets that pass through this filter
+         * @return Filter {@link Dataset}
+         */
+        private Dataset filterDataset(final String vertex, final Collection<Dataset> datasets) {
+            return plugins.computeIfAbsent(vertex, v -> {
+                final Dataset filter;
+                final RubyIntegration.Filter ruby = filters.get(v);
+                if (ruby.hasFlush()) {
+                    if (ruby.periodicFlush()) {
+                        filter = new Dataset.FilteredFlushableDataset(datasets, ruby);
+                    } else {
+                        filter = new Dataset.FilteredShutdownFlushableDataset(datasets, ruby);
+                    }
+                } else {
+                    filter = new Dataset.FilteredDataset(datasets, ruby);
+                }
+                return filter;
+            });
+        }
+
+        /**
+         * Build a {@link Dataset} representing the {@link JrubyEventExtLibrary.RubyEvent}s after
+         * the application of the given output.
+         * @param vertexId Vertex Id of the filter to create this {@link Dataset} for
+         * filter node in the topology once
+         * @param datasets All the datasets that are passed into this output
+         * @return Output {@link Dataset}
+         */
+        private Dataset outputDataset(final String vertexId, final Collection<Dataset> datasets) {
+            return plugins.computeIfAbsent(
+                vertexId, v -> new Dataset.OutputDataset(datasets, outputs.get(v))
+            );
+        }
+
+        /**
+         * Split the given {@link Dataset}s and return the dataset half of their elements that contains
+         * the {@link JrubyEventExtLibrary.RubyEvent} that fulfil the given {@link EventCondition}.
+         * @param datasets Datasets to split
+         * @param condition Condition that must be fulfilled
+         * @param index Vertex id to cache the resulting {@link Dataset} under
+         * @return The half of the datasets contents that fulfils the condition
+         */
+        private Dataset.SplitDataset split(final Collection<Dataset> datasets,
+            final EventCondition condition, final String index) {
+            return iffs
+                .computeIfAbsent(index, ind -> new Dataset.SplitDataset(datasets, condition));
+        }
+
+        /**
+         * Compiles the next level of the execution from the given {@link Vertex} or simply return
+         * the given {@link Dataset} at the previous level if the starting {@link Vertex} cannot
+         * be expanded any further (i.e. doesn't have any more incoming vertices that are either
+         * a {code filter} or and {code if} statement).
+         * @param datasets Nodes from the last already compiled level
+         * @param start Vertex to compile children for
+         * @return Datasets originating from given {@link Vertex}
+         */
+        private Collection<Dataset> flatten(final Collection<Dataset> datasets,
+            final Vertex start) {
+            final Collection<Vertex> dependencies = start.incomingVertices()
+                .filter(v -> isFilter(v) || isOutput(v) || v instanceof IfVertex)
+                .collect(Collectors.toList());
+            return dependencies.isEmpty() ? datasets
+                : compileDependencies(start, datasets, dependencies);
+        }
+
+        /**
+         * Compiles all child vertices for a given vertex.
+         * @param datasets Datasets from previous stage
+         * @param start Start Vertex that got expanded
+         * @param dependencies Dependencies of {@code start}
+         * @return Datasets compiled from vertex children
+         */
+        private Collection<Dataset> compileDependencies(final Vertex start,
+            final Collection<Dataset> datasets, final Collection<Vertex> dependencies) {
+            return dependencies.stream().map(
+                dependency -> {
+                    final Collection<Dataset> transientDependencies = flatten(datasets, dependency);
+                    if (isFilter(dependency)) {
+                        return filterDataset(dependency.getId(), transientDependencies);
+                    } else if (isOutput(dependency)) {
+                        return outputDataset(dependency.getId(), transientDependencies);
+                    } else {
+                        // We know that it's an if vertex since the the input children are either 
+                        // output, filter or if in type.
+                        final IfVertex ifvert = (IfVertex) dependency;
+                        final EventCondition iff = buildCondition(ifvert);
+                        final String index = ifvert.getId();
+                        // It is important that we double check that we are actually dealing with the
+                        // positive/left branch of the if condition
+                        if (ifvert.getOutgoingBooleanEdgesByType(true).stream()
+                            .anyMatch(edge -> Objects.equals(edge.getTo(), start))) {
+                            return split(transientDependencies, iff, index);
+                        } else {
+                            return split(transientDependencies, iff, index).right();
+                        }
+                    }
+                }).collect(Collectors.toList());
+        }
+    }
+}
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/DSL.java b/logstash-core/src/main/java/org/logstash/config/ir/DSL.java
index 4d193e56f70..1b878dd667e 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/DSL.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/DSL.java
@@ -1,18 +1,36 @@
 package org.logstash.config.ir;
 
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.Map;
 import org.logstash.common.SourceWithMetadata;
-import org.logstash.config.ir.expression.*;
-import org.logstash.config.ir.expression.binary.*;
+import org.logstash.config.ir.expression.BooleanExpression;
+import org.logstash.config.ir.expression.EventValueExpression;
+import org.logstash.config.ir.expression.Expression;
+import org.logstash.config.ir.expression.RegexValueExpression;
+import org.logstash.config.ir.expression.ValueExpression;
+import org.logstash.config.ir.expression.binary.And;
+import org.logstash.config.ir.expression.binary.Eq;
+import org.logstash.config.ir.expression.binary.Gt;
+import org.logstash.config.ir.expression.binary.Gte;
+import org.logstash.config.ir.expression.binary.In;
+import org.logstash.config.ir.expression.binary.Lt;
+import org.logstash.config.ir.expression.binary.Lte;
+import org.logstash.config.ir.expression.binary.Neq;
+import org.logstash.config.ir.expression.binary.Or;
+import org.logstash.config.ir.expression.binary.RegexEq;
 import org.logstash.config.ir.expression.unary.Not;
 import org.logstash.config.ir.expression.unary.Truthy;
 import org.logstash.config.ir.graph.Graph;
 import org.logstash.config.ir.graph.IfVertex;
 import org.logstash.config.ir.graph.PluginVertex;
-import org.logstash.config.ir.imperative.*;
-
-import java.util.Arrays;
-import java.util.HashMap;
-import java.util.Map;
+import org.logstash.config.ir.imperative.ComposedParallelStatement;
+import org.logstash.config.ir.imperative.ComposedSequenceStatement;
+import org.logstash.config.ir.imperative.ComposedStatement;
+import org.logstash.config.ir.imperative.IfStatement;
+import org.logstash.config.ir.imperative.NoopStatement;
+import org.logstash.config.ir.imperative.PluginStatement;
+import org.logstash.config.ir.imperative.Statement;
 
 /**
  * Created by andrewvc on 9/15/16.
@@ -107,6 +125,10 @@ public static And eAnd(Expression left, Expression right) {
         return new And(null, left, right);
     }
 
+    public static Not eNand(Expression left, Expression right) throws InvalidIRException {
+        return eNot(eAnd(left, right));
+    }
+
     public static Or eOr(SourceWithMetadata meta, Expression left, Expression right) {
         return new Or(meta, left, right);
     }
@@ -115,6 +137,10 @@ public static Or eOr(Expression left, Expression right) {
         return new Or(null, left, right);
     }
 
+    public static Or eXor(Expression left, Expression right) throws InvalidIRException {
+        return eOr(eAnd(eNot(left), right), eAnd(left, eNot(right)));
+    }
+
     public static RegexEq eRegexEq(SourceWithMetadata meta, Expression left, ValueExpression right) throws InvalidIRException {
         return new RegexEq(meta, left, right);
     }
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java b/logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
index 24623ca8e2e..fe1745ef71e 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
@@ -1,19 +1,19 @@
 package org.logstash.config.ir;
 
+import java.util.List;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
 import org.logstash.common.Util;
 import org.logstash.config.ir.graph.Graph;
 import org.logstash.config.ir.graph.PluginVertex;
 import org.logstash.config.ir.graph.QueueVertex;
 import org.logstash.config.ir.graph.Vertex;
 
-import java.util.List;
-import java.util.stream.Collectors;
-import java.util.stream.Stream;
-
 /**
  * Created by andrewvc on 9/20/16.
  */
-public class PipelineIR implements Hashable {
+public final class PipelineIR implements Hashable {
+
     private String uniqueHash;
 
     public Graph getGraph() {
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/PluginDefinition.java b/logstash-core/src/main/java/org/logstash/config/ir/PluginDefinition.java
index 270c9786977..e4fb708e3a2 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/PluginDefinition.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/PluginDefinition.java
@@ -11,7 +11,7 @@
 /**
  * Created by andrewvc on 9/20/16.
  */
-public class PluginDefinition implements SourceComponent, HashableWithSource {
+public final class PluginDefinition implements SourceComponent, HashableWithSource {
 
     @Override
     public String hashSource() {
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/compiler/Dataset.java b/logstash-core/src/main/java/org/logstash/config/ir/compiler/Dataset.java
new file mode 100644
index 00000000000..a6b5d61215d
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/config/ir/compiler/Dataset.java
@@ -0,0 +1,468 @@
+package org.logstash.config.ir.compiler;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import org.jruby.RubyArray;
+import org.jruby.RubyHash;
+import org.logstash.RubyUtil;
+import org.logstash.ext.JrubyEventExtLibrary;
+
+/**
+ * <p>A data structure backed by a {@link RubyArray} that represents one step of execution flow of a 
+ * batch is lazily filled with {@link JrubyEventExtLibrary.RubyEvent} computed from its dependent
+ * {@link Dataset}.</p>
+ * <p>Each {@link Dataset} either represents a filter, output or one branch of an {@code if}
+ * statement in a Logstash configuration file.</p>
+ * <p>Note: It does seem more natural to use the {@code clear} invocation to set the next
+ * batch of input data. For now this is intentionally not implemented since we want to clear
+ * the data stored in the Dataset tree as early as possible and before the output operations
+ * finish. Once the whole execution tree including the output operation is implemented in
+ * Java, this API can be adjusted as such.</p>
+ */
+public interface Dataset {
+
+    /**
+     * Compute the actual contents of the backing {@link RubyArray} and cache them.
+     * Repeated invocations will be effectively free.
+     * @param batch Input {@link JrubyEventExtLibrary.RubyEvent} received at the root
+     * of the execution
+     * @param flush True if flushing flushable nodes while traversing the execution
+     * @param shutdown True if this is the last call to this instance's compute method because
+     * the pipeline it belongs to is shut down
+     * @return Computed {@link RubyArray} of {@link JrubyEventExtLibrary.RubyEvent}
+     */
+    Collection<JrubyEventExtLibrary.RubyEvent> compute(RubyIntegration.Batch batch,
+        boolean flush, boolean shutdown);
+
+    /**
+     * Removes all data from the instance and all of its parents, making the instance ready for
+     * use with a new set of input data.
+     */
+    void clear();
+
+    /**
+     * Root {@link Dataset}s at the beginning of the execution tree that simply pass through
+     * the given set of {@link JrubyEventExtLibrary.RubyEvent} and have no state.
+     */
+    Collection<Dataset> ROOT_DATASETS = Collections.singleton(
+        new Dataset() {
+            @Override
+            public Collection<JrubyEventExtLibrary.RubyEvent> compute(
+                final RubyIntegration.Batch batch, final boolean flush, final boolean shutdown) {
+                return batch.to_a();
+            }
+
+            @Override
+            public void clear() {
+            }
+        }
+    );
+
+    /**
+     * <p>{@link Dataset} that contains all {@link JrubyEventExtLibrary.RubyEvent} instances of all 
+     * from its dependencies and is assumed to be at the end of an execution.</p>
+     * This dataset does not require an explicit call to {@link Dataset#clear()} since it will
+     * automatically {@code clear} all of its parents.
+     */
+    final class TerminalDataset implements Dataset {
+
+        /**
+         * Empty {@link Collection} returned by this class's
+         * {@link Dataset#compute(RubyIntegration.Batch, boolean, boolean)} implementation.
+         */
+        private static final Collection<JrubyEventExtLibrary.RubyEvent> EMPTY_RETURN =
+            Collections.emptyList();
+
+        /**
+         * Trivial {@link Dataset} that simply returns an empty collection of elements.
+         */
+        private static final Dataset EMPTY_DATASET = new Dataset() {
+
+            @Override
+            public Collection<JrubyEventExtLibrary.RubyEvent> compute(
+                final RubyIntegration.Batch batch, final boolean flush, final boolean shutdown) {
+                return EMPTY_RETURN;
+            }
+
+            @Override
+            public void clear() {
+            }
+        };
+
+        private final Collection<Dataset> parents;
+
+        /**
+         * <p>Builds a terminal {@link Dataset} from the given parent {@link Dataset}s.</p>
+         * <p>If the given set of parent {@link Dataset} is empty the sum is defined as the
+         * trivial dataset that does not invoke any computation whatsoever.</p>
+         * {@link Dataset#compute(RubyIntegration.Batch, boolean, boolean)} is always
+         * {@link Collections#emptyList()}.
+         * @param parents Parent {@link Dataset} to sum and terminate
+         * @return Dataset representing the sum of given parent {@link Dataset}
+         */
+        public static Dataset from(final Collection<Dataset> parents) {
+            final int count = parents.size();
+            final Dataset result;
+            if (count > 0) {
+                result = new Dataset.TerminalDataset(parents);
+            } else {
+                result = EMPTY_DATASET;
+            }
+            return result;
+        }
+
+        private TerminalDataset(final Collection<Dataset> parents) {
+            this.parents = parents;
+        }
+
+        @Override
+        public Collection<JrubyEventExtLibrary.RubyEvent> compute(final RubyIntegration.Batch batch,
+            final boolean flush, final boolean shutdown) {
+            parents.forEach(dataset -> dataset.compute(batch, flush, shutdown));
+            this.clear();
+            return EMPTY_RETURN;
+        }
+
+        @Override
+        public void clear() {
+            for (final Dataset parent : parents) {
+                parent.clear();
+            }
+        }
+
+    }
+
+    /**
+     * {@link Dataset} that results from the {@code if} branch of its backing
+     * {@link EventCondition} being applied to all of its dependencies.
+     */
+    final class SplitDataset implements Dataset {
+
+        private final Collection<Dataset> parents;
+
+        private final EventCondition func;
+
+        private final Collection<JrubyEventExtLibrary.RubyEvent> data;
+
+        private final Collection<JrubyEventExtLibrary.RubyEvent> complement;
+
+        private final Dataset opposite;
+
+        private boolean done;
+
+        public SplitDataset(final Collection<Dataset> parents, final EventCondition func) {
+            this.parents = parents;
+            this.func = func;
+            done = false;
+            data = new ArrayList<>(5);
+            complement = new ArrayList<>(5);
+            opposite = new Dataset.SplitDataset.Complement(this, complement);
+        }
+
+        @Override
+        public Collection<JrubyEventExtLibrary.RubyEvent> compute(final RubyIntegration.Batch batch,
+            final boolean flush, final boolean shutdown) {
+            if (done) {
+                return data;
+            }
+            for (final Dataset set : parents) {
+                for (final JrubyEventExtLibrary.RubyEvent event
+                    : set.compute(batch, flush, shutdown)) {
+                    if (func.fulfilled(event)) {
+                        data.add(event);
+                    } else {
+                        complement.add(event);
+                    }
+                }
+            }
+            done = true;
+            return data;
+        }
+
+        @Override
+        public void clear() {
+            for (final Dataset parent : parents) {
+                parent.clear();
+            }
+            data.clear();
+            complement.clear();
+            done = false;
+        }
+
+        public Dataset right() {
+            return opposite;
+        }
+
+        /**
+         * Complementary {@link Dataset} to a {@link Dataset.SplitDataset} representing the
+         * negative branch of the {@code if} statement.
+         */
+        private static final class Complement implements Dataset {
+
+            /**
+             * Positive branch of underlying {@code if} statement.
+             */
+            private final Dataset parent;
+
+            /**
+             * This collection is shared with {@link Dataset.SplitDataset.Complement#parent} and 
+             * mutated when calling its {@code compute} method. This class does not directly compute
+             * it.
+             */
+            private final Collection<JrubyEventExtLibrary.RubyEvent> data;
+
+            private boolean done;
+
+            /**
+             * Ctor.
+             * @param left Positive Branch {@link Dataset.SplitDataset}
+             * @param complement Collection of {@link JrubyEventExtLibrary.RubyEvent}s that did
+             * not match {@code left}
+             */
+            private Complement(
+                final Dataset left, final Collection<JrubyEventExtLibrary.RubyEvent> complement) {
+                this.parent = left;
+                data = complement;
+            }
+
+            @Override
+            public Collection<JrubyEventExtLibrary.RubyEvent> compute(
+                final RubyIntegration.Batch batch, final boolean flush, final boolean shutdown) {
+                if (done) {
+                    return data;
+                }
+                parent.compute(batch, flush, shutdown);
+                done = true;
+                return data;
+            }
+
+            @Override
+            public void clear() {
+                parent.clear();
+                done = false;
+            }
+        }
+    }
+
+    /**
+     * {@link Dataset} resulting from applying a backing {@link RubyIntegration.Filter} to all
+     * dependent {@link Dataset}.
+     */
+    final class FilteredDataset implements Dataset {
+
+        private final Collection<Dataset> parents;
+
+        private final RubyIntegration.Filter func;
+
+        private final Collection<JrubyEventExtLibrary.RubyEvent> data;
+
+        private final Collection<JrubyEventExtLibrary.RubyEvent> buffer;
+
+        private boolean done;
+
+        public FilteredDataset(Collection<Dataset> parents, final RubyIntegration.Filter func) {
+            this.parents = parents;
+            this.func = func;
+            data = new ArrayList<>(5);
+            buffer = new ArrayList<>(5);
+            done = false;
+        }
+
+        @Override
+        public Collection<JrubyEventExtLibrary.RubyEvent> compute(final RubyIntegration.Batch batch,
+            final boolean flush, final boolean shutdown) {
+            if (done) {
+                return data;
+            }
+            for (final Dataset set : parents) {
+                buffer.addAll(set.compute(batch, flush, shutdown));
+            }
+            done = true;
+            data.addAll(func.multiFilter(buffer));
+            buffer.clear();
+            return data;
+        }
+
+        @Override
+        public void clear() {
+            for (final Dataset parent : parents) {
+                parent.clear();
+            }
+            data.clear();
+            done = false;
+        }
+    }
+
+    /**
+     * {@link Dataset} resulting from applying a backing {@link RubyIntegration.Filter} that flushes
+     * periodically to all dependent {@link Dataset}.
+     */
+    final class FilteredFlushableDataset implements Dataset {
+
+        public static final RubyHash FLUSH_FINAL = flushOpts(true);
+
+        private static final RubyHash FLUSH_NOT_FINAL = flushOpts(false);
+
+        private final Collection<Dataset> parents;
+
+        private final RubyIntegration.Filter func;
+
+        private final Collection<JrubyEventExtLibrary.RubyEvent> data;
+
+        private final Collection<JrubyEventExtLibrary.RubyEvent> buffer;
+
+        private boolean done;
+
+        public FilteredFlushableDataset(Collection<Dataset> parents,
+            final RubyIntegration.Filter func) {
+            this.parents = parents;
+            this.func = func;
+            data = new ArrayList<>(5);
+            buffer = new ArrayList<>(5);
+            done = false;
+        }
+
+        @Override
+        public Collection<JrubyEventExtLibrary.RubyEvent> compute(final RubyIntegration.Batch batch,
+            final boolean flush, final boolean shutdown) {
+            if (done) {
+                return data;
+            }
+            for (final Dataset set : parents) {
+                buffer.addAll(set.compute(batch, flush, shutdown));
+            }
+            done = true;
+            data.addAll(func.multiFilter(buffer));
+            if (flush) {
+                data.addAll(func.flush(shutdown ? FLUSH_FINAL : FLUSH_NOT_FINAL));
+            }
+            buffer.clear();
+            return data;
+        }
+
+        @Override
+        public void clear() {
+            for (final Dataset parent : parents) {
+                parent.clear();
+            }
+            data.clear();
+            done = false;
+        }
+
+        private static RubyHash flushOpts(final boolean fin) {
+            final RubyHash res = RubyHash.newHash(RubyUtil.RUBY);
+            res.put(RubyUtil.RUBY.newSymbol("final"), RubyUtil.RUBY.newBoolean(fin));
+            return res;
+        }
+    }
+
+    /**
+     * {@link Dataset} resulting from applying a backing {@link RubyIntegration.Filter} that does
+     * flush, but only on shutdown, to all dependent {@link Dataset}.
+     */
+    final class FilteredShutdownFlushableDataset implements Dataset {
+
+        private final Collection<Dataset> parents;
+
+        private final RubyIntegration.Filter func;
+
+        private final Collection<JrubyEventExtLibrary.RubyEvent> data;
+
+        private final Collection<JrubyEventExtLibrary.RubyEvent> buffer;
+
+        private boolean done;
+
+        public FilteredShutdownFlushableDataset(Collection<Dataset> parents,
+            final RubyIntegration.Filter func) {
+            this.parents = parents;
+            this.func = func;
+            data = new ArrayList<>(5);
+            buffer = new ArrayList<>(5);
+            done = false;
+        }
+
+        @Override
+        public Collection<JrubyEventExtLibrary.RubyEvent> compute(final RubyIntegration.Batch batch,
+            final boolean flush, final boolean shutdown) {
+            if (done) {
+                return data;
+            }
+            for (final Dataset set : parents) {
+                buffer.addAll(set.compute(batch, flush, shutdown));
+            }
+            done = true;
+            data.addAll(func.multiFilter(buffer));
+            if (flush && shutdown) {
+                data.addAll(func.flush(FilteredFlushableDataset.FLUSH_FINAL));
+            }
+            buffer.clear();
+            return data;
+        }
+
+        @Override
+        public void clear() {
+            for (final Dataset parent : parents) {
+                parent.clear();
+            }
+            data.clear();
+            done = false;
+        }
+    }
+
+    /**
+     * Output {@link Dataset} that passes all its {@link JrubyEventExtLibrary.RubyEvent}
+     * to the underlying {@link RubyIntegration.Output#multiReceive(Collection)}.
+     */
+    final class OutputDataset implements Dataset {
+
+        /**
+         * Empty {@link Collection} returned by this class's
+         * {@link Dataset#compute(RubyIntegration.Batch, boolean, boolean)} implementation.
+         */
+        private static final Collection<JrubyEventExtLibrary.RubyEvent> EMPTY_RETURN =
+            Collections.emptyList();
+
+        private final Collection<Dataset> parents;
+
+        private final RubyIntegration.Output output;
+
+        private final Collection<JrubyEventExtLibrary.RubyEvent> buffer;
+
+        private boolean done;
+
+        public OutputDataset(Collection<Dataset> parents, final RubyIntegration.Output output) {
+            this.parents = parents;
+            this.output = output;
+            buffer = new ArrayList<>(5);
+            done = false;
+        }
+
+        @Override
+        public Collection<JrubyEventExtLibrary.RubyEvent> compute(final RubyIntegration.Batch batch,
+            final boolean flush, final boolean shutdown) {
+            if(!done) {
+                for (final Dataset set : parents) {
+                    for (final JrubyEventExtLibrary.RubyEvent event
+                        : set.compute(batch, flush, shutdown)) {
+                        if (!event.getEvent().isCancelled()) {
+                            buffer.add(event);
+                        }
+                    }
+                }
+                output.multiReceive(buffer);
+                done = true;
+                buffer.clear();
+            }
+            return EMPTY_RETURN;
+        }
+
+        @Override
+        public void clear() {
+            for (final Dataset parent : parents) {
+                parent.clear();
+            }
+            done = false;
+        }
+    }
+}
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/compiler/EventCondition.java b/logstash-core/src/main/java/org/logstash/config/ir/compiler/EventCondition.java
new file mode 100644
index 00000000000..b9a0ff03538
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/config/ir/compiler/EventCondition.java
@@ -0,0 +1,758 @@
+package org.logstash.config.ir.compiler;
+
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Objects;
+import org.jruby.RubyInteger;
+import org.jruby.RubyNumeric;
+import org.jruby.RubyString;
+import org.jruby.runtime.builtin.IRubyObject;
+import org.jruby.util.ByteList;
+import org.logstash.ConvertedList;
+import org.logstash.ConvertedMap;
+import org.logstash.FieldReference;
+import org.logstash.PathCache;
+import org.logstash.RubyUtil;
+import org.logstash.Valuefier;
+import org.logstash.bivalues.BiValues;
+import org.logstash.config.ir.expression.BinaryBooleanExpression;
+import org.logstash.config.ir.expression.BooleanExpression;
+import org.logstash.config.ir.expression.EventValueExpression;
+import org.logstash.config.ir.expression.Expression;
+import org.logstash.config.ir.expression.ValueExpression;
+import org.logstash.config.ir.expression.binary.And;
+import org.logstash.config.ir.expression.binary.Eq;
+import org.logstash.config.ir.expression.binary.Gt;
+import org.logstash.config.ir.expression.binary.Gte;
+import org.logstash.config.ir.expression.binary.In;
+import org.logstash.config.ir.expression.binary.Lt;
+import org.logstash.config.ir.expression.binary.Lte;
+import org.logstash.config.ir.expression.binary.Neq;
+import org.logstash.config.ir.expression.binary.Or;
+import org.logstash.config.ir.expression.binary.RegexEq;
+import org.logstash.config.ir.expression.unary.Not;
+import org.logstash.config.ir.expression.unary.Truthy;
+import org.logstash.ext.JrubyEventExtLibrary;
+
+/**
+ * A pipeline execution "if" condition, compiled from the {@link BooleanExpression} of an
+ * {@link org.logstash.config.ir.graph.IfVertex}.
+ */
+public interface EventCondition {
+
+    /**
+     * Checks if {@link JrubyEventExtLibrary.RubyEvent} fulfils the condition.
+     * @param event RubyEvent to check
+     * @return True iff event fulfils condition
+     */
+    boolean fulfilled(JrubyEventExtLibrary.RubyEvent event);
+
+    /**
+     * <h3>EventCondition Compiler.</h3>
+     * Compiles {@link BooleanExpression} into {@link EventCondition} globally ensuring that no
+     * duplicate {@link EventCondition} are generated by strict synchronization on the internal
+     * compiler cache {@link EventCondition.Compiler#CACHE}.
+     */
+    final class Compiler {
+
+        /**
+         * {@link EventCondition} that is always {@code true}.
+         */
+        private static final EventCondition TRUE = event -> true;
+
+        /**
+         * {@link EventCondition} that is always {@code false}.
+         */
+        private static final EventCondition FALSE = event -> false;
+
+        /**
+         * Cache of all compiled {@link EventCondition}.
+         */
+        private static final Map<String, EventCondition> CACHE = new HashMap<>(10);
+
+        private Compiler() {
+            //Utility Class.
+        }
+
+        /**
+         * Compiles a {@link BooleanExpression} into an {@link EventCondition}.
+         * All compilation is globally {@code synchronized} on {@link EventCondition.Compiler#CACHE}
+         * to minimize code size by avoiding compiling logically equivalent expressions in more than
+         * one instance.
+         * @param expression BooleanExpress to compile
+         * @return Compiled {@link EventCondition}
+         */
+        public static EventCondition buildCondition(final BooleanExpression expression) {
+            synchronized (CACHE) {
+                final String cachekey = expression.toRubyString();
+                final EventCondition cached = CACHE.get(cachekey);
+                if (cached != null) {
+                    return cached;
+                }
+                final EventCondition condition;
+                if (expression instanceof Eq) {
+                    condition = eq((Eq) expression);
+                } else if (expression instanceof RegexEq) {
+                    condition = regex((RegexEq) expression);
+                } else if (expression instanceof In) {
+                    condition = in((In) expression);
+                } else if (expression instanceof Or) {
+                    condition = or(booleanPair((BinaryBooleanExpression) expression));
+                } else if (expression instanceof Truthy) {
+                    condition = truthy((Truthy) expression);
+                } else if (expression instanceof Not) {
+                    condition = not((Not) expression);
+                } else if (expression instanceof Gt) {
+                    condition = gt((Gt) expression);
+                } else if (expression instanceof Gte) {
+                    condition = gte((Gte) expression);
+                } else if (expression instanceof Lt) {
+                    condition = lt((Lt) expression);
+                } else if (expression instanceof Lte) {
+                    condition = lte((Lte) expression);
+                } else if (expression instanceof And) {
+                    condition = and(booleanPair((BinaryBooleanExpression) expression));
+                } else if (expression instanceof Neq) {
+                    condition = neq((Neq) expression);
+                } else {
+                    throw new EventCondition.Compiler.UnexpectedTypeException(expression);
+                }
+                CACHE.put(cachekey, condition);
+                return condition;
+            }
+        }
+
+        /**
+         * Checks if a {@link BinaryBooleanExpression} consists of a {@link ValueExpression} on the
+         * left and a {@link EventValueExpression} on the right.
+         * @param expression Expression to check type for
+         * @return True if the left branch of the {@link BinaryBooleanExpression} is a
+         * {@link ValueExpression} and its right side is a {@link EventValueExpression}.
+         */
+        private static boolean vAndE(final BinaryBooleanExpression expression) {
+            return expression.getLeft() instanceof ValueExpression &&
+                expression.getRight() instanceof EventValueExpression;
+        }
+
+        private static boolean vAndV(final BinaryBooleanExpression expression) {
+            return expression.getLeft() instanceof ValueExpression &&
+                expression.getRight() instanceof ValueExpression;
+        }
+
+        private static boolean eAndV(final BinaryBooleanExpression expression) {
+            return expression.getLeft() instanceof EventValueExpression &&
+                expression.getRight() instanceof ValueExpression;
+        }
+
+        private static boolean eAndE(final BinaryBooleanExpression expression) {
+            return expression.getLeft() instanceof EventValueExpression &&
+                expression.getRight() instanceof EventValueExpression;
+        }
+
+        private static EventCondition neq(final Neq neq) {
+            final EventCondition condition;
+            final Expression uleft = neq.getLeft();
+            final Expression uright = neq.getRight();
+            if (eAndV(neq)) {
+                condition = not(eq((EventValueExpression) uleft, (ValueExpression) uright));
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(uleft, uright);
+            }
+            return condition;
+        }
+
+        private static EventCondition truthy(final Truthy truthy) {
+            final EventCondition condition;
+            final Expression inner = truthy.getExpression();
+            if (inner instanceof EventValueExpression) {
+                condition = truthy((EventValueExpression) inner);
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(inner);
+            }
+            return condition;
+        }
+
+        private static EventCondition regex(final RegexEq regex) {
+            final EventCondition condition;
+            final Expression uleft = regex.getLeft();
+            final Expression uright = regex.getRight();
+            if (eAndV(regex)) {
+                condition = new EventCondition.Compiler.FieldMatches(
+                    ((EventValueExpression) uleft).getFieldName(),
+                    ((ValueExpression) uright).get().toString()
+                );
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(uleft, uright);
+            }
+            return condition;
+        }
+
+        private static EventCondition not(final Not not) {
+            final EventCondition condition;
+            final Expression inner = not.getExpression();
+            if (inner instanceof BooleanExpression) {
+                condition = not(buildCondition((BooleanExpression) inner));
+            } else if (inner instanceof EventValueExpression) {
+                condition = not(truthy((EventValueExpression) inner));
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(inner);
+            }
+            return condition;
+        }
+
+        private static EventCondition gte(final Gte gte) {
+            final EventCondition condition;
+            final Expression uleft = gte.getLeft();
+            final Expression uright = gte.getRight();
+            if (eAndV(gte)) {
+                final EventValueExpression left = (EventValueExpression) uleft;
+                final ValueExpression right = (ValueExpression) uright;
+                condition = or(gt(left, right), eq(left, right));
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(uleft, uright);
+            }
+            return condition;
+        }
+
+        private static EventCondition lte(final Lte lte) {
+            final EventCondition condition;
+            final Expression uleft = lte.getLeft();
+            final Expression uright = lte.getRight();
+            if (eAndV(lte)) {
+                condition = not(gt((EventValueExpression) uleft, (ValueExpression) uright));
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(uleft, uright);
+            }
+            return condition;
+        }
+
+        private static EventCondition lt(final Lt lt) {
+            final EventCondition condition;
+            final Expression uleft = lt.getLeft();
+            final Expression uright = lt.getRight();
+            if (eAndV(lt)) {
+                final EventValueExpression left = (EventValueExpression) uleft;
+                final ValueExpression right = (ValueExpression) uright;
+                condition = not(or(gt(left, right), eq(left, right)));
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(uleft, uright);
+            }
+            return condition;
+        }
+
+        private static EventCondition in(final In in) {
+            final Expression left = in.getLeft();
+            final Expression right = in.getRight();
+            final EventCondition condition;
+            if (eAndV(in) && isScalar((ValueExpression) in.getRight())) {
+                condition = new EventCondition.Compiler.FieldInConstantScalar(
+                    PathCache.cache(((EventValueExpression) left).getFieldName()),
+                    ((ValueExpression) right).get().toString()
+                );
+            } else if (vAndE(in) && isScalar((ValueExpression) in.getLeft())) {
+                final Object leftv = ((ValueExpression) left).get();
+                final FieldReference rfield =
+                    PathCache.cache(((EventValueExpression) right).getFieldName());
+                if (leftv instanceof String) {
+                    condition = new EventCondition.Compiler.ConstantStringInField(
+                        rfield, (String) leftv
+                    );
+                } else {
+                    condition = new EventCondition.Compiler.ConstantScalarInField(rfield, leftv);
+                }
+            } else if (eAndV(in) && listValueRight(in)) {
+                condition = in(
+                    (EventValueExpression) left, (List<?>) ((ValueExpression) right).get()
+                );
+            } else if (eAndE(in)) {
+                condition = in((EventValueExpression) right, (EventValueExpression) left);
+            } else if (vAndV(in)) {
+                condition = in((ValueExpression) left, (ValueExpression) right);
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(left, right);
+            }
+            return condition;
+        }
+
+        private static EventCondition in(final EventValueExpression left, final List<?> right) {
+            return new EventCondition.Compiler.FieldInConstantList(
+                PathCache.cache(left.getFieldName()), right
+            );
+        }
+
+        /**
+         * Compiles a constant (due to both of its sides being constant {@link ValueExpression})
+         * conditional into either {@link EventCondition.Compiler#TRUE} or
+         * {@link EventCondition.Compiler#FALSE}.
+         * @param left Constant left side {@link ValueExpression}
+         * @param right Constant right side {@link ValueExpression}
+         * @return Either {@link EventCondition.Compiler#TRUE} or
+         * {@link EventCondition.Compiler#FALSE}
+         */
+        private static EventCondition in(final ValueExpression left, final ValueExpression right) {
+            final Object found = right.get();
+            final Object other = left.get();
+            if (found instanceof ConvertedList && other instanceof RubyString) {
+                return ((ConvertedList) found).stream().anyMatch(item -> item.toString()
+                    .equals(other.toString())) ? TRUE : FALSE;
+            } else if (found instanceof RubyString && other instanceof RubyString) {
+                return found.toString().contains(other.toString()) ? TRUE : FALSE;
+            } else if (found instanceof RubyString && other instanceof ConvertedList) {
+                return ((ConvertedList) other).stream()
+                    .anyMatch(item -> item.toString().equals(found.toString())) ? TRUE : FALSE;
+            } else {
+                return found != null && other != null && found.equals(other) ? TRUE : FALSE;
+            }
+        }
+
+        private static boolean listValueRight(final In in) {
+            return ((ValueExpression) in.getRight()).get() instanceof List;
+        }
+
+        private static boolean isScalar(final ValueExpression expression) {
+            final Object value = expression.get();
+            return value instanceof String || value instanceof Number;
+        }
+
+        private static EventCondition in(final EventValueExpression left,
+            final EventValueExpression right) {
+            return new EventCondition.Compiler.FieldInField(
+                PathCache.cache(left.getFieldName()), PathCache.cache(right.getFieldName())
+            );
+        }
+
+        private static EventCondition eq(final EventValueExpression evale,
+            final ValueExpression vale) {
+            final Object value = vale.get();
+            final String field = evale.getFieldName();
+            if (value instanceof String) {
+                return new EventCondition.Compiler.FieldEqualsString(field, (String) value);
+            } else if (value instanceof Long || value instanceof Integer ||
+                value instanceof Short) {
+                return new EventCondition.Compiler.FieldEqualsLong(
+                    field, ((Number) value).longValue()
+                );
+            }
+            throw new EventCondition.Compiler.UnexpectedTypeException(value);
+        }
+
+        private static EventCondition eq(final Eq equals) {
+            final Expression left = equals.getLeft();
+            final Expression right = equals.getRight();
+            final EventCondition condition;
+            if (eAndV(equals)) {
+                condition = eq((EventValueExpression) left, (ValueExpression) right);
+            } else if (vAndE(equals)) {
+                condition = eq((EventValueExpression) right, (ValueExpression) left);
+            } else if (eAndE(equals)) {
+                condition = eq((EventValueExpression) left, (EventValueExpression) right);
+            } else if (vAndV(equals)) {
+                condition = ((ValueExpression) left).get()
+                    .equals(((ValueExpression) right).get()) ? TRUE : FALSE;
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(left, right);
+            }
+            return condition;
+        }
+
+        private static EventCondition eq(final EventValueExpression first,
+            final EventValueExpression second) {
+            return new EventCondition.Compiler.FieldEqualsField(
+                PathCache.cache(first.getFieldName()), PathCache.cache(second.getFieldName())
+            );
+        }
+
+        private static EventCondition gt(final Gt greater) {
+            final EventCondition condition;
+            final Expression left = greater.getLeft();
+            final Expression right = greater.getRight();
+            if (eAndV(greater)) {
+                condition = gt((EventValueExpression) left, (ValueExpression) right);
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(left, right);
+            }
+            return condition;
+        }
+
+        private static EventCondition gt(final EventValueExpression left,
+            final ValueExpression right) {
+            final Object value = right.get();
+            final String field = left.getFieldName();
+            if (value instanceof String) {
+                return new EventCondition.Compiler.FieldGreaterThanString(field, (String) value);
+            } else if (value instanceof Long || value instanceof Integer ||
+                value instanceof Short) {
+                return new FieldGreaterThanNumber(
+                    field, RubyUtil.RUBY.newFixnum(((Number) value).longValue())
+                );
+            }
+            throw new EventCondition.Compiler.UnexpectedTypeException(value);
+        }
+
+        private static EventCondition truthy(final EventValueExpression evale) {
+            return new EventCondition.Compiler.FieldTruthy(PathCache.cache(evale.getFieldName()));
+        }
+
+        private static EventCondition[] booleanPair(final BinaryBooleanExpression expression) {
+            final Expression left = expression.getLeft();
+            final Expression right = expression.getRight();
+            final EventCondition first;
+            final EventCondition second;
+            if (left instanceof BooleanExpression && right instanceof BooleanExpression) {
+                first = buildCondition((BooleanExpression) left);
+                second = buildCondition((BooleanExpression) right);
+            } else if (eAndE(expression)) {
+                first = truthy((EventValueExpression) left);
+                second = truthy((EventValueExpression) right);
+            } else if (left instanceof BooleanExpression && right instanceof EventValueExpression) {
+                first = buildCondition((BooleanExpression) left);
+                second = truthy((EventValueExpression) right);
+            } else if (right instanceof BooleanExpression &&
+                left instanceof EventValueExpression) {
+                first = truthy((EventValueExpression) left);
+                second = buildCondition((BooleanExpression) right);
+            } else {
+                throw new EventCondition.Compiler.UnexpectedTypeException(left, right);
+            }
+            return new EventCondition[]{first, second};
+        }
+
+        private static EventCondition not(final EventCondition condition) {
+            return new EventCondition.Compiler.Negated(condition);
+        }
+
+        private static EventCondition or(final EventCondition... conditions) {
+            return new EventCondition.Compiler.OrCondition(conditions[0], conditions[1]);
+        }
+
+        private static EventCondition and(final EventCondition... conditions) {
+            return new EventCondition.Compiler.AndCondition(conditions[0], conditions[1]);
+        }
+
+        /**
+         * Contains function using Ruby equivalent comparison logic.
+         * @param list List to find value in
+         * @param value Value to find in list
+         * @return True iff value is in list
+         */
+        private static boolean contains(final ConvertedList list, final Object value) {
+            if (value == null || value == BiValues.NULL_BI_VALUE) {
+                return list.contains(BiValues.NULL_BI_VALUE);
+            }
+            for (final Object element : list) {
+                if (value.equals(element)) {
+                    return true;
+                }
+            }
+            return false;
+        }
+
+        private static final class Negated implements EventCondition {
+
+            private final EventCondition condition;
+
+            Negated(final EventCondition condition) {
+                this.condition = condition;
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                return !condition.fulfilled(event);
+            }
+        }
+
+        private static final class AndCondition implements EventCondition {
+
+            private final EventCondition first;
+
+            private final EventCondition second;
+
+            AndCondition(final EventCondition first, final EventCondition second) {
+                this.first = first;
+                this.second = second;
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                return first.fulfilled(event) && second.fulfilled(event);
+            }
+        }
+
+        private static final class OrCondition implements EventCondition {
+
+            private final EventCondition first;
+
+            private final EventCondition second;
+
+            OrCondition(final EventCondition first, final EventCondition second) {
+                this.first = first;
+                this.second = second;
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                return first.fulfilled(event) || second.fulfilled(event);
+            }
+        }
+
+        private static final class FieldGreaterThanString implements EventCondition {
+
+            private final FieldReference field;
+
+            private final RubyString value;
+
+            private FieldGreaterThanString(final String field, final String value) {
+                this.field = PathCache.cache(field);
+                this.value = RubyUtil.RUBY.newString(value);
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                return value.compareTo(
+                    (IRubyObject) event.getEvent().getUnconvertedField(field)
+                ) < 0;
+            }
+        }
+
+        private static final class FieldGreaterThanNumber implements EventCondition {
+
+            private final FieldReference field;
+
+            private final RubyNumeric value;
+
+            private FieldGreaterThanNumber(final String field, final RubyNumeric value) {
+                this.field = PathCache.cache(field);
+                this.value = value;
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                return value.compareTo(
+                    (IRubyObject) event.getEvent().getUnconvertedField(field)
+                ) < 0;
+            }
+        }
+
+        private static final class FieldEqualsString implements EventCondition {
+
+            private final FieldReference field;
+
+            private final RubyString value;
+
+            private FieldEqualsString(final String field, final String value) {
+                this.field = PathCache.cache(field);
+                this.value = RubyUtil.RUBY.newString(value);
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                final Object val = event.getEvent().getUnconvertedField(field);
+                return value.equals(val);
+            }
+        }
+
+        private static final class FieldEqualsLong implements EventCondition {
+
+            private final FieldReference field;
+
+            private final long value;
+
+            private FieldEqualsLong(final String field, final long value) {
+                this.field = PathCache.cache(field);
+                this.value = value;
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                final Object val = event.getEvent().getUnconvertedField(field);
+                return val instanceof RubyInteger && ((RubyInteger) val).getLongValue() == value;
+            }
+        }
+
+        private static final class FieldEqualsField implements EventCondition {
+
+            private final FieldReference one;
+
+            private final FieldReference other;
+
+            private FieldEqualsField(final FieldReference one, final FieldReference other) {
+                this.one = one;
+                this.other = other;
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                return event.getEvent().getUnconvertedField(one)
+                    .equals(event.getEvent().getUnconvertedField(other));
+            }
+        }
+
+        private static final class FieldMatches implements EventCondition {
+
+            private final FieldReference field;
+
+            private final RubyString regex;
+
+            private FieldMatches(final String field, final String regex) {
+                this.field = PathCache.cache(field);
+                this.regex = RubyUtil.RUBY.newString(regex);
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                final Object tomatch = event.getEvent().getUnconvertedField(field);
+                return tomatch instanceof RubyString &&
+                    !((RubyString) tomatch).match(RubyUtil.RUBY.getCurrentContext(), regex).isNil();
+            }
+        }
+
+        private static final class ConstantStringInField implements EventCondition {
+
+            private final FieldReference field;
+
+            private final ByteList bytes;
+
+            private final RubyString string;
+
+            private ConstantStringInField(final FieldReference field, final String value) {
+                this.field = field;
+                this.string = RubyUtil.RUBY.newString(value);
+                bytes = string.getByteList();
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                final Object found = event.getEvent().getUnconvertedField(field);
+                return found instanceof RubyString &&
+                    ((RubyString) found).getByteList().indexOf(bytes) > -1
+                    || found instanceof ConvertedList && contains((ConvertedList) found, string);
+            }
+        }
+
+        private static final class ConstantScalarInField implements EventCondition {
+
+            private final FieldReference field;
+
+            private final Object value;
+
+            private ConstantScalarInField(final FieldReference field, final Object value) {
+                this.field = field;
+                this.value = Valuefier.convert(value);
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                final Object found = event.getEvent().getUnconvertedField(field);
+                return found instanceof ConvertedList && contains((ConvertedList) found, value)
+                    || Objects.equals(found, field);
+            }
+        }
+
+        private static final class FieldInConstantScalar implements EventCondition {
+
+            private final FieldReference field;
+
+            private final ByteList value;
+
+            private FieldInConstantScalar(final FieldReference field, final String value) {
+                this.field = field;
+                this.value = RubyUtil.RUBY.newString(value).getByteList();
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                final Object found = event.getEvent().getUnconvertedField(field);
+                return found instanceof RubyString &&
+                    value.indexOf(((RubyString) found).getByteList()) > -1;
+            }
+        }
+
+        private static final class FieldInField implements EventCondition {
+
+            private final FieldReference left;
+
+            private final FieldReference right;
+
+            private FieldInField(final FieldReference left, final FieldReference right) {
+                this.left = left;
+                this.right = right;
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                final Object lfound = event.getEvent().getUnconvertedField(left);
+                final Object rfound = event.getEvent().getUnconvertedField(right);
+                if (lfound instanceof ConvertedList || lfound instanceof ConvertedMap) {
+                    return false;
+                } else if (lfound instanceof RubyString && rfound instanceof RubyString) {
+                    return ((RubyString) lfound).getByteList()
+                        .indexOf(((RubyString) rfound).getByteList()) > -1;
+                } else if (rfound instanceof ConvertedList) {
+                    return contains((ConvertedList) rfound, lfound);
+                } else {
+                    return lfound != null && rfound != null && lfound.equals(rfound);
+                }
+            }
+        }
+
+        private static final class FieldInConstantList implements EventCondition {
+
+            private final FieldReference field;
+
+            private final List<?> value;
+
+            private FieldInConstantList(final FieldReference field, final List<?> value) {
+                this.field = field;
+                this.value = value;
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                final Object found = event.getEvent().getUnconvertedField(field);
+                return found != null &&
+                    value.stream().anyMatch(val -> val.toString().equals(found.toString()));
+            }
+        }
+
+        private static final class FieldTruthy implements EventCondition {
+
+            private final FieldReference field;
+
+            private FieldTruthy(final FieldReference field) {
+                this.field = field;
+            }
+
+            @Override
+            public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
+                final Object object = event.getEvent().getUnconvertedField(field);
+                if (object == null) {
+                    return false;
+                }
+                final String other = object.toString();
+                return other != null && !other.isEmpty() &&
+                    !Boolean.toString(false).equals(other);
+            }
+        }
+
+        /**
+         * This {@link IllegalArgumentException} is thrown when the inputs to an {@code if}
+         * condition do not conform to the expected types. It being thrown is a bug in Logstash
+         * in every case.
+         */
+        private static final class UnexpectedTypeException extends IllegalArgumentException {
+
+            private static final long serialVersionUID = 1L;
+
+            UnexpectedTypeException(final Expression left, final Expression right) {
+                super(
+                    String.format("Unexpected input types %s %s", left.getClass(), right.getClass())
+                );
+            }
+
+            UnexpectedTypeException(final Object inner) {
+                super(String.format("Unexpected input type %s", inner.getClass()));
+            }
+        }
+    }
+}
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/compiler/RubyIntegration.java b/logstash-core/src/main/java/org/logstash/config/ir/compiler/RubyIntegration.java
new file mode 100644
index 00000000000..5e1966b31a7
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/config/ir/compiler/RubyIntegration.java
@@ -0,0 +1,97 @@
+package org.logstash.config.ir.compiler;
+
+import java.util.Collection;
+import org.jruby.RubyHash;
+import org.jruby.RubyInteger;
+import org.jruby.RubyString;
+import org.jruby.runtime.builtin.IRubyObject;
+import org.logstash.ext.JrubyEventExtLibrary;
+
+/**
+ * This class holds interfaces implemented by Ruby concrete classes.
+ */
+public final class RubyIntegration {
+
+    private RubyIntegration() {
+        //Utility Class.
+    }
+
+    /**
+     * A Ruby Plugin.
+     */
+    public interface Plugin {
+        void register();
+    }
+
+    /**
+     * A Ruby Filter. Currently, this interface is implemented only by the Ruby class
+     * {@code FilterDelegator}.
+     */
+    public interface Filter extends RubyIntegration.Plugin {
+
+        /**
+         * Same as {@code FilterDelegator}'s {@code multi_filter}.
+         * @param events Events to Filter
+         * @return Filtered {@link JrubyEventExtLibrary.RubyEvent}
+         */
+        Collection<JrubyEventExtLibrary.RubyEvent> multiFilter(
+            Collection<JrubyEventExtLibrary.RubyEvent> events
+        );
+
+        Collection<JrubyEventExtLibrary.RubyEvent> flush(RubyHash options);
+
+        /**
+         * Checks if this filter has a flush method.
+         * @return True iff this filter has a flush method
+         */
+        boolean hasFlush();
+
+        /**
+         * Checks if this filter does periodic flushing.
+         * @return True iff this filter uses periodic flushing
+         */
+        boolean periodicFlush();
+    }
+
+    /**
+     * A Ruby Output. Currently, this interface is implemented only by the Ruby class
+     * {@code OutputDelegator}.
+     */
+    public interface Output extends RubyIntegration.Plugin {
+        void multiReceive(Collection<JrubyEventExtLibrary.RubyEvent> events);
+    }
+
+    /**
+     * The Main Ruby Pipeline Class. Currently, this interface is implemented only by the Ruby class
+     * {@code BasePipeline}.
+     */
+    public interface Pipeline {
+
+        IRubyObject buildInput(RubyString name, RubyInteger line, RubyInteger column,
+            IRubyObject args);
+
+        RubyIntegration.Output buildOutput(RubyString name, RubyInteger line, RubyInteger column,
+            IRubyObject args);
+
+        RubyIntegration.Filter buildFilter(RubyString name, RubyInteger line, RubyInteger column,
+            IRubyObject args);
+
+        RubyIntegration.Filter buildCodec(RubyString name, IRubyObject args);
+    }
+
+    /**
+     * A Ruby {@code ReadBatch} implemented by {@code WrappedSynchronousQueue::ReadClient::ReadBatch}
+     * and {@code WrappedAckedQueue::ReadClient::ReadBatch}.
+     */
+    public interface Batch {
+
+        /**
+         * Retrieves all {@link JrubyEventExtLibrary.RubyEvent} from the batch that are not
+         * cancelled.
+         * @return Collection of all {@link JrubyEventExtLibrary.RubyEvent} in the batch that
+         * are not cancelled
+         */
+        Collection<JrubyEventExtLibrary.RubyEvent> to_a();
+
+    }
+}
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/expression/Expression.java b/logstash-core/src/main/java/org/logstash/config/ir/expression/Expression.java
index e78a63c7385..dca88ddac44 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/expression/Expression.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/expression/Expression.java
@@ -1,10 +1,7 @@
 package org.logstash.config.ir.expression;
 
-import org.jruby.RubyInstanceConfig;
-import org.jruby.embed.AttributeName;
-import org.jruby.embed.ScriptingContainer;
-import org.logstash.config.ir.BaseSourceComponent;
 import org.logstash.common.SourceWithMetadata;
+import org.logstash.config.ir.BaseSourceComponent;
 import org.logstash.config.ir.HashableWithSource;
 
 /*
@@ -16,19 +13,11 @@
  * Created by andrewvc on 9/6/16.
  */
 public abstract class Expression extends BaseSourceComponent implements HashableWithSource {
-    private ScriptingContainer container;
 
     public Expression(SourceWithMetadata meta) {
         super(meta);
     }
 
-    public void compile() {
-        container = new ScriptingContainer();
-        container.setCompileMode(RubyInstanceConfig.CompileMode.JIT);
-        container.setAttribute(AttributeName.SHARING_VARIABLES, false);
-        container.runScriptlet("def start(event)\n" + this.toString() + "\nend");
-    }
-
     @Override
     public String toString(int indent) {
         return toString();
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/expression/RegexValueExpression.java b/logstash-core/src/main/java/org/logstash/config/ir/expression/RegexValueExpression.java
index ce77404f554..f0536c39a43 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/expression/RegexValueExpression.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/expression/RegexValueExpression.java
@@ -1,18 +1,14 @@
 package org.logstash.config.ir.expression;
 
-import org.joni.Option;
-import org.joni.Regex;
-import org.logstash.config.ir.SourceComponent;
-import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
-
-import java.nio.charset.StandardCharsets;
+import org.logstash.config.ir.InvalidIRException;
+import org.logstash.config.ir.SourceComponent;
 
 /**
  * Created by andrewvc on 9/15/16.
  */
 public class RegexValueExpression extends ValueExpression {
-    private final Regex regex;
+    private final String regex;
 
     public RegexValueExpression(SourceWithMetadata meta, Object value) throws InvalidIRException {
         super(meta, value);
@@ -21,8 +17,7 @@ public RegexValueExpression(SourceWithMetadata meta, Object value) throws Invali
             throw new InvalidIRException("Regex value expressions can only take strings!");
         }
 
-        byte[] patternBytes = getSource().getBytes(StandardCharsets.UTF_8);
-        this.regex = new Regex(patternBytes, 0, patternBytes.length, Option.NONE);
+        this.regex = getSource();
     }
 
     @Override
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/expression/ValueExpression.java b/logstash-core/src/main/java/org/logstash/config/ir/expression/ValueExpression.java
index ce8cff1e500..82fc62df4a1 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/expression/ValueExpression.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/expression/ValueExpression.java
@@ -1,11 +1,11 @@
 package org.logstash.config.ir.expression;
 
-import org.logstash.config.ir.SourceComponent;
-import org.logstash.config.ir.InvalidIRException;
-import org.logstash.common.SourceWithMetadata;
-
 import java.math.BigDecimal;
+import java.time.Instant;
 import java.util.List;
+import org.logstash.common.SourceWithMetadata;
+import org.logstash.config.ir.InvalidIRException;
+import org.logstash.config.ir.SourceComponent;
 
 /**
  * Created by andrewvc on 9/13/16.
@@ -25,7 +25,7 @@ public ValueExpression(SourceWithMetadata meta, Object value) throws InvalidIREx
                 value instanceof BigDecimal ||
                 value instanceof String ||
                 value instanceof List ||
-                value instanceof java.time.Instant
+                value instanceof Instant
         )) {
             // This *should* be caught by the treetop grammar, but we need this case just in case there's a bug
             // somewhere
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/graph/BooleanEdge.java b/logstash-core/src/main/java/org/logstash/config/ir/graph/BooleanEdge.java
index b45bf47c9cc..b50e62fb30d 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/graph/BooleanEdge.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/graph/BooleanEdge.java
@@ -7,7 +7,7 @@
 /**
  * Created by andrewvc on 9/15/16.
  */
-public class BooleanEdge extends Edge {
+public final class BooleanEdge extends Edge {
     public static class BooleanEdgeFactory extends EdgeFactory {
         public Boolean getEdgeType() {
             return edgeType;
diff --git a/logstash-core/src/main/java/org/logstash/config/ir/imperative/PluginStatement.java b/logstash-core/src/main/java/org/logstash/config/ir/imperative/PluginStatement.java
index ba93e1fe490..47b677edd49 100644
--- a/logstash-core/src/main/java/org/logstash/config/ir/imperative/PluginStatement.java
+++ b/logstash-core/src/main/java/org/logstash/config/ir/imperative/PluginStatement.java
@@ -42,4 +42,8 @@ public Graph toGraph() throws InvalidIRException {
         g.addVertex(pluginVertex);
         return g;
     }
+
+    public PluginDefinition getPluginDefinition() {
+        return pluginDefinition;
+    }
 }
diff --git a/logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueReaderTest.java b/logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueReaderTest.java
index 89ab42d2da5..6945b50d7b8 100644
--- a/logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueReaderTest.java
+++ b/logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueReaderTest.java
@@ -209,7 +209,7 @@ private void validateEntries(Path firstLog, int startEntry, int endEntry, int st
     @Test
     public void testBlockBoundary() throws Exception {
 
-        final int PAD_FOR_BLOCK_SIZE_EVENT = 32513;
+        final int PAD_FOR_BLOCK_SIZE_EVENT = 32516;
         Event event = new Event();
         char[] field = new char[PAD_FOR_BLOCK_SIZE_EVENT];
         Arrays.fill(field, 'e');
@@ -234,7 +234,7 @@ public void testBlockBoundary() throws Exception {
     @Test
     public void testBlockBoundaryMultiple() throws Exception {
         Event event = new Event(Collections.emptyMap());
-        char[] field = new char[7952];
+        char[] field = new char[7934];
         Arrays.fill(field, 'x');
         event.setField("message", new String(field));
         long startTime = System.currentTimeMillis();
@@ -256,11 +256,10 @@ public void testBlockBoundaryMultiple() throws Exception {
         }
     }
 
-
     // This test tests for a single event that ends on a block and segment boundary
     @Test
     public void testBlockAndSegmentBoundary() throws Exception {
-        final int PAD_FOR_BLOCK_SIZE_EVENT = 32513;
+        final int PAD_FOR_BLOCK_SIZE_EVENT = 32516;
         Event event = new Event();
         event.setField("T", generateMessageContent(PAD_FOR_BLOCK_SIZE_EVENT));
         Timestamp timestamp = new Timestamp();
@@ -279,7 +278,6 @@ public void testBlockAndSegmentBoundary() throws Exception {
         }
     }
 
-
     @Test
     public void testWriteReadRandomEventSize() throws Exception {
         Event event = new Event(Collections.emptyMap());
diff --git a/rakelib/compile.rake b/rakelib/compile.rake
index 99c7e320efb..8f869a979e5 100644
--- a/rakelib/compile.rake
+++ b/rakelib/compile.rake
@@ -9,8 +9,6 @@ end
 namespace "compile" do
   desc "Compile the config grammar"
 
-  task "grammar" => "logstash-core/lib/logstash/config/grammar.rb"
-  
   def safe_system(*args)
     if !system(*args)
       status = $?
@@ -24,5 +22,5 @@ namespace "compile" do
   end
 
   desc "Build everything"
-  task "all" => ["grammar", "logstash-core-java"]
+  task "all" => ["logstash-core-java"]
 end
