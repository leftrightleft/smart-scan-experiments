diff --git a/logstash-core/src/main/java/org/logstash/common/Util.java b/logstash-core/src/main/java/org/logstash/common/Util.java
index be0b73af01c..d821711ea2a 100644
--- a/logstash-core/src/main/java/org/logstash/common/Util.java
+++ b/logstash-core/src/main/java/org/logstash/common/Util.java
@@ -1,8 +1,20 @@
 package org.logstash.common;
 
+import java.io.BufferedWriter;
+import java.io.File;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.nio.channels.SeekableByteChannel;
 import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.OpenOption;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
 import java.security.MessageDigest;
 import java.security.NoSuchAlgorithmException;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipInputStream;
 
 /**
  * Created by andrewvc on 12/23/16.
@@ -35,4 +47,38 @@ public static String bytesToHexString(byte[] bytes) {
 
         return hexString.toString();
     }
+
+    /**
+     * Unzips a ZipInputStream to a given directory
+     * @param input the ZipInputStream
+     * @param output path to the output
+     * @param omitParentDir omit the parent dir the zip is packaged with
+     * @throws IOException
+     */
+    public static void unzipToDirectory(final ZipInputStream input, final Path output, boolean omitParentDir) throws IOException {
+        ZipEntry entry;
+        final int bufSize = 4096;
+        byte[] buffer = new byte[bufSize];
+        while ((entry = input.getNextEntry()) != null) {
+            // Skip the top level dir
+            final String destinationPath = omitParentDir ?
+                    entry.getName().replaceFirst("[^/]+/", "") :
+                    entry.getName();
+
+            final Path fullPath = Paths.get(output.toString(), destinationPath);
+            // Create parent directories as required
+            if (entry.isDirectory()) {
+                Files.createDirectories(fullPath);
+            } else {
+                Files.createDirectories(fullPath.getParent());
+
+                int readLength;
+                try (SeekableByteChannel outputWriter = Files.newByteChannel(fullPath, StandardOpenOption.CREATE_NEW, StandardOpenOption.WRITE)) {
+                    while ((readLength = input.read(buffer, 0, bufSize)) != -1) {
+                        outputWriter.write(ByteBuffer.wrap(buffer, 0, readLength));
+                    }
+                }
+            }
+        }
+    }
 }
diff --git a/logstash-core/src/test/java/org/logstash/ackedqueue/io/QueueBinaryCompatibilityTest.java b/logstash-core/src/test/java/org/logstash/ackedqueue/io/QueueBinaryCompatibilityTest.java
new file mode 100644
index 00000000000..7e0642c31f0
--- /dev/null
+++ b/logstash-core/src/test/java/org/logstash/ackedqueue/io/QueueBinaryCompatibilityTest.java
@@ -0,0 +1,104 @@
+package org.logstash.ackedqueue.io;
+
+import org.junit.Test;
+import org.logstash.Event;
+import org.logstash.Timestamp;
+import org.logstash.ackedqueue.Batch;
+import org.logstash.ackedqueue.Queue;
+import org.logstash.ackedqueue.Queueable;
+import org.logstash.ackedqueue.Settings;
+import org.logstash.ackedqueue.SettingsImpl;
+import org.logstash.ackedqueue.TestSettings;
+import org.logstash.common.Util;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.math.BigInteger;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.zip.ZipInputStream;
+
+import static org.hamcrest.CoreMatchers.equalTo;
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.MatcherAssert.assertThat;
+
+/**
+ * Tests against old queue binary data
+ */
+public class QueueBinaryCompatibilityTest {
+    @Test
+    public void test6_3_0_all_data_types() throws IOException {
+        assertAllDataTypesSample("/binary-queue-samples/6.3.0_all_data_types.zip");
+    }
+
+    public void assertAllDataTypesSample(String zipFilename) throws IOException {
+        Queue queue = binaryQueueSample(zipFilename);
+        Batch batch = queue.nonBlockReadBatch(1000);
+        Event event = (Event) batch.getElements().get(0);
+        assertAllDataTypes(event);
+        queue.close();
+    }
+
+    public void assertAllDataTypes(Event event) {
+        assertThat(event.getField("bigint"), is(equalTo(new BigInteger("99999999999999999999999999999999999"))));
+        assertThat(event.getField("int_max"), is(equalTo((long) Integer.MAX_VALUE)));
+        assertThat(event.getField("int_min"), is(equalTo((long) Integer.MIN_VALUE)));
+        assertThat(event.getField("long_max"), is(equalTo(Long.MAX_VALUE)));
+        assertThat(event.getField("long_min"), is(equalTo(Long.MIN_VALUE)));
+        assertThat(event.getField("string"), is(equalTo("I am a string!")));
+        assertThat(event.getField("utf8_string"), is(equalTo("multibyte-chars-follow-十進数ウェブの国際化慶-and-here-they-end")));
+        assertThat(event.getField("boolean"), is(equalTo(false)));
+        assertThat(event.getField("timestamp"), is(equalTo(new Timestamp("2018-05-18T17:27:02.397Z"))));
+
+        Map nestedMap = new HashMap<>();
+        nestedMap.put("string", "I am a string!");
+        assertThat(event.getField("nested_map"), is(equalTo(nestedMap)));
+
+        List mixedArray = Arrays.asList("a", 1L, "b", new Timestamp("2018-05-18T17:27:02.397Z"), true);
+        assertThat(event.getField("mixed_array"), is(equalTo(mixedArray)));
+
+
+        Map complexMapA = new HashMap();
+        complexMapA.put("a", 1L);
+
+        Map complexMapB = new HashMap();
+        complexMapB.put("b", Arrays.asList("a string", 2L));
+
+        Map complexMapXYZ = new HashMap();
+        complexMapXYZ.put("x", "y");
+        complexMapXYZ.put("z", true);
+        Map complexMapC = new HashMap();
+        complexMapC.put("c", Arrays.asList(complexMapXYZ));
+
+
+        List complex = Arrays.asList(complexMapA, complexMapB, complexMapC);
+        assertThat(event.getField("complex"), is(equalTo(complex)));
+
+    }
+
+    Queue binaryQueueSample(String resourcePath) throws IOException {
+        Path queueDir = unpackBinarySample(resourcePath);
+        Settings settings = sampleSettings(queueDir, 1024*1024*250);
+        Queue queue =  new Queue(settings);
+        queue.open();
+        return queue;
+    }
+
+    Settings sampleSettings(Path queueDir, int pageCapacity) {
+        return SettingsImpl.fileSettingsBuilder(queueDir.toString()).capacity(pageCapacity)
+            .checkpointMaxWrites(1).elementClass(Event.class).build();
+    }
+
+    Path unpackBinarySample(String resourcePath) throws IOException {
+        InputStream is = QueueBinaryCompatibilityTest.class.getResourceAsStream(resourcePath);
+        assert(is != null);
+        ZipInputStream zis = new ZipInputStream(is);
+        Path destination = Files.createTempDirectory("temp");
+        Util.unzipToDirectory(zis, destination, true);
+        return destination;
+    }
+}
diff --git a/logstash-core/src/test/resources/binary-queue-samples/5.4.0-bigint.zip b/logstash-core/src/test/resources/binary-queue-samples/5.4.0-bigint.zip
new file mode 100644
index 00000000000..baf5c913cdc
Binary files /dev/null and b/logstash-core/src/test/resources/binary-queue-samples/5.4.0-bigint.zip differ
diff --git a/logstash-core/src/test/resources/binary-queue-samples/5.4.0-generator-2-pages-2000-events.zip b/logstash-core/src/test/resources/binary-queue-samples/5.4.0-generator-2-pages-2000-events.zip
new file mode 100644
index 00000000000..77f40c7c907
Binary files /dev/null and b/logstash-core/src/test/resources/binary-queue-samples/5.4.0-generator-2-pages-2000-events.zip differ
diff --git a/logstash-core/src/test/resources/binary-queue-samples/5.4.0-nmap-timestamp-as-str.zip b/logstash-core/src/test/resources/binary-queue-samples/5.4.0-nmap-timestamp-as-str.zip
new file mode 100644
index 00000000000..e67b532be2e
Binary files /dev/null and b/logstash-core/src/test/resources/binary-queue-samples/5.4.0-nmap-timestamp-as-str.zip differ
diff --git a/logstash-core/src/test/resources/binary-queue-samples/6.2.3-simple-generator.zip b/logstash-core/src/test/resources/binary-queue-samples/6.2.3-simple-generator.zip
new file mode 100644
index 00000000000..77cd9795dcd
Binary files /dev/null and b/logstash-core/src/test/resources/binary-queue-samples/6.2.3-simple-generator.zip differ
diff --git a/logstash-core/src/test/resources/binary-queue-samples/6.3.0_all_data_types.zip b/logstash-core/src/test/resources/binary-queue-samples/6.3.0_all_data_types.zip
new file mode 100644
index 00000000000..20bc398b0e4
Binary files /dev/null and b/logstash-core/src/test/resources/binary-queue-samples/6.3.0_all_data_types.zip differ
diff --git a/logstash-core/src/test/resources/binary-queue-samples/generator-simple.conf b/logstash-core/src/test/resources/binary-queue-samples/generator-simple.conf
new file mode 100644
index 00000000000..86cdd6ed600
--- /dev/null
+++ b/logstash-core/src/test/resources/binary-queue-samples/generator-simple.conf
@@ -0,0 +1,11 @@
+input {
+  generator { count => 1000 }
+}
+
+filter {
+  sleep { time => 1000 }
+}
+
+output {
+  stdout {}
+}
diff --git a/logstash-core/src/test/resources/binary-queue-samples/json-in.conf b/logstash-core/src/test/resources/binary-queue-samples/json-in.conf
new file mode 100644
index 00000000000..30ff7e7b765
--- /dev/null
+++ b/logstash-core/src/test/resources/binary-queue-samples/json-in.conf
@@ -0,0 +1,9 @@
+input {
+  tcp { codec => json_lines port => 5555 }
+}
+
+filter {
+  sleep { time => 1000 }
+}
+
+output { stdout { codec => rubydebug } }
diff --git a/logstash-core/src/test/resources/binary-queue-samples/json-sample.conf b/logstash-core/src/test/resources/binary-queue-samples/json-sample.conf
new file mode 100644
index 00000000000..b0ce62bfb4b
--- /dev/null
+++ b/logstash-core/src/test/resources/binary-queue-samples/json-sample.conf
@@ -0,0 +1 @@
+{"foo": "bar", "bigint": 9999999999999999999999999999999999, "baz": ["blah",1]}
diff --git a/logstash-core/src/test/resources/binary-queue-samples/netflow-in.conf b/logstash-core/src/test/resources/binary-queue-samples/netflow-in.conf
new file mode 100644
index 00000000000..95d14eebda1
--- /dev/null
+++ b/logstash-core/src/test/resources/binary-queue-samples/netflow-in.conf
@@ -0,0 +1,7 @@
+input {
+  udp { codec => netflow port => 5555 }
+}
+
+output {
+  stdout { codec => rubydebug }
+}
diff --git a/logstash-core/src/test/resources/binary-queue-samples/nmap-in.conf b/logstash-core/src/test/resources/binary-queue-samples/nmap-in.conf
new file mode 100644
index 00000000000..19a01c099ee
--- /dev/null
+++ b/logstash-core/src/test/resources/binary-queue-samples/nmap-in.conf
@@ -0,0 +1,13 @@
+# Test with nmap -sP example.net -oX - | curl -H "x-nmap-target: example.net" http://localhost:5555 --data-binary @-
+
+input {
+  http { codec => nmap port => 5555 }
+}
+
+filter { 
+  sleep { time => 20000 }
+}
+
+output {
+  stdout { codec => rubydebug }
+}
diff --git a/logstash-core/src/test/resources/binary-queue-samples/set_every_type.pipelines.yaml b/logstash-core/src/test/resources/binary-queue-samples/set_every_type.pipelines.yaml
new file mode 100644
index 00000000000..b526ab2a071
--- /dev/null
+++ b/logstash-core/src/test/resources/binary-queue-samples/set_every_type.pipelines.yaml
@@ -0,0 +1,21 @@
+# Config that attempts to create a binary PQ that contains a large number of datatypes
+# Run this then terminate it after the pipeline starts up
+# the long sleep should yield data in the queue directory.
+# Depending on how long it runs before shutting down more events will be acknowledged
+
+- pipeline.id: generator
+  queue.type: memory
+  config.string: |
+    input { generator { count => 1000 } }
+    filter {
+      ruby { path => "logstash-core/src/test/resources/binary-queue-samples/set_every_type.rb" }
+    }
+    output { pipeline { send_to => pq } }
+- pipeline.id: pq
+  pipeline.batch.size: 1
+  queue.type: persisted
+  queue.drain: false
+  config.string: |
+    input { pipeline { address => pq } }
+    filter { sleep { time => 1 } }
+    output { stdout { codec => rubydebug } }
diff --git a/logstash-core/src/test/resources/binary-queue-samples/set_every_type.rb b/logstash-core/src/test/resources/binary-queue-samples/set_every_type.rb
new file mode 100644
index 00000000000..f3b6bc3a9cc
--- /dev/null
+++ b/logstash-core/src/test/resources/binary-queue-samples/set_every_type.rb
@@ -0,0 +1,27 @@
+def filter(event)
+  event.set('bigint', 99999999999999999999999999999999999)
+  event.set('int_max', 2147483647)
+  event.set('int_min', -2147483648)
+  event.set('long_max', 9223372036854775807)
+  event.set('long_min', -9223372036854775808)
+  event.set('string', 'I am a string!')
+  event.set('utf8_string', 'multibyte-chars-follow-十進数ウェブの国際化慶-and-here-they-end')
+  event.set('boolean', false)
+  event.set('timestamp', ::LogStash::Timestamp.new("2018-05-18T17:27:02.397Z"))
+
+  event.set('nested_map', {
+      'string' => "I am a string!"
+  })
+
+  event.set('mixed_array', ["a", 1, "b", ::LogStash::Timestamp.new, true]);
+
+  event.set('complex', [
+      {"a" => 1},
+      {"b" => ["a string", 2]},
+      {"c" =>  [
+          {"x" => "y", "z" => true}
+        ] }
+  ])
+
+  return [event]
+end
\ No newline at end of file
