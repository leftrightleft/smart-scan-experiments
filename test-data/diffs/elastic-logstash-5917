diff --git a/ci/ci_integration.sh b/ci/ci_integration.sh
index 5aaeca0006f..088a1884b5b 100755
--- a/ci/ci_integration.sh
+++ b/ci/ci_integration.sh
@@ -6,5 +6,9 @@ set -e
 # installing gems. See https://github.com/elastic/logstash/issues/5179
 export JRUBY_OPTS="-J-Xmx1g"
 
-rake test:install-default
-rake test:integration
+rm -rf build/*
+rake artifact:tar
+cd build
+tar xvf *.tar.gz
+cd ../qa/integration
+rspec
diff --git a/qa/integration/.gitignore b/qa/integration/.gitignore
new file mode 100644
index 00000000000..9c614afcc31
--- /dev/null
+++ b/qa/integration/.gitignore
@@ -0,0 +1,5 @@
+/services/filebeat
+/fixtures/how.input
+/services/elasticsearch
+/services/kafka
+/fixtures/certificates
diff --git a/qa/integration/.rspec b/qa/integration/.rspec
new file mode 100644
index 00000000000..12f9968c306
--- /dev/null
+++ b/qa/integration/.rspec
@@ -0,0 +1 @@
+--default-path specs/
\ No newline at end of file
diff --git a/qa/integration/Gemfile b/qa/integration/Gemfile
new file mode 100644
index 00000000000..3be9c3cd812
--- /dev/null
+++ b/qa/integration/Gemfile
@@ -0,0 +1,2 @@
+source "https://rubygems.org"
+gemspec
diff --git a/qa/integration/README.md b/qa/integration/README.md
new file mode 100644
index 00000000000..2b411cf5156
--- /dev/null
+++ b/qa/integration/README.md
@@ -0,0 +1,41 @@
+## Logstash Integration Tests aka RATS
+
+These set of tests are full integration tests as in: they can start LS from a binary, run configs using `-e` and can use any external services like Kafka, ES and S3. This framework is hybrid -- a combination of bash scripts (to mainly setup services), Ruby service files, and RSpec. All test assertions are done in RSpec.
+
+No VMs, all tests run locally.
+
+## Dependencies
+* An existing Logstash binary, defaults to `LS_HOME/build/logstash-<version>`
+* `rspec`
+
+## Preparing a test run
+
+1. If you already have a LS binary in `LS_HOME/build/logstash-<version>`, skip to step 5
+2. From Logstash git source directory or `LS_HOME` run `rake artifact:tar` to build a package
+2. Untar the newly built package
+3. `cd build`
+4. `tar xvf logstash-<version>.tar.gz`
+5. `cd LS_HOME/qa/integration`
+6. `bundle install`: This will install test dependency gems.
+
+You are now ready to run any tests from `qa/integration`.
+* Run all tests: `rspec specs/*`
+* Run single test: `rspec specs/es_output_how_spec.rb`
+
+### Directory Layout
+
+* `fixtures`: In this dir you will test settings in form of `test_name.yml`. Here you specify services to run, LS config, test specific scripts ala `.travis.yml`
+* `services`: This dir has bash scripts that download and bootstrap binaries for services. This is where services like ES will be downloaded and run from. Service can have 3 files: `<service>_setup.sh`, `<service>_teardown.sh` and `<service>`.rb. The bash scripts deal with downloading and bootstrapping, but the ruby source will trigger them from the test as a shell out (using backticks). The tests are blocked until the setup/teardown completes. For example, Elasticsearch service has `elasticsearch_setup.sh`, `elasticsearch_teardown.sh` and `elasticsearch.rb`. The service name in yml is "elasticsearch".
+* `framework`: Test framework source code.
+* `specs`: Rspec tests that use services and validates stuff
+
+### Adding a new test
+
+1. Creating a new test -- lets use as example. Call it "test_file_input" which brings up LS to read from a file and assert file contents (file output) were as expected.
+2. You'll have to create a yml file in `fixtures` called `test_file_input_spec.yml`. Here you define any external services you need and any LS config.
+3. Create a corresponding `test_file_input_spec.rb` in `specs` folder and use the `fixtures` object to get all services, config etc. The `.yml` and rspec file has to be the same name for the settings to be picked up. You can start LS inside the tests and assume all external services have already been started.
+4. Write rspec code to validate.
+
+## Future Improvements
+
+1. Perform setup and teardown from Ruby and get rid of bash files altogether.
diff --git a/qa/integration/fixtures/beats_input_spec.yml b/qa/integration/fixtures/beats_input_spec.yml
new file mode 100644
index 00000000000..da8811e4986
--- /dev/null
+++ b/qa/integration/fixtures/beats_input_spec.yml
@@ -0,0 +1,33 @@
+---
+services:
+  - filebeat
+  - logstash
+config:
+  without_tls: |-
+    input {
+      beats {
+        port => 5044
+      }
+    }
+  tls_server_auth: |-
+    input {
+      beats {
+        ssl => true
+        port => 5044
+        ssl_certificate => '<%=options[:ssl_certificate]%>'
+        ssl_key => '<%=options[:ssl_key]%>'
+      }
+    }
+  tls_mutual_auth: |-
+    input {
+      beats {
+        ssl => true
+        port => 5044
+        ssl_certificate => '<%=options[:ssl_certificate]%>'
+        ssl_key => '<%=options[:ssl_key]%>'
+        ssl_verify_mode => "peer"
+      }
+    }
+input: how_sample.input
+setup_script: download_input.sh
+teardown_script:
diff --git a/qa/integration/fixtures/download_input.sh b/qa/integration/fixtures/download_input.sh
new file mode 100755
index 00000000000..280cfe5ad5c
--- /dev/null
+++ b/qa/integration/fixtures/download_input.sh
@@ -0,0 +1,10 @@
+#!/bin/bash
+set -ex
+current_dir="$(dirname "$0")"
+HOW_DATA_SET_URL=https://s3.amazonaws.com/data.elasticsearch.org/logstash/logs.gz
+
+if [ ! -f ${current_dir}/how.input ]; then
+  curl -sL $HOW_DATA_SET_URL > ${current_dir}/logs.gz
+  gunzip ${current_dir}/logs.gz
+  mv ${current_dir}/logs ${current_dir}/how.input
+fi
\ No newline at end of file
diff --git a/qa/integration/fixtures/es_output_how_spec.yml b/qa/integration/fixtures/es_output_how_spec.yml
new file mode 100644
index 00000000000..566e781d0bd
--- /dev/null
+++ b/qa/integration/fixtures/es_output_how_spec.yml
@@ -0,0 +1,35 @@
+---
+services:
+  - logstash
+  - elasticsearch
+config: |-
+  input {
+    stdin { }
+  }
+
+  filter {
+    grok {
+      match => {
+        "message" => "%{IPORHOST:clientip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{DATA:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:response:int} (?:-|%{NUMBER:bytes:int}) %{QS:referrer} %{QS:agent}"
+      }
+    }
+
+    date {
+      match => [ "timestamp", "dd/MMM/YYYY:HH:mm:ss Z" ]
+      locale => en
+    }
+    geoip {
+      source => "clientip"
+    }
+    useragent {
+      source => "agent"
+      target => "useragent"
+    }
+  }
+  output {
+    elasticsearch {}
+  }
+
+input: how.input
+setup_script: download_input.sh
+teardown_script:
diff --git a/qa/integration/fixtures/how_sample.input b/qa/integration/fixtures/how_sample.input
new file mode 100644
index 00000000000..bef7ff54b4e
--- /dev/null
+++ b/qa/integration/fixtures/how_sample.input
@@ -0,0 +1,37 @@
+74.125.176.147 - - [11/Sep/2014:21:50:37 +0000] "GET /?flav=rss20 HTTP/1.1" 200 29941 "-" "FeedBurner/1.0 (http://www.FeedBurner.com)"
+66.249.84.55 - - [11/Sep/2014:21:50:54 +0000] "GET / HTTP/1.1" 200 37932 "-" "Mozilla/5.0 (Windows NT 6.1; rv:6.0) Gecko/20110814 Firefox/6.0 Google favicon"
+66.249.84.55 - - [11/Sep/2014:21:50:54 +0000] "GET /favicon.ico HTTP/1.1" 200 3638 "-" "Mozilla/5.0 (Windows NT 6.1; rv:6.0) Gecko/20110814 Firefox/6.0 Google favicon"
+46.105.14.53 - - [11/Sep/2014:21:51:35 +0000] "GET /blog/tags/puppet?flav=rss20 HTTP/1.1" 200 14872 "-" "UniversalFeedParser/4.2-pre-314-svn +http://feedparser.org/"
+194.153.217.248 - - [11/Sep/2014:21:51:56 +0000] "GET /blog/geekery/debugging-java-performance.html HTTP/1.1" 200 15796 "http://logstash.net/docs/1.3.3/life-of-an-event" "Mozilla/5.0 (Windows NT 5.1; rv:27.0) Gecko/20100101 Firefox/27.0"
+194.153.217.248 - - [11/Sep/2014:21:51:57 +0000] "GET /style2.css HTTP/1.1" 200 4877 "http://www.semicomplete.com/blog/geekery/debugging-java-performance.html" "Mozilla/5.0 (Windows NT 5.1; rv:27.0) Gecko/20100101 Firefox/27.0"
+194.153.217.248 - - [11/Sep/2014:21:51:57 +0000] "GET /reset.css HTTP/1.1" 200 1015 "http://www.semicomplete.com/blog/geekery/debugging-java-performance.html" "Mozilla/5.0 (Windows NT 5.1; rv:27.0) Gecko/20100101 Firefox/27.0"
+194.153.217.248 - - [11/Sep/2014:21:51:58 +0000] "GET /favicon.ico HTTP/1.1" 200 3638 "-" "Mozilla/5.0 (Windows NT 5.1; rv:27.0) Gecko/20100101 Firefox/27.0"
+194.153.217.248 - - [11/Sep/2014:21:51:58 +0000] "GET /images/jordan-80.png HTTP/1.1" 200 6146 "http://www.semicomplete.com/blog/geekery/debugging-java-performance.html" "Mozilla/5.0 (Windows NT 5.1; rv:27.0) Gecko/20100101 Firefox/27.0"
+194.153.217.248 - - [11/Sep/2014:21:51:58 +0000] "GET /images/web/2009/banner.png HTTP/1.1" 200 52315 "http://www.semicomplete.com/style2.css" "Mozilla/5.0 (Windows NT 5.1; rv:27.0) Gecko/20100101 Firefox/27.0"
+159.253.145.222 - - [11/Sep/2014:21:51:53 +0000] "GET /files/logstash/logstash-1.1.0-monolithic.jar HTTP/1.1" 200 40923996 "-" "Chef Client/10.18.2 (ruby-1.8.7-p302; ohai-6.14.0; x86_64-linux; +http://opscode.com)"
+213.113.233.227 - - [11/Sep/2014:21:53:14 +0000] "GET /articles/dynamic-dns-with-dhcp/ HTTP/1.1" 200 18848 "https://www.google.se/" "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.154 Safari/537.36"
+173.192.221.211 - - [11/Sep/2014:21:53:31 +0000] "GET /files/logstash/logstash-1.1.0-monolithic.jar HTTP/1.1" 200 40923996 "-" "Chef Client/10.18.2 (ruby-1.8.7-p302; ohai-6.14.0; x86_64-linux; +http://opscode.com)"
+5.10.83.95 - - [11/Sep/2014:21:54:16 +0000] "GET /files/xdotool/docs/man/?C=N;O=D HTTP/1.1" 200 955 "-" "Mozilla/5.0 (compatible; AhrefsBot/5.0; +http://ahrefs.com/robot/)"
+194.103.63.154 - - [11/Sep/2014:21:54:26 +0000] "GET /favicon.ico HTTP/1.1" 304 - "-" "Mozilla/4.0 (compatible;)"
+95.30.144.170 - - [11/Sep/2014:21:56:20 +0000] "GET /presentations/vim/ HTTP/1.0" 200 20572 "http://semicomplete.com/presentations/vim/" "Opera/9.80 (Windows NT 6.1; WOW64; U; MRA 8.0 (build 5880); ru) Presto/2.10.289 Version/12.02"
+159.253.145.222 - - [11/Sep/2014:21:56:27 +0000] "GET /files/logstash/logstash-1.1.0-monolithic.jar HTTP/1.1" 200 40923996 "-" "Chef Client/10.18.2 (ruby-1.8.7-p302; ohai-6.14.0; x86_64-linux; +http://opscode.com)"
+46.105.14.53 - - [11/Sep/2014:21:56:36 +0000] "GET /blog/tags/puppet?flav=rss20 HTTP/1.1" 200 14872 "-" "UniversalFeedParser/4.2-pre-314-svn +http://feedparser.org/"
+202.69.11.26 - - [11/Sep/2014:21:56:40 +0000] "GET /blog/tags/X11 HTTP/1.1" 200 32742 "-" "HUAQIN60A_6464_11B_HW|0816 (MRE/3.1.00(1536);MAUI/PA_089A_V8_0_9;BDATE/2013/08/16 14:02;LCD/240320;CHIP/MT6260;KEY/Normal;TOUCH/0;CAMERA/1;SENSOR/0;DEV/HUAQIN60A_6464_11B_HW|0816;WAP Browser/MAUI (HTTP PGDL;HTTPS);GMOBI/001;MBOUNCE/002;MOMAGIC/003;INDEX/004;SPICEI2I/005;GAMELOFT/006;) ZS628PA_089A_V8_0_9 Release/2013.08.16 WAP Browser/MAUI (HTTP PGDL; HTTPS) Profile/  Q03C1-2.40 en-US"
+5.10.83.96 - - [11/Sep/2014:21:56:47 +0000] "GET /blog/geekery/insist-on-better-asserts.html HTTP/1.1" 200 9514 "-" "Mozilla/5.0 (compatible; AhrefsBot/5.0; +http://ahrefs.com/robot/)"
+202.69.11.26 - - [11/Sep/2014:21:56:48 +0000] "GET /reset.css HTTP/1.1" 200 1015 "-" "-"
+202.69.11.26 - - [11/Sep/2014:21:56:54 +0000] "GET /style2.css HTTP/1.1" 200 4877 "-" "-"
+202.69.11.26 - - [11/Sep/2014:21:56:57 +0000] "GET /images/jordan-80.png HTTP/1.1" 200 6146 "-" "HUAQIN60A_6464_11B_HW|0816 (MRE/3.1.00(1536);MAUI/PA_089A_V8_0_9;BDATE/2013/08/16 14:02;LCD/240320;CHIP/MT6260;KEY/Normal;TOUCH/0;CAMERA/1;SENSOR/0;DEV/HUAQIN60A_6464_11B_HW|0816;WAP Browser/MAUI (HTTP PGDL;HTTPS);GMOBI/001;MBOUNCE/002;MOMAGIC/003;INDEX/004;SPICEI2I/005;GAMELOFT/006;) ZS628PA_089A_V8_0_9 Release/2013.08.16 WAP Browser/MAUI (HTTP PGDL; HTTPS) Profile/  Q03C1-2.40 en-US"
+202.69.11.26 - - [11/Sep/2014:21:57:06 +0000] "GET /images/web/2009/banner.png HTTP/1.1" 200 52315 "-" "HUAQIN60A_6464_11B_HW|0816 (MRE/3.1.00(1536);MAUI/PA_089A_V8_0_9;BDATE/2013/08/16 14:02;LCD/240320;CHIP/MT6260;KEY/Normal;TOUCH/0;CAMERA/1;SENSOR/0;DEV/HUAQIN60A_6464_11B_HW|0816;WAP Browser/MAUI (HTTP PGDL;HTTPS);GMOBI/001;MBOUNCE/002;MOMAGIC/003;INDEX/004;SPICEI2I/005;GAMELOFT/006;) ZS628PA_089A_V8_0_9 Release/2013.08.16 WAP Browser/MAUI (HTTP PGDL; HTTPS) Profile/  Q03C1-2.40 en-US"
+174.36.228.156 - - [11/Sep/2014:21:57:28 +0000] "GET /blog HTTP/1.1" 200 37936 "-" "Mozilla/5.0 (X11; U; Linux x86_64; en-US; rv:1.9.0.19; aggregator:Spinn3r (Spinn3r 3.1); http://spinn3r.com/robot) Gecko/2010040121 Firefox/3.0.19"
+108.174.55.234 - - [11/Sep/2014:21:57:42 +0000] "GET /?flav=rss20 HTTP/1.1" 200 29941 "-" "-"
+173.192.221.212 - - [11/Sep/2014:21:58:16 +0000] "GET /files/logstash/logstash-1.1.0-monolithic.jar HTTP/1.1" 200 40923996 "-" "Chef Client/10.18.2 (ruby-1.8.7-p302; ohai-6.14.0; x86_64-linux; +http://opscode.com)"
+217.69.133.237 - - [11/Sep/2014:21:58:29 +0000] "GET /scripts/netcat-webserver HTTP/1.1" 304 - "-" "Mozilla/5.0 (compatible; Linux x86_64; Mail.RU_Bot/2.0; +http://go.mail.ru/help/robots)"
+202.69.11.26 - - [11/Sep/2014:21:58:52 +0000] "GET /images/googledotcom.png HTTP/1.1" 200 65748 "-" "HUAQIN60A_6464_11B_HW|0816 (MRE/3.1.00(1536);MAUI/PA_089A_V8_0_9;BDATE/2013/08/16 14:02;LCD/240320;CHIP/MT6260;KEY/Normal;TOUCH/0;CAMERA/1;SENSOR/0;DEV/HUAQIN60A_6464_11B_HW|0816;WAP Browser/MAUI (HTTP PGDL;HTTPS);GMOBI/001;MBOUNCE/002;MOMAGIC/003;INDEX/004;SPICEI2I/005;GAMELOFT/006;) ZS628PA_089A_V8_0_9 Release/2013.08.16 WAP Browser/MAUI (HTTP PGDL; HTTPS) Profile/  Q03C1-2.40 en-US"
+202.69.11.26 - - [11/Sep/2014:21:59:10 +0000] "GET /blog/tags/X11 HTTP/1.1" 200 32742 "-" "HUAQIN60A_6464_11B_HW|0816 (MRE/3.1.00(1536);MAUI/PA_089A_V8_0_9;BDATE/2013/08/16 14:02;LCD/240320;CHIP/MT6260;KEY/Normal;TOUCH/0;CAMERA/1;SENSOR/0;DEV/HUAQIN60A_6464_11B_HW|0816;WAP Browser/MAUI (HTTP PGDL;HTTPS);GMOBI/001;MBOUNCE/002;MOMAGIC/003;INDEX/004;SPICEI2I/005;GAMELOFT/006;) ZS628PA_089A_V8_0_9 Release/2013.08.16 WAP Browser/MAUI (HTTP PGDL; HTTPS) Profile/  Q03C1-2.40 en-US"
+202.69.11.26 - - [11/Sep/2014:21:59:15 +0000] "GET /reset.css HTTP/1.1" 200 1015 "-" "-"
+202.69.11.26 - - [11/Sep/2014:21:59:17 +0000] "GET /images/jordan-80.png HTTP/1.1" 200 6146 "-" "HUAQIN60A_6464_11B_HW|0816 (MRE/3.1.00(1536);MAUI/PA_089A_V8_0_9;BDATE/2013/08/16 14:02;LCD/240320;CHIP/MT6260;KEY/Normal;TOUCH/0;CAMERA/1;SENSOR/0;DEV/HUAQIN60A_6464_11B_HW|0816;WAP Browser/MAUI (HTTP PGDL;HTTPS);GMOBI/001;MBOUNCE/002;MOMAGIC/003;INDEX/004;SPICEI2I/005;GAMELOFT/006;) ZS628PA_089A_V8_0_9 Release/2013.08.16 WAP Browser/MAUI (HTTP PGDL; HTTPS) Profile/  Q03C1-2.40 en-US"
+202.69.11.26 - - [11/Sep/2014:21:59:19 +0000] "GET /style2.css HTTP/1.1" 200 4877 "-" "-"
+5.153.24.131 - - [11/Sep/2014:21:59:18 +0000] "GET /files/logstash/logstash-1.1.0-monolithic.jar HTTP/1.1" 200 40923996 "-" "Chef Client/10.18.2 (ruby-1.8.7-p302; ohai-6.14.0; x86_64-linux; +http://opscode.com)"
+198.46.149.143 - - [11/Sep/2014:21:59:29 +0000] "GET /blog/geekery/disabling-battery-in-ubuntu-vms.html?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+semicomplete%2Fmain+%28semicomplete.com+-+Jordan+Sissel%29 HTTP/1.1" 200 9316 "-" "Tiny Tiny RSS/1.11 (http://tt-rss.org/)"
+198.46.149.143 - - [11/Sep/2014:21:59:29 +0000] "GET /blog/geekery/solving-good-or-bad-problems.html?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+semicomplete%2Fmain+%28semicomplete.com+-+Jordan+Sissel%29 HTTP/1.1" 200 10756 "-" "Tiny Tiny RSS/1.11 (http://tt-rss.org/)"
+183.60.215.50 - - [11/Sep/2014:22:00:00 +0000] "GET /scripts/netcat-webserver HTTP/1.1" 200 182 "-" "Mozilla/5.0 (compatible; EasouSpider; +http://www.easou.com/search/spider.html)"
diff --git a/qa/integration/fixtures/kafka_input_spec.yml b/qa/integration/fixtures/kafka_input_spec.yml
new file mode 100644
index 00000000000..a7df6098eab
--- /dev/null
+++ b/qa/integration/fixtures/kafka_input_spec.yml
@@ -0,0 +1,24 @@
+---
+services:
+  - logstash
+  - kafka
+config: |-
+  input {
+    kafka {
+      topics => "logstash_topic_plain"
+      auto_offset_reset => "earliest"
+      codec => "plain"
+      group_id => "ls10"
+    }
+  }
+  output {
+    file {
+       path => "kafka_input.output"
+       flush_interval => 0
+       codec => line { format => "%{message}" }
+    }
+  }
+
+input: how_sample.input
+actual_output: kafka_input.output 
+teardown_script:
diff --git a/qa/integration/fixtures/monitoring_api_spec.yml b/qa/integration/fixtures/monitoring_api_spec.yml
new file mode 100644
index 00000000000..52bff4e9e95
--- /dev/null
+++ b/qa/integration/fixtures/monitoring_api_spec.yml
@@ -0,0 +1,4 @@
+---
+name: Metrics test
+services:
+  - logstash
diff --git a/qa/integration/framework/fixture.rb b/qa/integration/framework/fixture.rb
new file mode 100644
index 00000000000..7c3d7d21bd5
--- /dev/null
+++ b/qa/integration/framework/fixture.rb
@@ -0,0 +1,80 @@
+require_relative "../services/service_locator"
+
+# A class that holds all fixtures for a given test file. This deals with
+# bootstrapping services, dealing with config files, inputs etc
+class Fixture
+  FIXTURES_DIR = File.expand_path(File.join("..", "..", "fixtures"), __FILE__)
+
+  attr_reader :input
+  attr_reader :actual_output
+  attr_reader :test_dir
+
+  class TemplateContext
+    attr_reader :options
+
+    def initialize(options)
+      @options = options
+    end
+
+    def get_binding
+      binding
+    end
+  end
+
+  def initialize(test_file_location)
+    @test_file_location = test_file_location
+    @settings = TestSettings.new(@test_file_location)
+    @service_locator = ServiceLocator.new(@settings)
+    setup_services
+    @input = File.join(FIXTURES_DIR, @settings.get("input")) if @settings.is_set?("input")
+    @actual_output = @settings.get("actual_output")
+  end
+
+  def config(node = "root", options = nil)
+    if node == "root"
+      config = @settings.get("config")
+    else
+      config = @settings.get("config")[node]
+    end
+
+    if options != nil
+       ERB.new(config, nil, "-").result(TemplateContext.new(options).get_binding)
+    else
+      config
+    end
+  end
+
+  def get_service(name)
+    @service_locator.get_service(name)
+  end
+
+  def output_equals_expected?
+    FileUtils.identical?(@actual_output, @input)
+  end
+
+  def output_exists?
+    File.exists?(@actual_output)
+  end
+
+  def teardown
+    File.delete(@actual_output) if @settings.is_set?("actual_output") && output_exists?
+    puts "Tearing down services"
+    services = @settings.get("services")
+    services.each do |name|
+      @service_locator.get_service(name).teardown
+    end
+  end
+
+  def setup_services
+    puts "Setting up services"
+    services = @settings.get("services")
+    services.each do |name|
+     @service_locator.get_service(name).setup
+    end
+    if @settings.is_set?("setup_script")
+      puts "Setting up test specific fixtures"
+      script = File.join(FIXTURES_DIR, @settings.get("setup_script"))
+      `#{script}`
+    end
+  end
+end
diff --git a/qa/integration/framework/settings.rb b/qa/integration/framework/settings.rb
new file mode 100644
index 00000000000..d0a25ad3a6a
--- /dev/null
+++ b/qa/integration/framework/settings.rb
@@ -0,0 +1,53 @@
+require 'yaml'
+
+# All settings for a test, global and per test
+class TestSettings
+  # Setting for the entire test suite
+  INTEG_TESTS_DIR = File.expand_path(File.join("..", ".."), __FILE__)
+  # Test specific settings
+  SUITE_SETTINGS_FILE = File.join(INTEG_TESTS_DIR, "suite.yml")
+  FIXTURES_DIR = File.join(INTEG_TESTS_DIR, "fixtures")
+
+  def initialize(test_file_path)
+    test_name = File.basename(test_file_path, ".*" )
+    @tests_settings_file = File.join(FIXTURES_DIR, "#{test_name}.yml")
+    # Global suite settings
+    @suite_settings = YAML.load_file(SUITE_SETTINGS_FILE)
+    # Per test settings, where one can override stuff and define test specific config
+    @test_settings = YAML.load_file(@tests_settings_file)
+    
+    if verbose_mode?
+      puts "Test settings file: #{@tests_settings_file}"
+      puts "Suite settings file: #{SUITE_SETTINGS_FILE}"
+    end  
+
+    if is_set?("config")
+      if get("config").is_a?(Hash)
+        tmp = {}
+        get("config").each do |k, v|
+          tmp[k] = get("config")[k].gsub('\n','').split.join(" ")
+        end
+        @test_settings["config"] = tmp
+      else
+        config_string = get("config").gsub('\n','').split.join(" ")
+        @test_settings["config"] = config_string
+      end
+    end
+  end
+
+  def get(key)
+    if @test_settings.key?(key)
+      @test_settings[key]
+    else
+      @suite_settings[key]
+    end
+  end
+  
+  def verbose_mode?
+    @suite_settings["verbose_mode"]
+  end  
+
+  def is_set?(key)
+    @suite_settings.key?(key) || @test_settings.key?(key)
+  end
+end
diff --git a/qa/integration/integration_tests.gemspec b/qa/integration/integration_tests.gemspec
new file mode 100644
index 00000000000..9fdefb18348
--- /dev/null
+++ b/qa/integration/integration_tests.gemspec
@@ -0,0 +1,22 @@
+Gem::Specification.new do |s|
+  s.name        = 'logstash-integration-tests'
+  s.version     = '0.1.0'
+  s.licenses    = ['Apache License (2.0)']
+  s.summary     = "Tests LS binary"
+  s.description = "This is a Logstash integration test helper gem"
+  s.authors     = [ "Elastic"]
+  s.email       = 'info@elastic.co'
+  s.homepage    = "http://www.elastic.co/guide/en/logstash/current/index.html"
+
+  # Files
+  s.test_files = s.files.grep(%r{^(test|spec|features)/})
+
+  # Gem dependencies
+  s.add_development_dependency 'elasticsearch'
+  s.add_development_dependency 'childprocess'
+  s.add_development_dependency 'rspec-wait'
+  s.add_development_dependency 'manticore'
+  s.add_development_dependency 'stud'
+  s.add_development_dependency 'pry'
+  s.add_development_dependency 'logstash-devutils'
+end
diff --git a/qa/integration/services/elasticsearch_service.rb b/qa/integration/services/elasticsearch_service.rb
new file mode 100644
index 00000000000..66963aca5de
--- /dev/null
+++ b/qa/integration/services/elasticsearch_service.rb
@@ -0,0 +1,12 @@
+require 'elasticsearch'
+
+class ElasticsearchService < Service
+  def initialize(settings)
+    super("elasticsearch", settings)
+  end
+
+  def get_client
+    Elasticsearch::Client.new(:hosts => "localhost:9200")
+  end
+
+end
\ No newline at end of file
diff --git a/qa/integration/services/elasticsearch_setup.sh b/qa/integration/services/elasticsearch_setup.sh
new file mode 100755
index 00000000000..65078ab0d9b
--- /dev/null
+++ b/qa/integration/services/elasticsearch_setup.sh
@@ -0,0 +1,38 @@
+#!/bin/bash
+set -ex
+current_dir="$(dirname "$0")"
+
+if [ -n "${ES_VERSION+1}" ]; then
+  echo "Elasticsearch version is $ES_VERSION"
+  version=$ES_VERSION
+else
+   version=5.0.0-alpha5
+fi
+
+setup_es() {
+  if [ ! -d $current_dir/elasticsearch ]; then
+      local version=$1
+      download_url=https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/$version/elasticsearch-$version.tar.gz
+      curl -sL $download_url > $current_dir/elasticsearch.tar.gz
+      mkdir $current_dir/elasticsearch
+      tar -xzf $current_dir/elasticsearch.tar.gz --strip-components=1 -C $current_dir/elasticsearch/.
+      rm $current_dir/elasticsearch.tar.gz
+  fi
+}
+
+start_es() {
+  es_args=$@
+  $current_dir/elasticsearch/bin/elasticsearch $es_args -p $current_dir/elasticsearch/elasticsearch.pid > /tmp/elasticsearch.log 2>/dev/null &
+  count=120
+  echo "Waiting for elasticsearch to respond..."
+  while ! curl --silent localhost:9200 && [[ $count -ne 0 ]]; do
+      count=$(( $count - 1 ))
+      [[ $count -eq 0 ]] && return 1
+      sleep 1
+  done
+  echo "Elasticsearch is Up !"
+  return 0
+}
+
+setup_es $version
+start_es
diff --git a/qa/integration/services/elasticsearch_teardown.sh b/qa/integration/services/elasticsearch_teardown.sh
new file mode 100755
index 00000000000..5d59f30facf
--- /dev/null
+++ b/qa/integration/services/elasticsearch_teardown.sh
@@ -0,0 +1,11 @@
+#!/bin/bash
+set -ex
+current_dir="$(dirname "$0")"
+
+stop_es() {
+    pid=$(cat $current_dir/elasticsearch/elasticsearch.pid)
+    [ "x$pid" != "x" ] && [ "$pid" -gt 0 ]
+    kill -SIGTERM $pid
+}
+
+stop_es
\ No newline at end of file
diff --git a/qa/integration/services/filebeat_service.rb b/qa/integration/services/filebeat_service.rb
new file mode 100644
index 00000000000..a913f311845
--- /dev/null
+++ b/qa/integration/services/filebeat_service.rb
@@ -0,0 +1,51 @@
+# encoding: utf-8
+class FilebeatService < Service
+  FILEBEAT_CMD = [File.join(File.dirname(__FILE__), "filebeat", "filebeat"), "-c"]
+
+  class BackgroundProcess
+    def initialize(cmd)
+      @client_out = Stud::Temporary.file
+      @client_out.sync
+
+      @process = ChildProcess.build(*cmd)
+      @process.duplex = true
+      @process.io.stdout = @process.io.stderr = @client_out
+      ChildProcess.posix_spawn = true
+    end
+
+    def start
+      @process.start
+      sleep(0.1)
+      self
+    end
+
+    def execution_output
+      @client_out.rewind
+
+      # can be used to helper debugging when a test fails
+      @execution_output = @client_out.read
+    end
+
+    def stop
+      begin
+        @process.poll_for_exit(5)
+      rescue ChildProcess::TimeoutError
+        Process.kill("KILL", @process.pid)
+      end
+    end
+  end
+
+  def initialize(settings)
+    super("filebeat", settings)
+  end
+
+  def run(config_path)
+    cmd = FILEBEAT_CMD.dup << config_path
+    puts "Starting Filebeat with #{cmd.join(" ")}"
+    @process = BackgroundProcess.new(cmd).start
+  end
+
+  def stop
+    @process.stop
+  end
+end
diff --git a/qa/integration/services/filebeat_setup.sh b/qa/integration/services/filebeat_setup.sh
new file mode 100755
index 00000000000..f59defc191c
--- /dev/null
+++ b/qa/integration/services/filebeat_setup.sh
@@ -0,0 +1,32 @@
+#!/bin/bash
+set -ex
+current_dir="$(dirname "$0")"
+
+if [ -n "${FILEBEAT_VERSION}" ]; then
+  echo "Filebeat version is $FILEBEAT_VERSION"
+  version=$FILEBEAT_VERSION
+else
+   version=5.0.0-alpha5
+fi
+
+setup_fb() {
+    local version=$1
+    platform=`uname -s | tr '[:upper:]' '[:lower:]'`
+    architecture=`uname -m | tr '[:upper:]' '[:lower:]'`
+    download_url=https://download.elastic.co/beats/filebeat/filebeat-$version-$platform-$architecture.tar.gz
+    curl -sL $download_url > $current_dir/filebeat.tar.gz
+    mkdir $current_dir/filebeat
+    tar -xzf $current_dir/filebeat.tar.gz --strip-components=1 -C $current_dir/filebeat/.
+    rm $current_dir/filebeat.tar.gz
+}
+
+generate_certificate() {
+    target_directory=$current_dir/../fixtures/certificates
+    mkdir -p $target_directory
+    openssl req -subj '/CN=localhost/' -x509 -days $((100 * 365)) -batch -nodes -newkey rsa:2048 -keyout $target_directory/certificate.key -out $target_directory/certificate.crt
+}
+
+if [ ! -d $current_dir/filebeat ]; then
+    generate_certificate
+    setup_fb $version
+fi
diff --git a/qa/integration/services/kafka_service.rb b/qa/integration/services/kafka_service.rb
new file mode 100644
index 00000000000..71908f9acbb
--- /dev/null
+++ b/qa/integration/services/kafka_service.rb
@@ -0,0 +1,7 @@
+require_relative "service"
+
+class KafkaService < Service
+  def initialize(settings)
+    super("kafka", settings)
+  end
+end
diff --git a/qa/integration/services/kafka_setup.sh b/qa/integration/services/kafka_setup.sh
new file mode 100755
index 00000000000..26740d693e5
--- /dev/null
+++ b/qa/integration/services/kafka_setup.sh
@@ -0,0 +1,37 @@
+#!/bin/bash
+set -ex
+current_dir="$(dirname "$0")"
+
+if [ -n "${KAFKA_VERSION+1}" ]; then
+    echo "KAFKA_VERSION is $KAFKA_VERSION"
+    version=$KAFKA_VERSION
+else
+    version=0.10.0.0
+fi
+
+setup_kafka() {
+    local version=$1
+    if [ ! -d $current_dir/kafka ]; then
+        echo "Downloading Kafka version $version"
+        curl -s -o $current_dir/kafka.tgz "http://ftp.wayne.edu/apache/kafka/$version/kafka_2.11-$version.tgz"
+        mkdir $current_dir/kafka && tar xzf $current_dir/kafka.tgz -C $current_dir/kafka --strip-components 1
+        rm $current_dir/kafka.tgz
+    fi
+}
+
+start_kafka() {
+    echo "Starting ZooKeeper"
+    $current_dir/kafka/bin/zookeeper-server-start.sh -daemon $current_dir/kafka/config/zookeeper.properties
+    sleep 3
+    echo "Starting Kafka broker"
+    $current_dir/kafka/bin/kafka-server-start.sh -daemon $current_dir/kafka/config/server.properties --override delete.topic.enable=true
+    sleep 3
+}
+
+setup_kafka $version
+start_kafka
+
+# Set up topics
+$current_dir/kafka/bin/kafka-topics.sh --create --partitions 1 --replication-factor 1 --topic logstash_topic_plain --zookeeper localhost:2181
+cat $current_dir/../fixtures/how_sample.input | $current_dir/kafka/bin/kafka-console-producer.sh --topic logstash_topic_plain --broker-list localhost:9092
+echo "Kafka Setup complete"
diff --git a/qa/integration/services/kafka_teardown.sh b/qa/integration/services/kafka_teardown.sh
new file mode 100755
index 00000000000..57c0ce76d0a
--- /dev/null
+++ b/qa/integration/services/kafka_teardown.sh
@@ -0,0 +1,17 @@
+#!/bin/bash
+set -ex
+current_dir="$(dirname "$0")"
+
+stop_kafka() {
+    echo "Stopping Kafka broker"
+    $current_dir/kafka/bin/kafka-server-stop.sh
+    sleep 2
+    echo "Stopping zookeeper"
+    $current_dir/kafka/bin/zookeeper-server-stop.sh
+    sleep 2
+}
+
+# delete test topic
+echo "Deleting test topic in Kafka"
+$current_dir/kafka/bin/kafka-topics.sh --delete --topic logstash_topic_plain --zookeeper localhost:2181 --if-exists
+stop_kafka
diff --git a/qa/integration/services/logstash_service.rb b/qa/integration/services/logstash_service.rb
new file mode 100644
index 00000000000..09e3ea8068b
--- /dev/null
+++ b/qa/integration/services/logstash_service.rb
@@ -0,0 +1,139 @@
+require_relative "monitoring_api"
+
+require "childprocess"
+require "bundler"
+require "tempfile"
+require 'yaml'
+
+# A locally started Logstash service
+class LogstashService < Service
+
+  LS_VERSION_FILE = File.expand_path(File.join("../../../../", "versions.yml"), __FILE__)
+  LS_BIN = "bin/logstash"
+
+  STDIN_CONFIG = "input {stdin {}} output { }"
+  RETRY_ATTEMPTS = 10
+
+  @process = nil
+
+  def initialize(settings)
+    super("logstash", settings)
+
+    # if you need to point to a LS in different path
+    if @settings.is_set?("ls_home_abs_path")
+      @logstash_home = @settings.get("ls_home_abs_path")
+    else
+      # use the LS which was just built in source repo
+      ls_version_file = YAML.load_file(LS_VERSION_FILE)
+      ls_file = "logstash-" + ls_version_file["logstash"]
+      # First try without the snapshot if it's there
+      @logstash_home = File.expand_path(File.join("../../../../build", ls_file), __FILE__)
+      @logstash_home += "-SNAPSHOT" unless Dir.exists?(@logstash_home)
+
+      puts "Using #{@logstash_home} as LS_HOME"
+      @logstash_bin = File.join("#{@logstash_home}", LS_BIN)
+      raise "Logstash binary not found in path #{@logstash_home}" unless File.file? @logstash_bin
+    end
+
+    @monitoring_api = MonitoringAPI.new
+  end
+
+  def alive?
+    if @process.nil? || @process.exited?
+      raise "Logstash process is not up because of an errot, or it stopped"
+    else
+      @process.alive?
+    end
+  end
+
+  # Starts a LS process in background with a given config file
+  # and shuts it down after input is completely processed
+  def start_background(config_file)
+    spawn_logstash("-e", config_file)
+  end
+
+  # Given an input this pipes it to LS. Expects a stdin input in LS
+  def start_with_input(config, input)
+    Bundler.with_clean_env do
+      `cat #{input} | #{@logstash_bin} -e \'#{config}\'`
+    end
+  end
+
+  def start_with_config_string(config)
+    spawn_logstash("-e", "#{config} ")
+  end
+
+  # Can start LS in stdin and can send messages to stdin
+  # Useful to test metrics and such
+  def start_with_stdin
+    puts "Starting Logstash #{@logstash_bin} -e #{STDIN_CONFIG}"
+    Bundler.with_clean_env do
+      out = Tempfile.new("duplex")
+      out.sync = true
+      @process = ChildProcess.build(@logstash_bin, "-e", STDIN_CONFIG)
+      # pipe STDOUT and STDERR to a file
+      @process.io.stdout = @process.io.stderr = out
+      @process.duplex = true
+      @process.start
+      wait_for_logstash
+      puts "Logstash started with PID #{@process.pid}" if alive?
+    end
+  end
+
+  def write_to_stdin(input)
+    if alive?
+      @process.io.stdin.puts(input)
+    end
+  end
+
+  # Spawn LS as a child process
+  def spawn_logstash(cli_arg, value)
+    puts "Starting Logstash #{@logstash_bin} #{cli_arg} #{value}"
+    Bundler.with_clean_env do
+      @process = ChildProcess.build(@logstash_bin, cli_arg, value)
+      @process.io.inherit!
+      @process.start
+      wait_for_logstash
+      puts "Logstash started with PID #{@process.pid}" if @process.alive?
+    end
+  end
+
+  def teardown
+    if !@process.nil?
+      # todo: put this in a sleep-wait loop to kill it force kill
+      @process.io.stdin.close rescue nil
+      @process.stop
+      @process = nil
+    end
+  end
+
+  # check if LS HTTP port is open
+  def is_port_open?
+    begin
+      s = TCPSocket.open("localhost", 9600)
+      s.close
+      return true
+    rescue Errno::ECONNREFUSED, Errno::EHOSTUNREACH
+      return false
+    end
+  end
+
+  def monitoring_api
+    raise "Logstash is not up, but you asked for monitoring API" unless alive?
+    @monitoring_api
+  end
+
+  # Wait until LS is started by repeatedly doing a socket connection to HTTP port
+  def wait_for_logstash
+    tries = RETRY_ATTEMPTS
+    while tries > 0
+      if is_port_open?
+        break
+      else
+        sleep 1
+      end
+      tries -= 1
+    end
+  end
+
+end
diff --git a/qa/integration/services/monitoring_api.rb b/qa/integration/services/monitoring_api.rb
new file mode 100644
index 00000000000..291980f1bb4
--- /dev/null
+++ b/qa/integration/services/monitoring_api.rb
@@ -0,0 +1,25 @@
+require "manticore"
+require "json"
+
+# Convenience class to interact with the HTTP monitoring APIs
+class MonitoringAPI
+
+  def pipeline_stats
+    resp = Manticore.get("http://localhost:9600/_node/stats/pipeline").body
+    stats_response = JSON.parse(resp)
+    stats_response["pipeline"]
+  end
+
+  def event_stats
+    stats = pipeline_stats
+    stats["events"]
+  end
+
+  def version
+    request = @agent.get("http://localhost:9600/")
+    response = request.execute
+    r = JSON.parse(response.body.read)
+    r["version"]
+  end
+
+end
diff --git a/qa/integration/services/service.rb b/qa/integration/services/service.rb
new file mode 100644
index 00000000000..f2c3525d2f6
--- /dev/null
+++ b/qa/integration/services/service.rb
@@ -0,0 +1,30 @@
+# Base class for a service like Kafka, ES, Logstash
+class Service
+
+  def initialize(name, settings)
+    @name = name
+    @settings = settings
+    @setup_script = File.expand_path("../#{name}_setup.sh", __FILE__)
+    @teardown_script = File.expand_path("../#{name}_teardown.sh", __FILE__)
+  end
+
+  def setup
+    puts "Setting up #{@name} service"
+    if File.exists?(@setup_script)
+      `#{@setup_script}`
+    else
+      puts "Setup script not found for #{@name}"
+    end
+    puts "#{@name} service setup complete"
+  end
+
+  def teardown
+    puts "Tearing down #{@name} service"
+    if File.exists?(@setup_script)
+      `#{@teardown_script}`
+    else
+      puts "Teardown script not found for #{@name}"
+    end
+    puts "#{@name} service teardown complete"
+  end
+end
diff --git a/qa/integration/services/service_locator.rb b/qa/integration/services/service_locator.rb
new file mode 100644
index 00000000000..ff537ebcd2a
--- /dev/null
+++ b/qa/integration/services/service_locator.rb
@@ -0,0 +1,30 @@
+# encoding: utf-8
+require_relative "service"
+
+# This is a registry used in Fixtures so a test can get back any service class
+# at runtime
+# All new services should register here
+class ServiceLocator
+  FILE_PATTERN = "_service.rb"
+
+  def initialize(settings)
+    @services = {}
+    available_services do |name, klass|
+      @services[name] = klass.new(settings)
+    end
+  end
+
+  def get_service(name)
+    @services.fetch(name)
+  end
+
+  def available_services
+    Dir.glob(File.join(File.dirname(__FILE__), "*#{FILE_PATTERN}")).each do |f|
+      require f
+      basename = File.basename(f).gsub(/#{FILE_PATTERN}$/, "")
+      service_name = basename.downcase
+      klass = Object.const_get("#{service_name.capitalize}Service")
+      yield service_name, klass
+    end
+  end
+end
diff --git a/qa/integration/specs/beats_input_spec.rb b/qa/integration/specs/beats_input_spec.rb
new file mode 100644
index 00000000000..1dc31b5e10a
--- /dev/null
+++ b/qa/integration/specs/beats_input_spec.rb
@@ -0,0 +1,144 @@
+require_relative '../framework/fixture'
+require_relative '../framework/settings'
+require "stud/temporary"
+require "stud/try"
+require "rspec/wait"
+require "yaml"
+require "fileutils"
+
+describe "Beat Input" do
+  before(:all) do
+    @fixture = Fixture.new(__FILE__)
+  end
+
+  after :each do
+    logstash_service.teardown
+    filebeat_service.stop
+  end
+
+  let(:max_retry) { 120 }
+  let(:registry_file) { Stud::Temporary.file.path }
+  let(:logstash_service) { @fixture.get_service("logstash") }
+  let(:filebeat_service) { @fixture.get_service("filebeat") }
+  let(:log_path) do
+    tmp_path = Stud::Temporary.file.path #get around ignore older completely
+    source = File.expand_path(@fixture.input)
+    FileUtils.cp(source, tmp_path)
+    tmp_path
+  end
+  let(:number_of_events) do
+    File.open(log_path, "r").readlines.size
+  end
+
+  shared_examples "send events" do
+    let(:filebeat_config_path) do
+      file = Stud::Temporary.file
+      file.write(YAML.dump(filebeat_config))
+      file.close
+      file.path
+    end
+
+
+    it "sucessfully send events" do
+      logstash_service.start_background(logstash_config)
+      process = filebeat_service.run(filebeat_config_path)
+
+      # It can take some delay for filebeat to connect to logstash and start sending data.
+      # Its possible that logstash isn't completely initialized here, we can get "Connection Refused"
+      begin
+        sleep(1) while (result = logstash_service.monitoring_api.event_stats).nil?
+      rescue
+        retry
+      end
+
+      Stud.try(max_retry.times, RSpec::Expectations::ExpectationNotMetError) do
+         result = logstash_service.monitoring_api.event_stats
+         expect(result["in"]).to eq(number_of_events)
+      end
+    end
+  end
+
+  context "Without TLS" do
+    let(:logstash_config) { @fixture.config("without_tls") }
+    let(:filebeat_config) do
+      {
+        "filebeat" => {
+          "prospectors" => [{ "paths" => [log_path], "input_type" => "log" }],
+          "registry_file" => registry_file,
+          "scan_frequency" => "1s"
+        },
+        "output" => {
+          "logstash" => { "hosts" => ["localhost:5044"] },
+          "logging" => { "level" => "debug" }
+        }
+      }
+    end
+
+    include_examples "send events"
+  end
+
+  context "With TLS" do
+    let(:certificate_directory) { File.expand_path(File.join(File.dirname(__FILE__), "..", "fixtures", "certificates")) }
+    let(:certificate) { File.join(certificate_directory, "certificate.crt") }
+    let(:ssl_key) { File.join(certificate_directory, "certificate.key") }
+    let(:certificate_authorities) { [certificate] }
+
+    context "Server auth" do
+      let(:logstash_config) { @fixture.config("tls_server_auth", { :ssl_certificate => certificate, :ssl_key => ssl_key}) }
+      let(:filebeat_config) do
+        {
+          "filebeat" => {
+            "prospectors" => [{ "paths" => [log_path], "input_type" => "log" }],
+            "registry_file" => registry_file,
+            "scan_frequency" => "1s"
+          },
+          "output" => {
+            "logstash" => {
+              "hosts" => ["localhost:5044"],
+              "tls" => {
+                "certificate_authorities" => certificate_authorities
+              },
+              "ssl" => {
+                "certificate_authorities" => certificate_authorities
+              }
+            },
+            "logging" => { "level" => "debug" }
+          }
+        }
+      end
+
+      include_examples "send events"
+    end
+
+    context "Mutual auth" do
+      let(:logstash_config) { @fixture.config("tls_mutual_auth", { :ssl_certificate => certificate, :ssl_key => ssl_key}) }
+      let(:filebeat_config) do
+        {
+          "filebeat" => {
+            "prospectors" => [{ "paths" => [log_path], "input_type" => "log" }],
+            "registry_file" => registry_file,
+            "scan_frequency" => "1s"
+          },
+          "output" => {
+            "logstash" => {
+              "hosts" => ["localhost:5044"],
+              "tls" => {
+                "certificate_authorities" => certificate_authorities,
+                "certificate" => certificate,
+                "certificate_key" => ssl_key
+              },
+              "ssl" => {
+                "certificate_authorities" => certificate_authorities,
+                "certificate" => certificate,
+                "key" => ssl_key
+              }
+            },
+            "logging" => { "level" => "debug" }
+          }
+        }
+      end
+
+      include_examples "send events"
+    end
+  end
+end
diff --git a/qa/integration/specs/es_output_how_spec.rb b/qa/integration/specs/es_output_how_spec.rb
new file mode 100644
index 00000000000..27f2ef2d4b3
--- /dev/null
+++ b/qa/integration/specs/es_output_how_spec.rb
@@ -0,0 +1,29 @@
+require_relative '../framework/fixture'
+require_relative '../framework/settings'
+require_relative '../services/logstash_service'
+
+describe "a config which indexes data into Elasticsearch" do
+
+  before(:all) {
+    @fixture = Fixture.new(__FILE__)
+  }
+
+  after(:all) {
+    es_client = @fixture.get_service("elasticsearch").get_client
+    es_client.indices.delete(index: 'logstash-*')
+    @fixture.teardown
+  }
+
+  it "can ingest 300K log lines" do
+    logstash_service = @fixture.get_service("logstash")
+    es_service = @fixture.get_service("elasticsearch")
+    puts "Ingesting 300K lines of apache logs to ES. This may make your CPU sing.."
+    logstash_service.start_with_input(@fixture.config, @fixture.input)
+    es_client = es_service.get_client
+    # now we test if all data was indexed by ES, but first refresh manually
+    es_client.indices.refresh
+    result = es_client.search(index: 'logstash-*', size: 0, q: '*')
+    expect(result["hits"]["total"]).to eq(300000)
+  end
+
+end
diff --git a/qa/integration/specs/kafka_input_spec.rb b/qa/integration/specs/kafka_input_spec.rb
new file mode 100644
index 00000000000..2cd52e9e4dd
--- /dev/null
+++ b/qa/integration/specs/kafka_input_spec.rb
@@ -0,0 +1,25 @@
+require_relative '../framework/fixture'
+require_relative '../framework/settings'
+require_relative '../services/logstash_service'
+require "rspec/wait"
+
+describe "Kafka Input" do
+  let(:timeout_seconds) { 5 }
+  before(:all) {
+    @fixture = Fixture.new(__FILE__)
+  }
+
+  after(:all) {
+    @fixture.teardown
+  }
+
+  it "can ingest 37 apache log lines from Kafka broker" do
+    logstash_service = @fixture.get_service("logstash")
+    logstash_service.start_background(@fixture.config)
+
+    wait(timeout_seconds).for { @fixture.output_exists? }.to be true
+    expect(@fixture.output_equals_expected?).to be true
+      lambda { "Expected File output to match what was ingested into Kafka." }
+  end
+
+end
diff --git a/qa/integration/specs/monitoring_api_spec.rb b/qa/integration/specs/monitoring_api_spec.rb
new file mode 100644
index 00000000000..66028bb983c
--- /dev/null
+++ b/qa/integration/specs/monitoring_api_spec.rb
@@ -0,0 +1,35 @@
+require_relative '../framework/fixture'
+require_relative '../framework/settings'
+require_relative '../services/logstash_service'
+require "logstash/devutils/rspec/spec_helper"
+
+describe "Monitoring API" do
+  before(:all) {
+    @fixture = Fixture.new(__FILE__)
+  }
+
+  after(:all) {
+    @fixture.teardown
+  }
+  
+  let(:number_of_events) { 5 }
+  let(:max_retry) { 120 }
+
+  it "can retrieve event stats" do
+    logstash_service = @fixture.get_service("logstash")
+    logstash_service.start_with_stdin
+    number_of_events.times { logstash_service.write_to_stdin("Hello world") }
+    
+    begin
+      sleep(1) while (result = logstash_service.monitoring_api.event_stats).nil?
+    rescue
+      retry
+    end
+
+    Stud.try(max_retry.times, RSpec::Expectations::ExpectationNotMetError) do
+       result = logstash_service.monitoring_api.event_stats
+       expect(result["in"]).to eq(number_of_events)
+    end
+  end
+
+end
diff --git a/qa/integration/suite.yml b/qa/integration/suite.yml
new file mode 100644
index 00000000000..8ccdff47bbc
--- /dev/null
+++ b/qa/integration/suite.yml
@@ -0,0 +1,6 @@
+---
+# Use this to output more debug-level information  
+verbose_mode: false  
+# Typically we use the binaries in LS_HOME/build. If you want to QA a LS in different location, 
+# use the absolute path below  
+#ls_home_abs_path: /tmp/logstash-5.0.0-alpha6
\ No newline at end of file
