diff --git a/logstash-core/lib/logstash/api/commands/stats.rb b/logstash-core/lib/logstash/api/commands/stats.rb
index f578ba4adb2..100a58d7a6a 100644
--- a/logstash-core/lib/logstash/api/commands/stats.rb
+++ b/logstash-core/lib/logstash/api/commands/stats.rb
@@ -32,7 +32,7 @@ def process
         def events
           extract_metrics(
             [:stats, :events],
-            :in, :filtered, :out
+            :in, :filtered, :out, :duration_in_millis
           )
         end
 
diff --git a/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb b/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
index 9cb8c5ecfa1..bb20aef5c6d 100644
--- a/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
+++ b/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb
@@ -57,6 +57,9 @@ def initialize(queue, batch_size = 125, wait_for = 5)
         # Note that @infilght_batches as a central mechanism for tracking inflight
         # batches will fail if we have multiple read clients in the pipeline.
         @inflight_batches = {}
+
+        # allow the worker thread to report the execution time of the filter + output
+        @inflight_clocks = {}
         @batch_size = batch_size
         @wait_for = wait_for
       end
@@ -89,6 +92,7 @@ def take_batch
           batch = ReadBatch.new(@queue, @batch_size, @wait_for)
           add_starting_metrics(batch)
           set_current_thread_inflight_batch(batch)
+          start_clock
           batch
         end
       end
@@ -100,11 +104,23 @@ def set_current_thread_inflight_batch(batch)
       def close_batch(batch)
         @mutex.synchronize do
           @inflight_batches.delete(Thread.current)
+          stop_clock
         end
       end
 
+      def start_clock
+        @inflight_clocks[Thread.current] = [
+          @event_metric.time(:duration_in_millis),
+          @pipeline_metric.time(:duration_in_millis)
+        ]
+      end
+
+      def stop_clock
+        @inflight_clocks[Thread.current].each(&:stop)
+        @inflight_clocks.delete(Thread.current)
+      end
+
       def add_starting_metrics(batch)
-        return if @event_metric.nil? || @pipeline_metric.nil?
         @event_metric.increment(:in, batch.starting_size)
         @pipeline_metric.increment(:in, batch.starting_size)
       end
diff --git a/logstash-core/spec/api/lib/api/node_stats_spec.rb b/logstash-core/spec/api/lib/api/node_stats_spec.rb
index ea406980f88..3081bcf6c23 100644
--- a/logstash-core/spec/api/lib/api/node_stats_spec.rb
+++ b/logstash-core/spec/api/lib/api/node_stats_spec.rb
@@ -59,12 +59,13 @@
     },
    "pipeline" => {
      "events" => {
+        "duration_in_millis" => Numeric,
         "in" => Numeric,
         "filtered" => Numeric,
         "out" => Numeric
-     } 
-    } 
+     }
+    }
   }
-  
+
   test_api_and_resources(root_structure)
 end
diff --git a/logstash-core/spec/logstash/pipeline_spec.rb b/logstash-core/spec/logstash/pipeline_spec.rb
index fc29292f294..8bedf937bfa 100644
--- a/logstash-core/spec/logstash/pipeline_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_spec.rb
@@ -611,6 +611,7 @@ class TestPipeline < LogStash::Pipeline
       let(:collected_metric) { metric_store.get_with_path("stats/events") }
 
       it "populates the different metrics" do
+        expect(collected_metric[:stats][:events][:duration_in_millis].value).not_to be_nil
         expect(collected_metric[:stats][:events][:in].value).to eq(number_of_events)
         expect(collected_metric[:stats][:events][:filtered].value).to eq(number_of_events)
         expect(collected_metric[:stats][:events][:out].value).to eq(number_of_events)
@@ -621,6 +622,7 @@ class TestPipeline < LogStash::Pipeline
       let(:collected_metric) { metric_store.get_with_path("stats/pipelines/") }
 
       it "populates the pipelines core metrics" do
+        expect(collected_metric[:stats][:pipelines][:main][:events][:duration_in_millis].value).not_to be_nil
         expect(collected_metric[:stats][:pipelines][:main][:events][:in].value).to eq(number_of_events)
         expect(collected_metric[:stats][:pipelines][:main][:events][:filtered].value).to eq(number_of_events)
         expect(collected_metric[:stats][:pipelines][:main][:events][:out].value).to eq(number_of_events)
diff --git a/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb b/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb
index 12317f838a9..e0c5ce26d0c 100644
--- a/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb
+++ b/logstash-core/spec/logstash/util/wrapped_synchronous_queue_spec.rb
@@ -49,6 +49,12 @@ def poll(*) shift(); end
         let(:queue) { DummyQueue.new }
         let(:write_client) { LogStash::Util::WrappedSynchronousQueue::WriteClient.new(queue)}
         let(:read_client)  { LogStash::Util::WrappedSynchronousQueue::ReadClient.new(queue)}
+
+        before :each do
+          read_client.set_events_metric(LogStash::Instrument::NullMetric.new)
+          read_client.set_pipeline_metric(LogStash::Instrument::NullMetric.new)
+        end
+
         it "appends batches to the queue" do
           batch = write_client.get_new_batch
           5.times {|i| batch.push("value-#{i}")}
