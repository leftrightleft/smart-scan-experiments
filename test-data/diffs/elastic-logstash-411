diff --git a/CHANGELOG b/CHANGELOG
index 917bf91c761..71c4a75c1a4 100644
--- a/CHANGELOG
+++ b/CHANGELOG
@@ -19,6 +19,8 @@
     tagging events on failure. (#328, patch by Neil Prosser)
   - new: uaparser: parses user agent strings in to structured data based on
     BrowserScope data (#347, patch by Dan Everton)
+  - improvement: kv filter now accepts a include_fields option to selectively
+    include fields instead of parsing all fields
 
   ## outputs
   - fix bug in mongo output that would fail to load bson_java support
@@ -27,7 +29,7 @@
   - bugfix: elasticsearch: Fix a race condition. (#340, patch by Raymond Feng)
   - improvement: http: now supports a custom 'message' format for building your
     own http bodies from an event. (#319, patch by Christian S)
- 
+
 1.1.9 (January 10, 2013)
   ## inputs
   - bugfix: all inputs: fix bug where some @source values were not valid urls
@@ -129,7 +131,7 @@
  - improvement: grok: can now match against number types. Example, if you're
    sending a json format event with { "status": 403 } you can now grok that
    field.  The number is represented as a string "403" before pattern matching.
- - bugfix: date: Fix a bug that would crash the pipeline if no date pattern 
+ - bugfix: date: Fix a bug that would crash the pipeline if no date pattern
    matched. (LOGSTASH-705)
  - feature: kv: Adds field_split, value_split, prefix, and container
    settings. (#225, patch by Alex Wheeler)
@@ -157,7 +159,7 @@
  - feature: mongodb: new setting 'isodate' that, when true, stores the
    @timestamp field as a mongodb date instead of a string. (#224, patch by
    Kevin Amorin)
- - improvement: gelf: Allow full_message gelf property to be overridden (#245, 
+ - improvement: gelf: Allow full_message gelf property to be overridden (#245,
    patch by SÃ©bastien Masset)
  - misc: lumberjack: jls-lumberjack gem updated to 0.0.6
  - feature: nagios: New 'nagios_level' setting to let you change the level
@@ -183,7 +185,7 @@
    now work. (Fixes LOGSTASH-649, LOGSTASH-642, LOGSTASH-655)
  - several plugins received UTF-8-related fixes (file, lumberjack, etc)
    File bugs if you see any UTF-8 related crashes.
- - 'json_event' format inputs will now respect 'tags' (#239, patch by 
+ - 'json_event' format inputs will now respect 'tags' (#239, patch by
    Tim Laszlo)
  - logstash no longer uses nor recommends bundler (see 'gembag.rb'). The
    Gemfile will be purged in the near future.
@@ -251,7 +253,7 @@
 
  ## inputs
  - bugfix: redis: [LOGSTASH-526] fix bug with password passing
- - new: lumberjack: for use with the lumberjack log shipper 
+ - new: lumberjack: for use with the lumberjack log shipper
    (https://github.com/jordansissel/lumberjack)
  - new: sqs: Amazon SQS input (Patch by Sean Laurent, #211)
  - new: relp: RELP (rsyslog) plugin (Patch by Mike Worth, #177)
@@ -282,10 +284,10 @@
  - grok patterns: the URIPARAM pattern now includes pipe '|' as a valid
    character. (Patch by Chris Mague)
  - grok patterns: improve haproxy log patterns (Patch by Kevin Nuckolls)
- - grok patterns: include 'FATAL' as a valid LOGLEVEL match 
+ - grok patterns: include 'FATAL' as a valid LOGLEVEL match
    (patch by Corry Haines)
  - grok patterns: 'ZONE' is no longer captured by name in the HTTPDATE pattern
- - new: alter: adds some conditional field modification as well as a 
+ - new: alter: adds some conditional field modification as well as a
    'coalesce' feature which sets the value of a field to the first non-null
    value given in a list. (Patch by Francesco Salbaroli)
  - improvement: date: add TAI64N support
@@ -416,7 +418,7 @@
 
   ## IMPORTANT CHANGES FOR UPGRADES FROM 1.0.x
     - grok filter: named_captures_only now defaults to true
-        This means simple patterns %{NUMBER} without any other name will 
+        This means simple patterns %{NUMBER} without any other name will
         now not be included in the field set. You can revert to the old
         behavior by setting 'named_captures_only => false' in your grok
         filter config.
@@ -506,7 +508,7 @@
 1.0.17 (Aug 12, 2011)
   - Bugs fixed
     - [LOGSTASH-147] - grok filter incorrectly adding fields when a match failed
-    - [LOGSTASH-151] - Fix bug in routing keys on AMQP 
+    - [LOGSTASH-151] - Fix bug in routing keys on AMQP
     - [LOGSTASH-156] - amqp issue with 1.0.16?
 
   - Improvement
@@ -597,7 +599,7 @@
   - bugfix: amqp input now reconnects properly when the amqp broker restarts.
   - bugfix: Fix bug in gelf output when a fields were not arrays but numbers.
     Issue: https://logstash.jira.com/browse/LOGSTASH-113
-  - bugfix: Fix a bug in syslog udp input due to misfeatures in Ruby's URI 
+  - bugfix: Fix a bug in syslog udp input due to misfeatures in Ruby's URI
     class. https://logstash.jira.com/browse/LOGSTASH-115
   - misc: jquery and jquery ui now ship with logstash; previously they were
     loaded externally
@@ -605,7 +607,7 @@
   - testing: fixed logstash-test to now run properly
 
 1.0.12 (Jun 9, 2011)
-  - misc: clean up some excess debugging output 
+  - misc: clean up some excess debugging output
   - feature: for tcp input, allow 'data_timeout => -1' to mean "never time out"
 
 1.0.11 (Jun 9, 2011)
@@ -615,7 +617,7 @@
   - feature: Refactor runner to allow you to run multiple things in a single
     process.  You can end each instance with '--' flag. For example, to run one
     agent and one web instance:
-      % java -jar logstash-blah.jar agent -f myconfig -- web 
+      % java -jar logstash-blah.jar agent -f myconfig -- web
   - feature: Add 'embedded' option to the elasticsearch output:
       elasticsearch { embedded => true }
     Default is false. If true, logstash will run an elasticsearch server
@@ -632,7 +634,7 @@
     multihomed server.
   - feature: The mongodb output now supports authentication
   - bugfix: Fix bug in GELF output that caused the gelf short_message to be set as an
-    array if it came from a grok value. The short_message field should only 
+    array if it came from a grok value. The short_message field should only
     now be a string properly.
   - bugfix: Fix bug in grep filter that would drop/cancel events if you had
     more than one event type flowing through filters and didn't have a grep
@@ -679,7 +681,7 @@
   - Add shutdown processing. Shutdown starts when all inputs finish (like
     stdin) The sequence progresses using the same pipeline as the
     inputs/filters/outputs, so all in-flight events should finish getting
-    processed before the final shutdown event makes it's way to the outputs.  
+    processed before the final shutdown event makes it's way to the outputs.
   - Add retries to unhandled input exceptions (LOGSTASH-84)
 
 1.0.6 (May 11, 2011)
diff --git a/lib/logstash/filters/kv.rb b/lib/logstash/filters/kv.rb
index 94834e336b2..a1ad5b601a0 100644
--- a/lib/logstash/filters/kv.rb
+++ b/lib/logstash/filters/kv.rb
@@ -18,7 +18,7 @@
 # * error: REFUSED
 #
 # This is great for postfix, iptables, and other types of logs that
-# tend towards 'key=value' syntax. 
+# tend towards 'key=value' syntax.
 #
 # Further, this can often be used to parse query parameters like
 # 'foo=bar&baz=fizz' by setting the field_split to "&"
@@ -29,14 +29,28 @@ class LogStash::Filters::KV < LogStash::Filters::Base
   # The fields to perform 'key=value' searching on
   config :fields, :validate => :array
 
+  # An array that includes all the fields which will be parsed
+  # If this is present, only the specified keys will be parsed.
+  #
+  # for ex, if a string is: "Hey, from=<abc>, to=def foo=bar"
+  #
+  #     filter {
+  #       kv {
+  #         include_fields = [ "from", "to" ]
+  #       }
+  #
+  # Key "foo" will automatically be ignored.
+  config :include_fields, :validate => :array, :default => []
+
+  #
   # A string of characters to trim from the value. This is useful if your
   # values are wrapped in brackets or are terminated by comma (like postfix
   # logs)
   #
   # Example, to strip '<' '>' and ',' characters from values:
-  # 
-  #     filter { 
-  #       kv { 
+  #
+  #     filter {
+  #       kv {
   #         trim => "<>,"
   #       }
   #     }
@@ -52,7 +66,7 @@ class LogStash::Filters::KV < LogStash::Filters::Base
   #
   #     filter {
   #       kv {
-  #         field_split => "&?" 
+  #         field_split => "&?"
   #       }
   #     }
   #
@@ -71,7 +85,7 @@ class LogStash::Filters::KV < LogStash::Filters::Base
   #
   # Example, to identify key-values such as
   # 'key1:value1 key2:value2':
-  # 
+  #
   #     filter { kv { value_split => ":" } }
   config :value_split, :validate => :string, :default => '='
 
@@ -82,7 +96,7 @@ class LogStash::Filters::KV < LogStash::Filters::Base
   #     filter { kv { prefix => "arg_" } }
   config :prefix, :validate => :string, :default => ''
 
-  # The name of the container to put all of the key-value pairs into 
+  # The name of the container to put all of the key-value pairs into
   #
   # Example, to place all keys into container kv:
   #
@@ -96,7 +110,7 @@ class LogStash::Filters::KV < LogStash::Filters::Base
   #     filter { kv { source => "@message" } }
   config :source, :validate => :string, :default => '@message'
 
-  # The name of the container to put all of the key-value pairs into 
+  # The name of the container to put all of the key-value pairs into
   #
   # Example, to place all keys into field kv:
   #
@@ -123,6 +137,10 @@ def register
       @fields << @source
     end
 
+    #Check if all key value pairs need to be parsed
+    @catch_all_keys = true
+    @catch_all_keys = false if include_fields.length > 0
+
   end # def register
 
   def filter(event)
@@ -138,7 +156,7 @@ def filter(event)
         when nil; #Nothing to do
         when String; kv_keys = parse(value, event, kv_keys)
         when Array; value.each { |v| kv_keys = parse(v, event, kv_keys) }
-        else 
+        else
           @logger.warn("kv filter has no support for this type of data",
                        :type => value.class, :value => value)
       end # case value
@@ -166,7 +184,14 @@ def parse(text, event, kv_keys)
         value = value.gsub(@trim_re, "")
       end
       key = @prefix + key
-      kv_keys[key] = value
+
+      if @catch_all_keys
+        kv_keys[key] = value
+      else
+        if @include_fields.include? @prefix + key
+          kv_keys[key] = value
+        end
+      end
     end
     return kv_keys
   end
