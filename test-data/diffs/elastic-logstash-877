diff --git a/lib/logstash/filters/limit_duplicate.rb b/lib/logstash/filters/limit_duplicate.rb
new file mode 100644
index 00000000000..327c4772b0a
--- /dev/null
+++ b/lib/logstash/filters/limit_duplicate.rb
@@ -0,0 +1,78 @@
+# encoding: utf-8
+require "logstash/filters/base"
+require "logstash/namespace"
+
+# Reduce the duplicated events.
+#
+# This filter is used to limit the events which are duplicated in a peroid 
+# to only one event, which means only allow the first event pass the filter, 
+# and drop the following duplicated ones in a time period. Pay attention, usually
+# there is a timestamp at the beginning of the log message, which will make 
+# the log messages are not the same, just because the timestamp is not same, 
+# so you need grok filter to get rid of the timestamp, by parsing an new filed used
+# for duplicate checking.
+#
+# The config looks like this:
+#
+#     filter {
+#       limit_duplicate {
+#         limit_time_window => "30s"
+#         duplicated_by => ["some field1", "some field2"]
+#       }
+#     }
+class LogStash::Filters::LimitDuplicate < LogStash::Filters::Base
+
+  config_name "limit_duplicate"
+  milestone 1
+
+  # The peroid time window of the logs should be droped by duplicated.
+  config :limit_time_window, :validate => :string, :default => "30s"
+
+  # The fields name used to check duplicated or not, by default is the message. 
+  # It's a array, which means you can define it as ["field1","field2"], and it will check 
+  # if both two fields' value are duplicated, then it considers the event as duplicated.
+  config :duplicated_by, :validate => :array, :default => ["message"]
+
+  public
+  def register
+    require "thread"
+    require "rufus/scheduler"
+
+    @duplicated_by = @duplicated_by.uniq.sort
+    @mutex = Mutex.new
+    @uniqueEventSet = Set.new
+    @scheduler = Rufus::Scheduler.start_new
+    @job = @scheduler.every @limit_time_window do
+      @logger.info("Scheduler Activated")
+      @mutex.synchronize{
+        @uniqueEventSet.clear()
+      }
+    end
+  end # def register
+
+  public
+  def filter(event)
+    return unless filter?(event)
+    
+    @logger.info("do limit duplicate filter")
+    if event == LogStash::SHUTDOWN
+      @job.trigger()
+      @job.unschedule()
+      @logger.info("limit_duplicate filter thread shutdown.")
+      return
+    end
+
+    uniqueFieldsValueArray = @duplicated_by.map do |item|
+      event[item]
+    end
+
+    @mutex.synchronize{
+      if (@uniqueEventSet.include?(uniqueFieldsValueArray))
+        event.cancel
+      else
+        @uniqueEventSet << uniqueFieldsValueArray
+      end
+    }
+  end # def filter
+
+end #
diff --git a/spec/filters/limit_duplicate.rb b/spec/filters/limit_duplicate.rb
new file mode 100644
index 00000000000..1a34a4ee085
--- /dev/null
+++ b/spec/filters/limit_duplicate.rb
@@ -0,0 +1,196 @@
+require "test_utils"
+require "logstash/filters/limit_duplicate"
+
+describe LogStash::Filters::LimitDuplicate do
+  extend LogStash::RSpec
+
+  describe "drop duplicated event by default settings" do
+    config <<-CONFIG
+      filter {
+        limit_duplicate {
+        }
+      }
+    CONFIG
+
+    events = [
+      {
+        "message" => "messageA"
+      },
+      {
+        "message" => "messageB"
+      },
+      {
+        "message" => "messageA"
+      },
+      {
+        "message" => "messageB"
+      }
+    ]
+
+    sample(events) do
+      insist { subject }.is_a? Array
+      insist { subject.length } == 2 # the third event with messageA should be droped.
+      subject.each_with_index do |s,i|
+        if i == 0 # first one should be the messageA
+          insist { s["message"] } == "messageA"
+        end
+        if i == 1 # second one should be the messageB
+          insist { s["message"]} == "messageB"
+        end
+      end
+    end
+  end
+
+
+  describe "drop duplicated event by a specific field" do
+    config <<-CONFIG
+      filter {
+        limit_duplicate {
+          duplicated_by => ["someField"]
+        }
+      }
+    CONFIG
+
+    events = [
+      {
+        "someField" => "valueA",
+        "message" => "messageA"
+      },
+      {
+        "someField" => "valueA",
+        "message" => "messageB"
+      },
+      {
+        "someField" => "valueB",
+        "message" => "messageA"
+      },{
+        "someField" => "valueA",
+        "message" => "messageC"
+      },
+      {
+        "someField" => "valueB",
+        "message" => "messageD"
+      },
+      {
+        "someField" => "valueC",
+        "message" => "messageC"
+      }
+    ]
+
+    sample(events) do
+      insist { subject }.is_a? Array
+      insist { subject.length } == 3
+      subject.each_with_index do |s,i|
+        if i == 0 # first one should be the messageA
+          insist { s["message"] } == "messageA"
+        end
+        if i == 1 # second one should be the messageA
+          insist { s["message"] } == "messageA"
+        end
+        if i == 2 # third one should be the messageC
+          insist { s["message"] } == "messageC"
+        end
+      end
+    end
+  end
+
+  describe "limit only a specific event" do
+    config <<-CONFIG
+      filter {
+        grep {
+          add_tag => [ "duplicate" ]
+          match => [ "message", "A" ]
+          drop => false
+        }
+        if "duplicate" in [tags] {
+          limit_duplicate {
+          }
+        }
+      }
+    CONFIG
+
+    events = [
+      {
+        "message" => "messageA"
+      },
+      {
+        "message" => "messageB"
+      },
+      {
+        "message" => "messageA"
+      }
+    ]
+
+    sample(events) do
+      insist { subject }.is_a? Array
+      insist { subject.length } == 2
+      subject.each_with_index do |s,i|
+        if i == 0 # first one should be the messageA
+          insist { s["message"] } == "messageA"
+        end
+        if i == 1 # second one should be the messageA
+          insist { s["message"] } == "messageB"
+        end
+      end
+    end
+  end
+
+  describe "drop duplicated event by two specific fields" do
+    config <<-CONFIG
+      filter {
+        limit_duplicate {
+          duplicated_by => ["someField1", "someField2"]
+        }
+      }
+    CONFIG
+
+    events = [
+      {
+        "someField1" => "f1A",
+        "someField2" => "f2A",
+        "message" => "messageA"
+      },
+      {
+        "someField1" => "f1A",
+        "someField2" => "f2A",
+        "message" => "messageB"
+      },
+      {
+        "someField1" => "f1B",
+        "someField2" => "f2A",
+        "message" => "messageA"
+      },{
+        "someField1" => "f1A",
+        "someField2" => "f2B",
+        "message" => "messageA"
+      },
+      {
+        "someField1" => "f1A",
+        "someField2" => "f2B",
+        "message" => "messageB"
+      },
+      {
+        "someField1" => "f1A",
+        "someField2" => "f2A",
+        "message" => "messageC"
+      }
+    ]
+
+    sample(events) do
+      insist { subject }.is_a? Array
+      insist { subject.length } == 3
+      subject.each_with_index do |s,i|
+        if i == 0 # first one should be the messageA, the second and the sixth events will be removed.
+          insist { s["message"] } == "messageA"
+        end
+        if i == 1 # second one should be the messageA, the third event will not be removed.
+          insist { s["message"] } == "messageA"
+        end
+        if i == 2 # third one should be the messageA, the final event will be removed.
+          insist { s["message"] } == "messageA"
+        end
+      end
+    end
+  end
+
+end
