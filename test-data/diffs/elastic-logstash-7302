diff --git a/tools/ingest-converter/src/main/java/org/logstash/ingest/Date.java b/tools/ingest-converter/src/main/java/org/logstash/ingest/Date.java
index a6a4d0aac5e..2403db23581 100644
--- a/tools/ingest-converter/src/main/java/org/logstash/ingest/Date.java
+++ b/tools/ingest-converter/src/main/java/org/logstash/ingest/Date.java
@@ -19,7 +19,7 @@ private Date() {
 
     public static void main(final String... args) throws ScriptException, NoSuchMethodException {
         try {
-            final ScriptEngine engine = JsUtil.engine("/ingest-date.js");
+            final ScriptEngine engine = JsUtil.engine();
             Files.write(Paths.get(args[1]), ((String) ((Invocable) engine).invokeFunction(
                 "ingest_to_logstash_date",
                 new String(
diff --git a/tools/ingest-converter/src/main/java/org/logstash/ingest/GeoIp.java b/tools/ingest-converter/src/main/java/org/logstash/ingest/GeoIp.java
new file mode 100644
index 00000000000..7928ecba8d2
--- /dev/null
+++ b/tools/ingest-converter/src/main/java/org/logstash/ingest/GeoIp.java
@@ -0,0 +1,30 @@
+package org.logstash.ingest;
+
+import java.io.IOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import javax.script.Invocable;
+import javax.script.ScriptEngine;
+import javax.script.ScriptException;
+
+public final class GeoIp {
+
+    private GeoIp() {
+        // Utility Wrapper for JS Script.
+    }
+    
+    public static void main(final String... args) throws ScriptException, NoSuchMethodException {
+        try {
+            final ScriptEngine engine = JsUtil.engine();
+            Files.write(Paths.get(args[1]), ((String) ((Invocable) engine).invokeFunction(
+                "ingest_to_logstash_geoip",
+                new String(
+                    Files.readAllBytes(Paths.get(args[0])), StandardCharsets.UTF_8
+                )
+            )).getBytes(StandardCharsets.UTF_8));
+        } catch (final IOException ex) {
+            throw new IllegalStateException(ex);
+        }
+    }
+}
diff --git a/tools/ingest-converter/src/main/java/org/logstash/ingest/Grok.java b/tools/ingest-converter/src/main/java/org/logstash/ingest/Grok.java
index 0bd0f84d144..c8884e18027 100644
--- a/tools/ingest-converter/src/main/java/org/logstash/ingest/Grok.java
+++ b/tools/ingest-converter/src/main/java/org/logstash/ingest/Grok.java
@@ -19,7 +19,7 @@ private Grok() {
 
     public static void main(final String... args) throws ScriptException, NoSuchMethodException {
         try {
-            final ScriptEngine engine = JsUtil.engine("/ingest-grok.js");
+            final ScriptEngine engine = JsUtil.engine();
             Files.write(Paths.get(args[1]), ((String) ((Invocable) engine).invokeFunction(
                 "ingest_to_logstash_grok",
                 new String(
diff --git a/tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java b/tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java
index 19b386bc019..8885b0a71b2 100644
--- a/tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java
+++ b/tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java
@@ -9,31 +9,37 @@
 
 final class JsUtil {
 
+    /**
+     * Script names used by the converter in correct load order.
+     */
+    private static final String[] SCRIPTS = {"shared", "date", "grok", "geoip", "pipeline"};
+
     private JsUtil() {
         // Utility Class
     }
 
     /**
-     * Sets up a {@link ScriptEngine} for a given file loaded after `ingest-shared.js`.
-     * @param file File to set up {@link ScriptEngine} for
-     * @return {@link ScriptEngine} for file
+     * Sets up a {@link ScriptEngine} with all Ingest to LS DSL Converter JS scripts loaded.
+     * @return {@link ScriptEngine} for Ingest to LS DSL Converter
      */
-    public static ScriptEngine engine(final String file) {
+    public static ScriptEngine engine() {
         final ScriptEngine engine =
             new ScriptEngineManager().getEngineByName("nashorn");
-        try (
-            final Reader shared = reader("/ingest-shared.js");
-            final Reader reader = reader(file)
-        ) {
-            engine.eval(shared);
-            engine.eval(reader);
+        try {
+            for (final String file : SCRIPTS) {
+                add(engine, String.format("/ingest-%s.js", file));
+            }
         } catch (final IOException | ScriptException ex) {
             throw new IllegalStateException(ex);
         }
         return engine;
     }
 
-    private static Reader reader(final String file) {
-        return new InputStreamReader(JsUtil.class.getResourceAsStream(file));
+    private static void add(final ScriptEngine engine, final String file)
+        throws IOException, ScriptException {
+        try (final Reader reader =
+                 new InputStreamReader(JsUtil.class.getResourceAsStream(file))) {
+            engine.eval(reader);
+        }
     }
 }
diff --git a/tools/ingest-converter/src/main/java/org/logstash/ingest/Pipeline.java b/tools/ingest-converter/src/main/java/org/logstash/ingest/Pipeline.java
new file mode 100644
index 00000000000..5af07c47eb3
--- /dev/null
+++ b/tools/ingest-converter/src/main/java/org/logstash/ingest/Pipeline.java
@@ -0,0 +1,33 @@
+package org.logstash.ingest;
+
+import java.io.IOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import javax.script.Invocable;
+import javax.script.ScriptEngine;
+import javax.script.ScriptException;
+
+/**
+ * Ingest Full DSL to Logstash DSL Transpiler.
+ */
+public final class Pipeline {
+
+    private Pipeline() {
+        // Utility Wrapper for JS Script.
+    }
+
+    public static void main(final String... args) throws ScriptException, NoSuchMethodException {
+        try {
+            final ScriptEngine engine = JsUtil.engine();
+            Files.write(Paths.get(args[1]), ((String) ((Invocable) engine).invokeFunction(
+                "ingest_pipeline_to_logstash",
+                new String(
+                    Files.readAllBytes(Paths.get(args[0])), StandardCharsets.UTF_8
+                )
+            )).getBytes(StandardCharsets.UTF_8));
+        } catch (final IOException ex) {
+            throw new IllegalStateException(ex);
+        }
+    }
+}
diff --git a/tools/ingest-converter/src/main/resources/ingest-date.js b/tools/ingest-converter/src/main/resources/ingest-date.js
index ac92129231f..fedd7e12173 100644
--- a/tools/ingest-converter/src/main/resources/ingest-date.js
+++ b/tools/ingest-converter/src/main/resources/ingest-date.js
@@ -1,3 +1,43 @@
+var IngestDate = {
+    has_date: function (processor) {
+        return !!processor["date"];
+    },
+    date_hash: function (processor) {
+        var date_json = processor["date"];
+        var formats = date_json["formats"];
+        var match_contents = [IngestConverter.dots_to_square_brackets(date_json["field"])];
+        for (var f in formats) {
+            match_contents.push(formats[f]);
+        }
+        var date_contents = IngestConverter.create_field(
+            "match",
+            IngestConverter.create_pattern_array(match_contents)
+        );
+        if (date_json["target_field"]) {
+            var target = IngestConverter.create_field(
+                "target",
+                IngestConverter.quote_string(
+                    IngestConverter.dots_to_square_brackets(date_json["target_field"])
+                )
+            );
+            date_contents = IngestConverter.join_hash_fields([date_contents, target]);
+        }
+        if (date_json["timezone"]) {
+            var timezone = IngestConverter.create_field(
+                "timezone",
+                IngestConverter.quote_string(date_json["timezone"])
+            );
+            date_contents = IngestConverter.join_hash_fields([date_contents, timezone]);
+        }
+        if (date_json["locale"]) {
+            var locale = IngestConverter.create_field(
+                "locale", IngestConverter.quote_string(date_json["locale"]));
+            date_contents = IngestConverter.join_hash_fields([date_contents, locale]);
+        }
+        return date_contents;
+    }
+};
+
 /**
  * Converts Ingest Date JSON to LS Date filter.
  */
@@ -5,50 +45,12 @@ function ingest_to_logstash_date(json) {
 
     function map_processor(processor) {
 
-        function date_hash(processor) {
-            var date_json = processor["date"];
-            var formats = date_json["formats"];
-            var match_contents = [IngestConverter.dots_to_square_brackets(date_json["field"])];
-            for (var f in formats) {
-                match_contents.push(formats[f]);
-            }
-            var date_contents = IngestConverter.create_field(
-                "match",
-                IngestConverter.create_pattern_array(match_contents)
-            );
-            if (date_json["target_field"]) {
-                var target = IngestConverter.create_field(
-                    "target",
-                    IngestConverter.quote_string(
-                        IngestConverter.dots_to_square_brackets(date_json["target_field"])
-                    )
-                );
-                date_contents = IngestConverter.join_hash_fields([date_contents, target]);
-            }
-            if (date_json["timezone"]) {
-                var timezone = IngestConverter.create_field(
-                    "timezone",
-                    IngestConverter.quote_string(date_json["timezone"])
-                );
-                date_contents = IngestConverter.join_hash_fields([date_contents, timezone]);
-            }
-            if (date_json["locale"]) {
-                var locale = IngestConverter.create_field(
-                    "locale", IngestConverter.quote_string(date_json["locale"]));
-                date_contents = IngestConverter.join_hash_fields([date_contents, locale]);
-            }
-            return date_contents;
-        }
-
-        return IngestConverter.fix_indent(
+        return IngestConverter.filter_hash(
             IngestConverter.create_hash(
-                "filter",
-                IngestConverter.create_hash(
-                    "date", date_hash(processor)
-                )
+                "date", IngestDate.date_hash(processor)
             )
-        )
+        );
     }
 
-    return JSON.parse(json)["processors"].map(map_processor).join("\n\n") + "\n";
+    return IngestConverter.filters_to_file(JSON.parse(json)["processors"].map(map_processor));
 }
diff --git a/tools/ingest-converter/src/main/resources/ingest-geoip.js b/tools/ingest-converter/src/main/resources/ingest-geoip.js
new file mode 100644
index 00000000000..7250e3bfca9
--- /dev/null
+++ b/tools/ingest-converter/src/main/resources/ingest-geoip.js
@@ -0,0 +1,46 @@
+var IngestGeoIp = {
+    has_geoip: function (processor) {
+        return !!processor["geoip"];
+    },
+    geoip_hash: function (processor) {
+        var geoip_data = processor["geoip"];
+        var parts = [
+            IngestConverter.create_field(
+                "source",
+                IngestConverter.quote_string(
+                    IngestConverter.dots_to_square_brackets(geoip_data["field"])
+                )
+            ),
+            IngestConverter.create_field(
+                "target",
+                IngestConverter.quote_string(
+                    IngestConverter.dots_to_square_brackets(geoip_data["target_field"])
+                )
+            )
+        ];
+        if (geoip_data["properties"]) {
+            parts.push(
+                IngestConverter.create_field(
+                    "fields",
+                    IngestConverter.create_pattern_array(geoip_data["properties"])
+                )
+            );
+        }
+        return IngestConverter.join_hash_fields(parts);
+    }
+};
+
+/**
+ * Converts Ingest JSON to LS Grok.
+ */
+function ingest_to_logstash_geoip(json) {
+
+    function map_processor(processor) {
+
+        return IngestConverter.filter_hash(
+            IngestConverter.create_hash("geoip", IngestGeoIp.geoip_hash(processor))
+        )
+    }
+
+    return IngestConverter.filters_to_file(JSON.parse(json)["processors"].map(map_processor));
+}
diff --git a/tools/ingest-converter/src/main/resources/ingest-grok.js b/tools/ingest-converter/src/main/resources/ingest-grok.js
index f4126add26b..c81c01bba2d 100644
--- a/tools/ingest-converter/src/main/resources/ingest-grok.js
+++ b/tools/ingest-converter/src/main/resources/ingest-grok.js
@@ -1,9 +1,8 @@
-/**
- * Converts Ingest JSON to LS Grok.
- */
-function ingest_to_logstash_grok(json) {
-
-    function map_processor(processor) {
+var IngestGrok = {
+    has_grok: function (processor) {
+        return !!processor["grok"];
+    },
+    grok_hash: function (processor) {
 
         function create_hash_field(name, content) {
             return IngestConverter.create_field(
@@ -11,47 +10,49 @@ function ingest_to_logstash_grok(json) {
             );
         }
 
-        function grok_hash(processor) {
-            function create_pattern_definition_hash(definitions) {
-                var content = [];
-                for (var key in definitions) {
-                    if (definitions.hasOwnProperty(key)) {
-                        content.push(
-                            IngestConverter.create_field(
-                                IngestConverter.quote_string(key),
-                                IngestConverter.quote_string(definitions[key]))
-                        );
-                    }
+        function create_pattern_definition_hash(definitions) {
+            var content = [];
+            for (var key in definitions) {
+                if (definitions.hasOwnProperty(key)) {
+                    content.push(
+                        IngestConverter.create_field(
+                            IngestConverter.quote_string(key),
+                            IngestConverter.quote_string(definitions[key]))
+                    );
                 }
-                return create_hash_field("pattern_definitions", content);
             }
-
-            var grok_data = processor["grok"];
-            var grok_contents = create_hash_field(
-                "match",
-                IngestConverter.create_field(
-                    IngestConverter.quote_string(grok_data["field"]),
-                    IngestConverter.create_pattern_array(grok_data["patterns"])
-                )
-            );
-            if (grok_data["pattern_definitions"]) {
-                grok_contents = IngestConverter.join_hash_fields([
-                    grok_contents,
-                    create_pattern_definition_hash(grok_data["pattern_definitions"])
-                ])
-            }
-            return grok_contents;
+            return create_hash_field("pattern_definitions", content);
         }
 
-        return IngestConverter.fix_indent(
-            IngestConverter.create_hash(
-                "filter",
-                IngestConverter.create_hash(
-                    "grok", grok_hash(processor)
-                )
+        var grok_data = processor["grok"];
+        var grok_contents = create_hash_field(
+            "match",
+            IngestConverter.create_field(
+                IngestConverter.quote_string(grok_data["field"]),
+                IngestConverter.create_pattern_array_or_field(grok_data["patterns"])
             )
+        );
+        if (grok_data["pattern_definitions"]) {
+            grok_contents = IngestConverter.join_hash_fields([
+                grok_contents,
+                create_pattern_definition_hash(grok_data["pattern_definitions"])
+            ])
+        }
+        return grok_contents;
+    }
+};
+
+/**
+ * Converts Ingest JSON to LS Grok.
+ */
+function ingest_to_logstash_grok(json) {
+
+    function map_processor(processor) {
+
+        return IngestConverter.filter_hash(
+            IngestConverter.create_hash("grok", IngestGrok.grok_hash(processor))
         )
     }
 
-    return JSON.parse(json)["processors"].map(map_processor).join("\n\n") + "\n";
+    return IngestConverter.filters_to_file(JSON.parse(json)["processors"].map(map_processor));
 }
diff --git a/tools/ingest-converter/src/main/resources/ingest-pipeline.js b/tools/ingest-converter/src/main/resources/ingest-pipeline.js
new file mode 100644
index 00000000000..ab475c870a8
--- /dev/null
+++ b/tools/ingest-converter/src/main/resources/ingest-pipeline.js
@@ -0,0 +1,33 @@
+/**
+ * Converts Ingest JSON to LS Grok.
+ */
+function ingest_pipeline_to_logstash(json) {
+
+    function map_processor(processor) {
+
+        var filter_blocks = [];
+        if (IngestGrok.has_grok(processor)) {
+            filter_blocks.push(
+                IngestConverter.create_hash("grok", IngestGrok.grok_hash(processor))
+            )
+        }
+        if (IngestDate.has_date(processor)) {
+            filter_blocks.push(
+                IngestConverter.create_hash("date", IngestDate.date_hash(processor))
+            )
+        }
+        if (IngestGeoIp.has_geoip(processor)) {
+            filter_blocks.push(
+                IngestConverter.create_hash("geoip", IngestGeoIp.geoip_hash(processor))
+            )
+        }
+        return IngestConverter.join_hash_fields(filter_blocks);
+    }
+
+    return IngestConverter.filters_to_file([
+            IngestConverter.filter_hash(
+                IngestConverter.join_hash_fields(JSON.parse(json)["processors"].map(map_processor))
+            )
+        ]
+    );
+}
diff --git a/tools/ingest-converter/src/main/resources/ingest-shared.js b/tools/ingest-converter/src/main/resources/ingest-shared.js
index d195d68d917..6b39a0f57b1 100644
--- a/tools/ingest-converter/src/main/resources/ingest-shared.js
+++ b/tools/ingest-converter/src/main/resources/ingest-shared.js
@@ -89,5 +89,26 @@ var IngestConverter = {
         return "[\n" 
             + patterns.map(this.dots_to_square_brackets).map(this.quote_string).join(",\n") 
             + "\n]";
+    },
+    
+    /**
+     * Converts Ingest/JSON style pattern array to LS pattern array or string if the given array
+     * contains a single element only, performing necessary variable name and quote escaping
+     * adjustments.
+     * @param patterns Pattern Array in JSON formatting
+     * @returns {string} Pattern array or string in LS formatting
+     */
+    create_pattern_array_or_field: function (patterns) {
+        return patterns.length === 1
+            ? this.quote_string(this.dots_to_square_brackets(patterns[0]))
+            : this.create_pattern_array(patterns);
+    },
+    
+    filter_hash: function(contents) {
+        return this.fix_indent(this.create_hash("filter", contents))
+    },
+    
+    filters_to_file: function(filters) {
+        return filters.join("\n\n") + "\n";
     }
 };
diff --git a/tools/ingest-converter/src/test/java/org/logstash/ingest/DateTest.java b/tools/ingest-converter/src/test/java/org/logstash/ingest/DateTest.java
index e8b036efd93..ae26f8ffc0a 100644
--- a/tools/ingest-converter/src/test/java/org/logstash/ingest/DateTest.java
+++ b/tools/ingest-converter/src/test/java/org/logstash/ingest/DateTest.java
@@ -1,36 +1,25 @@
 package org.logstash.ingest;
 
+import java.util.Arrays;
 import org.junit.Test;
 
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
+import static org.junit.runners.Parameterized.Parameters;
 
 public final class DateTest extends IngestTest {
 
-    @Test
-    public void convertsFieldPatternsCorrectly() throws Exception {
-        final String date = getResultPath(temp);
-        Date.main(resourcePath("ingestDate.json"), date);
-        assertThat(
-            utf8File(date), is(utf8File(resourcePath("logstashDate.conf")))
-        );
-    }
-
-    @Test
-    public void convertsFieldDefinitionsCorrectly() throws Exception {
-        final String date = getResultPath(temp);
-        Date.main(resourcePath("ingestDateExtraFields.json"), date);
-        assertThat(
-            utf8File(date), is(utf8File(resourcePath("logstashDateExtraFields.conf")))
-        );
+    @Parameters
+    public static Iterable<String> data() {
+        return Arrays.asList("Date", "DateExtraFields", "DotsInDateField");
     }
 
     @Test
-    public void convertsDotsInDateField() throws Exception {
+    public void convertsDateFieldCorrectly() throws Exception {
         final String date = getResultPath(temp);
-        Date.main(resourcePath("dotsInDateField.json"), date);
+        Date.main(resourcePath(String.format("ingest%s.json", testCase)), date);
         assertThat(
-            utf8File(date), is(utf8File(resourcePath("dotsInDateField.conf")))
+            utf8File(date), is(utf8File(resourcePath(String.format("logstash%s.conf", testCase))))
         );
     }
 }
diff --git a/tools/ingest-converter/src/test/java/org/logstash/ingest/GeoIpTest.java b/tools/ingest-converter/src/test/java/org/logstash/ingest/GeoIpTest.java
new file mode 100644
index 00000000000..fb760781420
--- /dev/null
+++ b/tools/ingest-converter/src/test/java/org/logstash/ingest/GeoIpTest.java
@@ -0,0 +1,25 @@
+package org.logstash.ingest;
+
+import java.util.Arrays;
+import org.junit.Test;
+
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.junit.runners.Parameterized.Parameters;
+
+public final class GeoIpTest extends IngestTest {
+
+    @Parameters
+    public static Iterable<String> data() {
+        return Arrays.asList("GeoIpSimple", "DotsInGeoIpField");
+    }
+
+    @Test
+    public void convertsGeoIpFieldCorrectly() throws Exception {
+        final String date = getResultPath(temp);
+        GeoIp.main(resourcePath(String.format("ingest%s.json", testCase)), date);
+        assertThat(
+            utf8File(date), is(utf8File(resourcePath(String.format("logstash%s.conf", testCase))))
+        );
+    }
+}
diff --git a/tools/ingest-converter/src/test/java/org/logstash/ingest/GrokTest.java b/tools/ingest-converter/src/test/java/org/logstash/ingest/GrokTest.java
index dac0d6774ca..b843a5f1f74 100644
--- a/tools/ingest-converter/src/test/java/org/logstash/ingest/GrokTest.java
+++ b/tools/ingest-converter/src/test/java/org/logstash/ingest/GrokTest.java
@@ -1,27 +1,25 @@
 package org.logstash.ingest;
 
+import java.util.Arrays;
 import org.junit.Test;
 
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
+import static org.junit.runners.Parameterized.Parameters;
 
 public final class GrokTest extends IngestTest {
 
-    @Test
-    public void convertsFieldPatternsCorrectly() throws Exception {
-        final String grok = getResultPath(temp);
-        Grok.main(resourcePath("ingestGrok.json"), grok);
-        assertThat(
-            utf8File(grok), is(utf8File(resourcePath("logstashGrok.conf")))
-        );
+    @Parameters
+    public static Iterable<String> data() {
+        return Arrays.asList("Grok", "GrokPatternDefinition");
     }
 
     @Test
-    public void convertsFieldDefinitionsCorrectly() throws Exception {
-        final String grok = getResultPath(temp);
-        Grok.main(resourcePath("ingestGrokPatternDefinition.json"), grok);
+    public void convertsGrokFieldCorrectly() throws Exception {
+        final String date = getResultPath(temp);
+        Grok.main(resourcePath(String.format("ingest%s.json", testCase)), date);
         assertThat(
-            utf8File(grok), is(utf8File(resourcePath("logstashGrokPatternDefinition.conf")))
+            utf8File(date), is(utf8File(resourcePath(String.format("logstash%s.conf", testCase))))
         );
     }
 }
diff --git a/tools/ingest-converter/src/test/java/org/logstash/ingest/IngestTest.java b/tools/ingest-converter/src/test/java/org/logstash/ingest/IngestTest.java
index af3036a4426..dd326da478b 100644
--- a/tools/ingest-converter/src/test/java/org/logstash/ingest/IngestTest.java
+++ b/tools/ingest-converter/src/test/java/org/logstash/ingest/IngestTest.java
@@ -6,14 +6,22 @@
 import java.nio.file.Paths;
 import org.junit.Rule;
 import org.junit.rules.TemporaryFolder;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+
+import static org.junit.runners.Parameterized.*;
 
 /**
  * Base class for ingest migration tests
  */
+@RunWith(Parameterized.class)
 public abstract class IngestTest {
 
     @Rule
     public TemporaryFolder temp = new TemporaryFolder();
+
+    @Parameter
+    public String testCase;
     
     static String utf8File(final String path) throws IOException {
         return new String(Files.readAllBytes(Paths.get(path)), StandardCharsets.UTF_8);
diff --git a/tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java b/tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java
new file mode 100644
index 00000000000..c5aeec717a5
--- /dev/null
+++ b/tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java
@@ -0,0 +1,32 @@
+package org.logstash.ingest;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import org.junit.Test;
+
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.junit.runners.Parameterized.Parameters;
+
+public final class PipelineTest extends IngestTest {
+
+    @Parameters
+    public static Iterable<String> data() {
+        final Collection<String> cases = new ArrayList<>();
+        cases.add("ComplexCase1");
+        cases.add("ComplexCase2");
+        GeoIpTest.data().forEach(cases::add);
+        DateTest.data().forEach(cases::add);
+        GrokTest.data().forEach(cases::add);
+        return cases;
+    }
+
+    @Test
+    public void convertsComplexCaseCorrectly() throws Exception {
+        final String date = getResultPath(temp);
+        Pipeline.main(resourcePath(String.format("ingest%s.json", testCase)), date);
+        assertThat(
+            utf8File(date), is(utf8File(resourcePath(String.format("logstash%s.conf", testCase))))
+        );
+    }
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase1.json b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase1.json
new file mode 100644
index 00000000000..2577bb8f47c
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase1.json
@@ -0,0 +1,29 @@
+{
+  "description": "Pipeline to parse Apache logs",
+  "processors": [
+    {
+      "grok": {
+        "field": "message",
+        "patterns": [
+          "%{COMBINEDAPACHELOG}"
+        ]
+      }
+    },
+    {
+      "date": {
+        "field": "timestamp",
+        "target_field": "@timestamp",
+        "formats": [
+          "dd/MMM/YYYY:HH:mm:ss Z"
+        ],
+        "locale": "en"
+      }
+    },
+    {
+      "geoip": {
+        "field": "client.ip",
+        "target_field": "geo"
+      }
+    }
+  ]
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase2.json b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase2.json
new file mode 100644
index 00000000000..83424e612e3
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestComplexCase2.json
@@ -0,0 +1,35 @@
+{
+  "description": "Pipeline to parse Apache logs",
+  "processors": [
+    {
+      "grok": {
+        "field": "message",
+        "patterns": [
+          "%{COMBINEDAPACHELOG}"
+        ]
+      }
+    },
+    {
+      "date": {
+        "field": "timestamp",
+        "target_field": "@timestamp",
+        "formats": [
+          "dd/MMM/YYYY:HH:mm:ss Z"
+        ],
+        "locale": "en"
+      }
+    },
+    {
+      "geoip": {
+        "field": "client.ip",
+        "target_field": "client.geo"
+      }
+    },
+    {
+      "geoip": {
+        "field": "source.ip",
+        "target_field": "source.geo"
+      }
+    }
+  ]
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/dotsInDateField.json b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestDotsInDateField.json
similarity index 100%
rename from tools/ingest-converter/src/test/resources/org/logstash/ingest/dotsInDateField.json
rename to tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestDotsInDateField.json
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestDotsInGeoIpField.json b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestDotsInGeoIpField.json
new file mode 100644
index 00000000000..4a3b7fe18d3
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestDotsInGeoIpField.json
@@ -0,0 +1,13 @@
+{
+  "description" : "Add geoip info",
+  "processors" : [
+    {
+      "geoip" : {
+        "field" : "ip",
+        "target_field" : "apache.geo",
+        "database_file" : "GeoLite2-Country.mmdb.gz",
+        "properties": ["continent_name", "country_iso_code"]
+      }
+    }
+  ]
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestGeoIpSimple.json b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestGeoIpSimple.json
new file mode 100644
index 00000000000..2554b92c474
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/ingestGeoIpSimple.json
@@ -0,0 +1,16 @@
+{
+  "description": "Add geoip info",
+  "processors": [
+    {
+      "geoip": {
+        "field": "ip",
+        "target_field": "geo",
+        "database_file": "GeoLite2-Country.mmdb.gz",
+        "properties": [
+          "continent_name",
+          "country_iso_code"
+        ]
+      }
+    }
+  ]
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase1.conf b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase1.conf
new file mode 100644
index 00000000000..9fe32af333e
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase1.conf
@@ -0,0 +1,19 @@
+filter {
+   grok {
+      match => {
+         "message" => "%{COMBINEDAPACHELOG}"
+      }
+   }
+   date {
+      match => [
+         "timestamp",
+         "dd/MMM/YYYY:HH:mm:ss Z"
+      ]
+      target => "@timestamp"
+      locale => "en"
+   }
+   geoip {
+      source => "[client][ip]"
+      target => "geo"
+   }
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase2.conf b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase2.conf
new file mode 100644
index 00000000000..6ba7fd0f16a
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashComplexCase2.conf
@@ -0,0 +1,23 @@
+filter {
+   grok {
+      match => {
+         "message" => "%{COMBINEDAPACHELOG}"
+      }
+   }
+   date {
+      match => [
+         "timestamp",
+         "dd/MMM/YYYY:HH:mm:ss Z"
+      ]
+      target => "@timestamp"
+      locale => "en"
+   }
+   geoip {
+      source => "[client][ip]"
+      target => "[client][geo]"
+   }
+   geoip {
+      source => "[source][ip]"
+      target => "[source][geo]"
+   }
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/dotsInDateField.conf b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashDotsInDateField.conf
similarity index 100%
rename from tools/ingest-converter/src/test/resources/org/logstash/ingest/dotsInDateField.conf
rename to tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashDotsInDateField.conf
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashDotsInGeoIpField.conf b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashDotsInGeoIpField.conf
new file mode 100644
index 00000000000..1605360483e
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashDotsInGeoIpField.conf
@@ -0,0 +1,10 @@
+filter {
+   geoip {
+      source => "ip"
+      target => "[apache][geo]"
+      fields => [
+         "continent_name",
+         "country_iso_code"
+      ]
+   }
+}
diff --git a/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashGeoIpSimple.conf b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashGeoIpSimple.conf
new file mode 100644
index 00000000000..e23a07eaceb
--- /dev/null
+++ b/tools/ingest-converter/src/test/resources/org/logstash/ingest/logstashGeoIpSimple.conf
@@ -0,0 +1,10 @@
+filter {
+   geoip {
+      source => "ip"
+      target => "geo"
+      fields => [
+         "continent_name",
+         "country_iso_code"
+      ]
+   }
+}
