diff --git a/docs/static/advanced-pipeline.asciidoc b/docs/static/advanced-pipeline.asciidoc
index 41c5a887f7f..da442a497d8 100644
--- a/docs/static/advanced-pipeline.asciidoc
+++ b/docs/static/advanced-pipeline.asciidoc
@@ -406,7 +406,16 @@ Notice that the event now contains geographic location information:
 [[indexing-parsed-data-into-elasticsearch]]
 ==== Indexing Your Data into Elasticsearch
 
-Now that the web logs are broken down into specific fields, the Logstash pipeline can index the data into an
+Now that the web logs are broken down into specific fields, you're ready to get
+your data into Elasticsearch. 
+
+TIP: You can run Elasticsearch on your own hardware, or use our
+https://www.elastic.co/cloud/elasticsearch-service[hosted {es} Service] on
+Elastic Cloud. The Elasticsearch Service is available on both AWS and GCP.
+https://www.elastic.co/cloud/elasticsearch-service/signup[Try the {es} Service
+for free].
+
+The Logstash pipeline can index the data into an
 Elasticsearch cluster. Edit the `first-pipeline.conf` file and replace the entire `output` section with the following
 text:
 
