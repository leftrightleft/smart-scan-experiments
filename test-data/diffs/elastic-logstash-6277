diff --git a/docs/static/deploying.asciidoc b/docs/static/deploying.asciidoc
index 1cf0b82da2b..822fdd82b64 100644
--- a/docs/static/deploying.asciidoc
+++ b/docs/static/deploying.asciidoc
@@ -93,18 +93,18 @@ image::static/images/deploy_4.png[]
 ==== Managing Throughput Spikes with Message Queueing
 
 When the data coming into a Logstash pipeline exceeds the Elasticsearch cluster's ability to ingest the data, you can
-use a message queue as a buffer. By default, Logstash throttles incoming events when
+use a message broker as a buffer. By default, Logstash throttles incoming events when
 indexer consumption rates fall below incoming data rates. Since this throttling can lead to events being buffered at
-the data source, preventing backpressure with message queues becomes an important part of managing your deployment.
+the data source, preventing backpressure with message brokers becomes an important part of managing your deployment.
 
-Adding a message queue to your Logstash deployment also provides a level of protection from data loss. When a Logstash
-instance that has consumed data from the message queue fails, the data can be replayed from the message queue to an
+Adding a message broker to your Logstash deployment also provides a level of protection from data loss. When a Logstash
+instance that has consumed data from the message broker fails, the data can be replayed from the message broker to an
 active Logstash instance.
 
-Several third-party message queues exist, such as Redis, Kafka, or RabbitMQ. Logstash provides input and output plugins
-to integrate with several of these third-party message queues. When your Logstash deployment has a message queue
+Several third-party message brokers exist, such as Redis, Kafka, or RabbitMQ. Logstash provides input and output plugins
+to integrate with several of these third-party message brokers. When your Logstash deployment has a message broker
 configured, Logstash functionally exists in two phases: shipping instances, which handles data ingestion and storage in
-the message queue, and indexing instances, which retrieve the data from the message queue, apply any configured
+the message broker, and indexing instances, which retrieve the data from the message broker, apply any configured
 filtering, and write the filtered data to an Elasticsearch index.
 
 image::static/images/deploy_5.png[]
@@ -136,11 +136,11 @@ by eliminating single points of failure.
 A mature Logstash deployment typically has the following pipeline:
 
 * The _input_ tier consumes data from the source, and consists of Logstash instances with the proper input plugins.
-* The _message queue_ serves as a buffer to hold ingested data and serve as failover protection.
-* The _filter_ tier applies parsing and other processing to the data consumed from the message queue.
+* The _message broker_ serves as a buffer to hold ingested data and serve as failover protection.
+* The _filter_ tier applies parsing and other processing to the data consumed from the message broker.
 * The _indexing_ tier moves the processed data into Elasticsearch.
 
 Any of these layers can be scaled by adding computing resources. Examine the performance of these components regularly
 as your use case evolves and add resources as needed. When Logstash routinely throttles incoming events, consider
-adding storage for your message queue. Alternately, increase the Elasticsearch cluster's rate of data consumption by
+adding storage for your message broker. Alternately, increase the Elasticsearch cluster's rate of data consumption by
 adding more Logstash indexing instances.
