diff --git a/lib/logstash/agent.rb b/lib/logstash/agent.rb
index 0a6ce1da6bd..36dd61604c9 100644
--- a/lib/logstash/agent.rb
+++ b/lib/logstash/agent.rb
@@ -47,6 +47,22 @@ class LogStash::Agent < Clamp::Command
     I18n.t("logstash.agent.flag.configtest"),
     :attribute_name => :config_test
 
+  option ["--use-persistent-queues"], :flag,
+    "Enable global queue persistence",
+    :attribute_name => :use_persistent_queues
+
+  option ["--persistent-queues-path"], "PATH",
+    "Global persistent queues data files directory",
+    :attribute_name => :persistent_queues_path
+
+  option ["--persistent-queues-items"], "COUNT",
+    "Global persistent queues maximum items",
+    :attribute_name => :persistent_queues_items, &:to_i
+
+  option ["--persistent-queues-pagesize"], "BYTES",
+    "Global persistent queues size in bytes",
+    :attribute_name => :persistent_queues_pagesize, &:to_i
+
   # Emit a warning message.
   def warn(message)
     # For now, all warnings are fatal.
@@ -111,6 +127,7 @@ def execute
 
     begin
       pipeline = LogStash::Pipeline.new(@config_string)
+      configure_pipeline(pipeline)
     rescue LoadError => e
       fail("Configuration problem.")
     end
@@ -210,6 +227,28 @@ def configure
     configure_plugin_path(plugin_paths) if !plugin_paths.nil?
   end # def configure
 
+  def configure_pipeline(pipeline)
+    # persistent queue pipeline configuration
+    if use_persistent_queues?
+      pipeline.configure("use-persistent-queues", true)
+
+      if persistent_queues_path
+        fail("invalid persistent-queues-path=#{persistent_queues_path}") unless File.directory?(persistent_queues_path)
+        pipeline.configure("persistent-queues-path", persistent_queues_path)
+      end
+
+      if persistent_queues_items
+        fail("invalid persistent-queues-items=#{persistent_queues_items}") if persistent_queues_items <= 0
+        pipeline.configure("persistent-queues-items", persistent_queues_items)
+      end
+
+      if persistent_queues_pagesize
+        fail("invalid persistent-queues-pagesize=#{persistent_queues_pagesize}") if persistent_queues_pagesize <= 0
+        pipeline.configure("persistent-queues-pagesize", persistent_queues_pagesize)
+      end
+    end
+  end
+
   # Point logging at a specific path.
   def configure_logging(path)
     # Set with the -v (or -vv...) flag
diff --git a/lib/logstash/event.rb b/lib/logstash/event.rb
index df95bc30bcd..233fe508a91 100644
--- a/lib/logstash/event.rb
+++ b/lib/logstash/event.rb
@@ -39,6 +39,8 @@ class LogStash::FlushEvent; end
 #       message: "hello world"
 #     }
 class LogStash::Event
+  attr_reader :metadata
+
   class DeprecatedMethod < StandardError; end
 
   CHAR_PLUS = "+"
@@ -68,6 +70,8 @@ def initialize(data = {})
       {}
     end
     @metadata_accessors = LogStash::Util::Accessors.new(@metadata)
+
+    @json_cache = nil
   end # def initialize
 
   public
@@ -110,7 +114,7 @@ def to_s
 
   public
   def timestamp; return @data[TIMESTAMP]; end # def timestamp
-  def timestamp=(val); return @data[TIMESTAMP] = val; end # def timestamp=
+  def timestamp=(val); @json_cache = nil; return @data[TIMESTAMP] = val; end # def timestamp=
 
   def unix_timestamp
     raise DeprecatedMethod
@@ -144,6 +148,7 @@ def []=(fieldref, value)
     elsif fieldref == METADATA
       @metadata = value
     else
+      @json_cache = nil
       @accessors.set(fieldref, value)
     end
   end # def []=
@@ -156,16 +161,21 @@ def fields
   public
   def to_json(*args)
     # ignore arguments to respect accepted to_json method signature
-    LogStash::Json.dump(@data)
+    # LogStash::Json.dump(@data)
+    @json_cache ||= LogStash::Json.dump(@data)
   end # def to_json
 
   public
   def to_hash
+    # TBD it is dangerous to give access to the internal hash, if a mutation occurs
+    # the @json_cache will not be invalidated. We need to think about this
     @data
   end # def to_hash
 
   public
   def overwrite(event)
+    @json_cache = nil
+
     # pickup new event @data and also pickup @accessors
     # otherwise it will be pointing on previous data
     @data = event.instance_variable_get(:@data)
@@ -185,6 +195,8 @@ def include?(key)
   # Append an event to this one.
   public
   def append(event)
+    @json_cache = nil
+
     # non-destructively merge that event with ourselves.
 
     # no need to reset @accessors here because merging will not disrupt any existing field paths
@@ -196,6 +208,7 @@ def append(event)
   # deleted
   public
   def remove(fieldref)
+    @json_cache = nil
     @accessors.del(fieldref)
   end # def remove
 
@@ -287,11 +300,7 @@ def init_timestamp(o)
 
   public
   def to_hash_with_metadata
-    if @metadata.nil?
-      to_hash
-    else
-      to_hash.merge("@metadata" => @metadata)
-    end
+    @metadata.nil? ? self.to_hash : self.to_hash.merge({"@metadata" => @metadata})
   end
 
   public
diff --git a/lib/logstash/java_integration.rb b/lib/logstash/java_integration.rb
index 2bfeb3e81d2..564444bc403 100644
--- a/lib/logstash/java_integration.rb
+++ b/lib/logstash/java_integration.rb
@@ -3,8 +3,10 @@
 # this is mainly for usage with JrJackson json parsing in :raw mode which genenerates
 # Java::JavaUtil::ArrayList and Java::JavaUtil::LinkedHashMap native objects for speed.
 # these object already quacks like their Ruby equivalents Array and Hash but they will
-# not test for is_a?(Array) or is_a?(Hash) and we do not want to include tests for
-# both classes everywhere. see LogStash::JSon.
+# not test for is_a?(Array) or is_a?(Hash), and not support class equivalence Hash === LinkedHashMap.new
+# used in class case statements like: case o; when Hash ...
+#
+# we do not want to include tests for all Java classes everywhere. see LogStash::JSon.
 
 class Java::JavaUtil::ArrayList
   # have ArrayList objects report is_a?(Array) == true
@@ -14,19 +16,64 @@ def is_a?(clazz)
   end
 end
 
+class Java::JavaUtil::Vector
+  # have Vector objects report is_a?(Array) == true
+  def is_a?(clazz)
+    return true if clazz == Array
+    super
+  end
+end
+
 class Java::JavaUtil::LinkedHashMap
   # have LinkedHashMap objects report is_a?(Array) == true
   def is_a?(clazz)
     return true if clazz == Hash
     super
   end
+
+  # see https://github.com/jruby/jruby/issues/1249
+  if ENV_JAVA['java.specification.version'] >= '1.8'
+    def merge(other)
+      dup.merge!(other)
+    end
+  end
+end
+
+class Java::JavaUtil::HashMap
+  # have HashMap objects report is_a?(Array) == true
+  def is_a?(clazz)
+    return true if clazz == Hash
+    super
+  end
+
+  # see https://github.com/jruby/jruby/issues/1249
+  if ENV_JAVA['java.specification.version'] >= '1.8'
+    def merge(other)
+      dup.merge!(other)
+    end
+  end
+end
+
+class Java::JavaUtil::TreeMap
+  # have TreeMap objects report is_a?(Array) == true
+  def is_a?(clazz)
+    return true if clazz == Hash
+    super
+  end
+
+  # see https://github.com/jruby/jruby/issues/1249
+  if ENV_JAVA['java.specification.version'] >= '1.8'
+    def merge(other)
+      dup.merge!(other)
+    end
+  end
 end
 
 class Array
   # enable class equivalence between Array and ArrayList
   # so that ArrayList will work with case o when Array ...
   def self.===(other)
-    return true if other.is_a?(Java::JavaUtil::ArrayList)
+    return true if other.is_a?(Java::JavaUtil::List)
     super
   end
 end
@@ -35,7 +82,7 @@ class Hash
   # enable class equivalence between Hash and LinkedHashMap
   # so that LinkedHashMap will work with case o when Hash ...
   def self.===(other)
-    return true if other.is_a?(Java::JavaUtil::LinkedHashMap)
+    return true if other.is_a?(Java::JavaUtil::Map)
     super
   end
 end
diff --git a/lib/logstash/outputs/base.rb b/lib/logstash/outputs/base.rb
index 9fedbf10818..bb737578dfd 100644
--- a/lib/logstash/outputs/base.rb
+++ b/lib/logstash/outputs/base.rb
@@ -34,8 +34,19 @@ class LogStash::Outputs::Base < LogStash::Plugin
   config :workers, :validate => :number, :default => 1
 
   public
+
+  def initialize(params = {})
+    super
+    config_init(params)
+  end
+
+  def has_workers?
+    @workers > 1
+  end
+
   def workers_not_supported(message=nil)
-    return if @workers == 1
+    return unless has_workers?
+
     if message
       @logger.warn(I18n.t("logstash.pipeline.output-worker-unsupported-with-message", :plugin => self.class.config_name, :worker_count => @workers, :message => message))
     else
@@ -44,28 +55,20 @@ def workers_not_supported(message=nil)
     @workers = 1
   end
 
-  public
-  def initialize(params={})
-    super
-    config_init(params)
-  end
-
-  public
   def register
     raise "#{self.class}#register must be overidden"
   end # def register
 
-  public
   def receive(event)
     raise "#{self.class}#receive must be overidden"
   end # def receive
 
-  public
-  def worker_setup
-    return unless @workers > 1
+  # @param queue [SizedQueue] the queue instance for the output with multiple workers
+  def workers_setup(queue)
+    raise(ArgumentError, "workers_setup must be called only on when multiple workers are configured") unless @workers > 1
 
     define_singleton_method(:handle, method(:handle_worker))
-    @worker_queue = SizedQueue.new(20)
+    @worker_queue = queue
 
     @worker_threads = @workers.times do |i|
       Thread.new(original_params, @worker_queue) do |params, queue|
@@ -81,16 +84,16 @@ def worker_setup
     end
   end
 
-  public
   def handle(event)
     receive(event)
   end # def handle
-  
+
   def handle_worker(event)
     @worker_queue.push(event)
   end
 
   private
+
   def output?(event)
     if !@type.empty?
       if event["type"] != @type
diff --git a/lib/logstash/pipeline.rb b/lib/logstash/pipeline.rb
index 8811e1e5dc4..f8cffd4165c 100644
--- a/lib/logstash/pipeline.rb
+++ b/lib/logstash/pipeline.rb
@@ -1,5 +1,5 @@
 # encoding: utf-8
-require "thread" #
+require "thread"
 require "stud/interval"
 require "logstash/namespace"
 require "logstash/errors"
@@ -9,41 +9,45 @@
 require "logstash/inputs/base"
 require "logstash/outputs/base"
 
-class LogStash::Pipeline
+require "jruby-mmap-queues"
+require "logstash/queue_serializer"
 
+class LogStash::Pipeline
   FLUSH_EVENT = LogStash::FlushEvent.new
 
+  MAX_QUEUE_ITEMS = 20
+  INPUT_QUEUE_FILE = "input_to_filter_queue".freeze
+  FILTER_QUEUE_FILE = "filter_to_output_queue".freeze
+
+  # settings keys constants
+  SETTINGS_FILTER_WORKERS = "filter-workers".freeze
+  SETTINGS_USE_PERSISTENT_QUEUES = "use-persistent-queues".freeze
+  SETTINGS_PERSISTENT_QUEUES_PATH = "persistent-queues-path".freeze
+  SETTINGS_PERSISTENT_QUEUES_ITEMS = "persistent-queues-items".freeze
+  SETTINGS_PERSISTENT_QUEUES_PAGESIZE = "persistent-queues-pagesize".freeze
+
   def initialize(configstr)
     @logger = Cabin::Channel.get(LogStash)
-    grammar = LogStashConfigParser.new
-    @config = grammar.parse(configstr)
-    if @config.nil?
-      raise LogStash::ConfigurationError, grammar.failure_reason
+
+    LogStashConfigParser.new.tap do |grammar|
+      @config = grammar.parse(configstr)
+      raise LogStash::ConfigurationError, grammar.failure_reason if @config.nil?
     end
 
     # This will compile the config to ruby and evaluate the resulting code.
-    # The code will initialize all the plugins and define the
-    # filter and output methods.
-    code = @config.compile
-    # The config code is hard to represent as a log message...
-    # So just print it.
-    @logger.debug? && @logger.debug("Compiled pipeline code:\n#{code}")
-    begin
+    # The code will initialize all the plugins and define the filter and output methods.
+    @config.compile.tap do |code|
+      @logger.debug? && @logger.debug("Compiled pipeline code:\n#{code}")
       eval(code)
-    rescue => e
-      raise
     end
 
-    @input_to_filter = SizedQueue.new(20)
-
-    # If no filters, pipe inputs directly to outputs
-    if !filters?
-      @filter_to_output = @input_to_filter
-    else
-      @filter_to_output = SizedQueue.new(20)
-    end
+    # defaults settings
     @settings = {
-      "filter-workers" => 1,
+      SETTINGS_FILTER_WORKERS => 1,
+      SETTINGS_USE_PERSISTENT_QUEUES => false,
+      SETTINGS_PERSISTENT_QUEUES_PATH => "./",
+      SETTINGS_PERSISTENT_QUEUES_ITEMS => MAX_QUEUE_ITEMS,
+      SETTINGS_PERSISTENT_QUEUES_PAGESIZE => MAX_QUEUE_ITEMS * 1024 * 1024,
     }
   end # def initialize
 
@@ -56,13 +60,14 @@ def started?
   end
 
   def configure(setting, value)
-    if setting == "filter-workers"
+    if setting == SETTINGS_FILTER_WORKERS
       # Abort if we have any filters that aren't threadsafe
       if value > 1 && @filters.any? { |f| !f.threadsafe? }
         plugins = @filters.select { |f| !f.threadsafe? }.collect { |f| f.class.config_name }
         raise LogStash::ConfigurationError, "Cannot use more than 1 filter worker because the following plugins don't work with more than one worker: #{plugins.join(", ")}"
       end
     end
+
     @settings[setting] = value
   end
 
@@ -74,6 +79,9 @@ def run
     @started = true
     @input_threads = []
 
+    @input_to_filter = create_input_queue
+    @filter_to_output = create_filter_queue
+
     start_inputs
     start_filters if filters?
     start_outputs
@@ -131,7 +139,7 @@ def start_inputs
     moreinputs = []
     @inputs.each do |input|
       if input.threadable && input.threads > 1
-        (input.threads-1).times do |i|
+        (input.threads - 1).times do |i|
           moreinputs << input.clone
         end
       end
@@ -146,9 +154,7 @@ def start_inputs
 
   def start_filters
     @filters.each(&:register)
-    @filter_threads = @settings["filter-workers"].times.collect do
-      Thread.new { filterworker }
-    end
+    @filter_threads = @settings[SETTINGS_FILTER_WORKERS].times.collect { Thread.new { filterworker } }
 
     @flusher_lock = Mutex.new
     @flusher_thread = Thread.new { Stud.interval(5) { @flusher_lock.synchronize { @input_to_filter.push(FLUSH_EVENT) } } }
@@ -181,7 +187,6 @@ def inputworker(plugin)
         @logger.error(I18n.t("logstash.pipeline.worker-error",
                              :plugin => plugin.inspect, :error => e))
       end
-      puts e.backtrace if @logger.debug?
       plugin.teardown
       sleep 1
       retry
@@ -224,12 +229,16 @@ def filterworker
 
   def outputworker
     LogStash::Util::set_thread_name(">output")
-    @outputs.each(&:worker_setup)
+
+    # assign new queue to output with multiple workers
+    @outputs.select(&:has_workers?).each{|output| output.workers_setup(create_output_queue(output.class.config_name))}
+
     while true
       event = @filter_to_output.pop
       break if event.is_a?(LogStash::ShutdownEvent)
       output(event)
-    end # while true
+    end
+
     @outputs.each(&:teardown)
   end # def outputworker
 
@@ -245,6 +254,7 @@ def shutdown
       begin
         thread.wakeup # in case it's in blocked IO or sleeping
       rescue ThreadError
+        # ignore
       end
 
       # Sometimes an input is stuck in a blocking I/O
@@ -295,4 +305,42 @@ def flush_filters_to_output!(options = {})
     end
   end # flush_filters_to_output!
 
+  private
+
+  def create_input_queue
+    create_sized_queue(INPUT_QUEUE_FILE)
+  end
+
+  def create_filter_queue
+    # if no filters, pipe inputs directly to outputs
+    filters? ? create_sized_queue(FILTER_QUEUE_FILE) : @input_to_filter
+  end
+
+  def create_output_queue(name)
+    # config can contain multiple output of the same type thus having the same config_name
+    # to avoid persistent queue file name clash make sure to make them unique
+    create_sized_queue(uniquify(name))
+  end
+
+  def create_sized_queue(name)
+    if @settings[SETTINGS_USE_PERSISTENT_QUEUES]
+      Mmap::SizedQueue.new(@settings[SETTINGS_PERSISTENT_QUEUES_ITEMS],
+        :page_handler => Mmap::SinglePage.new(File.expand_path(name, @settings[SETTINGS_PERSISTENT_QUEUES_PATH]), :page_size => @settings[SETTINGS_PERSISTENT_QUEUES_PAGESIZE]),
+        :serializer => LogStash::JsonSerializer.new
+      )
+    else
+      SizedQueue.new(MAX_QUEUE_ITEMS)
+    end
+  end
+
+  # @param id [String] any string id we want to make unique
+  # @return [String] the original id with possibly an appended number to make it unique
+  def uniquify(id)
+    @unique_ids_index ||= 0
+    @unique_ids ||= {}
+    id = "#{id}-#{@unique_ids_index += 1}" while @unique_ids.has_key?(id)
+    @unique_ids[id] = true
+    id
+  end
+
 end # class Pipeline
diff --git a/lib/logstash/queue_serializer.rb b/lib/logstash/queue_serializer.rb
new file mode 100644
index 00000000000..5943303675a
--- /dev/null
+++ b/lib/logstash/queue_serializer.rb
@@ -0,0 +1,28 @@
+# encoding: utf-8
+require "logstash/json"
+require "msgpack"
+
+# pluggable serializer for the persistent queue
+
+class LogStash::JsonSerializer
+  NL = "\n".freeze
+
+  # @param event [LogStash::Event] the event to serialize
+  # @return [String] the serialized event or nil to skip persistence
+  def serialize(event)
+    # exclude non LogStash::Event like the LogStash::ShutdownEvent and LogStash::FlushEvent
+    return nil unless event.is_a?(LogStash::Event)
+
+    # separately serialize the event without metadata and the metadata
+    # to leverage the json wihout metadata caching by calling the Event#to_json
+    # method.
+    event.to_json + NL + LogStash::Json.dump(event.metadata)
+  end
+
+  # @param data [String] searialized string data to deserialize
+  # @return [LogStash::Event] the deserialzed event
+  def deserialize(data)
+    event, metadata = data.split(NL).map{|o| LogStash::Json.load(o)}
+    LogStash::Event.new(event.merge({"@metadata" => metadata}))
+  end
+end
diff --git a/spec/core/queuing_spec.rb b/spec/core/queuing_spec.rb
new file mode 100644
index 00000000000..21f5e735294
--- /dev/null
+++ b/spec/core/queuing_spec.rb
@@ -0,0 +1,58 @@
+# encoding: utf-8
+
+require "spec_helper"
+require "jruby-mmap-queues"
+require "logstash/queue_serializer"
+require "logstash/event"
+
+QUEUE_PATH = "persistent_queue_spec"
+
+describe "persistent queue" do
+  it "should push a serialized event and reload a deserialized event" do
+    q = Mmap::SizedQueue.new(20,
+      :page_handler => Mmap::SinglePage.new(QUEUE_PATH, :page_size => 1024 * 1024),
+      :serializer => LogStash::JsonSerializer.new
+    )
+    q.clear
+
+    event = LogStash::Event.new({"foo" => "bar", "@metadata" => {"baz" => "zoo"}})
+    expect(event["foo"]).to eq("bar")
+    expect(event.metadata).to eq({"baz" => "zoo"})
+
+    q.push(event)
+    q.close
+
+    # queue has been closed with one event in it, repopening on the same data will
+    # feed queue with persisted items
+
+    q = Mmap::SizedQueue.new(20,
+      :page_handler => Mmap::SinglePage.new(QUEUE_PATH, :page_size => 1024 * 1024),
+      :serializer => LogStash::JsonSerializer.new
+    )
+
+    event = q.pop
+    expect(event["foo"]).to eq("bar")
+    expect(event.metadata).to eq({"baz" => "zoo"})
+
+    expect(q.empty?).to be true
+    q.purge
+  end
+end
+
+describe "json serializer" do
+  it "should serialize an event with a newline" do
+    json = LogStash::JsonSerializer.new
+    source_event = LogStash::Event.new({"foo" => "bar\nbaz", "@metadata" => {"baz" => "zoo\nzoz"}})
+    result_event = json.deserialize(json.serialize(source_event))
+    expect(result_event["foo"]).to eq("bar\nbaz")
+    expect(result_event["@metadata"]["baz"]).to eq("zoo\nzoz")
+  end
+
+  it "should only serialize Event class otherwise return nil" do
+    json = LogStash::JsonSerializer.new
+    expect(json.serialize("test")).to be nil
+    expect(json.serialize({"foo" => "bar"})).to be nil
+    expect(json.serialize(LogStash::ShutdownEvent.new)).to be nil
+    expect(json.serialize(LogStash::FlushEvent.new)).to be nil
+  end
+end
diff --git a/spec/util/java_integration_spec.rb b/spec/util/java_integration_spec.rb
new file mode 100644
index 00000000000..a22668ed92e
--- /dev/null
+++ b/spec/util/java_integration_spec.rb
@@ -0,0 +1,53 @@
+# encoding: utf-8
+require "logstash/java_integration"
+
+describe "java_integration" do
+  if LogStash::Environment.jruby?
+
+    context "Java List" do
+      it "should report as Ruby Array" do
+        expect(Java::JavaUtil::ArrayList.new.is_a?(Array)).to be true
+        expect(Java::JavaUtil::Vector.new.is_a?(Array)).to be true
+      end
+    end
+
+    context "Java Map" do
+      it "should report as Ruby Hash" do
+        expect(Java::JavaUtil::HashMap.new.is_a?(Hash)).to be true
+        expect(Java::JavaUtil::LinkedHashMap.new.is_a?(Hash)).to be true
+        expect(Java::JavaUtil::TreeMap.new.is_a?(Hash)).to be true
+      end
+    end
+
+    context "Ruby Hash" do
+      it "should report as Java Map" do
+        expect(Hash === Java::JavaUtil::LinkedHashMap.new).to be true
+        expect(Hash === Java::JavaUtil::HashMap.new).to be true
+        expect(Hash === Java::JavaUtil::TreeMap.new).to be true
+      end
+    end
+
+    context "Ruby Array" do
+      it "should report as Java List" do
+        expect(Array === Java::JavaUtil::ArrayList.new).to be true
+        expect(Array === Java::JavaUtil::Vector.new).to be true
+      end
+    end
+
+    context "Java Map merge" do
+      # see https://github.com/jruby/jruby/issues/1249
+
+      it "should support HashMap merge" do
+        expect(Java::JavaUtil::HashMap.new.merge(:a => 1)).to eq({:a => 1})
+      end
+
+      it "should support LinkedHashMap merge" do
+        expect(Java::JavaUtil::LinkedHashMap.new.merge(:a => 1)).to eq({:a => 1})
+      end
+
+      it "should support TreeMap merge" do
+        expect(Java::JavaUtil::TreeMap.new.merge(:a => 1)).to eq({:a => 1})
+      end
+    end
+  end
+end
\ No newline at end of file
diff --git a/tools/Gemfile b/tools/Gemfile
index 0483cae4262..f4d99bb5c4e 100644
--- a/tools/Gemfile
+++ b/tools/Gemfile
@@ -2,4 +2,12 @@ source "https://rubygems.org"
 gemspec :path => File.expand_path(File.join(File.dirname(__FILE__), "..")), :name => "logstash", :development_group => :development
 
 # in development if a local, unpublished gems is required, you must add it first in the gemspec without the :path option
-# and also add it here with the :path option.
\ No newline at end of file
+# and also add it here with the :path option.
+
+# local dev setup
+# gem "jruby-mmap", :path => File.expand_path("../../../jruby-mmap", __FILE__)
+# gem "jruby-mmap-queues", :path => File.expand_path("../../../jruby-mmap-queues", __FILE__)
+
+# tmp PR WIP setup
+gem "jruby-mmap", ">= 0.1.1", :github => "colinsurprenant/jruby-mmap", :ref => "master"
+gem "jruby-mmap-queues", ">= 0.1.1", :github => "colinsurprenant/jruby-mmap-queues", :ref => "master"
diff --git a/tools/Gemfile.jruby-1.9.lock b/tools/Gemfile.jruby-1.9.lock
index 172b1472108..074a0a49ced 100644
--- a/tools/Gemfile.jruby-1.9.lock
+++ b/tools/Gemfile.jruby-1.9.lock
@@ -1,14 +1,29 @@
+GIT
+  remote: git://github.com/colinsurprenant/jruby-mmap-queues.git
+  revision: 9510329557c4f4ad142e8485dc294b855a8b555e
+  ref: master
+  specs:
+    jruby-mmap-queues (0.1.0-java)
+      jruby-mmap
+
+GIT
+  remote: git://github.com/colinsurprenant/jruby-mmap.git
+  revision: 8b658d195eed54ddc66ef2943f072638b583aa96
+  ref: master
+  specs:
+    jruby-mmap (0.1.1-java)
+
 PATH
   remote: /Users/colin/dev/src/elasticsearch/logstash
   specs:
-    logstash (1.5.0.dev-java)
+    logstash (2.0.0.dev-java)
       addressable
       awesome_print
       aws-sdk
       beefcake (= 0.3.7)
       bindata (>= 1.5.0)
       cabin (>= 0.6.0)
-      ci_reporter
+      ci_reporter (= 1.9.3)
       cinch
       clamp
       edn
@@ -67,18 +82,18 @@ GEM
       tzinfo (~> 1.1)
     addressable (2.3.6)
     atomic (1.1.16-java)
-    avl_tree (1.1.3)
+    avl_tree (1.2.0)
     awesome_print (1.2.0)
-    aws-sdk (1.54.0)
-      aws-sdk-v1 (= 1.54.0)
-    aws-sdk-v1 (1.54.0)
+    aws-sdk (1.56.0)
+      aws-sdk-v1 (= 1.56.0)
+    aws-sdk-v1 (1.56.0)
       json (~> 1.4)
       nokogiri (>= 1.4.4)
     axiom-types (0.1.1)
       descendants_tracker (~> 0.0.4)
       ice_nine (~> 0.11.0)
       thread_safe (~> 0.3, >= 0.3.1)
-    backports (3.6.1)
+    backports (3.6.3)
     beefcake (0.3.7)
     bindata (2.1.0)
     buftok (0.1)
@@ -114,7 +129,7 @@ GEM
     extlib (0.9.16)
     faraday (0.9.0)
       multipart-post (>= 1.2, < 3)
-    ffi (1.9.5-java)
+    ffi (1.9.6-java)
     ffi-rzmq (1.0.0)
       ffi
     filewatch (0.5.1)
@@ -156,9 +171,9 @@ GEM
       virtus (~> 1.0)
     metaclass (0.0.4)
     method_source (0.8.2)
-    metriks (0.9.9.6)
+    metriks (0.9.9.7)
       atomic (~> 1.0)
-      avl_tree (~> 1.1.2)
+      avl_tree (~> 1.2.0)
       hitimes (~> 1.1)
     mime-types (1.25.1)
     minitest (5.4.2)
@@ -233,97 +248,6 @@ GEM
     tins (1.3.3)
     treetop (1.4.15)
       polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
-      polyglot (>= 0.3.1)
       polyglot (>= 0.3.1)
     twitter (5.0.0.rc.1)
       buftok (~> 0.1.0)
@@ -348,5 +272,7 @@ PLATFORMS
 
 DEPENDENCIES
   coveralls
+  jruby-mmap!
+  jruby-mmap-queues!
   kramdown
   logstash!
