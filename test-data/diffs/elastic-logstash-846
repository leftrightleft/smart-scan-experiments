diff --git a/lib/logstash/outputs/csv.rb b/lib/logstash/outputs/csv.rb
new file mode 100644
index 00000000000..d35cb67c093
--- /dev/null
+++ b/lib/logstash/outputs/csv.rb
@@ -0,0 +1,55 @@
+require "csv"
+require "logstash/namespace"
+require "logstash/outputs/file"
+
+# CSV output.
+#
+# Write events to disk in CSV or other delimited format
+# Based on the file output, many config values are shared
+# Uses the Ruby csv library internally
+class LogStash::Outputs::CSV < LogStash::Outputs::File
+
+  config_name "csv"
+  milestone 1
+
+  # The field names from the event that should be written to the CSV file.
+  # Fields are written to the CSV in the same order as the array.
+  # If a field does not exist on the event, an empty string will be written.
+  # Supports field reference syntax eg: `fields => ["field1", "[nested][field]"]`.
+  config :fields, :validate => :array, :required => true
+  
+  # Options for CSV output. This is passed directly to the Ruby stdlib to\_csv function. 
+  # Full documentation is available here: [http://ruby-doc.org/stdlib-2.0.0/libdoc/csv/rdoc/index.html].
+  # A typical use case would be to use alternative column or row seperators eg: `csv_options => {"col_sep" => "\t" "row_sep" => "\r\n"}` gives tab seperated data with windows line endings
+  config :csv_options, :validate => :hash, :required => false, :default => Hash.new
+
+  public
+  def register
+    super
+    @csv_options = Hash[@csv_options.map{|(k,v)|[k.to_sym, v]}]
+  end
+
+  public
+  def receive(event)
+    return unless output?(event)
+    path = event.sprintf(@path)
+    fd = open(path)
+    csv_values = @fields.map {|name| get_value(name, event)}
+    fd.write(csv_values.to_csv(@csv_options))
+
+    flush(fd)
+    close_stale_files
+  end #def receive
+
+  private
+  def get_value(name, event)
+    val = event[name]
+    case val
+      when Hash
+        return val.to_json
+      else
+        return val
+    end
+  end
+end # class LogStash::Outputs::CSV
+
diff --git a/spec/outputs/csv.rb b/spec/outputs/csv.rb
new file mode 100644
index 00000000000..29fa719c89a
--- /dev/null
+++ b/spec/outputs/csv.rb
@@ -0,0 +1,266 @@
+require "csv"
+require "tempfile"
+require "test_utils"
+require "logstash/outputs/csv"
+
+describe LogStash::Outputs::CSV do
+  extend LogStash::RSpec
+
+  describe "Write a single field to a csv file" do
+    tmpfile = Tempfile.new('logstash-spec-output-csv')
+    config <<-CONFIG
+      input {
+        generator {
+          add_field => ["foo","bar"]
+          count => 1
+        }
+      }
+      output {
+        csv {
+          path => "#{tmpfile.path}"
+          fields => "foo"
+        }
+      }
+    CONFIG
+
+    agent do
+      lines = File.readlines(tmpfile.path)
+      insist {lines.count} == 1
+      insist {lines[0]} == "bar\n"
+    end
+  end
+
+  describe "write multiple fields and lines to a csv file" do
+    tmpfile = Tempfile.new('logstash-spec-output-csv')
+    config <<-CONFIG
+      input {
+        generator {
+          add_field => ["foo", "bar", "baz", "quux"]
+          count => 2
+        }
+      }
+      output {
+        csv {
+          path => "#{tmpfile.path}"
+          fields => ["foo", "baz"]
+        }
+      }
+    CONFIG
+
+    agent do
+      lines = File.readlines(tmpfile.path)
+      insist {lines.count} == 2
+      insist {lines[0]} == "bar,quux\n"
+      insist {lines[1]} == "bar,quux\n"
+    end
+  end
+
+  describe "missing event fields are empty in csv" do
+    tmpfile = Tempfile.new('logstash-spec-output-csv')
+    config <<-CONFIG
+      input {
+        generator {
+          add_field => ["foo","bar", "baz", "quux"]
+          count => 1
+        }
+      }
+      output {
+        csv {
+          path => "#{tmpfile.path}"
+          fields => ["foo", "not_there", "baz"]
+        }
+      }
+    CONFIG
+
+    agent do
+      lines = File.readlines(tmpfile.path)
+      insist {lines.count} == 1
+      insist {lines[0]} == "bar,,quux\n"
+    end
+  end
+
+  describe "commas are quoted properly" do
+    tmpfile = Tempfile.new('logstash-spec-output-csv')
+    config <<-CONFIG
+      input {
+        generator {
+          add_field => ["foo","one,two", "baz", "quux"]
+          count => 1
+        }
+      }
+      output {
+        csv {
+          path => "#{tmpfile.path}"
+          fields => ["foo", "baz"]
+        }
+      }
+    CONFIG
+
+    agent do
+      lines = File.readlines(tmpfile.path)
+      insist {lines.count} == 1
+      insist {lines[0]} == "\"one,two\",quux\n"
+    end
+  end
+
+  describe "new lines are quoted properly" do
+    tmpfile = Tempfile.new('logstash-spec-output-csv')
+    config <<-CONFIG
+      input {
+        generator {
+          add_field => ["foo","one\ntwo", "baz", "quux"]
+          count => 1
+        }
+      }
+      output {
+        csv {
+          path => "#{tmpfile.path}"
+          fields => ["foo", "baz"]
+        }
+      }
+    CONFIG
+
+    agent do
+      lines = CSV.read(tmpfile.path)
+      insist {lines.count} == 1
+      insist {lines[0][0]} == "one\ntwo"
+    end
+  end
+
+  describe "fields that are are objects are written as JSON" do
+    tmpfile = Tempfile.new('logstash-spec-output-csv')
+    config <<-CONFIG
+      input {
+        generator {
+          message => '{"foo":{"one":"two"},"baz": "quux"}'
+          count => 1
+        }
+      }
+      filter {
+        json { source => "message"}
+      }
+      output {
+        csv {
+          path => "#{tmpfile.path}"
+          fields => ["foo", "baz"]
+        }
+      }
+    CONFIG
+
+    agent do
+      lines = CSV.read(tmpfile.path)
+      insist {lines.count} == 1
+      insist {lines[0][0]} == '{"one":"two"}'
+    end
+  end
+
+  describe "can address nested field using field reference syntax" do
+    tmpfile = Tempfile.new('logstash-spec-output-csv')
+    config <<-CONFIG
+      input {
+        generator {
+          message => '{"foo":{"one":"two"},"baz": "quux"}'
+          count => 1
+        }
+      }
+      filter {
+        json { source => "message"}
+      }
+      output {
+        csv {
+          path => "#{tmpfile.path}"
+          fields => ["[foo][one]", "baz"]
+        }
+      }
+    CONFIG
+
+    agent do
+      lines = CSV.read(tmpfile.path)
+      insist {lines.count} == 1
+      insist {lines[0][0]} == "two"
+      insist {lines[0][1]} == "quux"
+    end
+  end
+
+  describe "missing nested field is blank" do
+    tmpfile = Tempfile.new('logstash-spec-output-csv')
+    config <<-CONFIG
+      input {
+        generator {
+          message => '{"foo":{"one":"two"},"baz": "quux"}'
+          count => 1
+        }
+      }
+      filter {
+        json { source => "message"}
+      }
+      output {
+        csv {
+          path => "#{tmpfile.path}"
+          fields => ["[foo][missing]", "baz"]
+        }
+      }
+    CONFIG
+
+    agent do
+      lines = File.readlines(tmpfile.path)
+      insist {lines.count} == 1
+      insist {lines[0]} == ",quux\n"
+    end
+  end
+
+  describe "can choose field seperator" do
+    tmpfile = Tempfile.new('logstash-spec-output-csv')
+    config <<-CONFIG
+      input {
+        generator {
+          message => '{"foo":"one","bar": "two"}'
+          count => 1
+        }
+      }
+      filter {
+        json { source => "message"}
+      }
+      output {
+        csv {
+          path => "#{tmpfile.path}"
+          fields => ["foo", "bar"]
+          csv_options => {"col_sep" => "|"}
+        }
+      }
+    CONFIG
+
+    agent do
+      lines = File.readlines(tmpfile.path)
+      insist {lines.count} == 1
+      insist {lines[0]} == "one|two\n"
+    end
+  end
+  describe "can choose line seperator" do
+    tmpfile = Tempfile.new('logstash-spec-output-csv')
+    config <<-CONFIG
+      input {
+        generator {
+          message => '{"foo":"one","bar": "two"}'
+          count => 2
+        }
+      }
+      filter {
+        json { source => "message"}
+      }
+      output {
+        csv {
+          path => "#{tmpfile.path}"
+          fields => ["foo", "bar"]
+          csv_options => {"col_sep" => "|" "row_sep" => "\t"}
+        }
+      }
+    CONFIG
+
+    agent do
+      lines = File.readlines(tmpfile.path)
+      insist {lines.count} == 1
+      insist {lines[0]} == "one|two\tone|two\t"
+    end
+  end
+end
diff --git a/tools/Gemfile.lock b/tools/Gemfile.lock
index 7c98e461814..8fc76ada2a1 100644
--- a/tools/Gemfile.lock
+++ b/tools/Gemfile.lock
@@ -1,12 +1,6 @@
 PATH
-  remote: /home/jls/projects/logstash
+  remote: /home/mattg/logstash
   specs:
-    logstash (1.2.3.dev)
-      cabin (>= 0.6.0)
-      i18n
-      json
-      pry
-      stud
     logstash (1.2.3.dev-java)
       addressable
       awesome_print
@@ -15,6 +9,7 @@ PATH
       bindata (>= 1.5.0)
       bouncy-castle-java (= 1.5.0147)
       cabin (>= 0.6.0)
+      ci_reporter
       cinch
       clamp
       edn
@@ -83,11 +78,10 @@ PATH
 GEM
   remote: https://rubygems.org/
   specs:
-    activesupport (3.2.15)
+    activesupport (3.2.16)
       i18n (~> 0.6, >= 0.6.4)
       multi_json (~> 1.0)
     addressable (2.3.5)
-    atomic (1.1.14)
     atomic (1.1.14-java)
     autoparse (0.3.3)
       addressable (>= 2.3.1)
@@ -110,6 +104,8 @@ GEM
     cabin (0.6.1)
     celluloid (0.15.2)
       timers (~> 1.1.0)
+    ci_reporter (1.9.0)
+      builder (>= 2.1.2)
     cinch (2.0.10)
     clamp (0.6.3)
     coderay (1.1.0)
@@ -182,7 +178,6 @@ GEM
       rubyzip
     heroku-api (0.3.15)
       excon (~> 0.25.1)
-    hitimes (1.2.1)
     hitimes (1.2.1-java)
     hot_bunnies (2.0.0.pre13-java)
     http (0.5.0)
@@ -191,7 +186,7 @@ GEM
     httparty (0.11.0)
       multi_json (~> 1.0)
       multi_xml (>= 0.5.2)
-    i18n (0.6.5)
+    i18n (0.6.9)
     insist (1.0.0)
     jdbc-mysql (5.1.27)
     jdbc-sqlite3 (3.7.2.1)
@@ -208,7 +203,6 @@ GEM
     jruby-openssl (0.8.7)
       bouncy-castle-java (>= 1.5.0147)
     jruby-win32ole (0.8.5)
-    json (1.8.1)
     json (1.8.1-java)
     jwt (0.1.8)
       multi_json (>= 1.5)
