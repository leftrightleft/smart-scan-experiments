diff --git a/docs/asciidoc/static/advanced-pipeline.asciidoc b/docs/asciidoc/static/advanced-pipeline.asciidoc
index 867f0a80263..71073667ee9 100644
--- a/docs/asciidoc/static/advanced-pipeline.asciidoc
+++ b/docs/asciidoc/static/advanced-pipeline.asciidoc
@@ -311,7 +311,7 @@ The information you need to manage often comes from several disparate sources, a
 destinations for your data. Your Logstash pipeline can use multiple input and output plugins to handle these 
 requirements.
 
-This example creates a Logstash pipeline that takes input from a Twitter feed and the Logstash Forwarder client, then 
+This example creates a Logstash pipeline that takes input from a Twitter feed and the Filebeat client, then 
 sends the information to an Elasticsearch cluster as well as writing the information directly to a file.
 
 [float]
@@ -342,60 +342,60 @@ twitter {
 
 [float]
 [[configuring-lsf]]
-===== The Logstash Forwarder
+===== The Filebeat Client
 
-The https://github.com/elastic/logstash-forwarder[Logstash Forwarder] is a lightweight, resource-friendly tool that 
+The https://github.com/elastic/filebeat[filebeat] client is a lightweight, resource-friendly tool that 
 collects logs from files on the server and forwards these logs to your Logstash instance for processing. The 
-Logstash Forwarder uses a secure protocol called _lumberjack_ to communicate with your Logstash instance. The 
-lumberjack protocol is designed for reliability and low latency. The Logstash Forwarder uses the computing resources of 
-the machine hosting the source data, and the Lumberjack input plugin minimizes the resource demands on the Logstash 
-instance.
+Filebeat client uses the secure Beats protocol to communicate with your Logstash instance. The 
+lumberjack protocol is designed for reliability and low latency. Filebeat uses the computing resources of 
+the machine hosting the source data, and the {logstash}plugins-inputs-beats.html[Beats input] plugin minimizes the 
+resource demands on the Logstash instance.
 
-NOTE: In a typical use case, the Logstash Forwarder client runs on a separate machine from the machine running your 
-Logstash instance. For the purposes of this tutorial, both Logstash and the Logstash Forwarder will be running on the
+NOTE: In a typical use case, Filebeat runs on a separate machine from the machine running your 
+Logstash instance. For the purposes of this tutorial, Logstash and Filebeat are running on the
 same machine.
 
-Default Logstash configuration includes the {logstash}plugins-inputs-lumberjack.html[Lumberjack input plugin], which is 
-designed to be resource-friendly. To install the Logstash Forwarder on your data source machine, install the 
-appropriate package from the main Logstash https://www.elastic.co/downloads/logstash[product page].
-
-Create a configuration file for the Logstash Forwarder similar to the following example:
-
-[source,json]
---------------------------------------------------------------------------------
-{
-    "network": {
-        "servers": [ "localhost:5043" ],
-        "ssl ca": "/path/to/localhost.crt", <1>
-        "timeout": 15
-    },
-    "files": [
-        {
-            "paths": [
-                "/path/to/sample-log" <2>
-            ],
-            "fields": { "type": "apache" }
-        }
-    ]
-}
---------------------------------------------------------------------------------
-
-<1> Path to the SSL certificate for the Logstash instance.
-<2> Path to the file or files that the Logstash Forwarder processes.
-
-Save this configuration file as `logstash-forwarder.conf`. 
-
-Configure your Logstash instance to use the Lumberjack input plugin by adding the following lines to the `input` section 
+Default Logstash configuration includes the {logstash}plugins-inputs-beats.html[Beats input plugin], which is 
+designed to be resource-friendly. To install Filebeat on your data source machine, download the 
+appropriate package from the Filebeat https://www.elastic.co/downloads/beats/filebeat[product page].
+
+Create a configuration file for Filebeat similar to the following example:
+
+[source,yaml]
+filebeat:
+  prospectors:
+    -
+      paths:
+        - "/path/to/sample-log" <2>
+      fields:
+        type: syslog
+output:
+  elasticsearch:
+    enabled: true
+    hosts: ["http://localhost:5043"]
+  tls:
+    certificate: /path/to/ssl-certificate.crt <2>
+    certificate_key: /path/to/ssl-certificate.key
+    certificate_authorities: /path/to/ssl-certificate.crt
+    timeout: 15
+
+<1> Path to the file or files that Filebeat processes.
+<2> Path to the SSL certificate for the Logstash instance.
+
+Save this configuration file as `filebeat.yml`. 
+
+Configure your Logstash instance to use the Filebeat input plugin by adding the following lines to the `input` section 
 of the `first-pipeline.conf` file:
 
 [source,json]
-lumberjack {
+beats {
     port => "5043"
+    ssl => true
     ssl_certificate => "/path/to/ssl-cert" <1>
     ssl_key => "/path/to/ssl-key" <2>
 }
 
-<1> Path to the SSL certificate that the Logstash instance uses to authenticate itself to Logstash Forwarder.
+<1> Path to the SSL certificate that the Logstash instance uses to authenticate itself to Filebeat.
 <2> Path to the key for the SSL certificate.
 
 [float]
@@ -451,8 +451,9 @@ input {
         oauth_token =>
         oauth_token_secret =>
     }
-    lumberjack {
+    beats {
         port => "5043"
+        ssl => true
         ssl_certificate => "/path/to/ssl-cert"
         ssl_key => "/path/to/ssl-key"
     }
@@ -467,15 +468,15 @@ output {
 }
 --------------------------------------------------------------------------------
 
-Logstash is consuming data from the Twitter feed you configured, receiving data from the Logstash Forwarder, and 
+Logstash is consuming data from the Twitter feed you configured, receiving data from Filebeat, and 
 indexing this information to three nodes in an Elasticsearch cluster as well as writing to a file.
 
-At the data source machine, run the Logstash Forwarder with the following command:
+At the data source machine, run Filebeat with the following command:
 
 [source,shell]
-logstash-forwarder -config logstash-forwarder.conf
+sudo ./filebeat -e -c filebeat.yml -d "publish"
 
-Logstash Forwarder will attempt to connect on port 5403. Until Logstash starts with an active Lumberjack plugin, there 
+Filebeat will attempt to connect on port 5403. Until Logstash starts with an active Beats plugin, there 
 wonâ€™t be any answer on that port, so any messages you see regarding failure to connect on that port are normal for now.
 
 To verify your configuration, run the following command:
diff --git a/docs/asciidoc/static/deploying.asciidoc b/docs/asciidoc/static/deploying.asciidoc
index a81239ddcfe..d33ea69a65e 100644
--- a/docs/asciidoc/static/deploying.asciidoc
+++ b/docs/asciidoc/static/deploying.asciidoc
@@ -39,18 +39,17 @@ filtering tasks. For example the `bin/logstash -w 8` command uses eight differen
 image::static/images/deploy_2.png[]
 
 [float]
-[[deploying-logstash-forwarder]]
-==== Using Logstash Forwarder
-
-The https://github.com/elastic/logstash-forwarder[Logstash Forwarder] is a lightweight, resource-friendly tool written 
-in Go that collects logs from files on the server and forwards these logs to other machines for processing. The 
-Logstash Forwarder uses a secure protocol called Lumberjack to communicate with a centralized Logstash instance. 
-Configure the Logstash instances that receive Lumberjack data to use the 
-{logstash}plugins-inputs-lumberjack.html[Lumberjack input plugin].
-
-The Logstash Forwarder uses the computing resources of the machine hosting the source data, and the Lumberjack input 
-plugin minimizes the resource demands on the Logstash instance, making this architecture attractive for use cases with 
-resource constraints.
+[[deploying-filebeat]]
+==== Using Filebeat
+
+https://www.elastic.co/guide/en/beats/filebeat/current/index.html[Filebeat] is a lightweight, resource-friendly tool
+written in Go that collects logs from files on the server and forwards these logs to other machines for processing. 
+Filebeat uses the https://www.elastic.co/guide/en/beats/libbeat/current/index.html[Beats] protocol to communicate with a 
+centralized Logstash instance. Configure the Logstash instances that receive Beats data to use the 
+{logstash}plugins-inputs-beats.html[Beats input plugin].
+
+Filebeat uses the computing resources of the machine hosting the source data, and the Beats input plugin minimizes the
+resource demands on the Logstash instance, making this architecture attractive for use cases with resource constraints.
 
 image::static/images/deploy_3.png[]
 
diff --git a/docs/asciidoc/static/introduction.asciidoc b/docs/asciidoc/static/introduction.asciidoc
index ec9af52cd15..c00119237b8 100644
--- a/docs/asciidoc/static/introduction.asciidoc
+++ b/docs/asciidoc/static/introduction.asciidoc
@@ -1,15 +1,3 @@
-[[introduction]]
-== Logstash Introduction
-
-Logstash is an open source data collection engine with real-time pipelining capabilities. Logstash can dynamically 
-unify data from disparate sources and normalize the data into destinations of your choice. Cleanse and democratize all 
-your data for diverse advanced downstream analytics and visualization use cases.
-
-While Logstash originally drove innovation in log collection, its capabilities extend well beyond that use case. Any 
-type of event can be enriched and transformed with a broad array of input, filter, and output plugins, with many 
-native codecs further simplifying the ingestion process. Logstash accelerates your insights by harnessing a greater 
-volume and variety of data.
-
 [float]
 [[power-of-logstash]]
 == The Power of Logstash
@@ -43,8 +31,7 @@ Where it all started.
 logs like <<plugins-inputs-log4j,log4j>> for Java
 ** Capture many other log formats like <<plugins-inputs-syslog,syslog>>, 
 <<plugins-inputs-eventlog,Windows event logs>>, networking and firewall logs, and more
-* Enjoy complementary secure log forwarding capabilities with https://github.com/elastic/logstash-forwarder[Logstash 
-Forwarder]
+* Enjoy complementary secure log forwarding capabilities with https://github.com/elastic/filebeat[Filebeat]
 * Collect metrics from <<plugins-inputs-ganglia,Ganglia>>, <<plugins-codecs-collectd,collectd>>, 
 <<plugins-codecs-netflow,NetFlow>>, <<plugins-inputs-jmx,JMX>>, and many other infrastructure 
 and application platforms over <<plugins-inputs-tcp,TCP>> and <<plugins-inputs-udp,UDP>>
diff --git a/docs/asciidoc/static/life-of-an-event.asciidoc b/docs/asciidoc/static/life-of-an-event.asciidoc
index 569bd545f7c..41cadb8ac6e 100644
--- a/docs/asciidoc/static/life-of-an-event.asciidoc
+++ b/docs/asciidoc/static/life-of-an-event.asciidoc
@@ -19,8 +19,7 @@ according to the RFC3164 format
 * *redis*: reads from a redis server, using both redis channels and redis lists.
 Redis is often used as a "broker" in a centralized Logstash installation, which
 queues Logstash events from remote Logstash "shippers".
-* *lumberjack*: processes events sent in the lumberjack protocol. Now called
-https://github.com/elastic/logstash-forwarder[logstash-forwarder].
+* *beats*: processes events sent by https://www.elastic.co/downloads/beats/filebeat[Filebeat].
 
 For more information about the available inputs, see
 <<input-plugins,Input Plugins>>.
diff --git a/docs/asciidoc/static/managing-multiline-events.asciidoc b/docs/asciidoc/static/managing-multiline-events.asciidoc
index 1185348bc7d..2e1cd694e70 100644
--- a/docs/asciidoc/static/managing-multiline-events.asciidoc
+++ b/docs/asciidoc/static/managing-multiline-events.asciidoc
@@ -9,8 +9,6 @@ processing is to implement the processing as early in the pipeline as possible.
 pipeline is the {logstash}plugins-codecs-multiline.html[multiline codec], which merges lines from a single input using 
 a simple set of rules.
 
-For more complex needs, the {logstash}plugins-filters-multiline.html[multiline filter] performs a similar task at the 
-filter stage of processing, where the Logstash instance aggregates multiple inputs.
 
 The most important aspects of configuring either multiline plugin are the following:
 
@@ -25,19 +23,10 @@ _do not_ match the regular expression specified in the `pattern` option.
 See the full documentation for the {logstash}plugins-codecs-multiline.html[multiline codec] or the 
 {logstash}plugins-filters-multiline.html[multiline filter] plugin for more information on configuration options.
 
-==== Multiline Special Cases
-
-* The current release of the multiline codec plugin treats all input from the 
-{logstash}plugins-inputs-lumberjack[lumberjack] input plugin as a single stream. When your use case involves the 
-Logstash Forwarder processing multiple files concurrently, proper event ordering can be challenging to maintain, and 
-any resulting errors can be difficult to diagnose. Carefully monitor the output of Logstash configurations that involve 
-multiline processing of multiple files handled by the Logstash Forwarder.
-
-* The multiline codec plugin does not support file input from files that contain events from multiple sources.
-
-* The multiline filter plugin is not thread-safe. Avoid using multiple filter workers with the multiline filter.
-
-NOTE: You can track the progress of upgrades to the functionality of the multiline codec at 
+NOTE: For more complex needs, the {logstash}plugins-filters-multiline.html[multiline filter] performs a similar task at 
+the filter stage of processing, where the Logstash instance aggregates multiple inputs.
+The multiline filter plugin is not thread-safe. Avoid using multiple filter workers with the multiline filter. You can 
+track the progress of upgrades to the functionality of the multiline codec at 
 https://github.com/logstash-plugins/logstash-codec-multiline/issues/10[this Github issue].
 
 ==== Examples of Multiline Plugin Configuration
