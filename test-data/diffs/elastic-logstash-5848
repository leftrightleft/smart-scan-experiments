diff --git a/logstash-core/lib/logstash/agent.rb b/logstash-core/lib/logstash/agent.rb
index 1c0e18dbd87..15588a12d16 100644
--- a/logstash-core/lib/logstash/agent.rb
+++ b/logstash-core/lib/logstash/agent.rb
@@ -48,6 +48,8 @@ def initialize(settings = LogStash::SETTINGS)
 
     # Create the collectors and configured it with the library
     configure_metrics_collectors
+
+    @reload_metric = metric.namespace([:stats, :pipelines])
   end
 
   def execute
@@ -99,6 +101,11 @@ def reload_state!
         begin
           reload_pipeline!(pipeline_id)
         rescue => e
+          @reload_metric.namespace([pipeline_id.to_sym, :reloads]).tap do |n|
+            n.increment(:failures)
+            n.gauge(:last_error, { :message => e.message, :backtrace => e.backtrace})
+            n.gauge(:last_failure_timestamp, LogStash::Timestamp.now)
+          end
           @logger.error(I18n.t("oops"), :message => e.message, :class => e.class.name, :backtrace => e.backtrace)
         end
       end
@@ -163,7 +170,11 @@ def configure_metrics_collectors
   end
 
   def reset_pipeline_metrics(id)
-    @collector.clear("stats/pipelines/#{id}")
+    # selectively reset metrics we don't wish to keep after reloading
+    # these include metrics about the plugins and number of processed events
+    # we want to keep other metrics like reload counts and error messages
+    @collector.clear("stats/pipelines/#{id}/plugins")
+    @collector.clear("stats/pipelines/#{id}/events")
   end
 
   def collect_metrics?
@@ -183,6 +194,11 @@ def create_pipeline(settings, config=nil)
     begin
       LogStash::Pipeline.new(config, settings, metric)
     rescue => e
+      @reload_metric.namespace([settings.get("pipeline.id").to_sym, :reloads]).tap do |n|
+        n.increment(:failures)
+        n.gauge(:last_error, { :message => e.message, :backtrace => e.backtrace})
+        n.gauge(:last_failure_timestamp, LogStash::Timestamp.now)
+      end
       if @logger.debug?
         @logger.error("fetched an invalid config", :config => config, :reason => e.message, :backtrace => e.backtrace)
       else
@@ -233,6 +249,11 @@ def start_pipeline(id)
       begin
         pipeline.run
       rescue => e
+        @reload_metric.namespace([id.to_sym, :reloads]) do |n|
+          n.increment(:failures)
+          n.gauge(:last_error, { :message => e.message, :backtrace => e.backtrace})
+          n.gauge(:last_failure_timestamp, LogStash::Timestamp.now)
+        end
         @logger.error("Pipeline aborted due to error", :exception => e, :backtrace => e.backtrace)
       end
     end
@@ -248,7 +269,11 @@ def stop_pipeline(id)
   end
 
   def start_pipelines
-    @pipelines.each { |id, _| start_pipeline(id) }
+    @pipelines.each do |id, _|
+      start_pipeline(id)
+      # no reloads yet, initalize all the reload metrics
+      init_pipeline_reload_metrics(id)
+    end
   end
 
   def shutdown_pipelines
@@ -265,6 +290,10 @@ def upgrade_pipeline(pipeline_id, new_pipeline)
     reset_pipeline_metrics(pipeline_id)
     @pipelines[pipeline_id] = new_pipeline
     start_pipeline(pipeline_id)
+    @reload_metric.namespace([pipeline_id.to_sym, :reloads]).tap do |n|
+      n.increment(:successes)
+      n.gauge(:last_success_timestamp, LogStash::Timestamp.now)
+    end
   end
 
   def clean_state?
@@ -274,4 +303,14 @@ def clean_state?
   def setting(key)
     @settings.get(key)
   end
+
+  def init_pipeline_reload_metrics(id)
+    @reload_metric.namespace([id.to_sym, :reloads]).tap do |n|
+      n.increment(:successes, 0)
+      n.increment(:failures, 0)
+      n.gauge(:last_error, nil)
+      n.gauge(:last_success_timestamp, nil)
+      n.gauge(:last_failure_timestamp, nil)
+    end
+  end
 end # class LogStash::Agent
diff --git a/logstash-core/lib/logstash/api/commands/stats.rb b/logstash-core/lib/logstash/api/commands/stats.rb
index ae80eecd0da..502c57fac03 100644
--- a/logstash-core/lib/logstash/api/commands/stats.rb
+++ b/logstash-core/lib/logstash/api/commands/stats.rb
@@ -91,7 +91,8 @@ def report(stats)
                 :inputs => plugin_stats(stats, :inputs),
                 :filters => plugin_stats(stats, :filters),
                 :outputs => plugin_stats(stats, :outputs)
-              }
+              },
+              :reloads => stats[:reloads],
             }
           end
         end # module PluginsStats
diff --git a/logstash-core/spec/logstash/agent_spec.rb b/logstash-core/spec/logstash/agent_spec.rb
index 212b6c62382..20700ceccc2 100644
--- a/logstash-core/spec/logstash/agent_spec.rb
+++ b/logstash-core/spec/logstash/agent_spec.rb
@@ -51,7 +51,7 @@
         "config.string" => config_string,
         "config.reload.automatic" => true,
         "config.reload.interval" => 0.01,
-	"pipeline.workers" => 4,
+        "pipeline.workers" => 4,
       }
     end
 
@@ -331,8 +331,6 @@
 
   context "metrics after config reloading" do
     let(:config) { "input { generator { } } output { dummyoutput { } }" }
-    let(:new_config_generator_counter) { 500 }
-    let(:new_config) { "input { generator { count => #{new_config_generator_counter} } } output { dummyoutput2 {} }" }
     let(:config_path) do
       f = Stud::Temporary.file
       f.write(config)
@@ -390,61 +388,121 @@ class DummyOutput2 < LogStash::Outputs::Base; end
       end
     end
 
-    it "resets the pipeline metric collector" do
-      # We know that the store has more events coming in.
-      i = 0
-      while dummy_output.events.size <= new_config_generator_counter
-        i += 1
-        raise "Waiting too long!" if i > 20
-        sleep(0.1)
+    context "when reloading a good config" do
+      let(:new_config_generator_counter) { 500 }
+      let(:new_config) { "input { generator { count => #{new_config_generator_counter} } } output { dummyoutput2 {} }" }
+      before :each do
+        # We know that the store has more events coming in.
+        i = 0
+        while dummy_output.events.size <= new_config_generator_counter
+          i += 1
+          raise "Waiting too long!" if i > 20
+          sleep(0.1)
+        end
+
+
+        # Also force a flush to disk to make sure ruby reload it.
+        File.open(config_path, "w") do |f|
+          f.write(new_config)
+          f.fsync
+        end
+
+        sleep(interval * 3) # Give time to reload the config
+
+        # be eventually consistent.
+        sleep(0.01) while dummy_output2.events.size < new_config_generator_counter
+      end
+
+      it "resets the pipeline metric collector" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:events][:in].value
+        expect(value).to eq(new_config_generator_counter)
       end
 
-      snapshot = subject.metric.collector.snapshot_metric
-      expect(snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:events][:in].value).to be > new_config_generator_counter
+      it "does not reset the global event count" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/events")[:stats][:events][:in].value
+        expect(value).to be > new_config_generator_counter
+      end
+
+      it "increases the successful reload count" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:successes].value
+        expect(value).to be(1)
+      end
 
-      # update the configuration and give some time to logstash to pick it up and do the work
-      # Also force a flush to disk to make sure ruby reload it.
-      File.open(config_path, "w") do |f|
-        f.write(new_config)
-        f.fsync
+      it "does not set the failure reload timestamp" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_failure_timestamp].value
+        expect(value).to be(nil)
       end
 
-      sleep(interval * 3) # Give time to reload the config
+      it "sets the success reload timestamp" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_success_timestamp].value
+        expect(value).to be_a(LogStash::Timestamp)
+      end
 
-      # be eventually consistent.
-      sleep(0.01) while dummy_output2.events.size < new_config_generator_counter
+      it "does not set the last reload error" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_error].value
+        expect(value).to be(nil)
+      end
 
-      snapshot = subject.metric.collector.snapshot_metric
-      value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:events][:in].value
-      expect(value).to eq(new_config_generator_counter)
     end
-    it "does not reset the global event count" do
-      # We know that the store has more events coming in.
-      i = 0
-      while dummy_output.events.size <= new_config_generator_counter
-        i += 1
-        raise "Waiting too long!" if i > 20
-        sleep(0.1)
+
+    context "when reloading a bad config" do
+      let(:new_config) { "input { generator { count => " }
+      let(:new_config_generator_counter) { 500 }
+      before :each do
+        # We know that the store has more events coming in.
+        i = 0
+        while dummy_output.events.size <= new_config_generator_counter
+          i += 1
+          raise "Waiting too long!" if i > 20
+          sleep(0.1)
+        end
+
+
+        # Also force a flush to disk to make sure ruby reload it.
+        File.open(config_path, "w") do |f|
+          f.write(new_config)
+          f.fsync
+        end
+
+        sleep(interval * 3) # Give time to reload the config
       end
 
-      snapshot = subject.metric.collector.snapshot_metric
-      expect(snapshot.metric_store.get_with_path("/stats/events")[:stats][:events][:in].value).to be > new_config_generator_counter
+      it "does not increase the successful reload count" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:successes].value
+        expect(value).to be(0)
+      end
 
-      # update the configuration and give some time to logstash to pick it up and do the work
-      # Also force a flush to disk to make sure ruby reload it.
-      File.open(config_path, "w") do |f|
-        f.write(new_config)
-        f.fsync
+      it "does not set the successful reload timestamp" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_success_timestamp].value
+        expect(value).to be(nil)
       end
 
-      sleep(interval * 3) # Give time to reload the config
+      it "sets the failure reload timestamp" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_failure_timestamp].value
+        expect(value).to be_a(LogStash::Timestamp)
+      end
 
-      # be eventually consistent.
-      sleep(0.01) while dummy_output2.events.size < new_config_generator_counter
+      it "sets the last reload error" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:last_error].value
+        expect(value).to be_a(Hash)
+        expect(value).to include(:message, :backtrace)
+      end
 
-      snapshot = subject.metric.collector.snapshot_metric
-      value = snapshot.metric_store.get_with_path("/stats/events")[:stats][:events][:in].value
-      expect(value).to be > new_config_generator_counter
+      it "increases the failed reload count" do
+        snapshot = subject.metric.collector.snapshot_metric
+        value = snapshot.metric_store.get_with_path("/stats/pipelines")[:stats][:pipelines][:main][:reloads][:failures].value
+        expect(value).to be > 1
+      end
     end
   end
 end
