diff --git a/README.md b/README.md
index 990adc740ce..077543706d7 100644
--- a/README.md
+++ b/README.md
@@ -101,11 +101,6 @@ For testing you can use the *test* `rake` tasks and the `bin/rspec` command, see
     bin/rspec
     bin/rspec spec/foo/bar_spec.rb
 
----
-Note that if a plugin is installed using the plugin manager `bin/plugin install ...` do not forget to also install the plugins development dependencies using the following command after the plugin installation:
-
-    bin/plugin install --development
-
 ### Plugins tests
 
 To run the tests of all currently installed plugins:
diff --git a/STYLE.md b/STYLE.md
index 894a31e88f3..5bc54a31766 100644
--- a/STYLE.md
+++ b/STYLE.md
@@ -27,6 +27,7 @@ Do this:
 * parentheses on function definitions/calls
 * explicit is better than implicit
   * implicit returns are forbidden except in the case of a single expression 
+* Avoid use of 'and' and 'or' in ruby code 
 
 The point is consistency and documentation. If you see inconsistencies, let me
 know, and I'll fix them :)
diff --git a/bin/setup.bat b/bin/setup.bat
index 4ad640ac7fa..40993179168 100644
--- a/bin/setup.bat
+++ b/bin/setup.bat
@@ -19,36 +19,45 @@ if not defined JAVA_HOME goto missing_java_home
 REM ***** JAVA options *****
 
 if "%LS_HEAP_SIZE%" == "" (
-set LS_HEAP_SIZE=1g
+    set LS_HEAP_SIZE=1g
 )
 
-set JAVA_OPTS=%JAVA_OPTS% -Xmx%LS_HEAP_SIZE%
-
-REM Enable aggressive optimizations in the JVM
-REM    - Disabled by default as it might cause the JVM to crash
-REM set JAVA_OPTS=%JAVA_OPTS% -XX:+AggressiveOpts
-
-set JAVA_OPTS=%JAVA_OPTS% -XX:+UseParNewGC
-set JAVA_OPTS=%JAVA_OPTS% -XX:+UseConcMarkSweepGC
-set JAVA_OPTS=%JAVA_OPTS% -XX:+CMSParallelRemarkEnabled
-set JAVA_OPTS=%JAVA_OPTS% -XX:SurvivorRatio=8
-set JAVA_OPTS=%JAVA_OPTS% -XX:MaxTenuringThreshold=1
-set JAVA_OPTS=%JAVA_OPTS% -XX:CMSInitiatingOccupancyFraction=75
-set JAVA_OPTS=%JAVA_OPTS% -XX:+UseCMSInitiatingOccupancyOnly
-
-REM GC logging options -- uncomment to enable
-REM JAVA_OPTS=%JAVA_OPTS% -XX:+PrintGCDetails
-REM JAVA_OPTS=%JAVA_OPTS% -XX:+PrintGCTimeStamps
-REM JAVA_OPTS=%JAVA_OPTS% -XX:+PrintClassHistogram
-REM JAVA_OPTS=%JAVA_OPTS% -XX:+PrintTenuringDistribution
-REM JAVA_OPTS=%JAVA_OPTS% -XX:+PrintGCApplicationStoppedTime
-REM JAVA_OPTS=%JAVA_OPTS% -Xloggc:/var/log/logstash/gc.log
-
-REM Causes the JVM to dump its heap on OutOfMemory.
-set JAVA_OPTS=%JAVA_OPTS% -XX:+HeapDumpOnOutOfMemoryError
-REM The path to the heap dump location, note directory must exists and have enough
-REM space for a full heap dump.
-set JAVA_OPTS=%JAVA_OPTS% -XX:HeapDumpPath="$LS_HOME/heapdump.hprof"
+IF NOT "%JAVA_OPTS%" == "" (
+    ECHO JAVA_OPTS was set to [%JAVA_OPTS%]. Logstash will trust these options, and not set any defaults that it might usually set
+) ELSE (
+    SET JAVA_OPTS=%JAVA_OPTS% -Xmx%LS_HEAP_SIZE%
+
+    REM Enable aggressive optimizations in the JVM
+    REM    - Disabled by default as it might cause the JVM to crash
+    REM set JAVA_OPTS=%JAVA_OPTS% -XX:+AggressiveOpts
+
+    SET JAVA_OPTS=%JAVA_OPTS% -XX:+UseParNewGC
+    SET JAVA_OPTS=%JAVA_OPTS% -XX:+UseConcMarkSweepGC
+    SET JAVA_OPTS=%JAVA_OPTS% -XX:+CMSParallelRemarkEnabled
+    SET JAVA_OPTS=%JAVA_OPTS% -XX:SurvivorRatio=8
+    SET JAVA_OPTS=%JAVA_OPTS% -XX:MaxTenuringThreshold=1
+    SET JAVA_OPTS=%JAVA_OPTS% -XX:CMSInitiatingOccupancyFraction=75
+    SET JAVA_OPTS=%JAVA_OPTS% -XX:+UseCMSInitiatingOccupancyOnly
+
+    REM GC logging options -- uncomment to enable
+    REM JAVA_OPTS=%JAVA_OPTS% -XX:+PrintGCDetails
+    REM JAVA_OPTS=%JAVA_OPTS% -XX:+PrintGCTimeStamps
+    REM JAVA_OPTS=%JAVA_OPTS% -XX:+PrintClassHistogram
+    REM JAVA_OPTS=%JAVA_OPTS% -XX:+PrintTenuringDistribution
+    REM JAVA_OPTS=%JAVA_OPTS% -XX:+PrintGCApplicationStoppedTime
+    REM JAVA_OPTS=%JAVA_OPTS% -Xloggc:/var/log/logstash/gc.log
+
+    REM Causes the JVM to dump its heap on OutOfMemory.
+    SET JAVA_OPTS=%JAVA_OPTS% -XX:+HeapDumpOnOutOfMemoryError
+    REM The path to the heap dump location, note directory must exists and have enough
+    REM space for a full heap dump.
+    SET JAVA_OPTS=%JAVA_OPTS% -XX:HeapDumpPath="$LS_HOME/heapdump.hprof"
+)
+
+IF NOT "%LS_JAVA_OPTS%" == "" (
+    ECHO LS_JAVA_OPTS was set to [%LS_JAVA_OPTS%]. This will be appended to the JAVA_OPTS [%JAVA_OPTS%]
+    SET JAVA_OPTS=%JAVA_OPTS% %LS_JAVA_OPTS%
+)
 
 REM setup_vendored_jruby()
 set JRUBY_BIN="%LS_HOME%\vendor\jruby\bin\jruby"
diff --git a/conf/logstash.yml b/conf/logstash.yml
new file mode 100644
index 00000000000..615e6c06f7e
--- /dev/null
+++ b/conf/logstash.yml
@@ -0,0 +1,47 @@
+# Settings file in YAML
+#
+# Settings can be specified either in hierarchical form, e.g.:
+#
+#   pipeline:
+#     batch:
+#       size: 125
+#       delay: 5
+#
+# Or as flat keys:
+#
+#   pipeline.batch.size: 125
+#   pipeline.batch.delay: 5
+#
+# ------------  Node identity ------------
+#
+# Use a descriptive name for the node:
+#
+# node.name: test
+#
+# If omitted the node name will default to the machine's host name
+#
+# ------------ Pipeline Settings --------------
+#
+# Set the number of workers that will, in parallel, execute the filters+outputs
+# stage of the pipeline.
+#
+# This defaults to half the number of the host's CPU cores.
+#
+# pipeline.workers: 2
+#
+# How many events to retrieve from inputs before sending to filters+workers
+#
+# pipeline.batch.size: 125
+#
+# How long to wait before dispatching an undersized batch to filters+workers
+# Value is in seconds.
+#
+# pipeline.batch.delay: 5
+#
+# Force Logstash to exit during shutdown even if there are still inflight
+# events in memory. By default, logstash will refuse to quit until all
+# received events have been pushed to the outputs.
+#
+# WARNING: enabling this can lead to data loss during shutdown
+#
+# pipeline.unsafe_shutdown: false
diff --git a/docs/asciidocgen.rb b/docs/asciidocgen.rb
index c95a4f2b79d..5392e6a6440 100644
--- a/docs/asciidocgen.rb
+++ b/docs/asciidocgen.rb
@@ -6,6 +6,7 @@
 $: << File.join(File.dirname(__FILE__), "..", "lib")
 $: << File.join(File.dirname(__FILE__), "..", "rakelib")
 
+require_relative "../lib/bootstrap/environment" #needed for LogStash::Environment constants LOGSTASH_HOME
 require "logstash/config/mixin"
 require "logstash/inputs/base"
 require "logstash/codecs/base"
@@ -161,7 +162,7 @@ def generate(file, settings)
     load file
 
     # Get the correct base path
-    base = File.join(::LogStash::Environment::LOGSTASH_HOME,'lib/logstash', file.split("/")[-2])
+    base = File.join(::LogStash::Environment::LOGSTASH_HOME,'logstash-core/lib/logstash', file.split("/")[-2])
 
     # parse base first
     parse(File.new(File.join(base, "base.rb"), "r").read)
diff --git a/docs/static/advanced-pipeline.asciidoc b/docs/static/advanced-pipeline.asciidoc
index 14b2829b829..7e541ce5eea 100644
--- a/docs/static/advanced-pipeline.asciidoc
+++ b/docs/static/advanced-pipeline.asciidoc
@@ -403,9 +403,8 @@ filebeat:
       fields:
         type: syslog
 output:
-  elasticsearch:
-    enabled: true
-    hosts: ["http://localhost:5043"]
+  logstash:
+    hosts: ["localhost:5043"]
   tls:
     certificate: /path/to/ssl-certificate.crt <2>
     certificate_key: /path/to/ssl-certificate.key
diff --git a/docs/static/command-line-flags.asciidoc b/docs/static/command-line-flags.asciidoc
index 894d0e84ae0..0e52a3930de 100644
--- a/docs/static/command-line-flags.asciidoc
+++ b/docs/static/command-line-flags.asciidoc
@@ -5,30 +5,30 @@ Logstash has the following flags. You can use the `--help` flag to display this
 
 [source,shell]
 ----------------------------------
--f, --config CONFIGFILE
+-f, --config.path CONFIGFILE
  Load the Logstash config from a specific file, directory, or a wildcard. If
  given a directory or wildcard, config files will be read from the directory in
  alphabetical order.
 
--e CONFIGSTRING
+-e, --config.string CONFIGSTRING
  Use the given string as the configuration data. Same syntax as the config file.
  If not input is specified, 'stdin { type => stdin }' is default. If no output
  is specified, 'stdout { codec => rubydebug }}' is default.
 
--w, --filterworkers COUNT
+-w, --pipeline.workers COUNT
  Sets the number of pipeline workers (threads) to run for filter and output
  processing (default: number of cores).
  If you find that events are backing up, or that the CPU is not saturated, consider increasing
  this number to better utilize machine processing power.
 
--b, --pipeline-batch-size SIZE
+-b, --pipeline.batch.size SIZE
  This parameter defines the maximum number of events an individual worker thread will collect
  before attempting to execute its filters and outputs. Default is 125 events.
  Larger batch sizes are generally more efficient, but come at the cost of increased memory
  overhead. You may have to increase the JVM heap size by setting the `LS_HEAP_SIZE`
  variable to effectively use the option.
 
--u, --pipeline-batch-delay DELAY_IN_MS
+-u, --pipeline.batch.delay DELAY_IN_MS
  When creating pipeline event batches, how long to wait while polling for the next event.
  Default is 5ms.
 
@@ -44,18 +44,29 @@ Logstash has the following flags. You can use the `--help` flag to display this
 -V, --version
   Display the version of Logstash.
 
--p, --pluginpath
+-p, --plugin.path
   A path of where to find plugins. This flag can be given multiple times to include
   multiple paths. Plugins are expected to be in a specific directory hierarchy:
   'PATH/logstash/TYPE/NAME.rb' where TYPE is 'inputs' 'filters', 'outputs' or 'codecs'
   and NAME is the name of the plugin.
 
--t, --configtest
+-t, --config.test
   Checks configuration and then exit. Note that grok patterns are not checked for
   correctness with this flag.
   Logstash can read multiple config files from a directory. If you combine this
   flag with `--debug`, Logstash will log the combined config file, annotating the
   individual config blocks with the source file it came from.
+  
+-r, --[no-]auto-reload
+  Monitor configuration changes and reload the configuration whenever it is changed.
+  
+--reload-interval RELOAD_INTERVAL
+  Specifies how often Logstash checks the config files for changes. The default is every 3 seconds.
+
+--pipeline.unsafe_shutdown
+  Force logstash to exit during shutdown even if there are still inflight events
+  in memory. By default, logstash will refuse to quit until all received events
+  have been pushed to the outputs.
 
 -h, --help
   Print help
diff --git a/docs/static/configuration.asciidoc b/docs/static/configuration.asciidoc
index fc28c22965c..72aaeae5731 100644
--- a/docs/static/configuration.asciidoc
+++ b/docs/static/configuration.asciidoc
@@ -599,6 +599,184 @@ output {
 }
 ----------------------------------
 
+[[environment-variables]]
+=== Using Environment Variables in Configuration
+==== Overview
+
+* You can set environment variable references into Logstash plugins configuration using `${var}` or `$var`.
+* Each reference will be replaced by environment variable value at Logstash startup.
+* The replacement is case-sensitive.
+* References to undefined variables raise a Logstash configuration error.
+* A default value can be given by using the form `${var:default value}`.
+* You can add environment variable references in any plugin option type : string, number, boolean, array or hash.
+* Environment variables are immutable. If you update the environment variable, you'll have to restart Logstash to pick the updated value.
+
+==== Examples
+
+[cols="a,a,a"]
+|==================================
+|Logstash config source	|Environment 	|Logstash config result
+
+|
+[source,ruby]
+----
+input {
+  tcp {
+    port => "$TCP_PORT"
+  }
+}
+----
+
+|
+[source,shell]
+----
+export TCP_PORT=12345
+----
+|
+[source,ruby]
+----
+input {
+  tcp {
+    port => 12345
+  }
+}
+----
+|
+[source,ruby]
+----
+input {
+  tcp {
+    port => "${TCP_PORT}"
+  }
+}
+----
+
+|
+[source,shell]
+----
+export TCP_PORT=12345
+----
+|
+[source,ruby]
+----
+input {
+  tcp {
+    port => 12345
+  }
+}
+----
+|
+[source,ruby]
+----
+input {
+  tcp {
+    port => "${TCP_PORT}"
+  }
+}
+----
+
+|
+No TCP_PORT defined
+|
+Raise a logstash configuration error
+|
+[source,ruby]
+----
+input {
+  tcp {
+    port => "${TCP_PORT:54321}"
+  }
+}
+----
+
+|
+No TCP_PORT defined
+|
+[source,ruby]
+----
+input {
+  tcp {
+    port => 54321
+  }
+}
+----
+|
+[source,ruby]
+----
+input {
+  tcp {
+    port => "${TCP_PORT:54321}"
+  }
+}
+----
+
+|
+[source,shell]
+----
+export TCP_PORT=12345
+----
+|
+[source,ruby]
+----
+input {
+  tcp {
+    port => 12345
+  }
+}
+----
+|
+[source,ruby]
+----
+filter {
+  mutate {
+    add_tag => [ "tag1", "${ENV_TAG}" ]
+  }
+}
+----
+
+|
+[source,shell]
+----
+export ENV_TAG="tag2"
+----
+|
+[source,ruby]
+----
+filter {
+  mutate {
+    add_tag => [ "tag1", "tag2" ]
+  }
+}
+----
+|
+[source,ruby]
+----
+filter {
+  mutate {
+    add_field => {
+      "my_path" => "${HOME}/file.log"
+    }
+  }
+}
+----
+|
+[source,shell]
+----
+export HOME="/path"
+----
+|
+[source,ruby]
+----
+filter {
+  mutate {
+    add_field => {
+      "my_path" => "/path/file.log"
+    }
+  }
+}
+----
+|==================================
+
 [[config-examples]]
 === Logstash Configuration Examples
 The following examples illustrate how you can configure Logstash to filter events, process Apache logs and syslog messages, and use conditionals to control what events are processed by a filter or output.
diff --git a/docs/static/contributing-patch.asciidoc b/docs/static/contributing-patch.asciidoc
index 4baf72784c3..470841574f2 100644
--- a/docs/static/contributing-patch.asciidoc
+++ b/docs/static/contributing-patch.asciidoc
@@ -308,13 +308,13 @@ require "logstash/outputs/zeromq"
 require "logstash/devutils/rspec/spec_helper"
 
 describe LogStash::Outputs::ZeroMQ do
-  let(:output) { described_class.new("mode" => "server", "topology" => "pushpull" }
+  let(:output) { described_class.new("mode" => "server", "topology" => "pushpull") }
   let(:tracer) { double("logger") }
 
   context "when in server mode" do
     it "a ‘bound’ info line is logged" do
       allow(tracer).to receive(:debug)
-      output.logger = logger
+      output.logger = tracer
       expect(tracer).to receive(:info).with("0mq: bound", {:address=>"tcp://127.0.0.1:2120"})
       output.register
       output.do_close
diff --git a/docs/static/getting-started-with-logstash.asciidoc b/docs/static/getting-started-with-logstash.asciidoc
index 936562fdb5c..2b2b244a0b7 100644
--- a/docs/static/getting-started-with-logstash.asciidoc
+++ b/docs/static/getting-started-with-logstash.asciidoc
@@ -44,7 +44,9 @@ bin/logstash -e 'input { stdin { } } output { stdout {} }'
 The `-e` flag enables you to specify a configuration directly from the command line. Specifying configurations at the
 command line lets you quickly test configurations without having to edit a file between iterations.
 This pipeline takes input from the standard input, `stdin`, and moves that input to the standard output, `stdout`, in a
-structured format. Type hello world at the command prompt to see Logstash respond:
+structured format.
+
+Once "Logstash startup completed" is displayed, type hello world at the command prompt to see Logstash respond:
 
 [source,shell]
 hello world
diff --git a/docs/static/life-of-an-event.asciidoc b/docs/static/life-of-an-event.asciidoc
index 3a5f72055c6..7baaba3a745 100644
--- a/docs/static/life-of-an-event.asciidoc
+++ b/docs/static/life-of-an-event.asciidoc
@@ -119,12 +119,12 @@ num_pipeline_workers.times do
 end
 wait_for_threads_to_terminate()
 
-There are three configurable options in the pipeline, `--pipeline-workers`, `--pipeline-batch-size`, and `--pipeline-batch-delay`.
-The `--pipeline-workers` or `-w` parameter determines how many threads to run for filter and output processing. If you find that events are backing up, or that the CPU is not saturated, consider increasing the value of this parameter to make better use of available processing power. Good results can even be found increasing this number past the number of available processors as these threads may spend significant time in an I/O wait state when writing to external systems. Legal values for this parameter are positive integers.
+There are three configurable options in the pipeline, `--pipeline.workers`, `--pipeline.batch.size`, and `--pipeline.batch.delay`.
+The `--pipeline.workers` or `-w` parameter determines how many threads to run for filter and output processing. If you find that events are backing up, or that the CPU is not saturated, consider increasing the value of this parameter to make better use of available processing power. Good results can even be found increasing this number past the number of available processors as these threads may spend significant time in an I/O wait state when writing to external systems. Legal values for this parameter are positive integers.
 
-The `--pipeline-batch-size` or `-b` parameter defines the maximum number of events an individual worker thread collects before attempting to execute filters and outputs. Larger batch sizes are generally more efficient, but increase memory overhead. Some hardware configurations require you to increase JVM heap size by setting the `LS_HEAP_SIZE` variable to avoid performance degradation with this option. Values of this parameter in excess of the optimum range cause performance degradation due to frequent garbage collection or JVM crashes related to out-of-memory exceptions. Output plugins can process each batch as a logical unit. The Elasticsearch output, for example, issues https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html[bulk requests] for each batch received. Tuning the `-b` parameter adjusts the size of bulk requests sent to Elasticsearch.
+The `--pipeline.batch.size` or `-b` parameter defines the maximum number of events an individual worker thread collects before attempting to execute filters and outputs. Larger batch sizes are generally more efficient, but increase memory overhead. Some hardware configurations require you to increase JVM heap size by setting the `LS_HEAP_SIZE` variable to avoid performance degradation with this option. Values of this parameter in excess of the optimum range cause performance degradation due to frequent garbage collection or JVM crashes related to out-of-memory exceptions. Output plugins can process each batch as a logical unit. The Elasticsearch output, for example, issues https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html[bulk requests] for each batch received. Tuning the `-b` parameter adjusts the size of bulk requests sent to Elasticsearch.
 
-The `--pipeline-batch-delay` option rarely needs to be tuned. This option adjusts the latency of the Logstash pipeline. Pipeline batch delay is the maximum amount of time in milliseconds that Logstash waits for new messages after receiving an event in the current pipeline worker thread. After this time elapses, Logstash beings to execute filters and outputs.The maximum time that Logstash waits between receiving an event and processing that event in a filter is the product of the `pipeline_batch_delay` and  `pipeline_batch_size` settings.
+The `--pipeline.batch.delay` option rarely needs to be tuned. This option adjusts the latency of the Logstash pipeline. Pipeline batch delay is the maximum amount of time in milliseconds that Logstash waits for new messages after receiving an event in the current pipeline worker thread. After this time elapses, Logstash beings to execute filters and outputs.The maximum time that Logstash waits between receiving an event and processing that event in a filter is the product of the `pipeline.batch.delay` and  `pipeline.batch.size` settings.
 
 [float]
 ==== Notes on Pipeline Configuration and Performance
diff --git a/docs/static/maintainer-guide.asciidoc b/docs/static/maintainer-guide.asciidoc
index 012835e58f7..5c8253ca8e3 100644
--- a/docs/static/maintainer-guide.asciidoc
+++ b/docs/static/maintainer-guide.asciidoc
@@ -43,8 +43,9 @@ reviewing and merging patches.
 
 ==== Patch Requirements
 
-A patch is a minimal and accurate answer to exactly one identified and agreed upon problem. It must conform to the code
-style guidelines and must include RSpec tests that verify the fitness of the solution.
+A patch is a minimal and accurate answer to exactly one identified and agreed upon problem. It must conform to the
+https://github.com/elastic/logstash/blob/master/STYLE.md[code style guidelines] and must include RSpec tests that verify
+the fitness of the solution.
 
 A patch will be automatically tested by a CI system that will report on the Pull Request status.
 
diff --git a/docs/static/monitoring-apis.asciidoc b/docs/static/monitoring-apis.asciidoc
new file mode 100644
index 00000000000..846896370a8
--- /dev/null
+++ b/docs/static/monitoring-apis.asciidoc
@@ -0,0 +1,286 @@
+[[monitoring]]
+== Monitoring APIs
+
+Logstash provides the following monitoring APIs to retrieve runtime metrics
+about Logstash:
+
+* <<root-resource-api>>
+* <<stats-info-api>>
+* <<hot-threads-api>>
+* <<plugins-api>>
+
+[float]
+[[monitoring-common-options]]
+=== Common Options
+
+The following options can be applied to all of the Logstash monitoring APIs.
+
+[float]
+==== Pretty Results
+
+When appending `?pretty=true` to any request made, the JSON returned
+will be pretty formatted (use it for debugging only!). Another option is
+to set `?format=yaml` which will cause the result to be returned in the
+(sometimes) more readable yaml format.
+
+[float]
+==== Human-Readable Output
+
+NOTE: For Alpha 1, the `human` option is supported for the <<hot-threads-api>>
+only. When you specify `human=true`, the results are returned in plain text instead of
+JSON format. The default is false.
+
+Statistics are returned in a format suitable for humans
+(eg `"exists_time": "1h"` or `"size": "1kb"`) and for computers
+(eg `"exists_time_in_millis": 3600000` or `"size_in_bytes": 1024`).
+The human-readable values can be turned off by adding `?human=false`
+to the query string. This makes sense when the stats results are
+being consumed by a monitoring tool, rather than intended for human
+consumption.  The default for the `human` flag is
+`false`.
+
+[[plugins-api]]
+=== Plugins API
+
+experimental[]
+
+The plugins API gets information about all Logstash plugins that are currently installed.
+This API basically returns the output of running the `bin/plugins list --verbose` command.
+
+[source,js]
+--------------------------------------------------
+GET /_plugins
+--------------------------------------------------
+
+The output is a JSON document.
+
+Example response:
+
+[source,js]
+--------------------------------------------------
+"total": 102
+"plugins" : [
+  {
+      "name": "logstash-output-pagerduty"
+      "version": "2.0.2"
+  },
+  {
+      "name": "logstash-output-elasticsearch"
+      "version": "2.1.2"
+  }
+....
+] 
+--------------------------------------------------
+
+[[root-resource-api]]
+=== Root Resource API
+
+experimental[]
+
+The root resource API retrieves general information about the Logstash instance, including
+the host name and version information.
+
+[source,js]
+--------------------------------------------------
+GET /
+--------------------------------------------------
+
+Example response:
+
+[source,js]
+--------------------------------------------------
+{
+   "hostname": "skywalker",
+    "version" : {
+        "number" : "2.1.0",       
+    }
+  }
+--------------------------------------------------
+
+
+See <<monitoring-common-options, Common Options>> for a list of options that can be applied to all
+Logstash monitoring APIs.
+
+[[stats-info-api]]
+=== Stats Info API
+
+experimental[]
+
+The stats info API retrieves runtime stats about Logstash. 
+
+// COMMENTED OUT until Logstash supports multiple pipelines: To retrieve all stats for the Logstash instance, use the `_node/stats` endpoint:
+
+[source,js]
+--------------------------------------------------
+GET /_node/stats/<types>
+--------------------------------------------------
+
+////
+COMMENTED OUT until Logstash supports multiple pipelines: To retrieve all stats per pipeline, use the `_pipelines/stats` endpoint:
+
+[source,js]
+--------------------------------------------------
+GET /_pipelines/stats/<types>
+--------------------------------------------------
+////
+
+Where `<types>` is optional and specifies the types of stats you want to return.
+
+By default, all stats are returned. You can limit this by combining any of the following types: 
+
+[horizontal]
+`events`::
+	Gets event information since startup. 
+`jvm`::
+	Gets JVM stats, including stats about garbage collection. 
+
+For example, the following request returns a JSON document that shows the number of events
+that were input, filtered, and output by Logstash since startup:
+
+[source,js]
+--------------------------------------------------
+GET /_node/stats/events
+--------------------------------------------------
+
+Example response:
+
+[source,js]
+--------------------------------------------------
+{
+    "events": {
+        "in": 91,
+        "filtered": 91,
+        "out": 91
+    }
+}
+--------------------------------------------------
+
+The following request returns a JSON document containing JVM stats:
+
+[source,js]
+--------------------------------------------------
+GET /_node/stats/jvm
+--------------------------------------------------
+
+Example response:
+
+[source,js]
+--------------------------------------------------
+"jvm":{  
+   "timestamp":1453233447702,
+   "uptime_in_millis":211125811,
+   "mem":{  
+      "heap_used_in_bytes":58442576,
+      "heap_used_percent":5,
+      "heap_committed_in_bytes":259522560,
+      "heap_max_in_bytes":1037959168,
+      "non_heap_used_in_bytes":56332256,
+      "non_heap_committed_in_bytes":57475072,
+      "pools":{  
+         "young":{  
+            "used_in_bytes":41672000,
+            "max_in_bytes":286326784,
+            "peak_used_in_bytes":71630848,
+            "peak_max_in_bytes":286326784
+         },
+         "survivor":{  
+            "used_in_bytes":260552,
+            "max_in_bytes":35782656,
+            "peak_used_in_bytes":8912896,
+            "peak_max_in_bytes":35782656
+         },
+         "old":{  
+            "used_in_bytes":16510024,
+            "max_in_bytes":715849728,
+            "peak_used_in_bytes":16510024,
+            "peak_max_in_bytes":715849728
+         }
+      }
+   }
+--------------------------------------------------
+
+See <<monitoring-common-options, Common Options>> for a list of options that can be applied to all
+Logstash monitoring APIs.
+
+[[hot-threads-api]]
+=== Hot Threads API
+
+experimental[]
+
+The hot threads API gets the current hot threads for Logstash. A hot thread is a
+Java thread that has high CPU usage and executes for a longer than normal period
+of time.
+
+[source,js]
+--------------------------------------------------
+GET /_node/hot_threads
+--------------------------------------------------
+
+The output is a JSON document that contains a breakdown of the top hot threads for
+Logstash. The parameters allowed are:
+
+[horizontal]
+`threads`:: 	        The number of hot threads to return. The default is 3. 
+`human`:: 	            If true, returns plain text instead of JSON format. The default is false. 
+`ignore_idle_threads`:: If true, does not return idle threads. The default is true.
+
+Example response:
+
+[source,js]
+--------------------------------------------------
+{
+  "hostname" : "Example-MBP-2",
+  "time" : "2016-03-08T17:58:18-08:00",
+  "busiest_threads" : 3,
+  "threads" : [ {
+    "name" : "LogStash::Runner",
+    "percent_of_cpu_time" : 16.93,
+    "state" : "timed_waiting",
+    "traces" : "\t\tjava.lang.Object.wait(Native Method)\n\t\tjava.lang.Thread.join(Thread.java:1253)\n\t\torg.jruby.internal.runtime.NativeThread.join(NativeThread.java:75)\n\t\torg.jruby.RubyThread.join(RubyThread.java:697)\n\t\torg.jruby.RubyThread$INVOKER$i$0$1$join.call(RubyThread$INVOKER$i$0$1$join.gen)\n\t\torg.jruby.internal.runtime.methods.JavaMethod$JavaMethodN.call(JavaMethod.java:663)\n\t\torg.jruby.internal.runtime.methods.DynamicMethod.call(DynamicMethod.java:198)\n\t\torg.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:306)\n\t\torg.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:136)\n\t\torg.jruby.ast.CallNoArgNode.interpret(CallNoArgNode.java:60)\n"
+  }, {
+    "name" : "Api Webserver",
+    "percent_of_cpu_time" : 0.39,
+    "state" : "timed_waiting",
+    "traces" : "\t\tjava.lang.Object.wait(Native Method)\n\t\tjava.lang.Thread.join(Thread.java:1253)\n\t\torg.jruby.internal.runtime.NativeThread.join(NativeThread.java:75)\n\t\torg.jruby.RubyThread.join(RubyThread.java:697)\n\t\torg.jruby.RubyThread$INVOKER$i$0$1$join.call(RubyThread$INVOKER$i$0$1$join.gen)\n\t\torg.jruby.internal.runtime.methods.JavaMethod$JavaMethodN.call(JavaMethod.java:663)\n\t\torg.jruby.internal.runtime.methods.DynamicMethod.call(DynamicMethod.java:198)\n\t\torg.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:306)\n\t\torg.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:136)\n\t\torg.jruby.ast.CallNoArgNode.interpret(CallNoArgNode.java:60)\n"
+  }, {
+    "name" : "Ruby-0-Thread-13",
+    "percent_of_cpu_time" : 0.15,
+    "state" : "timed_waiting",
+    "path" : "/Users/suyog/ws/elastic/logstash/build/logstash-3.0.0.dev/vendor/local_gems/f5685da5/logstash-core-3.0.0.dev-java/lib/logstash/pipeline.rb:496",
+    "traces" : "\t\tjava.lang.Object.wait(Native Method)\n\t\torg.jruby.RubyThread.sleep(RubyThread.java:1002)\n\t\torg.jruby.RubyKernel.sleep(RubyKernel.java:803)\n\t\torg.jruby.RubyKernel$INVOKER$s$0$1$sleep.call(RubyKernel$INVOKER$s$0$1$sleep.gen)\n\t\torg.jruby.internal.runtime.methods.JavaMethod$JavaMethodN.call(JavaMethod.java:667)\n\t\torg.jruby.internal.runtime.methods.DynamicMethod.call(DynamicMethod.java:206)\n\t\torg.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:168)\n\t\torg.jruby.ast.FCallOneArgNode.interpret(FCallOneArgNode.java:36)\n\t\torg.jruby.ast.NewlineNode.interpret(NewlineNode.java:105)\n\t\torg.jruby.ast.BlockNode.interpret(BlockNode.java:71)\n"
+  } ]
+--------------------------------------------------
+
+You can use the `?human` parameter to return the document in a human-readable format.
+
+[source,js]
+--------------------------------------------------
+GET /_node/hot_threads?human=true
+--------------------------------------------------
+
+Example of a human-readable response: 
+
+[source,js]
+--------------------------------------------------
+::: {Ringo Kid}{Gv3UrzR3SqmPQIgfG4qJMA}{127.0.0.1}{127.0.0.1:9300}
+   Hot threads at 2016-01-13T16:55:49.988Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:
+
+    0.0% (216micros out of 500ms) cpu usage by thread 'elasticsearch[Ringo Kid][transport_client_timer][T#1]{Hashed wheel timer #1}'
+     10/10 snapshots sharing following 5 elements
+       java.lang.Thread.sleep(Native Method)
+       org.jboss.netty.util.HashedWheelTimer$Worker.waitForNextTick(HashedWheelTimer.java:445)
+       org.jboss.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:364)
+       org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
+       java.lang.Thread.run(Thread.java:745)
+
+    0.0% (216micros out of 500ms) cpu usage by thread 'elasticsearch[Ringo Kid][transport_client_timer][T#1]{Hashed wheel timer #1}'
+     10/10 snapshots sharing following 5 elements
+       java.lang.Thread.sleep(Native Method)
+       org.jboss.netty.util.HashedWheelTimer$Worker.waitForNextTick(HashedWheelTimer.java:445)
+       org.jboss.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:364)
+       org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
+       java.lang.Thread.run(Thread.java:745)
+--------------------------------------------------
+
+See <<monitoring-common-options, Common Options>> for a list of options that can be applied to all
+Logstash monitoring APIs.
diff --git a/docs/static/reloading-config.asciidoc b/docs/static/reloading-config.asciidoc
new file mode 100644
index 00000000000..22f3118aac6
--- /dev/null
+++ b/docs/static/reloading-config.asciidoc
@@ -0,0 +1,43 @@
+[[reloading-config]]
+=== Reloading the Config File
+
+Starting with Logstash 2.3, you can set Logstash to detect and reload configuration
+changes automatically.
+
+To enable automatic config reloading, start Logstash with the `--auto-reload` (or `-r`)
+command-line option specified. For example:
+
+[source,shell]
+----------------------------------
+bin/logstash –f apache.config --auto-reload
+----------------------------------
+
+NOTE: The `--auto-reload` option is not available when you specify the `-e` flag to pass
+in  configuration settings from the command-line.
+
+By default, Logstash checks for configuration changes every 3 seconds. To change this interval,
+use the `--reload-interval <seconds>` option,  where `seconds` specifies how often Logstash
+checks the config files for changes. 
+
+If Logstash is already running without auto-reload enabled, you can force Logstash to
+reload the config file and restart the pipeline by sending a SIGHUP (signal hangup) to the
+process running Logstash. For example:
+
+[source,shell]
+----------------------------------
+kill -1 14175
+----------------------------------
+
+Where 14175 is the ID of the process running Logstash.
+
+==== How Automatic Config Reloading Works
+
+When Logstash detects a change in a config file, it stops the current pipeline by stopping
+all inputs, and it attempts to create a new pipeline that uses the updated configuration.
+After validating the syntax of the new configuration, Logstash verifies that all inputs
+and outputs can be initialized (for example, that all required ports are open). If the checks
+are successful, Logstash swaps the existing pipeline with the new pipeline. If the checks
+fail, the old pipeline continues to function, and the errors are propagated to the console.
+
+During automatic config reloading, the JVM is not restarted. The creating and swapping of
+pipelines all happens within the same process. 
diff --git a/lib/bootstrap/environment.rb b/lib/bootstrap/environment.rb
index 2316f993abe..f915ffa893d 100644
--- a/lib/bootstrap/environment.rb
+++ b/lib/bootstrap/environment.rb
@@ -17,6 +17,7 @@ module Environment
     GEMFILE_PATH = ::File.join(LOGSTASH_HOME, "Gemfile")
     LOCAL_GEM_PATH = ::File.join(LOGSTASH_HOME, 'vendor', 'local_gems')
     CACHE_PATH = File.join(LOGSTASH_HOME, "vendor", "cache")
+    SETTINGS_PATH = ::File.join(LOGSTASH_HOME, "conf", "logstash.yml")
 
     # @return [String] the ruby version string bundler uses to craft its gem path
     def gem_ruby_version
@@ -56,6 +57,31 @@ def pattern_path(path)
   end
 end
 
+def fetch_yml_settings(settings_path)
+  if settings = YAML.parse(IO.read(settings_path))
+    settings = settings.to_ruby
+    flat_settings_hash = LogStash::Util.flatten_hash(settings)
+    LogStash::Util.flatten_arguments(flat_settings_hash)
+  else
+    []
+  end
+end
+
+public
+def format_argv(argv)
+  # TODO deprecate these two arguments in the next major version.
+  # use -i irb or -i pry for console
+  if argv == ["irb"] || argv == ["pry"]
+    puts "Warn: option \"#{argv.first}\" is deprecated, use \"-i #{argv.first}\" or \"--interactive=#{argv.first}\" instead"
+    ["--interactive", argv.first]
+  else
+    # The Clamp library supports specifying the same argument multiple times
+    # and it keeps the last occurrence in an array. So in order for cli args
+    # to override the logstash.yml args, we can do `settings_from_yml + argv`
+    settings_from_yml = fetch_yml_settings(LogStash::Environment::SETTINGS_PATH)
+    settings_from_yml + argv
+  end
+end
 
 # when launched as a script, not require'd, (currently from bin/logstash and bin/plugin) the first
 # argument is the path of a Ruby file to require and a LogStash::Runner class is expected to be
@@ -64,12 +90,6 @@ def pattern_path(path)
 if $0 == __FILE__
   LogStash::Bundler.setup!({:without => [:build, :development]})
   require ARGV.shift
-  # TODO deprecate these arguments in the next major version. use -i only
-  if ARGV == ["irb"] || ARGV == ["pry"]
-    puts "Warn: option \"#{ARGV.first}\" is deprecated, use \"-i #{ARGV.first}\" or \"--interactive=#{ARGV.first}\" instead"
-    exit_status = LogStash::Runner.run("bin/logstash", ["--interactive", ARGV.first])
-  else
-    exit_status = LogStash::Runner.run("bin/logstash", ARGV)
-  end
+  exit_status = LogStash::Runner.run("bin/logstash", format_argv(ARGV))
   exit(exit_status || 0)
 end
diff --git a/logstash-core-event-java/spec/event_spec.rb b/logstash-core-event-java/spec/event_spec.rb
index e6f52105b48..9df705418f3 100644
--- a/logstash-core-event-java/spec/event_spec.rb
+++ b/logstash-core-event-java/spec/event_spec.rb
@@ -96,6 +96,14 @@
       e["[foo]"] = nil
       expect(e.to_hash).to include("foo" => nil)
     end
+
+    # BigDecinal is now natively converted by JRuby, see https://github.com/elastic/logstash/pull/4838
+    it "should set BigDecimal" do
+      e = LogStash::Event.new()
+      e["[foo]"] = BigDecimal.new(1)
+      expect(e["foo"]).to be_kind_of(BigDecimal)
+      expect(e["foo"]).to eq(BigDecimal.new(1))
+    end
   end
 
   context "timestamp" do
diff --git a/logstash-core-event-java/src/main/java/com/logstash/Rubyfier.java b/logstash-core-event-java/src/main/java/com/logstash/Rubyfier.java
index 455075a8672..0bafab8c9da 100644
--- a/logstash-core-event-java/src/main/java/com/logstash/Rubyfier.java
+++ b/logstash-core-event-java/src/main/java/com/logstash/Rubyfier.java
@@ -4,9 +4,11 @@
 import org.jruby.Ruby;
 import org.jruby.RubyArray;
 import org.jruby.RubyHash;
+import org.jruby.ext.bigdecimal.RubyBigDecimal;
 import org.jruby.javasupport.JavaUtil;
 import org.jruby.runtime.builtin.IRubyObject;
 
+import java.math.BigDecimal;
 import java.util.*;
 
 public final class Rubyfier {
@@ -20,6 +22,9 @@ public static IRubyObject deep(Ruby runtime, final Object input) {
         if (input instanceof Timestamp) return JrubyTimestampExtLibrary.RubyTimestamp.newRubyTimestamp(runtime, (Timestamp)input);
         if (input instanceof Collection) throw new ClassCastException("unexpected Collection type " + input.getClass());
 
+        // BigDecimal is not currenly handled by JRuby and this is the type Jackson uses for floats
+        if (input instanceof BigDecimal) return new RubyBigDecimal(runtime, runtime.getClass("BigDecimal"), (BigDecimal)input);
+
         return JavaUtil.convertJavaToUsableRubyObject(runtime, input);
     }
 
@@ -29,6 +34,9 @@ public static Object deepOnly(Ruby runtime, final Object input) {
         if (input instanceof Timestamp) return JrubyTimestampExtLibrary.RubyTimestamp.newRubyTimestamp(runtime, (Timestamp)input);
         if (input instanceof Collection) throw new ClassCastException("unexpected Collection type " + input.getClass());
 
+        // BigDecimal is not currenly handled by JRuby and this is the type Jackson uses for floats
+        if (input instanceof BigDecimal) return new RubyBigDecimal(runtime, runtime.getClass("BigDecimal"), (BigDecimal)input);
+
         return input;
     }
 
diff --git a/logstash-core-event-java/src/main/java/com/logstash/Timestamp.java b/logstash-core-event-java/src/main/java/com/logstash/Timestamp.java
index 6385f3fd6ab..434dc93a13c 100644
--- a/logstash-core-event-java/src/main/java/com/logstash/Timestamp.java
+++ b/logstash-core-event-java/src/main/java/com/logstash/Timestamp.java
@@ -70,7 +70,9 @@ public String toString() {
     }
 
     public long usec() {
-        return new Duration(JAN_1_1970.toDateTime(DateTimeZone.UTC), this.time).getMillis();
+        // JodaTime only supports milliseconds precision we can only return usec at millisec precision.
+        // note that getMillis() return millis since epoch
+        return (new Duration(JAN_1_1970.toDateTime(DateTimeZone.UTC), this.time).getMillis() % 1000) * 1000;
     }
 
     @Override
diff --git a/logstash-core-event-java/src/main/java/com/logstash/ext/JrubyTimestampExtLibrary.java b/logstash-core-event-java/src/main/java/com/logstash/ext/JrubyTimestampExtLibrary.java
index 4b523a52cc7..9748a815ccb 100644
--- a/logstash-core-event-java/src/main/java/com/logstash/ext/JrubyTimestampExtLibrary.java
+++ b/logstash-core-event-java/src/main/java/com/logstash/ext/JrubyTimestampExtLibrary.java
@@ -5,6 +5,7 @@
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;
 import org.jruby.exceptions.RaiseException;
+import org.jruby.ext.bigdecimal.RubyBigDecimal;
 import org.jruby.javasupport.JavaUtil;
 import org.jruby.runtime.Arity;
 import org.jruby.runtime.ObjectAllocator;
@@ -139,7 +140,7 @@ public IRubyObject ruby_to_json(ThreadContext context, IRubyObject[] args)
             return RubyString.newString(context.runtime,  "\"" + this.timestamp.toIso8601() + "\"");
         }
 
-        public static Timestamp newTimetsamp(IRubyObject time)
+        public static Timestamp newTimestamp(IRubyObject time)
         {
             if (time.isNil()) {
                 return new Timestamp();
@@ -159,7 +160,7 @@ public static Timestamp newTimetsamp(IRubyObject time)
         public static IRubyObject ruby_coerce(ThreadContext context, IRubyObject recv, IRubyObject time)
         {
             try {
-                Timestamp ts = newTimetsamp(time);
+                Timestamp ts = newTimestamp(time);
                 return (ts == null) ? context.runtime.getNil() : RubyTimestamp.newRubyTimestamp(context.runtime, ts);
              } catch (IllegalArgumentException e) {
                 throw new RaiseException(
@@ -177,7 +178,7 @@ public static IRubyObject ruby_parse_iso8601(ThreadContext context, IRubyObject
         {
             if (time instanceof RubyString) {
                 try {
-                    return RubyTimestamp.newRubyTimestamp(context.runtime, newTimetsamp(time));
+                    return RubyTimestamp.newRubyTimestamp(context.runtime, newTimestamp(time));
                 } catch (IllegalArgumentException e) {
                     throw new RaiseException(
                             context.runtime,
@@ -197,11 +198,19 @@ public static IRubyObject ruby_at(ThreadContext context, IRubyObject recv, IRuby
         {
             RubyTime t;
             if (args.length == 1) {
-                t = (RubyTime)RubyTime.at(context, context.runtime.getTime(), args[0]);
+                IRubyObject epoch = args[0];
+
+                if (epoch instanceof RubyBigDecimal) {
+                    // bug in JRuby prevents correcly parsing a BigDecimal fractional part, see https://github.com/elastic/logstash/issues/4565
+                    double usec = ((RubyBigDecimal)epoch).frac().convertToFloat().getDoubleValue() * 1000000;
+                    t = (RubyTime)RubyTime.at(context, context.runtime.getTime(), ((RubyBigDecimal)epoch).to_int(), new RubyFloat(context.runtime, usec));
+                } else {
+                    t = (RubyTime)RubyTime.at(context, context.runtime.getTime(), epoch);
+                }
             } else {
                 t = (RubyTime)RubyTime.at(context, context.runtime.getTime(), args[0], args[1]);
             }
-            return RubyTimestamp.newRubyTimestamp(context.runtime,  new Timestamp(t.getDateTime()));
+            return RubyTimestamp.newRubyTimestamp(context.runtime, new Timestamp(t.getDateTime()));
         }
 
         @JRubyMethod(name = "now", meta = true)
diff --git a/logstash-core-event-java/src/test/java/com/logstash/RubyfierTest.java b/logstash-core-event-java/src/test/java/com/logstash/RubyfierTest.java
new file mode 100644
index 00000000000..af8ecbf0c28
--- /dev/null
+++ b/logstash-core-event-java/src/test/java/com/logstash/RubyfierTest.java
@@ -0,0 +1,220 @@
+package com.logstash;
+
+import org.jruby.*;
+import org.jruby.ext.bigdecimal.RubyBigDecimal;
+import org.jruby.javasupport.JavaUtil;
+import org.jruby.runtime.builtin.IRubyObject;
+import org.junit.Test;
+
+import java.lang.reflect.Method;
+import java.math.BigDecimal;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import static org.junit.Assert.*;
+
+public class RubyfierTest {
+
+    @Test
+    public void testDeepWithString() {
+        Object result = Rubyfier.deep(Ruby.getGlobalRuntime(), "foo");
+        assertEquals(RubyString.class, result.getClass());
+        assertEquals("foo", result.toString());
+    }
+
+    @Test
+    public void testDeepMapWithString()
+            throws Exception
+    {
+        Map data = new HashMap();
+        data.put("foo", "bar");
+        RubyHash rubyHash = ((RubyHash)Rubyfier.deep(Ruby.getGlobalRuntime(), data));
+
+        // Hack to be able to retrieve the original, unconverted Ruby object from Map
+        // it seems the only method providing this is internalGet but it is declared protected.
+        // I know this is bad practice but I think this is practically acceptable.
+        Method internalGet = RubyHash.class.getDeclaredMethod("internalGet", IRubyObject.class);
+        internalGet.setAccessible(true);
+        Object result = internalGet.invoke(rubyHash, JavaUtil.convertJavaToUsableRubyObject(Ruby.getGlobalRuntime(), "foo"));
+
+        assertEquals(RubyString.class, result.getClass());
+        assertEquals("bar", result.toString());
+    }
+
+    @Test
+    public void testDeepListWithString()
+            throws Exception
+    {
+        List data = new ArrayList();
+        data.add("foo");
+
+        RubyArray rubyArray = ((RubyArray)Rubyfier.deep(Ruby.getGlobalRuntime(), data));
+
+        // toJavaArray does not convert inner elemenst to Java types \o/
+        assertEquals(RubyString.class, rubyArray.toJavaArray()[0].getClass());
+        assertEquals("foo", rubyArray.toJavaArray()[0].toString());
+    }
+
+    @Test
+    public void testDeepWithInteger() {
+        Object result = Rubyfier.deep(Ruby.getGlobalRuntime(), 1);
+        assertEquals(RubyFixnum.class, result.getClass());
+        assertEquals(1L, ((RubyFixnum)result).getLongValue());
+    }
+
+    @Test
+    public void testDeepMapWithInteger()
+            throws Exception
+    {
+        Map data = new HashMap();
+        data.put("foo", 1);
+        RubyHash rubyHash = ((RubyHash)Rubyfier.deep(Ruby.getGlobalRuntime(), data));
+
+        // Hack to be able to retrieve the original, unconverted Ruby object from Map
+        // it seems the only method providing this is internalGet but it is declared protected.
+        // I know this is bad practice but I think this is practically acceptable.
+        Method internalGet = RubyHash.class.getDeclaredMethod("internalGet", IRubyObject.class);
+        internalGet.setAccessible(true);
+        Object result = internalGet.invoke(rubyHash, JavaUtil.convertJavaToUsableRubyObject(Ruby.getGlobalRuntime(), "foo"));
+
+        assertEquals(RubyFixnum.class, result.getClass());
+        assertEquals(1L, ((RubyFixnum)result).getLongValue());
+    }
+
+    @Test
+    public void testDeepListWithInteger()
+            throws Exception
+    {
+        List data = new ArrayList();
+        data.add(1);
+
+        RubyArray rubyArray = ((RubyArray)Rubyfier.deep(Ruby.getGlobalRuntime(), data));
+
+        // toJavaArray does not convert inner elemenst to Java types \o/
+        assertEquals(RubyFixnum.class, rubyArray.toJavaArray()[0].getClass());
+        assertEquals(1L, ((RubyFixnum)rubyArray.toJavaArray()[0]).getLongValue());
+    }
+
+    @Test
+    public void testDeepWithFloat() {
+        Object result = Rubyfier.deep(Ruby.getGlobalRuntime(), 1.0F);
+        assertEquals(RubyFloat.class, result.getClass());
+        assertEquals(1.0D, ((RubyFloat)result).getDoubleValue(), 0);
+    }
+
+    @Test
+    public void testDeepMapWithFloat()
+            throws Exception
+    {
+        Map data = new HashMap();
+        data.put("foo", 1.0F);
+        RubyHash rubyHash = ((RubyHash)Rubyfier.deep(Ruby.getGlobalRuntime(), data));
+
+        // Hack to be able to retrieve the original, unconverted Ruby object from Map
+        // it seems the only method providing this is internalGet but it is declared protected.
+        // I know this is bad practice but I think this is practically acceptable.
+        Method internalGet = RubyHash.class.getDeclaredMethod("internalGet", IRubyObject.class);
+        internalGet.setAccessible(true);
+        Object result = internalGet.invoke(rubyHash, JavaUtil.convertJavaToUsableRubyObject(Ruby.getGlobalRuntime(), "foo"));
+
+        assertEquals(RubyFloat.class, result.getClass());
+        assertEquals(1.0D, ((RubyFloat)result).getDoubleValue(), 0);
+    }
+
+    @Test
+    public void testDeepListWithFloat()
+            throws Exception
+    {
+        List data = new ArrayList();
+        data.add(1.0F);
+
+        RubyArray rubyArray = ((RubyArray)Rubyfier.deep(Ruby.getGlobalRuntime(), data));
+
+        // toJavaArray does not convert inner elemenst to Java types \o/
+        assertEquals(RubyFloat.class, rubyArray.toJavaArray()[0].getClass());
+        assertEquals(1.0D, ((RubyFloat)rubyArray.toJavaArray()[0]).getDoubleValue(), 0);
+    }
+
+    @Test
+    public void testDeepWithDouble() {
+        Object result = Rubyfier.deep(Ruby.getGlobalRuntime(), 1.0D);
+        assertEquals(RubyFloat.class, result.getClass());
+        assertEquals(1.0D, ((RubyFloat)result).getDoubleValue(), 0);
+    }
+
+    @Test
+    public void testDeepMapWithDouble()
+            throws Exception
+    {
+        Map data = new HashMap();
+        data.put("foo", 1.0D);
+        RubyHash rubyHash = ((RubyHash)Rubyfier.deep(Ruby.getGlobalRuntime(), data));
+
+        // Hack to be able to retrieve the original, unconverted Ruby object from Map
+        // it seems the only method providing this is internalGet but it is declared protected.
+        // I know this is bad practice but I think this is practically acceptable.
+        Method internalGet = RubyHash.class.getDeclaredMethod("internalGet", IRubyObject.class);
+        internalGet.setAccessible(true);
+        Object result = internalGet.invoke(rubyHash, JavaUtil.convertJavaToUsableRubyObject(Ruby.getGlobalRuntime(), "foo"));
+
+        assertEquals(RubyFloat.class, result.getClass());
+        assertEquals(1.0D, ((RubyFloat)result).getDoubleValue(), 0);
+    }
+
+    @Test
+    public void testDeepListWithDouble()
+            throws Exception
+    {
+        List data = new ArrayList();
+        data.add(1.0D);
+
+        RubyArray rubyArray = ((RubyArray)Rubyfier.deep(Ruby.getGlobalRuntime(), data));
+
+        // toJavaArray does not convert inner elemenst to Java types \o/
+        assertEquals(RubyFloat.class, rubyArray.toJavaArray()[0].getClass());
+        assertEquals(1.0D, ((RubyFloat)rubyArray.toJavaArray()[0]).getDoubleValue(), 0);
+    }
+
+    @Test
+    public void testDeepWithBigDecimal() {
+        Object result = Rubyfier.deep(Ruby.getGlobalRuntime(), new BigDecimal(1));
+        assertEquals(RubyBigDecimal.class, result.getClass());
+        assertEquals(1.0D, ((RubyBigDecimal)result).getDoubleValue(), 0);
+    }
+
+    @Test
+    public void testDeepMapWithBigDecimal()
+            throws Exception
+    {
+        Map data = new HashMap();
+        data.put("foo", new BigDecimal(1));
+
+        RubyHash rubyHash = ((RubyHash)Rubyfier.deep(Ruby.getGlobalRuntime(), data));
+
+        // Hack to be able to retrieve the original, unconverted Ruby object from Map
+        // it seems the only method providing this is internalGet but it is declared protected.
+        // I know this is bad practice but I think this is practically acceptable.
+        Method internalGet = RubyHash.class.getDeclaredMethod("internalGet", IRubyObject.class);
+        internalGet.setAccessible(true);
+        Object result = internalGet.invoke(rubyHash, JavaUtil.convertJavaToUsableRubyObject(Ruby.getGlobalRuntime(), "foo"));
+
+        assertEquals(RubyBigDecimal.class, result.getClass());
+        assertEquals(1.0D, ((RubyBigDecimal)result).getDoubleValue(), 0);
+    }
+
+    @Test
+    public void testDeepListWithBigDecimal()
+            throws Exception
+    {
+        List data = new ArrayList();
+        data.add(new BigDecimal(1));
+
+        RubyArray rubyArray = ((RubyArray)Rubyfier.deep(Ruby.getGlobalRuntime(), data));
+
+        // toJavaArray does not convert inner elemenst to Java types \o/
+        assertEquals(RubyBigDecimal.class, rubyArray.toJavaArray()[0].getClass());
+        assertEquals(1.0D, ((RubyBigDecimal)rubyArray.toJavaArray()[0]).getDoubleValue(), 0);
+    }
+}
diff --git a/logstash-core-event/spec/logstash/timestamp_spec.rb b/logstash-core-event/spec/logstash/timestamp_spec.rb
index 337660db4b4..196b895c39e 100644
--- a/logstash-core-event/spec/logstash/timestamp_spec.rb
+++ b/logstash-core-event/spec/logstash/timestamp_spec.rb
@@ -1,6 +1,7 @@
 # encoding: utf-8
 require "spec_helper"
 require "logstash/timestamp"
+require "bigdecimal"
 
 describe LogStash::Timestamp do
 
@@ -106,4 +107,64 @@
       expect(subject.to_f).to eq(now.to_f)
     end
   end
+
+  context "at" do
+    context "with integer epoch" do
+      it "should convert to correct date" do
+        expect(LogStash::Timestamp.at(946702800).to_iso8601).to eq("2000-01-01T05:00:00.000Z")
+      end
+
+      it "should return zero usec" do
+        expect(LogStash::Timestamp.at(946702800).usec).to eq(0)
+      end
+
+      it "should return prior to epoch date on negative input" do
+        expect(LogStash::Timestamp.at(-1).to_iso8601).to eq("1969-12-31T23:59:59.000Z")
+      end
+    end
+
+    context "with float epoch" do
+      it "should convert to correct date" do
+        expect(LogStash::Timestamp.at(946702800.123456.to_f).to_iso8601).to eq("2000-01-01T05:00:00.123Z")
+      end
+
+      it "should return usec with a minimum of millisec precision" do
+        expect(LogStash::Timestamp.at(946702800.123456.to_f).usec).to be_within(1000).of(123456)
+      end
+    end
+
+    context "with BigDecimal epoch" do
+      it "should convert to correct date" do
+        expect(LogStash::Timestamp.at(BigDecimal.new("946702800.123456")).to_iso8601).to eq("2000-01-01T05:00:00.123Z")
+      end
+
+      it "should return usec with a minimum of millisec precision" do
+        # since Java Timestamp relies on JodaTime which supports only milliseconds precision
+        # the usec method will only be precise up to milliseconds.
+        expect(LogStash::Timestamp.at(BigDecimal.new("946702800.123456")).usec).to be_within(1000).of(123456)
+      end
+    end
+
+    context "with illegal parameters" do
+      it "should raise exception on nil input" do
+        expect{LogStash::Timestamp.at(nil)}.to raise_error
+      end
+
+      it "should raise exception on invalid input type" do
+        expect{LogStash::Timestamp.at(:foo)}.to raise_error
+      end
+    end
+  end
+
+  context "usec" do
+    it "should support millisecond precision" do
+      expect(LogStash::Timestamp.at(946702800.123).usec).to eq(123000)
+    end
+
+    it "should try to preserve and report microseconds precision if possible" do
+      # since Java Timestamp relies on JodaTime which supports only milliseconds precision
+      # the usec method will only be precise up to milliseconds.
+      expect(LogStash::Timestamp.at(946702800.123456).usec).to be_within(1000).of(123456)
+    end
+  end
 end
diff --git a/logstash-core/lib/logstash/agent.rb b/logstash-core/lib/logstash/agent.rb
index 5d2fde3201d..3d26f8c164c 100644
--- a/logstash-core/lib/logstash/agent.rb
+++ b/logstash-core/lib/logstash/agent.rb
@@ -28,12 +28,11 @@ class LogStash::Agent
   #   :auto_reload [Boolean] - enable reloading of pipelines
   #   :reload_interval [Integer] - reload pipelines every X seconds
   #   :logger [Cabin::Channel] - logger instance
-  def initialize(params)
+  def initialize(params = {})
     @logger = params[:logger]
     @auto_reload = params[:auto_reload]
-
     @pipelines = {}
-    @node_name = params[:node_name] || Socket.gethostname
+    @node_name = params[:node_name] || LogStash::DEFAULT_SETTINGS["node.name"]
     @web_api_http_host = params[:web_api_http_host]
     @web_api_http_port = params[:web_api_http_port]
 
diff --git a/logstash-core/lib/logstash/api/init.ru b/logstash-core/lib/logstash/api/init.ru
index 550092f1d0e..7fc0c93e9b9 100644
--- a/logstash-core/lib/logstash/api/init.ru
+++ b/logstash-core/lib/logstash/api/init.ru
@@ -7,6 +7,7 @@ require 'app/root'
 require 'app/modules/stats'
 require 'app/modules/node'
 require 'app/modules/node_stats'
+require 'app/modules/plugins'
 
 env = ENV["RACK_ENV"].to_sym
 set :environment, env
@@ -20,7 +21,8 @@ run LogStash::Api::Root
 
 namespaces = { "/_node" => LogStash::Api::Node,
                "/_node/stats" => LogStash::Api::NodeStats,
-               "/_stats" => LogStash::Api::Stats }
+               "/_stats" => LogStash::Api::Stats,
+               "/_plugins" => LogStash::Api::Plugins }
 
 namespaces.each_pair do |namespace, app|
   map(namespace) do
diff --git a/logstash-core/lib/logstash/api/lib/app/command_factory.rb b/logstash-core/lib/logstash/api/lib/app/command_factory.rb
index 7de93384649..29e71e6c4f7 100644
--- a/logstash-core/lib/logstash/api/lib/app/command_factory.rb
+++ b/logstash-core/lib/logstash/api/lib/app/command_factory.rb
@@ -4,6 +4,7 @@
 require "app/commands/stats/events_command"
 require "app/commands/stats/hotthreads_command"
 require "app/commands/stats/memory_command"
+require "app/commands/system/plugins_command"
 
 module LogStash::Api
   class CommandFactory
@@ -16,7 +17,8 @@ def initialize(service)
         :system_basic_info => SystemBasicInfoCommand,
         :events_command => StatsEventsCommand,
         :hot_threads_command => HotThreadsCommand,
-        :memory_command => JvmMemoryCommand
+        :memory_command => JvmMemoryCommand,
+        :plugins_command => PluginsCommand
       )
     end
 
diff --git a/logstash-core/lib/logstash/api/lib/app/commands/system/plugins_command.rb b/logstash-core/lib/logstash/api/lib/app/commands/system/plugins_command.rb
new file mode 100644
index 00000000000..07623283ecc
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/commands/system/plugins_command.rb
@@ -0,0 +1,28 @@
+# encoding: utf-8
+require "app/command"
+
+class LogStash::Api::PluginsCommand < LogStash::Api::Command
+
+  def run
+    { :total => plugins.count, :plugins => plugins }
+  end
+
+  private
+
+  def plugins
+    @plugins ||= find_plugins_gem_specs.map do |spec|
+      { :name => spec.name, :version => spec.version.to_s }
+    end.sort_by do |spec|
+      spec[:name]
+    end
+  end
+
+  def find_plugins_gem_specs
+    @specs ||= Gem::Specification.find_all.select{|spec| logstash_plugin_gem_spec?(spec)}
+  end
+
+  def logstash_plugin_gem_spec?(spec)
+    spec.metadata && spec.metadata["logstash_plugin"] == "true"
+  end
+
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/modules/node_stats.rb b/logstash-core/lib/logstash/api/lib/app/modules/node_stats.rb
index 8f9e7392485..8317cad3369 100644
--- a/logstash-core/lib/logstash/api/lib/app/modules/node_stats.rb
+++ b/logstash-core/lib/logstash/api/lib/app/modules/node_stats.rb
@@ -11,12 +11,11 @@ class NodeStats < BaseApp
     # retrieved and show
     get "/" do
       events_command = factory.build(:events_command)
-      memory_command = factory.build(:memory_command)
       payload = {
         :events => events_command.run,
-        :start_time_in_millis => events_command.started_at,
-        :jvm => { :memory => memory_command.run }
+        :jvm => jvm_payload
       }
+
       respond_with payload
     end
 
@@ -35,9 +34,18 @@ class NodeStats < BaseApp
 
     # return hot threads information
     get "/jvm" do
-      command = factory.build(:memory_command)
-      respond_with({ :memory => command.run })
+      respond_with jvm_payload
     end
 
+    private
+
+    def jvm_payload
+      command = factory.build(:memory_command)
+      {
+        :timestamp => command.started_at,
+        :uptime_in_millis => command.uptime,
+        :mem => command.run
+      }
+    end
   end
 end
diff --git a/logstash-core/lib/logstash/api/lib/app/modules/plugins.rb b/logstash-core/lib/logstash/api/lib/app/modules/plugins.rb
new file mode 100644
index 00000000000..93a94bf76c3
--- /dev/null
+++ b/logstash-core/lib/logstash/api/lib/app/modules/plugins.rb
@@ -0,0 +1,15 @@
+# encoding: utf-8
+require "app"
+
+module LogStash::Api
+  class Plugins < BaseApp
+
+    helpers AppHelpers
+
+    get "/" do
+      command = factory.build(:plugins_command)
+      respond_with(command.run())
+    end
+
+  end
+end
diff --git a/logstash-core/lib/logstash/api/lib/app/service.rb b/logstash-core/lib/logstash/api/lib/app/service.rb
index b8396e07577..4b63593c18a 100644
--- a/logstash-core/lib/logstash/api/lib/app/service.rb
+++ b/logstash-core/lib/logstash/api/lib/app/service.rb
@@ -23,6 +23,10 @@ def agent
     LogStash::Instrument::Collector.instance.agent
   end
 
+  def started?
+    !@snapshot.nil? && has_counters?
+  end
+
   def update(snapshot)
     logger.debug("[api-service] snapshot received", :snapshot => snapshot) if logger.debug?
     if @snapshot_rotation_mutex.try_lock
@@ -40,4 +44,18 @@ def get(key)
     end
     LogStash::Json.dump(data)
   end
+
+  private
+
+  def has_counters?
+    (["LogStash::Instrument::MetricType::Counter", "LogStash::Instrument::MetricType::Gauge"] - metric_types).empty?
+  end
+
+  def metric_types
+    types = []
+    @snapshot_rotation_mutex.synchronize do
+      types = @snapshot.metric_store.all.map { |t| t.class.to_s }
+    end
+    return types
+  end
 end
diff --git a/logstash-core/lib/logstash/config/mixin.rb b/logstash-core/lib/logstash/config/mixin.rb
index cd20f36de6f..1d152062222 100644
--- a/logstash-core/lib/logstash/config/mixin.rb
+++ b/logstash-core/lib/logstash/config/mixin.rb
@@ -38,6 +38,8 @@ module LogStash::Config::Mixin
   PLUGIN_VERSION_1_0_0 = LogStash::Util::PluginVersion.new(1, 0, 0)
   PLUGIN_VERSION_0_9_0 = LogStash::Util::PluginVersion.new(0, 9, 0)
 
+  ENV_PLACEHOLDER_REGEX = /\$(?<name>\w+)|\$\{(?<name>\w+)(\:(?<default>[^}]*))?\}/
+
   # This method is called when someone does 'include LogStash::Config'
   def self.included(base)
     # Add the DSL methods to the 'base' given.
@@ -99,6 +101,23 @@ def config_init(params)
       end
     end
 
+    # Resolve environment variables references
+    params.each do |name, value|
+      if (value.is_a?(Hash))
+        value.each do |valueHashKey, valueHashValue|
+          value[valueHashKey.to_s] = replace_env_placeholders(valueHashValue)
+        end
+      else
+        if (value.is_a?(Array))
+          value.each_index do |valueArrayIndex|
+            value[valueArrayIndex] = replace_env_placeholders(value[valueArrayIndex])
+          end
+        else
+          params[name.to_s] = replace_env_placeholders(value)
+        end
+      end
+    end
+
     if !self.class.validate(params)
       raise LogStash::ConfigurationError,
         I18n.t("logstash.runner.configuration.invalid_plugin_settings")
@@ -126,6 +145,29 @@ def config_init(params)
     @config = params
   end # def config_init
 
+  # Replace all environment variable references in 'value' param by environment variable value and return updated value
+  # Process following patterns : $VAR, ${VAR}, ${VAR:defaultValue}
+  def replace_env_placeholders(value)
+    return value unless value.is_a?(String)
+    #raise ArgumentError, "Cannot replace ENV placeholders on non-strings. Got #{value.class}" if !value.is_a?(String)
+
+    value.gsub(ENV_PLACEHOLDER_REGEX) do |placeholder|
+      # Note: Ruby docs claim[1] Regexp.last_match is thread-local and scoped to
+      # the call, so this should be thread-safe.
+      #
+      # [1] http://ruby-doc.org/core-2.1.1/Regexp.html#method-c-last_match
+      name = Regexp.last_match(:name)
+      default = Regexp.last_match(:default)
+
+      replacement = ENV.fetch(name, default)
+      if replacement.nil?
+        raise LogStash::ConfigurationError, "Cannot evaluate `#{placeholder}`. Environment variable `#{name}` is not set and there is no default value given."
+      end
+      @logger.info? && @logger.info("Evaluating environment variable placeholder", :placeholder => placeholder, :replacement => replacement)
+      replacement
+    end
+  end # def replace_env_placeholders
+
   module DSL
     attr_accessor :flags
 
diff --git a/logstash-core/lib/logstash/environment.rb b/logstash-core/lib/logstash/environment.rb
index 79e7f24d86c..10ee4e1dfed 100644
--- a/logstash-core/lib/logstash/environment.rb
+++ b/logstash-core/lib/logstash/environment.rb
@@ -1,7 +1,27 @@
 # encoding: utf-8
 require "logstash/errors"
+require "logstash/config/cpu_core_strategy"
 
 module LogStash
+
+  DEFAULT_SETTINGS = {
+    "node.name" => Socket.gethostname,
+    "config.path" => nil,
+    "config.string" => nil,
+    "config.test" => false,
+    "pipeline.workers" => LogStash::Config::CpuCoreStrategy.maximum,
+    "pipeline.batch.size" => 125,
+    "pipeline.batch.delay" => 5, # in milliseconds
+    "pipeline.flush_interval" => 5, # in seconds
+    "pipeline.flush_timeout_interval" => 60, # in seconds
+    "pipeline.unsafe_shutdown" => false,
+    "plugin.paths" => [],
+    "log" => nil,
+    "debug" => false,
+    "verbose" => false,
+    "quiet" => false,
+  }
+
   module Environment
     extend self
 
diff --git a/logstash-core/lib/logstash/filter_delegator.rb b/logstash-core/lib/logstash/filter_delegator.rb
index ce2c71d6644..132d03f933e 100644
--- a/logstash-core/lib/logstash/filter_delegator.rb
+++ b/logstash-core/lib/logstash/filter_delegator.rb
@@ -3,14 +3,15 @@
 module LogStash
   class FilterDelegator
     extend Forwardable
-
-    def_delegators :@filter,
+    DELEGATED_METHODS = [
       :register,
       :close,
       :threadsafe?,
       :do_close,
       :do_stop,
       :periodic_flush
+    ]
+    def_delegators :@filter, *DELEGATED_METHODS
 
     def initialize(logger, klass, metric, *args)
       options = args.reduce({}, :merge)
@@ -20,7 +21,7 @@ def initialize(logger, klass, metric, *args)
       @filter = klass.new(options)
 
       # Scope the metrics to the plugin
-      namespaced_metric = metric.namespace(@filter.id.to_sym)
+      namespaced_metric = metric.namespace(@filter.plugin_unique_name.to_sym)
       @filter.metric = metric
 
       @metric_events = namespaced_metric.namespace(:events)
@@ -41,7 +42,8 @@ def multi_filter(events)
       # There is no garantee in the context of filter
       # that EVENTS_INT == EVENTS_OUT, see the aggregates and
       # the split filter
-      @metric_events.increment(:out, new_events.size) unless new_events.nil?
+      c = new_events.count { |event| !event.cancelled? }
+      @metric_events.increment(:out, c) if c > 0
 
       return new_events
     end
@@ -55,7 +57,7 @@ def define_flush_method
 
         # Filter plugins that does buffering or spooling of events like the
         # `Logstash-filter-aggregates` can return `NIL` and will flush on the next flush ticks.
-        @metric_events.increment(:out, new_events.size) unless new_events.nil?
+        @metric_events.increment(:out, new_events.size) if new_events && new_events.size > 0
         new_events
       end
     end
diff --git a/logstash-core/lib/logstash/instrument/collector.rb b/logstash-core/lib/logstash/instrument/collector.rb
index 1666810bf95..614ba372a40 100644
--- a/logstash-core/lib/logstash/instrument/collector.rb
+++ b/logstash-core/lib/logstash/instrument/collector.rb
@@ -28,8 +28,6 @@ def initialize
       @metric_store = MetricStore.new
       @agent = nil
       start_periodic_snapshotting
-
-      @async_worker_pool
     end
 
     # The metric library will call this unique interface
diff --git a/logstash-core/lib/logstash/instrument/periodic_poller/jvm.rb b/logstash-core/lib/logstash/instrument/periodic_poller/jvm.rb
index b4dd0086067..3b85d92efa6 100644
--- a/logstash-core/lib/logstash/instrument/periodic_poller/jvm.rb
+++ b/logstash-core/lib/logstash/instrument/periodic_poller/jvm.rb
@@ -47,10 +47,20 @@ def collect_pools_metrics(data)
     end
 
     def build_pools_metrics(data)
+      heap = data["heap"]
+      old  = {}
+      old = old.merge!(heap["CMS Old Gen"]) if heap.has_key?("CMS Old Gen")
+      old = old.merge!(heap["PS Old Gen"])  if heap.has_key?("PS Old Gen")
+      young = {}
+      young = young.merge!(heap["Par Eden Space"]) if heap.has_key?("Par Eden Space")
+      young = young.merge!(heap["PS Eden Space"])  if heap.has_key?("PS Eden Space")
+      survivor = {}
+      survivor = survivor.merge!(heap["Par Survivor Space"]) if heap.has_key?("Par Survivor Space")
+      survivor = survivor.merge!(heap["PS Survivor Space"])  if heap.has_key?("PS Survivor Space")
       {
-        "young"    => aggregate_information_for(data["heap"]["Par Eden Space"]),
-        "old"      => aggregate_information_for(data["heap"]["CMS Old Gen"]),
-        "survivor" => aggregate_information_for(data["heap"]["Par Survivor Space"]),
+        "young"    => aggregate_information_for(young),
+        "old"      => aggregate_information_for(old),
+        "survivor" => aggregate_information_for(survivor)
       }
     end
 
diff --git a/logstash-core/lib/logstash/output_delegator.rb b/logstash-core/lib/logstash/output_delegator.rb
index 7ac962dfeb7..50a5a9d49c7 100644
--- a/logstash-core/lib/logstash/output_delegator.rb
+++ b/logstash-core/lib/logstash/output_delegator.rb
@@ -22,7 +22,9 @@ def initialize(logger, klass, default_worker_count, metric, *args)
     output = @klass.new(*args)
 
     # Scope the metrics to the plugin
-    @metric = metric.namespace(output.id.to_sym)
+    namespaced_metric = metric.namespace(output.plugin_unique_name.to_sym)
+    @metric_events = namespaced_metric.namespace(:events)
+
 
     # We define this as an array regardless of threadsafety
     # to make reporting simpler, even though a threadsafe plugin will just have
@@ -114,17 +116,20 @@ def register
 
   def threadsafe_multi_receive(events)
     @events_received.increment(events.length)
-    @metric.increment(:events_in, events.length)
+    @metric_events.increment(:in, events.length)
 
     @threadsafe_worker.multi_receive(events)
+    @metric_events.increment(:out, events.length)
   end
 
   def worker_multi_receive(events)
     @events_received.increment(events.length)
+    @metric_events.increment(:in, events.length)
 
     worker = @worker_queue.pop
     begin
       worker.multi_receive(events)
+      @metric_events.increment(:out, events.length)
     ensure
       @worker_queue.push(worker)
     end
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 0eef3bdb501..a16778cb468 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -9,8 +9,6 @@
 require "logstash/filters/base"
 require "logstash/inputs/base"
 require "logstash/outputs/base"
-require "logstash/config/cpu_core_strategy"
-require "logstash/util/defaults_printer"
 require "logstash/shutdown_watcher"
 require "logstash/util/wrapped_synchronous_queue"
 require "logstash/pipeline_reporter"
@@ -37,13 +35,6 @@ module LogStash; class Pipeline
     :config_str,
     :original_settings
 
-  DEFAULT_SETTINGS = {
-    :default_pipeline_workers => LogStash::Config::CpuCoreStrategy.maximum,
-    :pipeline_batch_size => 125,
-    :pipeline_batch_delay => 5, # in milliseconds
-    :flush_interval => 5, # in seconds
-    :flush_timeout_interval => 60 # in seconds
-  }
   MAX_INFLIGHT_WARN_THRESHOLD = 10_000
 
   def self.validate_config(config_str, settings = {})
@@ -60,8 +51,7 @@ def initialize(config_str, settings = {})
     @original_settings = settings
     @logger = Cabin::Channel.get(LogStash)
     @pipeline_id = settings[:pipeline_id] || self.object_id
-    @settings = DEFAULT_SETTINGS.clone
-    settings.each {|setting, value| configure(setting, value) }
+    @settings = LogStash::DEFAULT_SETTINGS.merge(settings)
     @reporter = LogStash::PipelineReporter.new(@logger, self)
 
     @inputs = nil
@@ -120,13 +110,9 @@ def ready?
     @ready.value
   end
 
-  def configure(setting, value)
-    @settings[setting] = value
-  end
-
   def safe_pipeline_worker_count
-    default = DEFAULT_SETTINGS[:default_pipeline_workers]
-    thread_count = @settings[:pipeline_workers] #override from args "-w 8" or config
+    default = @settings["pipeline.workers"]
+    thread_count = @original_settings["pipeline.workers"] #override from args "-w 8" or config
     safe_filters, unsafe_filters = @filters.partition(&:threadsafe?)
 
     if unsafe_filters.any?
@@ -161,14 +147,12 @@ def filters?
   def run
     @started_at = Time.now
 
-    LogStash::Util.set_thread_name("[#{pipeline_id}]-pipeline-manager")
-    @logger.terminal(LogStash::Util::DefaultsPrinter.print(@settings))
     @thread = Thread.current
+    LogStash::Util.set_thread_name("[#{pipeline_id}]-pipeline-manager")
 
     start_workers
 
-    @logger.info("Pipeline started")
-    @logger.terminal("Logstash startup completed")
+    @logger.log("Pipeline #{@pipeline_id} started")
 
     # Block until all inputs have stopped
     # Generally this happens if SIGINT is sent and `shutdown` is called from an external thread
@@ -183,8 +167,7 @@ def run
     shutdown_flusher
     shutdown_workers
 
-    @logger.info("Pipeline shutdown complete.")
-    @logger.terminal("Logstash shutdown completed")
+    @logger.log("Pipeline #{@pipeline_id} has been shutdown")
 
     # exit code
     return 0
@@ -216,15 +199,15 @@ def start_workers
       @filters.each {|f| f.register }
 
       pipeline_workers = safe_pipeline_worker_count
-      batch_size = @settings[:pipeline_batch_size]
-      batch_delay = @settings[:pipeline_batch_delay]
+      batch_size = @settings["pipeline.batch.size"]
+      batch_delay = @settings["pipeline.batch.delay"]
       max_inflight = batch_size * pipeline_workers
       @logger.info("Starting pipeline",
-                   :id => self.pipeline_id,
-                   :pipeline_workers => pipeline_workers,
-                   :batch_size => batch_size,
-                   :batch_delay => batch_delay,
-                   :max_inflight => max_inflight)
+                   "id" => self.pipeline_id,
+                   "pipeline.workers" => pipeline_workers,
+                   "pipeline.batch.size" => batch_size,
+                   "pipeline.batch.delay" => batch_delay,
+                   "pipeline.max_inflight" => max_inflight)
       if max_inflight > MAX_INFLIGHT_WARN_THRESHOLD
         @logger.warn "CAUTION: Recommended inflight events max exceeded! Logstash will run with up to #{max_inflight} events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently #{batch_size}), or changing the number of pipeline workers (currently #{pipeline_workers})"
       end
@@ -467,7 +450,7 @@ def plugin(plugin_type, name, *args)
   end
 
   def default_output_workers
-    @settings[:pipeline_workers] || @settings[:default_pipeline_workers]
+    @settings["pipeline.workers"] || LogStash::DEFAULT_SETTINGS["pipeline.workers"]
   end
 
   # for backward compatibility in devutils for the rspec helpers, this method is not used
diff --git a/logstash-core/lib/logstash/plugin.rb b/logstash-core/lib/logstash/plugin.rb
index 0ac1fc78ce5..d6c335e7279 100644
--- a/logstash-core/lib/logstash/plugin.rb
+++ b/logstash-core/lib/logstash/plugin.rb
@@ -59,6 +59,14 @@ def id
     (@params["id"].nil? || @params["id"].empty?) ? SecureRandom.uuid : @params["id"]
   end
 
+  # Return a unique_name, This is composed by the name of
+  # the plugin and the generated ID (of the configured one)
+  #
+  # @return [String] a unique name
+  def plugin_unique_name
+    "#{config_name}_#{id}"
+  end
+
   # close is called during shutdown, after the plugin worker
   # main task terminates
   def do_close
@@ -99,6 +107,13 @@ def metric
     @metric_plugin ||= enable_metric ? @metric : LogStash::Instrument::NullMetric.new
   end
 
+  # return the configured name of this plugin
+  # @return [String] The name of the plugin defined by `config_name`
+  def config_name
+    self.class.config_name
+  end
+
+
   # Look up a plugin by type and name.
   def self.lookup(type, name)
     path = "logstash/#{type}s/#{name}"
diff --git a/logstash-core/lib/logstash/runner.rb b/logstash-core/lib/logstash/runner.rb
index a355fba4d42..035875940e5 100644
--- a/logstash-core/lib/logstash/runner.rb
+++ b/logstash-core/lib/logstash/runner.rb
@@ -15,73 +15,83 @@
 
 class LogStash::Runner < Clamp::Command
 
-  option ["-f", "--config"], "CONFIG_PATH",
+  # Node Settings
+  option ["-n", "--node.name"], "NAME",
+    I18n.t("logstash.runner.flag.node_name"),
+    :attribute_name => :node_name,
+    :default => LogStash::DEFAULT_SETTINGS["node.name"]
+
+  # Config Settings
+  option ["-f", "--config.path"], "CONFIG_PATH",
     I18n.t("logstash.runner.flag.config"),
     :attribute_name => :config_path
 
-  option "-e", "CONFIG_STRING",
+  option ["-e", "--config.string"], "CONFIG_STRING",
     I18n.t("logstash.runner.flag.config-string",
-           :default_input => LogStash::Config::Defaults.input,
-           :default_output => LogStash::Config::Defaults.output),
+      :default_input => LogStash::Config::Defaults.input,
+      :default_output => LogStash::Config::Defaults.output),
     :default => nil, :attribute_name => :config_string
 
-  option ["-w", "--pipeline-workers"], "COUNT",
+  # Pipeline settings
+  option ["-w", "--pipeline.workers"], "COUNT",
     I18n.t("logstash.runner.flag.pipeline-workers"),
     :attribute_name => :pipeline_workers,
-    :default => LogStash::Pipeline::DEFAULT_SETTINGS[:default_pipeline_workers]
+    :default => LogStash::DEFAULT_SETTINGS["pipeline.workers"]
+
+  option ["-b", "--pipeline.batch.size"], "SIZE",
+    I18n.t("logstash.runner.flag.pipeline-batch-size"),
+    :attribute_name => :pipeline_batch_size,
+    :default => LogStash::DEFAULT_SETTINGS["pipeline.batch.size"]
+
+  option ["-u", "--pipeline.batch.delay"], "DELAY_IN_MS",
+    I18n.t("logstash.runner.flag.pipeline-batch-delay"),
+    :attribute_name => :pipeline_batch_delay,
+    :default => LogStash::DEFAULT_SETTINGS["pipeline.batch.delay"]
 
-  option ["-b", "--pipeline-batch-size"], "SIZE",
-         I18n.t("logstash.runner.flag.pipeline-batch-size"),
-         :attribute_name => :pipeline_batch_size,
-         :default => LogStash::Pipeline::DEFAULT_SETTINGS[:pipeline_batch_size]
+  option ["--[no-]pipeline.unsafe_shutdown"], :flag,
+    I18n.t("logstash.runner.flag.unsafe_shutdown"),
+    :attribute_name => :unsafe_shutdown
+  #  :default => LogStash::DEFAULT_SETTINGS["pipeline.unsafe_shutdown"]
 
-  option ["-u", "--pipeline-batch-delay"], "DELAY_IN_MS",
-         I18n.t("logstash.runner.flag.pipeline-batch-delay"),
-         :attribute_name => :pipeline_batch_delay,
-         :default => LogStash::Pipeline::DEFAULT_SETTINGS[:pipeline_batch_delay]
+  # Plugins Settings
+  option ["-p", "--plugin.paths"] , "PATH",
+    I18n.t("logstash.runner.flag.pluginpath"),
+    :multivalued => true, :attribute_name => :plugin_paths,
+    :default => LogStash::DEFAULT_SETTINGS["plugin.paths"]
 
+  # Logging Settings
   option ["-l", "--log"], "FILE",
     I18n.t("logstash.runner.flag.log"),
     :attribute_name => :log_file
 
-  # Old support for the '-v' flag'
-  option "-v", :flag,
-    I18n.t("logstash.runner.flag.verbosity"),
-    :attribute_name => :verbosity, :multivalued => true
+  option "--[no-]debug", :flag, I18n.t("logstash.runner.flag.debug"),
+    :default => LogStash::DEFAULT_SETTINGS["debug"]
+  option "--[no-]quiet", :flag, I18n.t("logstash.runner.flag.quiet"),
+    :default => LogStash::DEFAULT_SETTINGS["quiet"]
+  option "--[no-]verbose", :flag, I18n.t("logstash.runner.flag.verbose"),
+    :default => LogStash::DEFAULT_SETTINGS["verbose"]
 
-  option "--quiet", :flag, I18n.t("logstash.runner.flag.quiet")
-  option "--verbose", :flag, I18n.t("logstash.runner.flag.verbose")
-  option "--debug", :flag, I18n.t("logstash.runner.flag.debug")
+  # Other settings
+  option ["-i", "--interactive"], "SHELL",
+    I18n.t("logstash.runner.flag.rubyshell"),
+    :attribute_name => :ruby_shell
 
   option ["-V", "--version"], :flag,
     I18n.t("logstash.runner.flag.version")
 
-  option ["-p", "--pluginpath"] , "PATH",
-    I18n.t("logstash.runner.flag.pluginpath"),
-    :multivalued => true,
-    :attribute_name => :plugin_paths
-
-  option ["-t", "--configtest"], :flag,
+  option ["-t", "--[no-]config.test"], :flag,
     I18n.t("logstash.runner.flag.configtest"),
-    :attribute_name => :config_test
-
-  option "--[no-]allow-unsafe-shutdown", :flag,
-    I18n.t("logstash.runner.flag.unsafe_shutdown"),
-    :attribute_name => :unsafe_shutdown,
-    :default => false
-
-  option ["-i", "--interactive"], "SHELL",
-    I18n.t("logstash.runner.flag.rubyshell"),
-    :attribute_name => :ruby_shell
-
-  option ["-n", "--node-name"], "NAME",
-    I18n.t("logstash.runner.flag.node_name"),
-    :attribute_name => :node_name
+    :attribute_name => :config_test,
+    :default => LogStash::DEFAULT_SETTINGS["config.test"]
 
   option ["-r", "--[no-]auto-reload"], :flag,
     I18n.t("logstash.runner.flag.auto_reload"),
     :attribute_name => :auto_reload, :default => false
 
+  option ["--reload-interval"], "RELOAD_INTERVAL",
+    I18n.t("logstash.runner.flag.reload_interval"),
+    :attribute_name => :reload_interval, :default => 3, &:to_i
+
   option ["--http-host"], "WEB_API_HTTP_HOST",
     I18n.t("logstash.web_api.flag.http_host"),
     :attribute_name => :web_api_http_host, :default => "127.0.0.1"
@@ -91,21 +101,22 @@ class LogStash::Runner < Clamp::Command
     :attribute_name => :web_api_http_port, :default => 9600
 
   def pipeline_workers=(pipeline_workers_value)
-    @pipeline_settings[:pipeline_workers] = validate_positive_integer(pipeline_workers_value)
+    @pipeline_settings["pipeline.workers"] = validate_positive_integer(pipeline_workers_value)
   end
 
   def pipeline_batch_size=(pipeline_batch_size_value)
-    @pipeline_settings[:pipeline_batch_size] = validate_positive_integer(pipeline_batch_size_value)
+    @pipeline_settings["pipeline.batch.size"] = validate_positive_integer(pipeline_batch_size_value)
   end
 
   def pipeline_batch_delay=(pipeline_batch_delay_value)
-    @pipeline_settings[:pipeline_batch_delay] = validate_positive_integer(pipeline_batch_delay_value)
+    @pipeline_settings["pipeline.batch.delay"] = validate_positive_integer(pipeline_batch_delay_value)
   end
 
-  def validate_positive_integer(str_arg)
-    int_arg = str_arg.to_i
+  def validate_positive_integer(arg)
+    int_arg = arg.to_i
+    str_arg = arg.to_s
     if str_arg !~ /^\d+$/ || int_arg < 1
-      raise ArgumentError, "Expected a positive integer, got '#{str_arg}'"
+      raise ArgumentError, "Expected a positive integer, got '#{arg}'"
     end
 
     int_arg
@@ -125,7 +136,6 @@ def execute
     require "stud/task"
     require "cabin" # gem 'cabin'
 
-
     # Configure Logstash logging facility, this need to be done before everything else to
     # make sure the logger has the correct settings and the log level is correctly defined.
     configure_logging(log_file)
@@ -143,7 +153,7 @@ def execute
     LogStash::ShutdownWatcher.unsafe_shutdown = unsafe_shutdown?
     LogStash::ShutdownWatcher.logger = @logger
 
-    configure
+    configure_plugin_paths(plugin_paths)
 
     if version?
       show_version
@@ -152,11 +162,15 @@ def execute
 
     return start_shell(@ruby_shell, binding) if @ruby_shell
 
+    settings = build_settings_hash
+    settings.merge!(@pipeline_settings)
+    format_settings(settings).each {|line| @logger.log(line) }
+
     if config_string.nil? && config_path.nil?
       fail(I18n.t("logstash.runner.missing-configuration"))
     end
 
-    if @auto_reload && config_path.nil?
+    if auto_reload? && config_path.nil?
       # there's nothing to reload
       signal_usage_error(I18n.t("logstash.runner.reload-without-config-path"))
     end
@@ -166,7 +180,7 @@ def execute
       config_str = config_loader.format_config(config_path, config_string)
       config_error = LogStash::Pipeline.config_valid?(config_str)
       if config_error == true
-        @logger.terminal "Configuration OK"
+        @logger.log "Configuration OK"
         return 0
       else
         @logger.fatal I18n.t("logstash.error", :error => config_error)
@@ -175,7 +189,8 @@ def execute
     end
 
     @agent = create_agent(:logger => @logger,
-                          :auto_reload => @auto_reload,
+                          :auto_reload => auto_reload?,
+                          :reload_interval => @reload_interval,
                           :collect_metric => true,
                           :debug => debug?,
                           :node_name => node_name,
@@ -280,19 +295,7 @@ def configure_logging(path)
     elsif debug?
       @logger.level = :debug
     else
-      # Old support for the -v and -vv stuff.
-      if verbosity? && verbosity?.any?
-        # this is an array with length of how many times the flag is given
-        if verbosity?.length == 1
-          @logger.warn("The -v flag is deprecated and will be removed in a future release. You should use --verbose instead.")
-          @logger.level = :info
-        else
-          @logger.warn("The -vv flag is deprecated and will be removed in a future release. You should use --debug instead.")
-          @logger.level = :debug
-        end
-      else
-        @logger.level = :warn
-      end
+      @logger.level = :warn
     end
 
     if log_file
@@ -370,4 +373,36 @@ def trap_sigint
     end
   end
 
-end # class LogStash::Runner
+  def build_settings_hash
+    hash = {}
+    self.class.declared_options.each do |opt|
+      option_name = opt.long_switch.sub("--", "").sub("[no-]", "")
+      value = self.send(opt.read_method)
+      if opt.flag?
+        hash[option_name] = value ? value : false
+      elsif value
+        hash[option_name] = value
+      end
+    end
+    hash
+  end
+
+  def format_settings(settings)
+    output = []
+    output << "-------- Logstash Settings (* means modified) ---------"
+    LogStash::DEFAULT_SETTINGS.each do |setting, default_value|
+      value = settings[setting]
+      if default_value == value # print setting and its default value
+        output << "#{setting}: #{value.inspect}" unless value.nil?
+      elsif default_value.nil? # print setting and warn it has been set
+        output << "*#{setting}: #{value.inspect}"
+      elsif value.nil? # default setting not set by user
+        output << "#{setting}: #{default_value.inspect}"
+      else # print setting, warn it has been set, and show default value
+        output << "*#{setting}: #{value.inspect} (default: #{default_value.inspect})"
+      end
+    end
+    output << "--------------- Logstash Settings -------------------"
+    output
+  end
+end
diff --git a/logstash-core/lib/logstash/util.rb b/logstash-core/lib/logstash/util.rb
index 88f8b999200..7362c7abd22 100644
--- a/logstash-core/lib/logstash/util.rb
+++ b/logstash-core/lib/logstash/util.rb
@@ -209,4 +209,31 @@ def self.deep_clone(o)
       Marshal.load(Marshal.dump(o))
     end
   end
+
+
+  def self.flatten_hash(h,f="",g={})
+    return g.update({ f => h }) unless h.is_a? Hash
+    if f.empty?
+      h.each { |k,r| flatten_hash(r,k,g) }
+    else
+      h.each { |k,r| flatten_hash(r,"#{f}.#{k}",g) }
+    end
+    g
+  end
+
+  def self.flatten_arguments(hash)
+    args = []
+    hash.each do |key, value|
+      next if value.nil?
+      if value == true
+        args << "--#{key}"
+      elsif value == false
+        args << "--no-#{key}"
+      else
+        args << "--#{key}"
+        args << value
+      end
+    end
+    args
+  end
 end # module LogStash::Util
diff --git a/logstash-core/lib/logstash/util/defaults_printer.rb b/logstash-core/lib/logstash/util/defaults_printer.rb
deleted file mode 100644
index 6dd850e1d50..00000000000
--- a/logstash-core/lib/logstash/util/defaults_printer.rb
+++ /dev/null
@@ -1,31 +0,0 @@
-# encoding: utf-8
-require "logstash/namespace"
-require "logstash/util"
-require "logstash/util/worker_threads_default_printer"
-
-
-# This class exists to format the settings for defaults used
-module LogStash module Util class DefaultsPrinter
-  def self.print(settings)
-    new(settings).print
-  end
-
-  def initialize(settings)
-    @settings = settings
-    @printers = [workers]
-  end
-
-  def print
-    collector = []
-    @printers.each do |printer|
-      printer.visit(collector)
-    end
-    "Settings: " + collector.join(', ')
-  end
-
-  private
-
-  def workers
-    WorkerThreadsDefaultPrinter.new(@settings)
-  end
-end end end
diff --git a/logstash-core/lib/logstash/util/worker_threads_default_printer.rb b/logstash-core/lib/logstash/util/worker_threads_default_printer.rb
index 43869162865..b35058ac24e 100644
--- a/logstash-core/lib/logstash/util/worker_threads_default_printer.rb
+++ b/logstash-core/lib/logstash/util/worker_threads_default_printer.rb
@@ -6,8 +6,8 @@
 module LogStash module Util class WorkerThreadsDefaultPrinter
 
   def initialize(settings)
-    @setting = settings.fetch(:pipeline_workers, 0)
-    @default = settings.fetch(:default_pipeline_workers, 0)
+    @setting = settings.fetch('pipeline.workers', 0)
+    @default = settings.fetch('default-pipeline-workers', 0)
   end
 
   def visit(collector)
diff --git a/logstash-core/lib/logstash/webserver.rb b/logstash-core/lib/logstash/webserver.rb
index 45587d11f15..23bcaf0b576 100644
--- a/logstash-core/lib/logstash/webserver.rb
+++ b/logstash-core/lib/logstash/webserver.rb
@@ -24,7 +24,12 @@ def initialize(logger, options={})
       @options     = {}
       @cli_options = options.merge({ :rackup => ::File.join(::File.dirname(__FILE__), "api", "init.ru"),
                                      :binds => ["tcp://#{http_host}:#{http_port}"],
-                                     :debug => logger.debug? })
+                                     :debug => logger.debug?,
+                                     # Prevent puma from queueing request when not able to properly handling them,
+                                     # fixed https://github.com/elastic/logstash/issues/4674. See
+                                     # https://github.com/puma/puma/pull/640 for mode internal details in PUMA.
+                                     :queue_requests => false
+      })
       @status      = nil
 
       parse_options
diff --git a/logstash-core/locales/en.yml b/logstash-core/locales/en.yml
index 1bd4e874848..7797fee5730 100644
--- a/logstash-core/locales/en.yml
+++ b/logstash-core/locales/en.yml
@@ -186,6 +186,9 @@ en:
           Monitor configuration changes and reload
           whenever it is changed.
           NOTE: use SIGHUP to manually reload the config
+        reload_interval: |+
+          How frequently to poll the configuration location
+          for changes, in seconds.
         log: |+
           Write logstash internal logs to the given
           file. Without this flag, logstash will emit
diff --git a/logstash-core/spec/api/fixtures/memory.json b/logstash-core/spec/api/fixtures/memory.json
deleted file mode 100644
index 2cd94aef053..00000000000
--- a/logstash-core/spec/api/fixtures/memory.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-	"heap": {
-		"used_in_bytes": 1,
-		"committed_in_bytes": 2,
-		"max_in_bytes": 3,
-		"peak_used_in_bytes": 4,
-		"peak_max_in_bytes": 5,
-		"used_percent": 7
-
-	},
-	"non_heap": {
-		"used_in_bytes": 1,
-		"committed_in_bytes": 2,
-		"max_in_bytes": 3,
-		"peak_used_in_bytes": 4,
-		"peak_max_in_bytes": 5
-
-	},
-	"pools": {
-		"young": {
-			"used_in_bytes": 1,
-			"committed_in_bytes": 2,
-			"max_in_bytes": 3,
-			"peak_used_in_bytes": 4,
-			"peak_max_in_bytes": 5
-		},
-		"old": {
-			"used_in_bytes": 1,
-			"committed_in_bytes": 2,
-			"max_in_bytes": 3,
-			"peak_used_in_bytes": 4,
-			"peak_max_in_bytes": 5
-		},
-		"survivor": {
-			"used_in_bytes": 1,
-			"committed_in_bytes": 2,
-			"max_in_bytes": 3,
-			"peak_used_in_bytes": 4,
-			"peak_max_in_bytes": 5
-		}
-	}
-}
diff --git a/logstash-core/spec/api/lib/api/node_spec.rb b/logstash-core/spec/api/lib/api/node_spec.rb
new file mode 100644
index 00000000000..51a016ff280
--- /dev/null
+++ b/logstash-core/spec/api/lib/api/node_spec.rb
@@ -0,0 +1,78 @@
+# encoding: utf-8
+require_relative "../../spec_helper"
+require "sinatra"
+require "app/modules/node"
+require "logstash/json"
+
+describe LogStash::Api::Node do
+
+  include Rack::Test::Methods
+
+  def app()
+    described_class
+  end
+
+  describe "#hot threads" do
+
+    before(:all) do
+      do_request { get "/hot_threads" }
+    end
+
+    it "respond OK" do
+      expect(last_response).to be_ok
+    end
+
+    it "should return a JSON object" do
+      expect{ LogStash::Json.load(last_response.body) }.not_to raise_error
+    end
+
+    context "#threads count" do
+
+      before(:all) do
+        do_request { get "/hot_threads?threads=5" }
+      end
+
+      let(:payload) { LogStash::Json.load(last_response.body) }
+
+      it "should return a json payload content type" do
+        expect(last_response.content_type).to eq("application/json")
+      end
+
+      it "should return information for <= # requested threads" do
+        expect(payload["threads"].count).to be <= 5
+      end
+    end
+
+    context "when asking for human output" do
+
+      before(:all) do
+        do_request { get "/hot_threads?human" }
+      end
+
+      let(:payload) { last_response.body }
+
+      it "should return a text/plain content type" do
+        expect(last_response.content_type).to eq("text/plain;charset=utf-8")
+      end
+
+      it "should return a plain text payload" do
+        expect{ JSON.parse(payload) }.to raise_error
+      end
+    end
+
+    context "when requesting idle threads" do
+
+      before(:all) do
+        do_request { get "/hot_threads?ignore_idle_threads=false&threads=10" }
+      end
+
+      let(:payload) { LogStash::Json.load(last_response.body) }
+
+      it "should return JIT threads" do
+        thread_names = payload["threads"].map { |thread_info| thread_info["name"] }
+        expect(thread_names.grep(/pool/)).not_to be_empty
+      end
+    end
+
+  end
+end
diff --git a/logstash-core/spec/api/lib/api/node_stats_spec.rb b/logstash-core/spec/api/lib/api/node_stats_spec.rb
index 809ab40e12b..c90d167e3a7 100644
--- a/logstash-core/spec/api/lib/api/node_stats_spec.rb
+++ b/logstash-core/spec/api/lib/api/node_stats_spec.rb
@@ -2,6 +2,7 @@
 require_relative "../../spec_helper"
 require "sinatra"
 require "app/modules/node_stats"
+require "logstash/json"
 
 describe LogStash::Api::NodeStats do
 
@@ -11,24 +12,57 @@ def app()
     described_class
   end
 
-  let(:mem) do
-    { :heap_used_in_bytes => 10,
-      :pools => { :used_in_bytes => 20 }}
-  end
+  let(:payload) { LogStash::Json.load(last_response.body) }
+
+  context "#root" do
+
+    before(:all) do
+      do_request { get "/" }
+    end
+
+    it "respond OK" do
+      expect(last_response).to be_ok
+    end
 
-  let(:events) do
-    { :in => 10, :out => 20 }
+    ["events", "jvm"].each do |key|
+      it "contains #{key} information" do
+        expect(payload).to include(key)
+      end
+    end
   end
 
-  it "respond to the events resource" do
-    expect_any_instance_of(LogStash::Api::StatsEventsCommand).to receive(:run).and_return(events)
-    get "/events"
-    expect(last_response).to be_ok
+  context "#events" do
+
+    let(:payload) { LogStash::Json.load(last_response.body) }
+
+    before(:all) do
+      do_request { get "/events" }
+    end
+
+    it "respond OK" do
+      expect(last_response).to be_ok
+    end
+
+    it "contains events information" do
+      expect(payload).to include("events")
+    end
   end
 
-  it "respond to the jvm resource" do
-    expect_any_instance_of(LogStash::Api::JvmMemoryCommand).to receive(:run).and_return(mem)
-    get "jvm"
-    expect(last_response).to be_ok
+  context "#jvm" do
+
+    let(:payload) { LogStash::Json.load(last_response.body) }
+
+    before(:all) do
+      do_request { get "/jvm" }
+    end
+
+    it "respond OK" do
+      expect(last_response).to be_ok
+    end
+
+    it "contains memory information" do
+      expect(payload).to include("mem")
+    end
   end
+
 end
diff --git a/logstash-core/spec/api/lib/api/plugins_spec.rb b/logstash-core/spec/api/lib/api/plugins_spec.rb
new file mode 100644
index 00000000000..4e0aa66b48b
--- /dev/null
+++ b/logstash-core/spec/api/lib/api/plugins_spec.rb
@@ -0,0 +1,57 @@
+# encoding: utf-8
+require_relative "../../spec_helper"
+require "sinatra"
+require "app/modules/plugins"
+require "logstash/json"
+
+describe LogStash::Api::Plugins do
+
+  include Rack::Test::Methods
+
+  def app()
+    described_class
+  end
+
+  before(:all) do
+    get "/"
+  end
+
+  let(:payload) { LogStash::Json.load(last_response.body) }
+
+  it "respond to plugins resource" do
+    expect(last_response).to be_ok
+  end
+
+  it "return valid json content type" do
+    expect(last_response.content_type).to eq("application/json")
+  end
+
+  context "#schema" do
+    it "return the expected schema" do
+      expect(payload.keys).to include("plugins", "total")
+      payload["plugins"].each do |plugin|
+        expect(plugin.keys).to include("name", "version")
+      end
+    end
+  end
+
+  context "#values" do
+
+    it "return totals of plugins" do
+      expect(payload["total"]).to eq(payload["plugins"].count)
+    end
+
+    it "return a list of available plugins" do
+      payload["plugins"].each do |plugin|
+        expect(plugin).to be_available?
+      end
+    end
+
+    it "return non empty version values" do
+      payload["plugins"].each do |plugin|
+        expect(plugin["version"]).not_to be_empty
+      end
+    end
+
+  end
+end
diff --git a/logstash-core/spec/api/lib/api/root_spec.rb b/logstash-core/spec/api/lib/api/root_spec.rb
index 83abb232957..6bc8a4937b6 100644
--- a/logstash-core/spec/api/lib/api/root_spec.rb
+++ b/logstash-core/spec/api/lib/api/root_spec.rb
@@ -12,15 +12,8 @@ def app()
     described_class
   end
 
-  let(:agent) { double("agent") }
-
-  before(:each) do
-    allow(agent).to receive(:node_name).and_return("foo")
-    expect_any_instance_of(LogStash::Api::Service).to receive(:agent).and_return(agent)
-  end
-
   it "should respond to root resource" do
-    get "/"
+    do_request { get "/" }
     expect(last_response).to be_ok
   end
 
diff --git a/logstash-core/spec/api/lib/api/stats_spec.rb b/logstash-core/spec/api/lib/api/stats_spec.rb
index 2f140e05c95..8dfd2617b42 100644
--- a/logstash-core/spec/api/lib/api/stats_spec.rb
+++ b/logstash-core/spec/api/lib/api/stats_spec.rb
@@ -11,19 +11,8 @@ def app()
     described_class
   end
 
-  let(:mem) do
-    { :heap_used_in_bytes => 10,
-      :pools => { :used_in_bytes => 20 }}
-  end
-
-  before(:each) do
-    expect_any_instance_of(LogStash::Api::JvmMemoryCommand).to receive(:started_at).and_return(1234567890)
-    expect_any_instance_of(LogStash::Api::JvmMemoryCommand).to receive(:uptime).and_return(10)
-    expect_any_instance_of(LogStash::Api::JvmMemoryCommand).to receive(:run).and_return(mem)
-  end
-
   it "respond to the jvm resource" do
-    get "/jvm"
+    do_request { get "/jvm" }
     expect(last_response).to be_ok
   end
 
diff --git a/logstash-core/spec/api/lib/commands/events_spec.rb b/logstash-core/spec/api/lib/commands/events_spec.rb
index 54c4dc86459..9bbcc3e7aa8 100644
--- a/logstash-core/spec/api/lib/commands/events_spec.rb
+++ b/logstash-core/spec/api/lib/commands/events_spec.rb
@@ -4,26 +4,14 @@
 
 describe LogStash::Api::StatsEventsCommand do
 
-  let(:service) { double("snapshot-service") }
-
-  subject { described_class.new(service) }
-
-  let(:stats) do
-    { "stats" => { "events" => { "in" => 100,
-                                 "out" => 0,
-                                 "filtered" => 200 }}}
-  end
-
-  before(:each) do
-    allow(service).to receive(:get).with(:events_stats).and_return(LogStash::Json.dump(stats))
-  end
-
   context "#schema" do
-    let(:report) { subject.run }
 
-    it "return events information" do
-      expect(report).to include({"in" => 100, "filtered" => 200 })
+    let(:report) do
+      do_request { subject.run }
     end
 
+    it "return events information" do
+      expect(report).to include("in", "filtered", "out")
+    end
   end
 end
diff --git a/logstash-core/spec/api/lib/commands/jvm_spec.rb b/logstash-core/spec/api/lib/commands/jvm_spec.rb
index 5cf1651b221..e3f01d00aaf 100644
--- a/logstash-core/spec/api/lib/commands/jvm_spec.rb
+++ b/logstash-core/spec/api/lib/commands/jvm_spec.rb
@@ -5,20 +5,15 @@
 
 describe "JVM stats" do
 
-  let(:agent) { double("agent") }
-
   describe LogStash::Api::HotThreadsCommand do
 
-    before(:each) do
-      allow(agent).to receive(:node_name).and_return("foo")
-      expect_any_instance_of(LogStash::Api::Service).to receive(:agent).and_return(agent)
-      allow(subject).to receive(:uptime).and_return(10)
+    let(:report) do
+      do_request { subject.run }
     end
 
     context "#schema" do
-      let(:report) { subject.run }
-
       it "return hot threads information" do
+        report = do_request { subject.run }
         expect(report.to_s).not_to be_empty
       end
 
@@ -29,22 +24,8 @@
 
     context "#schema" do
 
-      let(:service) { double("snapshot-service") }
-
-      subject { described_class.new(service) }
-
-      let(:stats) do
-        read_fixture("memory.json")
-      end
-
-      before(:each) do
-        allow(service).to receive(:agent).and_return(agent)
-        allow(service).to receive(:get).with(:jvm_memory_stats).and_return(stats)
-      end
-
-
       let(:report) do
-        subject.run
+        do_request { subject.run }
       end
 
       it "return hot threads information" do
diff --git a/logstash-core/spec/api/spec_helper.rb b/logstash-core/spec/api/spec_helper.rb
index f6f9ac70ca9..90a1bb1e378 100644
--- a/logstash-core/spec/api/spec_helper.rb
+++ b/logstash-core/spec/api/spec_helper.rb
@@ -1,7 +1,5 @@
 # encoding: utf-8
-ROOT = File.expand_path(File.join(File.dirname(__FILE__), "..", "..", "lib", "logstash", "api"))
-$LOAD_PATH.unshift File.join(ROOT, 'lib')
-Dir.glob(File.join(ROOT, "lib" "**")).each{ |d| $LOAD_PATH.unshift(d) }
+API_ROOT = File.expand_path(File.join(File.dirname(__FILE__), "..", "..", "lib", "logstash", "api"))
 
 require "logstash/devutils/rspec/spec_helper"
 
@@ -11,9 +9,120 @@
 
 ENV['RACK_ENV'] = 'test'
 
-Rack::Builder.parse_file(File.join(ROOT, 'init.ru'))
+Rack::Builder.parse_file(File.join(API_ROOT, 'init.ru'))
 
 def read_fixture(name)
   path = File.join(File.dirname(__FILE__), "fixtures", name)
   File.read(path)
 end
+
+module LogStash
+  class DummyAgent < Agent
+    def fetch_config(settings)
+      "input { generator {count => 0} } output { }"
+    end
+
+    def start_webserver; end
+    def stop_webserver; end
+  end
+end
+
+##
+# Class used to wrap and manage the execution of an agent for test,
+# this helps a lot in order to have a more integrated test for the
+# web api, could be also used for other use cases if generalized enought
+##
+class LogStashRunner
+
+  attr_reader :config_str, :agent, :pipeline_settings
+
+  def initialize
+    args = [
+      :logger => Cabin::Channel.get(LogStash),
+      :auto_reload => false,
+      :collect_metric => true,
+      :debug => false,
+      :node_name => "test_agent",
+      :web_api_http_port => rand(9600..9700)
+    ]
+
+    @config_str   = "input { generator {count => 0} } output { }"
+    @agent = LogStash::DummyAgent.new(*args)
+    @pipeline_settings ||= { :pipeline_id => "main",
+                             :config_str => config_str,
+                            :pipeline_batch_size => 1,
+                            :flush_interval => 1,
+                            :pipeline_workers => 1 }
+  end
+
+  def start
+    agent.register_pipeline("main", pipeline_settings)
+    @runner = Thread.new(agent) do |_agent|
+      _agent.execute
+    end
+    wait_until_snapshot_received
+  end
+
+  def stop
+    agent.shutdown
+    Thread.kill(@runner)
+    sleep 0.1 while !@runner.stop?
+  end
+
+  private
+
+  def wait_until_snapshot_received
+    while !LogStash::Api::Service.instance.started? do
+      sleep 0.5
+    end
+  end
+end
+
+
+##
+# Method used to wrap up a request in between of a running
+# pipeline, this makes the hole execution model easier and
+# more contained as some threads might go wild.
+##
+def do_request(&block)
+  runner = LogStashRunner.new
+  runner.start
+  ret_val = block.call
+  runner.stop
+  ret_val
+end
+
+##
+# Helper module that setups necessary mocks when doing the requests,
+# this could be just included in the test and the runner will be
+# started managed for all tests.
+##
+module LogStash; module RSpec; module RunnerConfig
+  def self.included(klass)
+    klass.before(:all) do
+      LogStashRunner.instance.start
+    end
+
+    klass.before(:each) do
+      runner = LogStashRunner.instance
+      allow(LogStash::Instrument::Collector.instance).to receive(:agent).and_return(runner.agent)
+    end
+
+    klass.after(:all) do
+      LogStashRunner.instance.stop
+    end
+  end
+end; end; end
+
+require 'rspec/expectations'
+
+RSpec::Matchers.define :be_available? do
+  match do |plugin|
+    begin
+      Gem::Specification.find_by_name(plugin["name"])
+      true
+    rescue
+      false
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/agent_spec.rb b/logstash-core/spec/logstash/agent_spec.rb
index b7ad9065e04..14729c37db2 100644
--- a/logstash-core/spec/logstash/agent_spec.rb
+++ b/logstash-core/spec/logstash/agent_spec.rb
@@ -17,6 +17,10 @@
     end
   end
 
+  it "fallback to hostname when no name is provided" do
+    expect(LogStash::Agent.new.node_name).to eq(Socket.gethostname)
+  end
+
   describe "register_pipeline" do
     let(:pipeline_id) { "main" }
     let(:settings) { {
diff --git a/logstash-core/spec/logstash/config/mixin_spec.rb b/logstash-core/spec/logstash/config/mixin_spec.rb
index 7c73b805d63..2a9bb8ac3d5 100644
--- a/logstash-core/spec/logstash/config/mixin_spec.rb
+++ b/logstash-core/spec/logstash/config/mixin_spec.rb
@@ -151,4 +151,80 @@
       expect(subject.params).to include("password")
     end
   end
+
+  context "environment variable evaluation" do
+    let(:plugin_class) do
+      Class.new(LogStash::Filters::Base)  do
+        config_name "one_plugin"
+        config :oneString, :validate => :string
+        config :oneBoolean, :validate => :boolean
+        config :oneNumber, :validate => :number
+        config :oneArray, :validate => :array
+        config :oneHash, :validate => :hash
+      end
+    end
+
+    context "when an environment variable is not set" do
+      context "and no default is given" do
+        before do
+          # Canary. Just in case somehow this is set.
+          expect(ENV["NoSuchVariable"]).to be_nil
+        end
+
+        it "should raise a configuration error" do
+          expect do
+            plugin_class.new("oneString" => "${NoSuchVariable}")
+          end.to raise_error(LogStash::ConfigurationError)
+        end
+      end
+
+      context "and a default is given" do
+        subject do
+          plugin_class.new(
+            "oneString" => "${notExistingVar:foo}",
+            "oneBoolean" => "${notExistingVar:true}",
+            "oneArray" => [ "first array value", "${notExistingVar:foo}", "${notExistingVar:}", "${notExistingVar: }", "${notExistingVar:foo bar}" ],
+            "oneHash" => { "key" => "${notExistingVar:foo}" }
+          )
+        end
+
+        it "should use the default" do
+          expect(subject.oneString).to(be == "foo")
+          expect(subject.oneBoolean).to be_truthy
+          expect(subject.oneArray).to(be == ["first array value", "foo", "", " ", "foo bar"])
+          expect(subject.oneHash).to(be == { "key" => "foo" })
+        end
+      end
+    end
+
+    context "when an environment variable is set" do
+      before do
+        ENV["FunString"] = "fancy"
+        ENV["FunBool"] = "true"
+      end
+
+      after do
+        ENV.delete("FunString")
+        ENV.delete("FunBool")
+      end
+
+      subject do
+        plugin_class.new(
+          "oneString" => "${FunString:foo}",
+          "oneBoolean" => "${FunBool:false}",
+          "oneArray" => [ "first array value", "${FunString:foo}" ],
+          "oneHash" => { "key1" => "${FunString:foo}", "key2" => "$FunString is ${FunBool}", "key3" => "${FunBool:false} or ${funbool:false}" }
+        )
+      end
+
+      it "should use the value in the variable" do
+        expect(subject.oneString).to(be == "fancy")
+        expect(subject.oneBoolean).to(be_truthy)
+        expect(subject.oneArray).to(be == [ "first array value", "fancy" ])
+        expect(subject.oneHash).to(be == { "key1" => "fancy", "key2" => "fancy is true", "key3" => "true or false" })
+      end
+
+    end
+  end
+
 end
diff --git a/logstash-core/spec/logstash/filter_delegator_spec.rb b/logstash-core/spec/logstash/filter_delegator_spec.rb
new file mode 100644
index 00000000000..595fbfedc36
--- /dev/null
+++ b/logstash-core/spec/logstash/filter_delegator_spec.rb
@@ -0,0 +1,143 @@
+# encoding: utf-8
+require "spec_helper"
+require "logstash/filter_delegator"
+require "logstash/instrument/null_metric"
+require "logstash/event"
+
+describe LogStash::FilterDelegator do
+  let(:logger) { double(:logger) }
+  let(:filter_id) { "my-filter" }
+  let(:config) do
+    { "host" => "127.0.0.1", "id" => filter_id }
+  end
+  let(:metric) { LogStash::Instrument::NullMetric.new }
+  let(:events) { [LogStash::Event.new, LogStash::Event.new] }
+
+  before :each do
+    allow(metric).to receive(:namespace).with(anything).and_return(metric)
+  end
+
+  let(:plugin_klass) do
+    Class.new(LogStash::Filters::Base) do
+      config_name "super_plugin"
+      config :host, :validate => :string
+      def register; end
+    end
+  end
+
+  subject { described_class.new(logger, plugin_klass, metric, config) }
+
+  it "create a plugin with the passed options" do
+    expect(plugin_klass).to receive(:new).with(config).and_return(plugin_klass.new(config))
+    described_class.new(logger, plugin_klass, metric, config)
+  end
+
+  context "when the plugin support flush" do
+    let(:plugin_klass) do
+      Class.new(LogStash::Filters::Base) do
+        config_name "super_plugin"
+        config :host, :validate => :string
+        def register; end
+        def flush(options = {}); @events ; end
+        def filter(event)
+          @events ||= []
+          @events << event
+          event.cancel
+        end
+      end
+    end
+
+    it "defines a flush method" do
+      expect(subject.respond_to?(:flush)).to be_truthy
+    end
+
+    context "when the flush return events" do
+      it "increments the out" do
+        subject.multi_filter([LogStash::Event.new])
+        expect(metric).to receive(:increment).with(:out, 1)
+        subject.flush({})
+      end
+    end
+
+    context "when the flush doesn't return anything" do
+      it "doesnt increment the out" do
+        expect(metric).not_to receive(:increment)
+        subject.flush({})
+      end
+    end
+
+    context "when the filter buffer events" do
+      it "doesn't increment out" do
+        expect(metric).to receive(:increment).with(:in, events.size)
+        expect(metric).not_to receive(:increment)
+
+        subject.multi_filter(events)
+      end
+    end
+
+    context "when the fitler create more events" do
+      let(:plugin_klass) do
+        Class.new(LogStash::Filters::Base) do
+          config_name "super_plugin"
+          config :host, :validate => :string
+          def register; end
+          def flush(options = {}); @events ; end
+
+          # naive split filter implementation
+          def filter(event)
+            event.cancel
+            2.times { yield LogStash::Event.new }
+          end
+        end
+      end
+
+      it "increments the in/out of the metric" do
+        expect(metric).to receive(:increment).with(:in, events.size)
+        expect(metric).to receive(:increment).with(:out, events.size * 2)
+
+        subject.multi_filter(events)
+      end
+    end
+  end
+
+  context "when the plugin doesnt support flush" do
+    let(:plugin_klass) do
+      Class.new(LogStash::Filters::Base) do
+        config_name "super_plugin"
+        config :host, :validate => :string
+        def register; end
+        def filter(event)
+          event
+        end
+      end
+    end
+
+    it "doesnt define a flush method" do
+      expect(subject.respond_to?(:flush)).to be_falsey
+    end
+
+    it "increments the in/out of the metric" do
+      expect(metric).to receive(:increment).with(:in, events.size)
+      expect(metric).to receive(:increment).with(:out, events.size)
+
+      subject.multi_filter(events)
+    end
+  end
+
+  context "#config_name" do
+    it "proxy the config_name to the class method" do
+      expect(subject.config_name).to eq("super_plugin")
+    end
+  end
+
+  context "delegate methods to the original plugin" do
+    # I am not testing the behavior of these methods
+    # this is done in the plugin tests. I just want to make sure
+    # the proxy delegates the methods.
+    LogStash::FilterDelegator::DELEGATED_METHODS.each do |method|
+      it "delegate method: `#{method}` to the filter" do
+        expect(subject.respond_to?(method))
+      end
+    end
+  end
+end
diff --git a/logstash-core/spec/logstash/inputs/metrics_spec.rb b/logstash-core/spec/logstash/inputs/metrics_spec.rb
index 5a214924b39..97a89facda3 100644
--- a/logstash-core/spec/logstash/inputs/metrics_spec.rb
+++ b/logstash-core/spec/logstash/inputs/metrics_spec.rb
@@ -3,6 +3,10 @@
 require "spec_helper"
 
 describe LogStash::Inputs::Metrics do
+  before :each do
+    LogStash::Instrument::Collector.instance.clear
+  end
+
   let(:queue) { [] }
 
   describe "#run" do
diff --git a/logstash-core/spec/logstash/output_delegator_spec.rb b/logstash-core/spec/logstash/output_delegator_spec.rb
index c3683a9526a..524ad779ec9 100644
--- a/logstash-core/spec/logstash/output_delegator_spec.rb
+++ b/logstash-core/spec/logstash/output_delegator_spec.rb
@@ -21,6 +21,7 @@
       allow(out_inst).to receive(:multi_receive)
       allow(out_inst).to receive(:metric=).with(any_args)
       allow(out_inst).to receive(:id).and_return("a-simple-plugin")
+      allow(out_inst).to receive(:plugin_unique_name).and_return("hello-123")
       allow(logger).to receive(:debug).with(any_args)
     end
 
diff --git a/logstash-core/spec/logstash/pipeline_spec.rb b/logstash-core/spec/logstash/pipeline_spec.rb
index d594a84592a..3b24cf6886f 100644
--- a/logstash-core/spec/logstash/pipeline_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_spec.rb
@@ -107,7 +107,7 @@ class TestPipeline < LogStash::Pipeline
 end
 
 describe LogStash::Pipeline do
-  let(:worker_thread_count)     { LogStash::Pipeline::DEFAULT_SETTINGS[:default_pipeline_workers] }
+  let(:worker_thread_count)     { LogStash::DEFAULT_SETTINGS["pipeline.workers"] }
   let(:safe_thread_count)       { 1 }
   let(:override_thread_count)   { 42 }
 
@@ -149,12 +149,13 @@ class TestPipeline < LogStash::Pipeline
       end
 
       context "when there is command line -w N set" do
+        let(:pipeline_settings) { {"pipeline.workers" => override_thread_count } }
         it "starts multiple filter thread" do
-          msg = "Warning: Manual override - there are filters that might not work with multiple worker threads"
-          pipeline = TestPipeline.new(test_config_with_filters)
+          msg = "Warning: Manual override - there are filters that might" +
+                " not work with multiple worker threads"
+          pipeline = TestPipeline.new(test_config_with_filters, pipeline_settings)
           expect(pipeline.logger).to receive(:warn).with(msg,
             {:worker_threads=> override_thread_count, :filters=>["dummyfilter"]})
-          pipeline.configure(:pipeline_workers, override_thread_count)
           pipeline.run
           expect(pipeline.worker_threads.size).to eq(override_thread_count)
         end
@@ -314,7 +315,7 @@ class TestPipeline < LogStash::Pipeline
   describe "max inflight warning" do
     let(:config) { "input { dummyinput {} } output { dummyoutput {} }" }
     let(:batch_size) { 1 }
-    let(:pipeline) { LogStash::Pipeline.new(config, :pipeline_batch_size => batch_size, :pipeline_workers => 1) }
+    let(:pipeline) { LogStash::Pipeline.new(config, "pipeline.batch.size" => batch_size, "pipeline.workers" => 1) }
     let(:logger) { pipeline.logger }
     let(:warning_prefix) { /CAUTION: Recommended inflight events max exceeded!/ }
 
@@ -529,26 +530,45 @@ class TestPipeline < LogStash::Pipeline
     end
   end
 
-  context "when collecting metric in the pipeline" do
+  context "when collecting metrics in the pipeline" do
     subject { described_class.new(config, { :metric => metric, :pipeline_id => pipeline_id }) }
     let(:pipeline_id) { :main }
     let(:metric) { LogStash::Instrument::Metric.new }
     let(:number_of_events) { 1000 }
+    let(:multiline_id) { "my-multiline" }
+    let(:multiline_id_other) { "my-multiline_other" }
+    let(:dummy_output_id) { "my-dummyoutput" }
+    let(:generator_id) { "my-generator" }
     let(:config) do
       <<-EOS
-      input { generator { count => #{number_of_events}} }
+      input {
+        generator {
+           count => #{number_of_events}
+           id => "#{generator_id}"
+        }
+      }
       filter {
          multiline {
+              id => "#{multiline_id}"
               pattern => "hello"
               what => next
           }
+          multiline {
+               id => "#{multiline_id_other}"
+               pattern => "hello"
+               what => next
+           }
+      }
+      output {
+        dummyoutput {
+          id => "#{dummy_output_id}"
+        }
       }
-      output { dummyoutput {} }
       EOS
     end
-    let(:dummyoutput) { DummyOutput.new }
+    let(:dummyoutput) { DummyOutput.new({ "id" => dummy_output_id }) }
 
-    before do
+    before :each do
       allow(DummyOutput).to receive(:new).with(any_args).and_return(dummyoutput)
       allow(LogStash::Plugin).to receive(:lookup).with("input", "generator").and_return(LogStash::Inputs::Generator)
       allow(LogStash::Plugin).to receive(:lookup).with("codec", "plain").and_return(LogStash::Codecs::Plain)
@@ -557,30 +577,48 @@ class TestPipeline < LogStash::Pipeline
 
       # Reset the metric store
       LogStash::Instrument::Collector.instance.clear
-    end
 
-    it "populates the differents core metrics" do
-      t = Thread.new { subject.run }
+      Thread.new { subject.run }
       # make sure we have received all the generated events
-      sleep 0.01 while dummyoutput.events.size < number_of_events
+      sleep 1 while dummyoutput.events.size < number_of_events
+    end
+
+    after :each do
+      subject.shutdown
+    end
 
-      collected_metric = LogStash::Instrument::Collector.instance.snapshot_metric.metric_store.get_with_path("stats/events")
+    context "global metric" do
+      let(:collected_metric) { LogStash::Instrument::Collector.instance.snapshot_metric.metric_store.get_with_path("stats/events") }
 
-      expect(collected_metric[:stats][:events][:in].value).to eq(number_of_events)
-      expect(collected_metric[:stats][:events][:filtered].value).to eq(number_of_events)
-      expect(collected_metric[:stats][:events][:out].value).to eq(number_of_events)
+      it "populates the differents" do
+        expect(collected_metric[:stats][:events][:in].value).to eq(number_of_events)
+        expect(collected_metric[:stats][:events][:filtered].value).to eq(number_of_events)
+        expect(collected_metric[:stats][:events][:out].value).to eq(number_of_events)
+      end
     end
 
-    it "populates the pipelines core metrics" do
-      t = Thread.new { subject.run }
-      # make sure we have received all the generated events
-      sleep 0.01 while dummyoutput.events.size < number_of_events
+    context "pipelines" do
+      let(:collected_metric) { LogStash::Instrument::Collector.instance.snapshot_metric.metric_store.get_with_path("stats/pipelines/") }
+
+      it "populates the pipelines core metrics" do
+        expect(collected_metric[:stats][:pipelines][:main][:events][:in].value).to eq(number_of_events)
+        expect(collected_metric[:stats][:pipelines][:main][:events][:filtered].value).to eq(number_of_events)
+        expect(collected_metric[:stats][:pipelines][:main][:events][:out].value).to eq(number_of_events)
+      end
 
-      collected_metric = LogStash::Instrument::Collector.instance.snapshot_metric.metric_store.get_with_path("stats/pipelines/")
+      it "populates the filter metrics" do
+        [multiline_id, multiline_id_other].map(&:to_sym).each do |id|
+          [:in, :out].each do |metric_key|
+            plugin_name = "multiline_#{id}".to_sym
+            expect(collected_metric[:stats][:pipelines][:main][:plugins][:filters][plugin_name][:events][metric_key].value).to eq(number_of_events)
+          end
+        end
+      end
 
-      expect(collected_metric[:stats][:pipelines][:main][:events][:in].value).to eq(number_of_events)
-      expect(collected_metric[:stats][:pipelines][:main][:events][:filtered].value).to eq(number_of_events)
-      expect(collected_metric[:stats][:pipelines][:main][:events][:out].value).to eq(number_of_events)
+      it "populates the output metrics" do
+        plugin_name = "dummyoutput_#{dummy_output_id}".to_sym
+        expect(collected_metric[:stats][:pipelines][:main][:plugins][:outputs][plugin_name][:events][:out].value).to eq(number_of_events)
+      end
     end
   end
 end
diff --git a/logstash-core/spec/logstash/plugin_spec.rb b/logstash-core/spec/logstash/plugin_spec.rb
index fa94ca7350d..3950fbcc6e3 100644
--- a/logstash-core/spec/logstash/plugin_spec.rb
+++ b/logstash-core/spec/logstash/plugin_spec.rb
@@ -222,4 +222,39 @@ def register; end
       end
     end
   end
+
+  describe "#plugin_unique_name" do
+    let(:plugin) do
+      Class.new(LogStash::Filters::Base,) do
+        config_name "simple_plugin"
+        config :host, :validate => :string
+
+        def register; end
+      end
+    end
+
+    let(:config) do
+      {
+        "host" => "127.0.0.1"
+      }
+    end
+
+    context "when the id is provided" do
+      let(:my_id) { "mysuper-plugin" }
+      let(:config) { super.merge({ "id" => my_id })}
+      subject { plugin.new(config) }
+
+      it "return a human readable ID" do
+        expect(subject.plugin_unique_name).to eq("simple_plugin_#{my_id}")
+      end
+    end
+
+    context "when the id is not provided provided" do
+      subject { plugin.new(config) }
+
+      it "return a human readable ID" do
+        expect(subject.plugin_unique_name).to match(/^simple_plugin_/)
+      end
+    end
+  end
 end
diff --git a/logstash-core/spec/logstash/runner_spec.rb b/logstash-core/spec/logstash/runner_spec.rb
index f8bcd9a6f35..445333fed66 100644
--- a/logstash-core/spec/logstash/runner_spec.rb
+++ b/logstash-core/spec/logstash/runner_spec.rb
@@ -16,10 +16,31 @@ def run(args); end
 
   before :each do
     allow(Cabin::Channel).to receive(:get).with(LogStash).and_return(channel)
+    allow(LogStash::ShutdownWatcher).to receive(:logger).and_return(channel)
+    allow(channel).to receive(:log) {}
+  end
+
+  after :all do
+    LogStash::ShutdownWatcher.logger = nil
+  end
+
+  describe "argument precedence" do
+    let(:config) { "input {} output {}" }
+    let(:cli_args) { ["-e", config, "-w", 20] }
+    let(:settings_yml) { ["--pipeline.workers", 2] }
+
+    it "favors the last occurence of an option" do
+      expect(LogStash::Pipeline).to receive(:new).
+        with(config, hash_including("pipeline.workers" => 20)).and_call_original
+      subject.run("bin/logstash", settings_yml + cli_args)
+    end
   end
 
   describe "argument parsing" do
     subject { LogStash::Runner.new("") }
+    before :each do
+      allow(Cabin::Channel.get(LogStash)).to receive(:terminal)
+    end
     context "when -e is given" do
 
       let(:args) { ["-e", "input {} output {}"] }
@@ -118,7 +139,7 @@ def run(args); end
 
     context "when :pipeline_workers is defined by the user" do
       it "should pass the value to the pipeline" do
-        main_pipeline_settings[:pipeline_workers] = 2
+        main_pipeline_settings["pipeline.workers"] = 2
         expect(LogStash::Pipeline).to receive(:new).with(pipeline_string, hash_including(main_pipeline_settings)).and_return(pipeline)
 
         args = ["-w", "2", "-e", pipeline_string]
diff --git a/logstash-core/spec/logstash/util/defaults_printer_spec.rb b/logstash-core/spec/logstash/util/defaults_printer_spec.rb
deleted file mode 100644
index b3f0576a3a9..00000000000
--- a/logstash-core/spec/logstash/util/defaults_printer_spec.rb
+++ /dev/null
@@ -1,50 +0,0 @@
-# encoding: utf-8
-require "spec_helper"
-require "logstash/util/defaults_printer"
-
-describe LogStash::Util::DefaultsPrinter do
-  shared_examples "a defaults printer" do
-    it 'the .print method returns a defaults description' do
-      expect(actual_block.call).to eq(expected)
-    end
-  end
-
-  let(:workers)  { 1 }
-  let(:expected) { "Settings: User set pipeline workers: #{workers}" }
-  let(:settings) { {} }
-
-  describe 'class methods API' do
-    let(:actual_block) do
-      -> {described_class.print(settings)}
-    end
-
-    context 'when the settings hash is empty' do
-      let(:expected) { "Settings: " }
-      it_behaves_like "a defaults printer"
-    end
-
-    context 'when the settings hash has content' do
-      let(:worker_queue) { 42 }
-      let(:settings) { {:pipeline_workers => workers} }
-      it_behaves_like "a defaults printer"
-    end
-  end
-
-  describe 'instance method API' do
-    let(:actual_block) do
-      -> {described_class.new(settings).print}
-    end
-
-    context 'when the settings hash is empty' do
-      let(:expected) { "Settings: " }
-      it_behaves_like "a defaults printer"
-    end
-
-    context 'when the settings hash has content' do
-      let(:workers) { 13 }
-      let(:settings) { {:pipeline_workers => workers} }
-
-      it_behaves_like "a defaults printer"
-    end
-  end
-end
diff --git a/logstash-core/spec/logstash/util/worker_threads_default_printer_spec.rb b/logstash-core/spec/logstash/util/worker_threads_default_printer_spec.rb
deleted file mode 100644
index 1842b4373ad..00000000000
--- a/logstash-core/spec/logstash/util/worker_threads_default_printer_spec.rb
+++ /dev/null
@@ -1,45 +0,0 @@
-# encoding: utf-8
-require "spec_helper"
-require "logstash/util/worker_threads_default_printer"
-
-describe LogStash::Util::WorkerThreadsDefaultPrinter do
-  let(:settings)  { {} }
-  let(:collector) { [] }
-
-  subject { described_class.new(settings) }
-
-  before { subject.visit(collector) }
-
-  describe "the #visit method" do
-    context 'when the settings hash is empty' do
-      it 'adds nothing to the collector' do
-        subject.visit(collector)
-        expect(collector).to eq([])
-      end
-    end
-
-    context 'when the settings hash has both user and default content' do
-      let(:settings) { {:pipeline_workers => 42, :default_pipeline_workers => 5} }
-
-      it 'adds two strings' do
-        expect(collector).to eq(["User set pipeline workers: 42", "Default pipeline workers: 5"])
-      end
-    end
-
-    context 'when the settings hash has only user content' do
-      let(:settings) { {:pipeline_workers => 42} }
-
-      it 'adds a string with user set pipeline workers' do
-        expect(collector.first).to eq("User set pipeline workers: 42")
-      end
-    end
-
-    context 'when the settings hash has only default content' do
-      let(:settings) { {:default_pipeline_workers => 5} }
-
-      it 'adds a string with default pipeline workers' do
-        expect(collector.first).to eq("Default pipeline workers: 5")
-      end
-    end
-  end
-end
diff --git a/pkg/logstash.sysv b/pkg/logstash.sysv
index 25ec27f99fb..d971b4a405c 100755
--- a/pkg/logstash.sysv
+++ b/pkg/logstash.sysv
@@ -90,13 +90,13 @@ stop() {
     echo "Killing $name (pid $pid) with SIGTERM"
     kill -TERM $pid
     # Wait for it to exit.
-    for i in 1 2 3 4 5 ; do
+    for i in 1 2 3 4 5 6 7 8 9 ; do
       echo "Waiting $name (pid $pid) to die..."
       status || break
       sleep 1
     done
     if status ; then
-      if [ "$KILL_ON_STOP_TIMEOUT" -eq 1 ] ; then
+      if [[ $KILL_ON_STOP_TIMEOUT -eq 1 ]] ; then
         echo "Timeout reached. Killing $name (pid $pid) with SIGKILL. This may result in data loss."
         kill -KILL $pid
         echo "$name killed with SIGKILL."
@@ -142,7 +142,7 @@ configtest() {
   fi
 
   HOME=${LS_HOME}
-  export PATH HOME JAVA_OPTS LS_HEAP_SIZE LS_JAVA_OPTS LS_USE_GC_LOGGING
+  export PATH HOME
 
   test_args="--configtest -f ${LS_CONF_DIR} ${LS_OPTS}"
   $program ${test_args}
diff --git a/rakelib/artifacts.rake b/rakelib/artifacts.rake
index dcdbbf7f80b..bc3d086e105 100644
--- a/rakelib/artifacts.rake
+++ b/rakelib/artifacts.rake
@@ -13,6 +13,13 @@ namespace "artifact" do
       "lib/pluginmanager/**/*",
       "patterns/**/*",
       "vendor/??*/**/*",
+      # To include ruby-maven's hidden ".mvn" directory, we need to
+      # do add the line below. This directory contains a file called
+      # "extensions.xml", which loads the ruby DSL for POMs.
+      # Failing to include this file results in updates breaking for
+      # plugins which use jar-dependencies.
+      # See more in https://github.com/elastic/logstash/issues/4818
+      "vendor/??*/**/.mvn/**/*",
       "Gemfile",
       "Gemfile.jruby-1.9.lock",
     ]
diff --git a/spec/bootstrap/environment_spec.rb b/spec/bootstrap/environment_spec.rb
new file mode 100644
index 00000000000..069161072cc
--- /dev/null
+++ b/spec/bootstrap/environment_spec.rb
@@ -0,0 +1,31 @@
+# encoding: utf-8
+require "spec_helper"
+require "bootstrap/environment"
+
+describe LogStash::Environment do
+  describe "format_argv" do
+    context "when passing just irb/pry" do
+      before(:each) do
+        allow(subject).to receive(:puts)
+      end
+      ["pry", "irb"].each do |console|
+        it "transforms [\"#{console}\"] to --interactive switches" do
+          expect(subject.format_argv([console])).to eq(["--interactive", console])
+        end
+      end
+    end
+
+    context "when passing cli arguments" do
+      let(:argv) { ["--pipeline.workers", 4] }
+      let(:yml_settings) { ["--pipeline.workers", 2] }
+
+      before(:each) do
+        allow(subject).to receive(:fetch_yml_settings).and_return(yml_settings)
+      end
+
+      it "should place settings from yaml before settings from cli" do
+        expect(subject.format_argv(argv)).to eq(yml_settings + argv)
+      end
+    end
+  end
+end
