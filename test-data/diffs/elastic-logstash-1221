diff --git a/lib/cache.rb b/lib/cache.rb
new file mode 100644
index 00000000000..4c32d1be540
--- /dev/null
+++ b/lib/cache.rb
@@ -0,0 +1,320 @@
+#! /usr/bin/env ruby
+#
+# Copyright (C) 2002  Yoshinori K. Okuji <okuji@enbug.org>
+#
+# You may redistribute it and/or modify it under the same term as Ruby.
+
+# Cache manager based on the LRU algorithm.
+class Cache
+
+  CACHE_OBJECT = Struct.new('CacheObject', :content, :size, :atime)
+  CACHE_VERSION = '0.3'
+
+  include Enumerable
+  
+  def self.version
+    CACHE_VERSION
+  end
+
+  # initialize(max_obj_size = nil, max_size = nil, max_num = nil,
+  #            expiration = nil, &hook)
+  # initialize(hash, &hook)
+  def initialize(*args, &hook)
+    if args.size == 1 and args[0].kind_of?(Hash)
+      @max_obj_size = @max_size = @max_num = @expiration = nil
+      args[0].each do |k, v|
+	k = k.intern if k.respond_to?(:intern)
+	case k
+	when :max_obj_size
+	  @max_obj_size = v
+	when :max_size
+	  @max_size = v
+	when :max_num
+	  @max_num = v
+	when :expiration
+	  @expiration = v
+	end
+      end
+    else
+      @max_obj_size, @max_size, @max_num, @expiration = args
+    end
+
+    # Sanity checks.
+    if @max_obj_size and @max_size and @max_obj_size > @max_size
+      raise ArgumentError, "max_obj_size exceeds max_size (#{@max_obj_size} > #{@max_size})"
+    end
+    if @max_obj_size and @max_obj_size <= 0
+      raise ArgumentError, "invalid max_obj_size `#{@max_obj_size}'"
+    end
+    if @max_size and @max_size <= 0
+      raise ArgumentError, "invalid max_size `#{@max_size}'"
+    end
+    if @max_num and @max_num <= 0
+      raise ArgumentError, "invalid max_num `#{@max_num}'"
+    end
+    if @expiration and @expiration <= 0
+      raise ArgumentError, "invalid expiration `#{@expiration}'"
+    end
+    
+    @hook = hook
+    
+    @objs = {}
+    @size = 0
+    @list = []
+    
+    @hits = 0
+    @misses = 0
+  end
+
+  attr_reader :max_obj_size, :max_size, :max_num, :expiration
+
+  def cached?(key)
+    @objs.include?(key)
+  end
+  alias :include? :cached?
+  alias :member? :cached?
+  alias :key? :cached?
+  alias :has_key? :cached?
+
+  def cached_value?(val)
+    self.each_value do |v|
+      return true if v == val
+    end
+    false
+  end
+  alias :has_value? :cached_value?
+  alias :value? :cached_value?
+
+  def index(val)
+    self.each_pair do |k,v|
+      return k if v == val
+    end
+    nil
+  end
+
+  def keys
+    @objs.keys
+  end
+
+  def length
+    @objs.length
+  end
+  alias :size :length
+
+  def to_hash
+    @objs.dup
+  end
+
+  def values
+    @objs.collect {|key, obj| obj.content}
+  end
+  
+  def invalidate(key)
+    obj = @objs[key]
+    if obj
+      if @hook
+	@hook.call(key, obj.content)
+      end
+      @size -= obj.size
+      @objs.delete(key)
+      @list.each_index do |i|
+	if @list[i] == key
+	  @list.delete_at(i)
+	  break
+	end
+      end
+    elsif block_given?
+      return yield(key)
+    end
+    obj.content
+  end
+  alias :delete :invalidate
+  
+  def invalidate_all()
+    if @hook
+      @objs.each do |key, obj|
+	@hook.call(key, obj)
+      end
+    end
+
+    @objs.clear
+    @list.clear
+    @size = 0
+  end
+  alias :clear :invalidate_all
+  
+  def quiet_delete(key)
+    obj = @objs[key]
+    if obj
+      if @hook
+	#johnar: commenting out hook call
+	#@hook.call(key, obj.content)
+      end
+      @size -= obj.size
+      @objs.delete(key)
+      @list.each_index do |i|
+	if @list[i] == key
+	  @list.delete_at(i)
+	  break
+	end
+      end
+    elsif block_given?
+      return yield(key)
+    end
+    obj.content
+  end
+  alias :delete :invalidate
+  
+  def expire()
+    if @expiration
+      now = Time.now.to_i
+      @list.each_index do |i|
+	key = @list[i]
+	
+	break unless @objs[key].atime + @expiration <= now
+	self.invalidate(key)
+      end
+    end
+#    GC.start
+  end
+	
+  def [](key)
+    self.expire()
+    
+    unless @objs.include?(key)
+      @misses += 1
+      return nil
+    end
+    
+    obj = @objs[key]
+    obj.atime = Time.now.to_i
+
+    @list.each_index do |i|
+      if @list[i] == key
+	@list.delete_at(i)
+	break
+      end
+    end
+    @list.push(key)
+
+    @hits += 1
+    obj.content
+  end
+  
+  def []=(key, obj)
+    self.expire()
+    
+    if self.cached?(key)
+      #johnar: change to quiet_delete so hook isn't called on updates
+	  #self.invalidate(key)
+	  self.quiet_delete(key)
+    end
+
+    size = obj.to_s.size
+    if @max_obj_size and @max_obj_size < size
+      if $DEBUG
+	$stderr.puts("warning: `#{obj.inspect}' isn't cached because its size exceeds #{@max_obj_size}")
+      end
+      return obj
+    end
+    if @max_obj_size.nil? and @max_size and @max_size < size
+      if $DEBUG
+	$stderr.puts("warning: `#{obj.inspect}' isn't cached because its size exceeds #{@max_size}")
+      end
+      return obj
+    end
+      
+    if @max_num and @max_num == @list.size
+      self.invalidate(@list.first)
+    end
+
+    @size += size
+    if @max_size
+      while @max_size < @size
+	self.invalidate(@list.first)
+      end
+    end
+
+    @objs[key] = CACHE_OBJECT.new(obj, size, Time.now.to_i)
+    @list.push(key)
+
+    obj
+  end
+
+  def store(key, value)
+    self[key] = value
+  end
+
+  def each_pair
+    @objs.each do |key, obj|
+      yield key, obj.content
+    end
+    self
+  end
+  alias :each :each_pair
+
+  def each_key
+    @objs.each_key do |key|
+      yield key
+    end
+    self
+  end
+
+  def each_value
+    @objs.each_value do |obj|
+      yield obj.content
+    end
+    self
+  end
+
+  def empty?
+    @objs.empty?
+  end
+
+  def fetch(key, default = nil)
+    val = self[key]
+    if val.nil?
+      if default
+	val = self[key] = default
+      elsif block_given?
+	val = self[key] = yield(key)
+      else
+	raise IndexError, "invalid key `#{key}'"
+      end
+    end
+    val
+  end
+  
+  # The total size of cached objects, the number of cached objects,
+  # the number of cache hits, and the number of cache misses.
+  def statistics()
+    [@size, @list.size, @hits, @misses]
+  end
+end
+
+# Run a test, if executed.
+if __FILE__ == $0
+  cache = Cache.new(100 * 1024, 100 * 1024 * 1024, 256, 1)
+  1000.times do
+    key = rand(1000)
+    cache[key] = key.to_s
+  end
+  1000.times do
+    key = rand(1000)
+    puts cache[key]
+  end
+  sleep 1
+  1000.times do
+    key = rand(1000)
+    puts cache[key]
+  end
+  
+  stat = cache.statistics()
+  hits = stat[2]
+  misses = stat[3]
+  ratio = hits.to_f / (hits + misses)
+  
+  puts "Total size:\t#{stat[0]}"
+  puts "Number:\t\t#{stat[1]}"
+  puts "Hit ratio:\t#{ratio * 100}% (#{hits} / #{hits + misses})"
+end
diff --git a/lib/logstash/filters/multiline.rb b/lib/logstash/filters/multiline.rb
index 55ad67b0330..197695f709a 100644
--- a/lib/logstash/filters/multiline.rb
+++ b/lib/logstash/filters/multiline.rb
@@ -1,14 +1,23 @@
 # encoding: utf-8
+# multiline filter
+#
+# This filter will collapse multiline messages into a single event.
+# 
+
 require "logstash/filters/base"
 require "logstash/namespace"
 require "set"
+require "cache"  #rubygem 'ruby-cache'
+require "stud/interval" # gem stud
+
+# The multiline filter is for combining multiple events from a single source
+# into the same event.
 #
-# This filter will collapse multiline messages from a single source into one Logstash event.
-# 
 # The original goal of this filter was to allow joining of multi-line messages
 # from files into a single event. For example - joining java exception and
 # stacktrace messages into a single event.
 #
+# TODO(sissel): Document any issues?
 # The config looks like this:
 #
 #     filter {
@@ -20,18 +29,18 @@
 #       }
 #     }
 # 
-# The `pattern` should be a regexp which matches what you believe to be an indicator
-# that the field is part of an event consisting of multiple lines of log data.
+# The 'regexp' should match what you believe to be an indicator that
+# the field is part of a multi-line event
 #
-# The `what` must be "previous" or "next" and indicates the relation
-# to the multi-line event.
+# The 'what' must be "previous" or "next" and indicates the relation
+# to the multi-line event. "streamcache" is for reassembling ongoing streams when messages arrive out-of-order.
 #
-# The `negate` can be "true" or "false" (defaults to false). If "true", a 
+# The 'negate' can be "true" or "false" (defaults false). If true, a 
 # message not matching the pattern will constitute a match of the multiline
-# filter and the `what` will be applied. (vice-versa is also true)
+# filter and the what will be applied. (vice-versa is also true)
 #
-# For example, Java stack traces are multiline and usually have the message
-# starting at the far-left, with each subsequent line indented. Do this:
+# For example, java stack traces are multiline and usually have the message
+# starting at the far-left, then each subsequent line indented. Do this:
 # 
 #     filter {
 #       multiline {
@@ -40,7 +49,7 @@
 #         what => "previous"
 #       }
 #     }
-#
+#     
 # This says that any line starting with whitespace belongs to the previous line.
 #
 # Another example is C line continuations (backslash). Here's how to do that:
@@ -53,25 +62,28 @@
 #       }
 #     }
 #     
-# This says that any line ending with a backslash should be combined with the
-# following line.
-#
 class LogStash::Filters::Multiline < LogStash::Filters::Base
 
   config_name "multiline"
   milestone 3
 
-  # The regular expression to match.
+  # The regular expression to match
   config :pattern, :validate => :string, :required => true
 
   # If the pattern matched, does event belong to the next or previous event?
-  config :what, :validate => ["previous", "next"], :required => true
+  config :what, :validate => ["previous", "next", "streamcache"], :required => true
 
+  # Cache size, the maximum number of cached messages
+  config :cache_size, :validate => :number, :default => 50000
+  
+  # Cache TTL (seconds)
+  config :cache_ttl, :validate => :number, :default => 5
+  
   # Negate the regexp pattern ('if not matched')
   config :negate, :validate => :boolean, :default => false
   
   # The stream identity is how the multiline filter determines which stream an
-  # event belongs to. This is generally used for differentiating, say, events
+  # event belongs. This is generally used for differentiating, say, events
   # coming from multiple files in the same file input, or multiple connections
   # coming from a tcp input.
   #
@@ -84,7 +96,7 @@ class LogStash::Filters::Multiline < LogStash::Filters::Base
   # case, you can use "%{@source_host}.%{@type}" instead.
   config :stream_identity , :validate => :string, :default => "%{host}.%{path}.%{type}"
   
-  # Logstash ships by default with a bunch of patterns, so you don't
+  # logstash ships by default with a bunch of patterns, so you don't
   # necessarily need to define this yourself unless you are adding additional
   # patterns.
   #
@@ -114,6 +126,29 @@ def initialize(config = {})
     # This filter needs to keep state.
     @types = Hash.new { |h,k| h[k] = [] }
     @pending = Hash.new
+	
+	# Hook is called when cached objects are invalidated.
+	# This will send reassembled messages back to the pipeline.
+	hook = Proc.new {|key, event| 
+		@logger.info("Calling hook for event output.", :key => key, :event => event)
+		filter_matched(event)
+	}
+	
+	# Create cache, set the maximum number of cached objects and the expiration time 
+	@cache = Cache.new(nil, nil, @cache_size, @cache_ttl, &hook)
+	@logger.debug("StreamCache created.")
+	
+	# this will periodically go through and wipe out expired cache members.
+	def cache_expire
+		@logger.debug("Expiring cache items...")
+		@cache.expire
+	end
+	
+	# Set up the periodic cache expiry thread. Depending on event arrival timing, expiry can take up to 2x TTL time... How to fix?  expire more often?  1/2 the TTL time? Every second?
+    @expire_thread = Thread.new { Stud.interval(@cache_ttl) { cache_expire } }
+	
+
+
   end # def initialize
 
   public
@@ -157,8 +192,7 @@ def filter(event)
     key = event.sprintf(@stream_identity)
     pending = @pending[key]
 
-    @logger.debug("Multiline", :pattern => @pattern, :message => event["message"],
-                  :match => match, :negate => @negate)
+    @logger.debug("Multiline", :pattern => @pattern, :message => event["message"], :match => match, :negate => @negate)
 
     # Add negate option
     match = (match and !@negate) || (!match and @negate)
@@ -179,7 +213,7 @@ def filter(event)
         # this line is not part of the previous event
         # if we have a pending event, it's done, send it.
         # put the current event into pending
-        if pending
+		if pending
           tmp = event.to_hash
           event.overwrite(pending)
           @pending[key] = LogStash::Event.new(tmp)
@@ -209,6 +243,29 @@ def filter(event)
           @pending.delete(key)
         end
       end # if/else match
+	when "streamcache"
+		
+		key = event.sprintf(@stream_identity)
+		cached = @cache[key]
+		#first lookup the stream_identity to see if the stream is already in cache.
+		if cached
+			#if it is, append new message and re-cache
+			event.tag "multiline"
+			cached.append(event)
+			#flatten the event before storing
+			cached["message"] = cached["message"].join("\n") if cached["message"].is_a?(Array)
+			cached["@timestamp"] = cached["@timestamp"].first if cached["@timestamp"].is_a?(Array)
+			@logger.debug("Appending cache item 'what'.", :what => key, :event => cached)
+			@cache.store(key, cached)
+			event.cancel
+		
+		else			
+			#if it's not, add this message to the cache
+			cached = LogStash::Event.new(event.to_hash)
+			@logger.debug("Adding cache item 'what'.", :what => key)
+			@cache.store(key, cached)
+			event.cancel
+		end
     else
       # TODO(sissel): Make this part of the 'register' method.
       @logger.warn("Unknown multiline 'what' value.", :what => @what)
@@ -217,10 +274,16 @@ def filter(event)
     if !event.cancelled?
       event["message"] = event["message"].join("\n") if event["message"].is_a?(Array)
       event["@timestamp"] = event["@timestamp"].first if event["@timestamp"].is_a?(Array)
+	  @logger.info("Outputting event", :message => event["message"])
       filter_matched(event) if match
     end
+	 
   end # def filter
 
+
+ 
+   
+  
   # Flush any pending messages. This is generally used for unit testing only.
   #
   # Note: flush is disabled now; it is preferable to use the multiline codec.
@@ -234,4 +297,6 @@ def __flush
     @pending.clear
     return events
   end # def flush
+  
+ 
 end # class LogStash::Filters::Multiline
