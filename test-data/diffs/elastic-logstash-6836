diff --git a/config/logstash.yml b/config/logstash.yml
index 1cdec6f74d6..c50e6bd614c 100644
--- a/config/logstash.yml
+++ b/config/logstash.yml
@@ -131,6 +131,16 @@
 #
 # queue.checkpoint.interval: 1000
 #
+# ------------ Dead-Letter Queue Settings --------------
+# Flag to turn on dead-letter queue.
+#
+# dead_letter_queue.enable: false
+#
+# If using dead_letter_queue.enable: true, the directory path where the data files will be stored.
+# Default is path.data/dead_letter_queue
+#
+# path.dead_letter_queue:
+#
 # ------------ Metrics Settings --------------
 #
 # Bind address for the metrics REST endpoint
diff --git a/docs/static/settings-file.asciidoc b/docs/static/settings-file.asciidoc
index a09ab1a9b1c..62286435039 100644
--- a/docs/static/settings-file.asciidoc
+++ b/docs/static/settings-file.asciidoc
@@ -134,6 +134,14 @@ The `logstash.yml` file includes the following settings:
 | The interval in milliseconds when a checkpoint is forced on the head page when persistent queues are enabled (`queue.type: persisted`). Specify `queue.checkpoint.interval: 0` for no periodic checkpoint.
 | 1000
 
+| `dead_letter_queue.enable`
+| Flag to instruct Logstash to enable the DLQ feature supported by plugins.
+| `false`
+
+| `path.dead_letter_queue`
+| The directory path where the data files will be stored for the dead-letter queue.
+| `path.data/dead_letter_queue`
+
 | `http.host`
 | The bind address for the metrics REST endpoint.
 | `"127.0.0.1"`
diff --git a/logstash-core/lib/logstash/environment.rb b/logstash-core/lib/logstash/environment.rb
index 8f5f9d33380..c84d94b5926 100644
--- a/logstash-core/lib/logstash/environment.rb
+++ b/logstash-core/lib/logstash/environment.rb
@@ -48,6 +48,7 @@ module Environment
             Setting::Numeric.new("queue.checkpoint.acks", 1024), # 0 is unlimited
             Setting::Numeric.new("queue.checkpoint.writes", 1024), # 0 is unlimited
             Setting::Numeric.new("queue.checkpoint.interval", 1000), # 0 is no time-based checkpointing
+            Setting::Boolean.new("dead_letter_queue.enable", false),
             Setting::TimeValue.new("slowlog.threshold.warn", "-1"),
             Setting::TimeValue.new("slowlog.threshold.info", "-1"),
             Setting::TimeValue.new("slowlog.threshold.debug", "-1"),
@@ -57,13 +58,21 @@ module Environment
   # Compute the default queue path based on `path.data`
   default_queue_file_path = ::File.join(SETTINGS.get("path.data"), "queue")
   SETTINGS.register Setting::WritableDirectory.new("path.queue", default_queue_file_path)
-  
+  # Compute the default dead_letter_queue path based on `path.data`
+  default_dlq_file_path = ::File.join(SETTINGS.get("path.data"), "dead_letter_queue")
+  SETTINGS.register Setting::WritableDirectory.new("path.dead_letter_queue", default_dlq_file_path)
+
   SETTINGS.on_post_process do |settings|
     # If the data path is overridden but the queue path isn't recompute the queue path
     # We need to do this at this stage because of the weird execution order
     # our monkey-patched Clamp follows
-    if settings.set?("path.data") && !settings.set?("path.queue")
-      settings.set_value("path.queue", ::File.join(settings.get("path.data"), "queue"))
+    if settings.set?("path.data")
+      if !settings.set?("path.queue")
+        settings.set_value("path.queue", ::File.join(settings.get("path.data"), "queue"))
+      end
+      if !settings.set?("path.dead_letter_queue")
+        settings.set_value("path.dead_letter_queue", ::File.join(settings.get("path.data"), "dead_letter_queue"))
+      end
     end
   end
 
diff --git a/logstash-core/lib/logstash/filter_delegator.rb b/logstash-core/lib/logstash/filter_delegator.rb
index 092f01c2542..083ba9b5735 100644
--- a/logstash-core/lib/logstash/filter_delegator.rb
+++ b/logstash-core/lib/logstash/filter_delegator.rb
@@ -4,6 +4,7 @@ module LogStash
   class FilterDelegator
     extend Forwardable
     DELEGATED_METHODS = [
+      :do_register,
       :register,
       :close,
       :threadsafe?,
diff --git a/logstash-core/lib/logstash/output_delegator.rb b/logstash-core/lib/logstash/output_delegator.rb
index 23166f0cf0a..cd9417e0933 100644
--- a/logstash-core/lib/logstash/output_delegator.rb
+++ b/logstash-core/lib/logstash/output_delegator.rb
@@ -15,11 +15,11 @@ def initialize(logger, output_class, metric, strategy_registry, plugin_args)
 
     raise ArgumentError, "No strategy registry specified" unless strategy_registry
     raise ArgumentError, "No ID specified! Got args #{plugin_args}" unless id
-    
+
     @strategy = strategy_registry.
                   class_for(self.concurrency).
                   new(@logger, @output_class, @metric, plugin_args)
-    
+
     @namespaced_metric = metric.namespace(id.to_sym)
     @namespaced_metric.gauge(:name, config_name)
     @metric_events = @namespaced_metric.namespace(:events)
@@ -41,6 +41,10 @@ def register
     @strategy.register
   end
 
+  def do_register(dlq_manager=nil)
+    @strategy.do_register(dlq_manager)
+  end
+
   def multi_receive(events)
     @metric_events.increment(:in, events.length)
     clock = @metric_events.time(:duration_in_millis)
diff --git a/logstash-core/lib/logstash/output_delegator_strategies/legacy.rb b/logstash-core/lib/logstash/output_delegator_strategies/legacy.rb
index 81f695afc9d..9023dce89b6 100644
--- a/logstash-core/lib/logstash/output_delegator_strategies/legacy.rb
+++ b/logstash-core/lib/logstash/output_delegator_strategies/legacy.rb
@@ -1,7 +1,7 @@
 # Remove this in Logstash 6.0
 module LogStash module OutputDelegatorStrategies class Legacy
   attr_reader :worker_count, :workers
-  
+
   def initialize(logger, klass, metric, plugin_args)
     @worker_count = (plugin_args["workers"] || 1).to_i
     @workers = @worker_count.times.map { klass.new(plugin_args) }
@@ -9,11 +9,17 @@ def initialize(logger, klass, metric, plugin_args)
     @worker_queue = SizedQueue.new(@worker_count)
     @workers.each {|w| @worker_queue << w}
   end
-  
+
   def register
     @workers.each(&:register)
   end
-  
+
+  def do_register(dlq_manager=nil)
+    @workers.each do |w|
+      w.do_register(dlq_manager)
+    end
+  end
+
   def multi_receive(events)
     worker = @worker_queue.pop
     worker.multi_receive(events)
diff --git a/logstash-core/lib/logstash/output_delegator_strategies/shared.rb b/logstash-core/lib/logstash/output_delegator_strategies/shared.rb
index 9650cf7ee22..8dd5007713a 100644
--- a/logstash-core/lib/logstash/output_delegator_strategies/shared.rb
+++ b/logstash-core/lib/logstash/output_delegator_strategies/shared.rb
@@ -3,19 +3,23 @@ def initialize(logger, klass, metric, plugin_args)
     @output = klass.new(plugin_args)
     @output.metric = metric
   end
-  
+
   def register
     @output.register
   end
 
+  def do_register(dlq_manager=nil)
+    @output.do_register(dlq_manager)
+  end
+
   def multi_receive(events)
     @output.multi_receive(events)
   end
 
-  def do_close    
+  def do_close
     @output.do_close
   end
 
-  ::LogStash::OutputDelegatorStrategyRegistry.instance.register(:shared, self)  
+  ::LogStash::OutputDelegatorStrategyRegistry.instance.register(:shared, self)
 end; end; end
 
diff --git a/logstash-core/lib/logstash/output_delegator_strategies/single.rb b/logstash-core/lib/logstash/output_delegator_strategies/single.rb
index d576a22df6f..5e13487de73 100644
--- a/logstash-core/lib/logstash/output_delegator_strategies/single.rb
+++ b/logstash-core/lib/logstash/output_delegator_strategies/single.rb
@@ -8,7 +8,11 @@ def initialize(logger, klass, metric, plugin_args)
   def register
     @output.register
   end
-  
+
+  def do_register(dlq_manager=nil)
+    @output.do_register(dlq_manager)
+  end
+
   def multi_receive(events)
     @mutex.synchronize do
       @output.multi_receive(events)
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index ac940a86ac0..2015d125566 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -1,4 +1,3 @@
-# encoding: utf-8
 require "thread"
 require "stud/interval"
 require "concurrent"
@@ -27,14 +26,14 @@ module LogStash; class BasePipeline
   include LogStash::Util::Loggable
 
   attr_reader :config_str, :config_hash, :inputs, :filters, :outputs, :pipeline_id, :lir
-  
+
   def initialize(config_str, settings = SETTINGS)
     @logger = self.logger
     @config_str = config_str
     @config_hash = Digest::SHA1.hexdigest(@config_str)
-    
+
     @lir = compile_lir
-    
+
     # Every time #plugin is invoked this is incremented to give each plugin
     # a unique id when auto-generating plugin ids
     @plugin_counter ||= 0
@@ -67,7 +66,7 @@ def initialize(config_str, settings = SETTINGS)
       raise e
     end
   end
-  
+
   def compile_lir
     LogStash::Compiler.compile_pipeline(self.config_str)
   end
@@ -128,7 +127,8 @@ module LogStash; class Pipeline < BasePipeline
     :metric,
     :filter_queue_client,
     :input_queue_client,
-    :queue
+    :queue,
+    :dlq_manager
 
   MAX_INFLIGHT_WARN_THRESHOLD = 10_000
 
@@ -165,6 +165,15 @@ def initialize(config_str, settings = SETTINGS, namespaced_metric = nil)
     )
     @drain_queue =  @settings.get_value("queue.drain")
 
+    @dlq_manager = nil
+    if @settings.get_value("dead_letter_queue.enable")
+      managed_path = ::File.join(@settings.get_value("path.dead_letter_queue"), @pipeline_id)
+      managed_path = java.nio.file.Paths.get(managed_path)
+      max_segment_size = 10485760 # 10MB
+      max_queue_size = java.lang.Long::MAX_VALUE
+      @dlq_manager = org.logstash.common.io.DeadLetterQueueWriteManager.new(managed_path, max_segment_size, max_queue_size)
+    end
+
     @events_filtered = Concurrent::AtomicFixnum.new(0)
     @events_consumed = Concurrent::AtomicFixnum.new(0)
 
@@ -174,8 +183,6 @@ def initialize(config_str, settings = SETTINGS, namespaced_metric = nil)
     @running = Concurrent::AtomicBoolean.new(false)
     @flushing = Concurrent::AtomicReference.new(false)
   end # def initialize
-  
-  
 
   def ready?
     @ready.value
@@ -244,6 +251,7 @@ def run
   def close
     @filter_queue_client.close
     @queue.close
+    @dlq_manager.close unless @dlq_manager.nil?
   end
 
   def transition_to_running
@@ -265,8 +273,8 @@ def stopped?
   # register_plugin simply calls the plugin #register method and catches & logs any error
   # @param plugin [Plugin] the plugin to register
   # @return [Plugin] the registered plugin
-  def register_plugin(plugin)
-    plugin.register
+  def register_plugin(plugin, dlq_manager=nil)
+    plugin.do_register(dlq_manager)
     plugin
   rescue => e
     @logger.error("Error registering plugin", :plugin => plugin.inspect, :error => e.message)
@@ -275,9 +283,9 @@ def register_plugin(plugin)
 
   # register_plugins calls #register_plugin on the plugins list and upon exception will call Plugin#do_close on all registered plugins
   # @param plugins [Array[Plugin]] the list of plugins to register
-  def register_plugins(plugins)
+  def register_plugins(plugins, dlq_manager=nil)
     registered = []
-    plugins.each { |plugin| registered << register_plugin(plugin) }
+    plugins.each { |plugin| registered << register_plugin(plugin, dlq_manager) }
   rescue => e
     registered.each(&:do_close)
     raise e
@@ -286,8 +294,8 @@ def register_plugins(plugins)
   def start_workers
     @worker_threads.clear # In case we're restarting the pipeline
     begin
-      register_plugins(@outputs)
-      register_plugins(@filters)
+      register_plugins(@outputs, @dlq_manager)
+      register_plugins(@filters, @dlq_manager)
 
       pipeline_workers = safe_pipeline_worker_count
       batch_size = @settings.get("pipeline.batch.size")
@@ -351,6 +359,7 @@ def worker_loop(batch_size, batch_delay)
       filter_batch(batch)
       flush_filters_to_batch(batch, :final => false) if signal.flush?
       output_batch(batch)
+
       @filter_queue_client.close_batch(batch)
 
       # keep break at end of loop, after the read_batch operation, some pipeline specs rely on this "final read_batch" before shutdown.
@@ -407,7 +416,6 @@ def output_batch(batch)
     output_events_map.each do |output, events|
       output.multi_receive(events)
     end
-    
     @filter_queue_client.add_output_metrics(batch)
   end
 
@@ -427,7 +435,7 @@ def start_inputs
     @inputs += moreinputs
 
     # first make sure we can register all input plugins
-    register_plugins(@inputs)
+    register_plugins(@inputs, @dlq_manager)
 
     # then after all input plugins are successfully registered, start them
     @inputs.each { |input| start_input(input) }
diff --git a/logstash-core/lib/logstash/plugin.rb b/logstash-core/lib/logstash/plugin.rb
index 9d448c30dba..bca46d71d40 100644
--- a/logstash-core/lib/logstash/plugin.rb
+++ b/logstash-core/lib/logstash/plugin.rb
@@ -44,7 +44,7 @@ def eql?(other)
     self.class.name == other.class.name && @params == other.params
   end
 
-  def initialize(params=nil)
+  def initialize(params)
     @logger = self.logger
     # need to access settings statically because plugins are initialized in config_ast with no context.
     settings = LogStash::SETTINGS
@@ -58,6 +58,14 @@ def initialize(params=nil)
     @params["id"] ||= "#{self.class.config_name}_#{SecureRandom.uuid}"
   end
 
+  def register
+  end
+
+  def do_register(dlq_manager=nil)
+    @dlq_manager = dlq_manager
+    register
+  end
+
   # Return a uniq ID for this plugin configuration, by default
   # we will generate a UUID
   #
@@ -122,12 +130,20 @@ def metric
                          LogStash::Instrument::NamespacedNullMetric.new(@metric, :null)
                        end
   end
+
   # return the configured name of this plugin
   # @return [String] The name of the plugin defined by `config_name`
   def config_name
     self.class.config_name
   end
 
+  # commit event to dlq
+  def dlq_commit(event, reason)
+    if @dlq_manager
+      @dlq_manager.writeEntry(event.to_java, config_name, id, reason)
+    end
+  end
+
   # This is keep for backward compatibility, the logic was moved into the registry class
   # but some plugins use this method to return a specific instance on lookup
   #
diff --git a/logstash-core/lib/logstash/util/wrapped_acked_queue.rb b/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
index 9d34869a8dc..29000c2136d 100644
--- a/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
+++ b/logstash-core/lib/logstash/util/wrapped_acked_queue.rb
@@ -201,6 +201,7 @@ def close_batch(batch)
       end
 
       def start_clock
+        return if @event_metric.nil? || @pipeline_metric.nil?
         @inflight_clocks[Thread.current] = [
           @event_metric.time(:duration_in_millis),
           @pipeline_metric.time(:duration_in_millis)
@@ -226,11 +227,13 @@ def add_starting_metrics(batch)
       end
 
       def add_filtered_metrics(batch)
+        return if @event_metric.nil? || @pipeline_metric.nil?
         @event_metric.increment(:filtered, batch.filtered_size)
         @pipeline_metric.increment(:filtered, batch.filtered_size)
       end
 
       def add_output_metrics(batch)
+        return if @event_metric.nil? || @pipeline_metric.nil?
         @event_metric.increment(:out, batch.filtered_size)
         @pipeline_metric.increment(:out, batch.filtered_size)
       end
diff --git a/logstash-core/spec/logstash/agent_spec.rb b/logstash-core/spec/logstash/agent_spec.rb
index 7c40baab865..6dd3a478cdf 100644
--- a/logstash-core/spec/logstash/agent_spec.rb
+++ b/logstash-core/spec/logstash/agent_spec.rb
@@ -456,8 +456,8 @@
     # Theses values are compared with what we store in the metric store.
     class DummyOutput2 < LogStash::Outputs::DroppingDummyOutput; end
 
-    let!(:dummy_output) { LogStash::Outputs::DroppingDummyOutput.new }
-    let!(:dummy_output2) { DummyOutput2.new }
+    let!(:dummy_output) { LogStash::Outputs::DroppingDummyOutput.new({}) }
+    let!(:dummy_output2) { DummyOutput2.new({}) }
     let(:initial_generator_threshold) { 1000 }
     let(:pipeline_thread) do
       Thread.new do
diff --git a/logstash-core/spec/logstash/output_delegator_spec.rb b/logstash-core/spec/logstash/output_delegator_spec.rb
index e86c0556f71..3c5dce050f9 100644
--- a/logstash-core/spec/logstash/output_delegator_spec.rb
+++ b/logstash-core/spec/logstash/output_delegator_spec.rb
@@ -24,7 +24,7 @@
       allow(out_klass).to receive(:name).and_return("example")
       allow(out_klass).to receive(:concurrency).with(any_args).and_return concurrency
       allow(out_klass).to receive(:config_name).and_return("dummy_plugin")
-      allow(out_inst).to receive(:register)
+      allow(out_inst).to receive(:do_register)
       allow(out_inst).to receive(:multi_receive)
       allow(out_inst).to receive(:metric=).with(any_args)
       allow(out_inst).to receive(:id).and_return("a-simple-plugin")
@@ -44,7 +44,7 @@
 
     context "after having received a batch of events" do
       before do
-        subject.register
+        subject.do_register
       end
 
       it "should pass the events through" do
@@ -68,11 +68,11 @@
 
     describe "closing" do
       before do
-        subject.register
+        subject.do_register
       end
 
       it "should register the output plugin instance on register" do
-        expect(out_inst).to have_received(:register)
+        expect(out_inst).to have_received(:do_register)
       end
 
       it "should close the output plugin instance when closing" do
diff --git a/logstash-core/spec/logstash/pipeline_dlq_commit_spec.rb b/logstash-core/spec/logstash/pipeline_dlq_commit_spec.rb
new file mode 100644
index 00000000000..f93a61459e4
--- /dev/null
+++ b/logstash-core/spec/logstash/pipeline_dlq_commit_spec.rb
@@ -0,0 +1,138 @@
+# encoding: utf-8
+require "spec_helper"
+require "tmpdir"
+
+class DLQCommittingInput < LogStash::Inputs::Base
+  config_name "dlq_commit"
+  milestone 2
+
+  def register
+  end
+
+  def run(queue)
+    (0..9).each do |i|
+      event = LogStash::Event.new({"i" => i})
+      @codec.decode(event) do |event|
+        dlq_commit(event, "testing input")
+        queue << event
+      end
+    end
+  end
+
+  def close
+  end
+end
+
+class DLQCommittingCodec < LogStash::Codecs::Base
+  config_name "dlq_commit"
+  milestone 2
+
+  def decode(data)
+    dlq_commit(data, "testing codec#decode")
+    yield data
+  end
+
+  def encode(event)
+    dlq_commit(event, "testing codec#encode")
+    @on_event.call(event, "foobar")
+  end
+
+  def close
+  end
+end
+
+class DLQCommittingFilter < LogStash::Filters::Base
+  config_name "dlq_commit"
+  milestone 2
+
+  def register() end
+
+  def filter(event)
+    dlq_commit(event, "testing filter")
+  end
+
+  def threadsafe?() true; end
+
+  def close() end
+end
+
+class DLQCommittingOutput < LogStash::Outputs::Base
+  config_name "dlq_commit"
+  milestone 2
+
+  def register
+    @codec.on_event do |event, data|
+      dlq_commit(event, "testing output")
+    end
+  end
+
+  def receive(event)
+    @codec.encode(event)
+  end
+
+  def threadsafe?() true; end
+
+  def close() end
+end
+
+describe LogStash::Pipeline do
+  let(:pipeline_settings_obj) { LogStash::SETTINGS }
+  let(:pipeline_id) { "test" }
+  let(:pipeline_settings) do
+    {
+      "pipeline.workers" => 2,
+      "pipeline.id" => pipeline_id,
+      "dead_letter_queue.enable" => true,
+      "path.dead_letter_queue" => Dir.mktmpdir
+    }
+  end
+  let(:metric) { LogStash::Instrument::Metric.new(LogStash::Instrument::Collector.new) }
+  let(:test_config) {
+    <<-eos
+        input {
+          dlq_commit { codec => dlq_commit }
+        }
+
+        filter {
+          dlq_commit {}
+        }
+
+        output {
+          dlq_commit { codec => dlq_commit }
+        }
+    eos
+  }
+
+  subject { LogStash::Pipeline.new(test_config, pipeline_settings_obj, metric) }
+
+  before(:each) do
+    pipeline_settings.each {|k, v| pipeline_settings_obj.set(k, v) }
+    allow(LogStash::Plugin).to receive(:lookup).with("input", "dlq_commit").and_return(DLQCommittingInput)
+    allow(LogStash::Plugin).to receive(:lookup).with("codec", "dlq_commit").and_return(DLQCommittingCodec)
+    allow(LogStash::Plugin).to receive(:lookup).with("filter", "dlq_commit").and_return(DLQCommittingFilter)
+    allow(LogStash::Plugin).to receive(:lookup).with("output", "dlq_commit").and_return(DLQCommittingOutput)
+  end
+
+  after(:each) do
+    FileUtils.remove_entry pipeline_settings["path.dead_letter_queue"]
+  end
+
+
+  it "executes dlq_commit from inputs/filters/outputs only. no codecs" do
+    subject.run
+    subject.close
+    dlq_path = java.nio.file.Paths.get(pipeline_settings_obj.get("path.dead_letter_queue"), pipeline_id)
+    dlq_reader = org.logstash.common.io.DeadLetterQueueReadManager.new(dlq_path)
+    commit_count = 0
+    (0..30).each do |i|
+      entry = dlq_reader.pollEntry(40)
+      if i < 30
+        commit_count += 1
+      else
+        expect(i).to eq(30)
+        expect(entry).to be_nil
+      end
+    end
+    expect(commit_count).to eq(30)
+  end
+end
diff --git a/logstash-core/spec/logstash/plugin_spec.rb b/logstash-core/spec/logstash/plugin_spec.rb
index c6eda09c5ac..882eeadf0cb 100644
--- a/logstash-core/spec/logstash/plugin_spec.rb
+++ b/logstash-core/spec/logstash/plugin_spec.rb
@@ -311,7 +311,7 @@ def register
       context "when no metric is set to the plugin" do
         context "when `enable_metric` is TRUE" do
           it "recording metric should not raise an exception" do
-            expect { subject.register }.not_to raise_error
+            expect { subject.do_register }.not_to raise_error
           end
 
           it "should use a `NullMetric`" do
@@ -323,7 +323,7 @@ def register
           let(:config) { { "enable_metric" => false } }
 
           it "recording metric should not raise an exception" do
-            expect { subject.register }.not_to raise_error
+            expect { subject.do_register }.not_to raise_error
           end
 
           it "should use a `NullMetric`" do
@@ -341,7 +341,7 @@ def register
           end
 
           it "recording metric should not raise an exception" do
-            expect { subject.register }.not_to raise_error
+            expect { subject.do_register }.not_to raise_error
           end
 
           it "should use the configured metric" do
@@ -353,7 +353,7 @@ def register
           let(:config) { { "enable_metric" => false } }
 
           it "recording metric should not raise an exception" do
-            expect { subject.register }.not_to raise_error
+            expect { subject.do_register }.not_to raise_error
           end
 
           it "should use a `NullMetric`" do
diff --git a/logstash-core/spec/logstash/runner_spec.rb b/logstash-core/spec/logstash/runner_spec.rb
index e64412ebdc1..73f8647baad 100644
--- a/logstash-core/spec/logstash/runner_spec.rb
+++ b/logstash-core/spec/logstash/runner_spec.rb
@@ -165,38 +165,56 @@ def run(args); end
       allow(pipeline).to receive(:run).and_return(task)
       allow(pipeline).to receive(:shutdown)
     end
-    
+
     context "when :path.data is defined by the user" do
       let(:test_data_path) { "/tmp/ls-test-data" }
       let(:test_queue_path) { test_data_path + "/" + "queue" }
-      
+      let(:test_dlq_path) { test_data_path + "/" + "dead_letter_queue" }
+
       it "should set data paths" do
         expect(LogStash::Agent).to receive(:new) do |settings|
           expect(settings.get("path.data")).to eq(test_data_path)
           expect(settings.get("path.queue")).to eq(test_queue_path)
+          expect(settings.get("path.dead_letter_queue")).to eq(test_dlq_path)
         end
-        
+
         args = ["--path.data", test_data_path, "-e", pipeline_string]
         subject.run("bin/logstash", args)
       end
-      
+
       context "and path.queue is manually set" do
         let(:queue_override_path) { "/tmp/queue-override_path" }
-        
+
         it "should set data paths" do
           expect(LogStash::Agent).to receive(:new) do |settings|
             expect(settings.get("path.data")).to eq(test_data_path)
             expect(settings.get("path.queue")).to eq(queue_override_path)
           end
-          
+
           LogStash::SETTINGS.set("path.queue", queue_override_path)
-          
+
+          args = ["--path.data", test_data_path, "-e", pipeline_string]
+          subject.run("bin/logstash", args)
+        end
+      end
+
+      context "and path.dead_letter_queue is manually set" do
+        let(:queue_override_path) { "/tmp/queue-override_path" }
+
+        it "should set data paths" do
+          expect(LogStash::Agent).to receive(:new) do |settings|
+            expect(settings.get("path.data")).to eq(test_data_path)
+            expect(settings.get("path.dead_letter_queue")).to eq(queue_override_path)
+          end
+
+          LogStash::SETTINGS.set("path.dead_letter_queue", queue_override_path)
+
           args = ["--path.data", test_data_path, "-e", pipeline_string]
           subject.run("bin/logstash", args)
         end
       end
     end
-    
+
     context "when :http.host is defined by the user" do
       it "should pass the value to the webserver" do
         expect(LogStash::Agent).to receive(:new) do |settings|
diff --git a/logstash-core/spec/support/mocks_classes.rb b/logstash-core/spec/support/mocks_classes.rb
index a69b89bc821..ed9c3839c5c 100644
--- a/logstash-core/spec/support/mocks_classes.rb
+++ b/logstash-core/spec/support/mocks_classes.rb
@@ -8,6 +8,14 @@ module Inputs
     class DummyInput < LogStash::Inputs::Base
       config_name "dummyinput"
 
+      attr_reader :num_closes, :events
+
+      def initialize(params={})
+        super
+        @num_closes = 0
+        @events = []
+      end
+
       def run(queue)
         # noop
       end
diff --git a/logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriteManager.java b/logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriteManager.java
index 3a822fc2b61..b2ca5308748 100644
--- a/logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriteManager.java
+++ b/logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriteManager.java
@@ -21,6 +21,8 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.logstash.DLQEntry;
+import org.logstash.Event;
+import org.logstash.Timestamp;
 
 import java.io.IOException;
 import java.nio.channels.FileChannel;
@@ -46,6 +48,7 @@ public class DeadLetterQueueWriteManager {
     private RecordIOWriter currentWriter;
     private long currentQueueSize;
     private int currentSegmentIndex;
+    private Timestamp lastEntryTimestamp;
 
     /**
      *
@@ -54,6 +57,8 @@ public class DeadLetterQueueWriteManager {
      * @throws IOException
      */
     public DeadLetterQueueWriteManager(Path queuePath, long maxSegmentSize, long maxQueueSize) throws IOException {
+        // ensure path exists, create it otherwise.
+        Files.createDirectories(queuePath);
         // check that only one instance of the writer is open in this configured path
         Path lockFilePath = queuePath.resolve(LOCK_FILE);
         boolean isNewlyCreated = lockFilePath.toFile().createNewFile();
@@ -77,6 +82,7 @@ public DeadLetterQueueWriteManager(Path queuePath, long maxSegmentSize, long max
                 .mapToInt(Integer::parseInt)
                 .max().orElse(0);
         this.currentWriter = nextWriter();
+        this.lastEntryTimestamp = Timestamp.now();
     }
 
     private long getStartupQueueSize() throws IOException {
@@ -99,11 +105,25 @@ static Stream<Path> getSegmentPaths(Path path) throws IOException {
         return Files.list(path).filter((p) -> p.toString().endsWith(".log"));
     }
 
-    public synchronized void writeEntry(DLQEntry event) throws IOException {
-        byte[] record = event.serialize();
+    public synchronized void writeEntry(DLQEntry entry) throws IOException {
+        innerWriteEntry(entry);
+    }
+
+    public synchronized void writeEntry(Event event, String pluginName, String pluginId, String reason) throws IOException {
+        Timestamp entryTimestamp = Timestamp.now();
+        if (entryTimestamp.getTime().isBefore(lastEntryTimestamp.getTime())) {
+            entryTimestamp = lastEntryTimestamp;
+        }
+        DLQEntry entry = new DLQEntry(event, pluginName, pluginId, reason);
+        innerWriteEntry(entry);
+        lastEntryTimestamp = entryTimestamp;
+    }
+
+    private void innerWriteEntry(DLQEntry entry) throws IOException {
+        byte[] record = entry.serialize();
         int eventPayloadSize = RECORD_HEADER_SIZE + record.length;
         if (currentQueueSize + eventPayloadSize > maxQueueSize) {
-            logger.error("cannot write event to DLQ, no space available");
+            logger.error("cannot write event to DLQ: reached maxQueueSize of " + maxQueueSize);
             return;
         } else if (currentWriter.getPosition() + eventPayloadSize > maxSegmentSize) {
             currentWriter.close();
@@ -112,6 +132,7 @@ public synchronized void writeEntry(DLQEntry event) throws IOException {
         currentQueueSize += currentWriter.writeEvent(record);
     }
 
+
     public synchronized void close() throws IOException {
         this.lock.release();
         if (currentWriter != null) {
diff --git a/logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueWriteManagerTest.java b/logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueWriteManagerTest.java
index c9bf4cf1f67..19f6ab122c1 100644
--- a/logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueWriteManagerTest.java
+++ b/logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueWriteManagerTest.java
@@ -25,14 +25,27 @@
 import org.junit.rules.TemporaryFolder;
 import org.logstash.DLQEntry;
 import org.logstash.Event;
+import org.logstash.Timestamp;
 
+import java.io.IOException;
 import java.nio.channels.FileChannel;
 import java.nio.channels.OverlappingFileLockException;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.stream.IntStream;
 
 import static junit.framework.TestCase.assertFalse;
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.core.IsEqual.equalTo;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
@@ -92,4 +105,43 @@ public void testWrite() throws Exception {
         writer.writeEntry(entry);
         writer.close();
     }
+
+    @Test
+    public void multithreadedWriting() throws Exception {
+        DeadLetterQueueWriteManager writer = new DeadLetterQueueWriteManager(dir, 1000, 1000000);
+        AtomicInteger count = new AtomicInteger(0);
+        Runnable writeTask = () -> {
+            String threadName = Thread.currentThread().getName();
+            try {
+                writer.writeEntry(new Event(), "type", String.valueOf(count.getAndAdd(1)), threadName);
+            } catch (IOException e) {
+                // no-op
+            }
+        };
+
+        ExecutorService executor = Executors.newFixedThreadPool(3);
+        IntStream.range(0, 1000)
+                .forEach(i -> executor.submit(writeTask));
+        executor.shutdown();
+
+        executor.awaitTermination(Long.MAX_VALUE, TimeUnit.NANOSECONDS);
+
+        DeadLetterQueueReadManager readManager = new DeadLetterQueueReadManager(dir);
+        Timestamp prevTime = new Timestamp(0L);
+        for (int i = 0; i < 1000; i++) {
+            DLQEntry entry = readManager.pollEntry(20);
+            assertNotNull(entry);
+            assertFalse(entry.getEntryTime().getTime().isBefore(prevTime.getTime()));
+            prevTime = entry.getEntryTime();
+        }
+        assertNull(readManager.pollEntry(20));
+    }
+
+    @Test
+    public void reachedMaxQueueSize() throws Exception {
+        TestLogger
+        DeadLetterQueueWriteManager writer = new DeadLetterQueueWriteManager(dir, 1, 1);
+        DLQEntry entry = new DLQEntry(new Event(), "type", "id", "reason");
+        writer.writeEntry(entry);
+    }
 }
\ No newline at end of file
