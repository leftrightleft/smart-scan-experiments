diff --git a/lib/logstash/codecs/line.rb b/lib/logstash/codecs/line.rb
new file mode 100644
index 00000000000..e9e4945cbe2
--- /dev/null
+++ b/lib/logstash/codecs/line.rb
@@ -0,0 +1,56 @@
+require "logstash/codecs/base"
+
+# Line-oriented text data.
+#
+# Decoding behavior: Only whole line events will be emitted.
+#
+# Encoding behavior: Each event will be emitted with a trailing newline.
+class LogStash::Codecs::Line < LogStash::Codecs::Base
+  config_name "line"
+  milestone 3
+
+  # Set the desired text format for encoding.
+  config :format, :validate => :string
+
+  # The character encoding used in this input. Examples include "UTF-8"
+  # and "cp1252"
+  #
+  # This setting is useful if your log files are in Latin-1 (aka cp1252)
+  # or in another character set other than UTF-8.
+  #
+  # This only affects "plain" format logs since json is UTF-8 already.
+  config :charset, :validate => ::Encoding.name_list, :default => "UTF-8"
+
+  public
+  def register
+    require "logstash/util/buftok"
+    @buffer = FileWatch::BufferedTokenizer.new
+  end
+  
+  public
+  def decode(data)
+    @buffer.extract(data).each do |line|
+      line.force_encoding(@charset)
+      if @charset != "UTF-8"
+        # The user has declared the character encoding of this data is
+        # something other than UTF-8. Let's convert it (as cleanly as possible)
+        # into UTF-8 so we can use it with JSON, etc.
+
+        # To convert, we first tell ruby the string is *really* encoded as
+        # somethign else (@charset), then we convert it to UTF-8.
+        data = data.encode("UTF-8", :invalid => :replace, :undef => :replace)
+      end
+      yield LogStash::Event.new({"message" => line})
+    end
+  end # def decode
+
+  public
+  def encode(data)
+    if data.is_a? LogStash::Event and @format
+      @on_event.call(data.sprintf(@format))
+    else
+      @on_event.call(data.to_s)
+    end
+  end # def encode
+
+end # class LogStash::Codecs::Plain
diff --git a/lib/logstash/codecs/plain.rb b/lib/logstash/codecs/plain.rb
index 6c81770a49c..73bec3e52e2 100644
--- a/lib/logstash/codecs/plain.rb
+++ b/lib/logstash/codecs/plain.rb
@@ -6,6 +6,8 @@ class LogStash::Codecs::Plain < LogStash::Codecs::Base
   milestone 3
 
   # Set the desired text format for encoding.
+  #
+  # This setting only affects encoding.
   config :format, :validate => :string
 
   # The character encoding used in this input. Examples include "UTF-8"
@@ -16,23 +18,17 @@ class LogStash::Codecs::Plain < LogStash::Codecs::Base
   #
   # This only affects "plain" format logs since json is UTF-8 already.
   config :charset, :validate => ::Encoding.name_list, :default => "UTF-8"
-
-  public
-  def register
-    require "logstash/util/buftok"
-    @buffer = FileWatch::BufferedTokenizer.new
-  end
   
   public
   def decode(data)
-    @buffer.extract(data).each do |line|
-      line.force_encoding(@charset)
-      if @charset != "UTF-8"
-        # Convert to UTF-8 if not in that character set.
-        line = line.encode("UTF-8", :invalid => :replace, :undef => :replace)
-      end
-      yield LogStash::Event.new({"message" => line})
+    data.force_encoding(@charset)
+    if @charset != "UTF-8"
+      # The user has declared the character encoding of this data is
+      # something other than UTF-8. Let's convert it (as cleanly as possible)
+      # into UTF-8 so we can use it with JSON, etc.
+      data = data.encode("UTF-8", :invalid => :replace, :undef => :replace)
     end
+    yield LogStash::Event.new({"message" => data})
   end # def decode
 
   public
diff --git a/lib/logstash/config/mixin.rb b/lib/logstash/config/mixin.rb
index 1edc344cc03..fc42ed12e04 100644
--- a/lib/logstash/config/mixin.rb
+++ b/lib/logstash/config/mixin.rb
@@ -71,6 +71,11 @@ def config_init(params)
             params[name.to_s] = opts[:default].clone
         end
       end
+
+      # Allow plugins to override default values of config settings
+      if self.class.default?(name)
+        params[name.to_s] = self.class.get_default(name)
+      end
     end
 
     if !self.class.validate(params)
@@ -124,19 +129,22 @@ def config(name, opts={})
       end
     end # def config
 
+    def default(name, value)
+      @defaults ||= {}
+      @defaults[name.to_s] = value
+    end
+
     def get_config
       return @config
     end # def get_config
 
-    # Define a flag 
-    def flag(*args, &block)
-      @flags ||= []
+    def get_default(name)
+      return @defaults && @defaults[name]
+    end
 
-      @flags << {
-        :args => args,
-        :block => block
-      }
-    end # def flag
+    def default?(name)
+      return @defaults && @defaults.include?(name)
+    end
 
     def options(opts)
       # add any options from this class
diff --git a/lib/logstash/errors.rb b/lib/logstash/errors.rb
index 50f7ae90454..25fb08fc02e 100644
--- a/lib/logstash/errors.rb
+++ b/lib/logstash/errors.rb
@@ -3,4 +3,7 @@ class Error < ::StandardError; end
   class ConfigurationError < Error; end
   class PluginLoadingError < Error; end
   class ShutdownSignal < StandardError; end
+
+  class Bug < Error; end
+  class ThisMethodWasRemoved < Bug; end
 end
diff --git a/lib/logstash/event.rb b/lib/logstash/event.rb
index 148c4f933fd..24b7e0cd8a7 100644
--- a/lib/logstash/event.rb
+++ b/lib/logstash/event.rb
@@ -42,8 +42,15 @@ def initialize(data={})
     @cancelled = false
 
     @data = data
-    @data["@timestamp"] = ::Time.now.utc if !@data.include?("@timestamp")
-    @data["@version"] = "1" if !@data.include?("@version")
+    if data.include?("@timestamp")
+      t = data["@timestamp"]
+      if t.is_a?(String)
+        data["@timestamp"] = Time.parse(t).gmtime
+      end
+    else
+      data["@timestamp"] = ::Time.now.utc 
+    end
+    data["@version"] = "1" if !@data.include?("@version")
   end # def initialize
 
   # Add class methods on inclusion.
diff --git a/lib/logstash/filters/checksum.rb b/lib/logstash/filters/checksum.rb
index eb864fa9bba..5ba2a1770b7 100644
--- a/lib/logstash/filters/checksum.rb
+++ b/lib/logstash/filters/checksum.rb
@@ -42,6 +42,6 @@ def filter(event)
 
     digested_string = OpenSSL::Digest.hexdigest(@algorithm, @to_checksum)
     @logger.debug("Digested string", :digested_string => digested_string)
-    event.fields['logstash_checksum'] = digested_string
+    event['logstash_checksum'] = digested_string
   end
 end # class LogStash::Filters::Checksum
diff --git a/lib/logstash/filters/environment.rb b/lib/logstash/filters/environment.rb
index de70d17e876..4ea13015e72 100644
--- a/lib/logstash/filters/environment.rb
+++ b/lib/logstash/filters/environment.rb
@@ -19,7 +19,7 @@ def register
   def filter(event)
     return unless filter?(event)
     @add_field_from_env.each do |field, env|
-      event.fields[field] = ENV[env]
+      event[field] = ENV[env]
     end
     filter_matched(event)
   end # def filter
diff --git a/lib/logstash/filters/gelfify.rb b/lib/logstash/filters/gelfify.rb
index 37399ad117e..174953a2879 100644
--- a/lib/logstash/filters/gelfify.rb
+++ b/lib/logstash/filters/gelfify.rb
@@ -28,15 +28,15 @@ def filter(event)
     return unless event.type == @type
     @logger.debug("GELFIFY FILTER: received event of type #{event.type}")
 
-    if event.fields.include?("severity")
-      sev = event.fields["severity"].to_i rescue nil
-      if sev.to_s != event.fields["severity"].to_s
+    if event.include?("severity")
+      sev = event["severity"].to_i rescue nil
+      if sev.to_s != event["severity"].to_s
         # severity isn't convertable to an integer.
         # "foo".to_i => 0, which would default to EMERG.
         @logger.debug("GELFIFY FILTER: existing severity field is not an int")
       elsif SYSLOG_LEVEL_MAP[sev]
         @logger.debug("GELFIFY FILTER: Severity level successfully mapped")
-        event.fields["GELF_severity"] = SYSLOG_LEVEL_MAP[sev]
+        event["GELF_severity"] = SYSLOG_LEVEL_MAP[sev]
       else
         @logger.debug("GELFIFY FILTER: unknown severity #{sev}")
       end
diff --git a/lib/logstash/filters/grokdiscovery.rb b/lib/logstash/filters/grokdiscovery.rb
index 458933c7041..72a15c30c28 100644
--- a/lib/logstash/filters/grokdiscovery.rb
+++ b/lib/logstash/filters/grokdiscovery.rb
@@ -42,9 +42,9 @@ def filter(event)
     match = false
 
     if event.type and @discover_fields.include?(event.type)
-      discover = @discover_fields[event.type] & event.fields.keys
+      discover = @discover_fields[event.type] & event.to_hash.keys
       discover.each do |field|
-        value = event.fields[field]
+        value = event[field]
         value = [value] if value.is_a?(String)
 
         value.each do |v| 
@@ -54,7 +54,7 @@ def filter(event)
           match = @grok.match(v)
           if match
             @logger.warn(["Match", match.captures])
-            event.fields.merge!(match.captures) do |key, oldval, newval|
+            event.to_hash.merge!(match.captures) do |key, oldval, newval|
               @logger.warn(["Merging #{key}", oldval, newval])
               oldval + newval # should both be arrays...
             end
diff --git a/lib/logstash/filters/syslog_pri.rb b/lib/logstash/filters/syslog_pri.rb
index 5eb5658a513..9e59c0ba015 100644
--- a/lib/logstash/filters/syslog_pri.rb
+++ b/lib/logstash/filters/syslog_pri.rb
@@ -75,31 +75,31 @@ def filter(event)
   def parse_pri(event)
     # Per RFC3164, priority = (facility * 8) + severity
     # = (facility << 3) & (severity)
-    if event.fields[@syslog_pri_field_name]
-      if event.fields[@syslog_pri_field_name].is_a?(Array)
-        priority = event.fields[@syslog_pri_field_name].first.to_i
+    if event[@syslog_pri_field_name]
+      if event[@syslog_pri_field_name].is_a?(Array)
+        priority = event[@syslog_pri_field_name].first.to_i
       else
-        priority = event.fields[@syslog_pri_field_name].to_i
+        priority = event[@syslog_pri_field_name].to_i
       end
     else
       priority = 13  # default
     end
     severity = priority & 7 # 7 is 111 (3 bits)
     facility = priority >> 3
-    event.fields["syslog_severity_code"] = severity
-    event.fields["syslog_facility_code"] = facility
+    event["syslog_severity_code"] = severity
+    event["syslog_facility_code"] = facility
 
     # Add human-readable names after parsing severity and facility from PRI
     if @use_labels
-      facility_number = event.fields["syslog_facility_code"]
-      severity_number = event.fields["syslog_severity_code"]
+      facility_number = event["syslog_facility_code"]
+      severity_number = event["syslog_severity_code"]
 
       if @facility_labels[facility_number]
-        event.fields["syslog_facility"] = @facility_labels[facility_number]
+        event["syslog_facility"] = @facility_labels[facility_number]
       end
 
       if @severity_labels[severity_number]
-        event.fields["syslog_severity"] = @severity_labels[severity_number]
+        event["syslog_severity"] = @severity_labels[severity_number]
       end
     end
   end # def parse_pri
diff --git a/lib/logstash/filters/urldecode.rb b/lib/logstash/filters/urldecode.rb
index 28d35adc97a..ce3ac45d0d4 100644
--- a/lib/logstash/filters/urldecode.rb
+++ b/lib/logstash/filters/urldecode.rb
@@ -24,8 +24,8 @@ def filter(event)
 
     # If all_fields is true then try to decode them all
     if @all_fields
-      event.fields.each do |name, value|
-        event.fields[name] = urldecode(value)
+      event.to_hash.each do |name, value|
+        event[name] = urldecode(value)
       end
     # Else decode the specified field
     else
diff --git a/lib/logstash/inputs/base.rb b/lib/logstash/inputs/base.rb
index 48650a7b134..800e4284aaf 100644
--- a/lib/logstash/inputs/base.rb
+++ b/lib/logstash/inputs/base.rb
@@ -43,7 +43,7 @@ class LogStash::Inputs::Base < LogStash::Plugin
   # or in another character set other than UTF-8.
   #
   # This only affects "plain" format logs since json is UTF-8 already.
-  config :charset, :validate => ::Encoding.name_list, :default => "UTF-8"
+  config :charset, :validate => ::Encoding.name_list, :deprecated => true
 
   # If format is "json", an event sprintf string to build what
   # the display @message should be given (defaults to the raw JSON).
@@ -71,6 +71,16 @@ def initialize(params={})
     @threadable = false
     config_init(params)
     @tags ||= []
+
+    if @charset && @codec.class.get_config.include?("charset")
+      # charset is deprecated on inputs, but provide backwards compatibility
+      # by copying the charset setting into the codec.
+
+      @logger.warn("Copying input's charset setting into codec", :input => self, :codec => @codec)
+      charset = @charset
+      @codec.instance_eval { @charset = charset }
+    end
+
   end # def initialize
 
   public
@@ -84,99 +94,7 @@ def tag(newtag)
   end # def tag
 
   protected
-  def to_event(raw, source)
-    @format ||= "plain"
-
-    event = LogStash::Event.new
-    event.tags = @tags.clone rescue []
-    event.source = source
-
-    case @format
-    when "plain"
-      raw.force_encoding(@charset)
-      if @charset != "UTF-8"
-        # Convert to UTF-8 if not in that character set.
-        raw = raw.encode("UTF-8", :invalid => :replace, :undef => :replace)
-      end
-      event.message = raw
-    when "json"
-      begin
-        # JSON must be valid UTF-8, and many inputs come from ruby IO
-        # instances, which almost all default to ASCII-8BIT. Force UTF-8
-        fields = JSON.parse(raw.force_encoding("UTF-8"))
-        fields.each { |k, v| event[k] = v }
-        if @message_format
-          event.message = event.sprintf(@message_format)
-        else
-          event.message = raw
-        end
-      rescue => e
-        # Instead of dropping the event, should we treat it as
-        # plain text and try to do the best we can with it?
-        @logger.info? and @logger.info("Trouble parsing json input, falling " \
-                                       "back to plain text", :input => raw,
-                                       :source => source, :exception => e)
-        event.message = raw
-        event.tags << "_jsonparsefailure"
-      end
-    when "json_event"
-      begin
-        # JSON must be valid UTF-8, and many inputs come from ruby IO
-        # instances, which almost all default to ASCII-8BIT. Force UTF-8
-        event = LogStash::Event.from_json(raw.force_encoding("UTF-8"))
-        event["tags"] ||= []
-        event["tags"] += @tags
-        if @message_format
-          event.message ||= event.sprintf(@message_format)
-        end
-      rescue => e
-        # Instead of dropping the event, should we treat it as
-        # plain text and try to do the best we can with it?
-        @logger.info? and @logger.info("Trouble parsing json input, falling " \
-                                       "back to plain text", :input => raw,
-                                       :source => source, :exception => e, :stack => e.backtrace)
-        event.message = raw
-        event["tags"] ||= []
-        event["tags"] << "_jsonparsefailure"
-      end
-    when "msgpack_event"
-      begin
-        # Msgpack does not care about UTF-8
-        event = LogStash::Event.new(MessagePack.unpack(raw))
-        event["tags"] ||= []
-        event["tags"] |= @tags
-        if @message_format
-          event.message ||= event.sprintf(@message_format)
-        end
-      rescue => e
-        ## TODO(sissel): Instead of dropping the event, should we treat it as
-        ## plain text and try to do the best we can with it?
-        @logger.warn("Trouble parsing msgpack input, falling back to plain text",
-                     :input => raw, :source => source, :exception => e)
-        event.message = raw
-        event["tags"] ||= []
-        event["tags"] << "_msgpackparsefailure"
-      end
-
-      if event.source == "unknown"
-        event.source = source
-      end
-    else
-      raise "unknown event format #{@format}, this should never happen"
-    end
-
-    event["type"] = @type if @type
-
-    @add_field.each do |field, value|
-      if event.include?(field)
-        event[field] = [event[field]] if !event[field].is_a?(Array)
-        event[field] << value
-      else
-        event[field] = value
-      end
-    end
-
-    @logger.debug? and @logger.debug("Received new event", :source => source, :event => event)
-    return event
+  def to_event(raw, source) 
+    raise LogStash::ThisMethodWasRemoved("LogStash::Inputs::Base#to_event - you should use codecs now instead of to_event. Not sure what this means? Get help on logstash-users@googlegroups.com!")
   end # def to_event
 end # class LogStash::Inputs::Base
diff --git a/lib/logstash/inputs/drupal_dblog.rb b/lib/logstash/inputs/drupal_dblog.rb
index d661dd67b0b..944ae2f8eae 100644
--- a/lib/logstash/inputs/drupal_dblog.rb
+++ b/lib/logstash/inputs/drupal_dblog.rb
@@ -17,6 +17,8 @@ class LogStash::Inputs::DrupalDblog < LogStash::Inputs::Base
   config_name "drupal_dblog"
   milestone 1
 
+  default :codec, "plain"
+
   # Specify all drupal databases that you whish to import from.
   # This can be as many as you whish.
   # The format is a hash, with a unique site name as the key, and a databse
@@ -53,12 +55,6 @@ class LogStash::Inputs::DrupalDblog < LogStash::Inputs::Base
   # can also use the type to search for in the web interface.
   config :type, :validate => :string, :default => 'watchdog'
 
-  public
-  def initialize(params)
-    super
-    @format = "json_event"
-  end # def initialize
-
   public
   def register
     require "php_serialize"
@@ -319,9 +315,7 @@ def build_event(row)
       "message" => msg
     }.merge(row)
 
-    event = to_event(JSON.dump(entry), @sitename)
-
-    return event
+    return LogStash::Event.new(entry)
   end # def build_event
 
 end # class LogStash::Inputs::DrupalDblog
diff --git a/lib/logstash/inputs/elasticsearch.rb b/lib/logstash/inputs/elasticsearch.rb
index d24709ae572..4547c5c5034 100644
--- a/lib/logstash/inputs/elasticsearch.rb
+++ b/lib/logstash/inputs/elasticsearch.rb
@@ -22,6 +22,8 @@ class LogStash::Inputs::Elasticsearch < LogStash::Inputs::Base
   config_name "elasticsearch"
   milestone 1
 
+  default :codec, "json"
+
   # When mode is `server`, the address to listen on.
   # When mode is `client`, the address to connect to.
   config :host, :validate => :string, :default => "0.0.0.0"
@@ -44,7 +46,6 @@ def register
       "size" => "1000",
     }
     @url = "http://#{@host}:#{@port}/#{@index}/_search?#{encode(params)}"
-    @format ||= "json_event"
   end # def register
 
   private
diff --git a/lib/logstash/inputs/eventlog.rb b/lib/logstash/inputs/eventlog.rb
index 0de1a03b123..8c66e93720b 100644
--- a/lib/logstash/inputs/eventlog.rb
+++ b/lib/logstash/inputs/eventlog.rb
@@ -17,15 +17,11 @@ class LogStash::Inputs::EventLog < LogStash::Inputs::Base
   config_name "eventlog"
   milestone 2
 
+  default :codec, "plain"
+
   # Event Log Name
   config :logfile, :validate => :array, :default => [ "Application", "Security", "System" ]
 
-  public
-  def initialize(params)
-    super
-    @format ||= "json_event"
-  end # def initialize
-
   public
   def register
 
diff --git a/lib/logstash/inputs/exec.rb b/lib/logstash/inputs/exec.rb
index 20d798167ca..800e2b0d838 100644
--- a/lib/logstash/inputs/exec.rb
+++ b/lib/logstash/inputs/exec.rb
@@ -14,6 +14,8 @@ class LogStash::Inputs::Exec < LogStash::Inputs::Base
 
   config_name "exec"
   milestone 2
+
+  default :codec, "plain"
   
   # Set this to true to enable debugging on an input.
   config :debug, :validate => :boolean, :default => false
diff --git a/lib/logstash/inputs/file.rb b/lib/logstash/inputs/file.rb
index d59aea55825..05d7747df66 100644
--- a/lib/logstash/inputs/file.rb
+++ b/lib/logstash/inputs/file.rb
@@ -15,6 +15,10 @@ class LogStash::Inputs::File < LogStash::Inputs::Base
   config_name "file"
   milestone 2
 
+  # TODO(sissel): This should switch to use the 'line' codec by default
+  # once file following
+  default :codec, "plain"
+
   # The path to the file to use as an input.
   # You can use globs here, such as `/var/log/*.log`
   # Paths must be absolute and cannot be relative.
diff --git a/lib/logstash/inputs/ganglia.rb b/lib/logstash/inputs/ganglia.rb
index a8e12ea4773..dc3e84a8ad5 100644
--- a/lib/logstash/inputs/ganglia.rb
+++ b/lib/logstash/inputs/ganglia.rb
@@ -12,6 +12,8 @@ class LogStash::Inputs::Ganglia < LogStash::Inputs::Base
   config_name "ganglia"
   milestone 1
 
+  default :codec, "plain"
+
   # The address to listen on
   config :host, :validate => :string, :default => "0.0.0.0"
 
@@ -24,9 +26,6 @@ def initialize(params)
     super
     @shutdown_requested = false
     BasicSocket.do_not_reverse_lookup = true
-
-    # force "plain" format. others don't make sense here.
-    @format = "plain"
   end # def initialize
 
   public
@@ -71,7 +70,7 @@ def udp_listener(output_queue)
       # Ruby uri sucks, so don't use it.
       source = "ganglia://#{client[3]}/"
 
-      e = packet_to_event(packet,source)
+      e = parse_packet(packet,source)
       unless e.nil?
         output_queue << e
       end
@@ -99,7 +98,7 @@ def close_udp
   end
 
   public
-  def packet_to_event(packet,source)
+  def parse_packet(packet,source)
 
     gmonpacket=GmonPacket.new(packet)
     if gmonpacket.meta?
@@ -115,26 +114,22 @@ def packet_to_event(packet,source)
       data=gmonpacket.parse_data(@metadata)
 
       # Check if it was a valid data request
-      unless data.nil?
-
-        event=LogStash::Event.new
-        #event['@timestamp'] = Time.now.to_i
-        event.source = source
-        event.type = @config["type"]
-
-        data['program'] = "ganglia"
-        event['@fields'] = data
-        event['@fields']['log_host'] =  data['hostname']
-        %w{dmax tmax slope type units}.each do |info|
-          event.fields[info] = @metadata[data['name']][info]
-        end
-        return event
+      return nil unless data
+
+      event=LogStash::Event.new
+      #event['@timestamp'] = Time.now.to_i
+      event["source"] = source
+      event["type"] = @type
+
+      data["program"] = "ganglia"
+      event["log_host"] = data["hostname"]
+      %w{dmax tmax slope type units}.each do |info|
+        event[info] = @metadata[data["name"]][info]
       end
+      return event
     else
       # Skipping unknown packet types
       return nil
     end
-
-
-  end # def packet_to_event
+  end # def parse_packet
 end # class LogStash::Inputs::Ganglia
diff --git a/lib/logstash/inputs/gelf.rb b/lib/logstash/inputs/gelf.rb
index b773802c2ef..eef5a74259c 100644
--- a/lib/logstash/inputs/gelf.rb
+++ b/lib/logstash/inputs/gelf.rb
@@ -14,6 +14,8 @@ class LogStash::Inputs::Gelf < LogStash::Inputs::Base
   config_name "gelf"
   milestone 2
 
+  default :codec, "plain"
+
   # The address to listen on
   config :host, :validate => :string, :default => "0.0.0.0"
 
@@ -38,10 +40,6 @@ class LogStash::Inputs::Gelf < LogStash::Inputs::Base
   def initialize(params)
     super
     BasicSocket.do_not_reverse_lookup = true
-
-    # nothing else makes sense here
-    # gelf messages ARE json
-    @format = "json"
   end # def initialize
 
   public
@@ -88,11 +86,10 @@ def udp_listener(output_queue)
       # The nil guard is needed to deal with chunked messages.
       # Gelfd::Parser.parse will only return the message when all chunks are
       # completed
-      e = to_event(data, source) unless data.nil?
-      if e
-        remap_gelf(e) if @remap
-        output_queue << e
-      end
+      event = LogStash::Event.new(data)
+      event["source"] = client[3]
+      remap_gelf(event) if @remap
+      output_queue << event
     end
   ensure
     if @udp
@@ -103,17 +100,17 @@ def udp_listener(output_queue)
 
   private
   def remap_gelf(event)
-    if event.fields["full_message"]
-      event.message = event.fields["full_message"].dup
-    elsif event.fields["short_message"]
-      event.message = event.fields["short_message"].dup
+    if event["full_message"]
+      event.message = event["full_message"].dup
+    elsif event["short_message"]
+      event.message = event["short_message"].dup
     end
-    if event.fields["host"]
-      event.source_host = event.fields["host"]
+    if event["host"]
+      event.source_host = event["host"]
     end
-    if event.fields["file"]
-      event.source_path = event.fields["file"]
+    if event["file"]
+      event.source_path = event["file"]
     end
-    event.source = "gelf://#{event.fields["host"]}/#{event.fields["file"]}"
+    event.source = "gelf://#{event["host"]}/#{event["file"]}"
   end # def remap_gelf
 end # class LogStash::Inputs::Gelf
diff --git a/lib/logstash/inputs/gemfire.rb b/lib/logstash/inputs/gemfire.rb
index 9c3f1ab703b..e08c9cccfde 100644
--- a/lib/logstash/inputs/gemfire.rb
+++ b/lib/logstash/inputs/gemfire.rb
@@ -16,6 +16,8 @@ class LogStash::Inputs::Gemfire < LogStash::Inputs::Threadable
   config_name "gemfire"
   milestone 1
 
+  default :codec, "plain"
+
   # Your client cache name
   config :cache_name, :validate => :string, :default => "logstash"
 
@@ -51,14 +53,6 @@ class LogStash::Inputs::Gemfire < LogStash::Inputs::Threadable
   # How the message is serialized in the cache. Can be one of "json" or "plain"; default is plain
   config :serialization, :validate => :string, :default => nil
 
-  public
-  def initialize(params)
-    super
-
-    @format ||= "plain"
-
-  end # def initialize
-
   public
   def register
     import com.gemstone.gemfire.cache.AttributesMutator
@@ -148,9 +142,9 @@ def deserialize_message(message)
 
   def process_event(event, event_name, source)
     message = deserialize_message(event)
-    e = to_event(message, source)
-    if e
-      @logstash_queue << e
+    @codec.decode(message) do |event|
+      event["source"] = source
+      @logstash_queue << event
     end
   end
 
diff --git a/lib/logstash/inputs/generator.rb b/lib/logstash/inputs/generator.rb
index fc78209191d..0fb4675eb14 100644
--- a/lib/logstash/inputs/generator.rb
+++ b/lib/logstash/inputs/generator.rb
@@ -11,6 +11,8 @@ class LogStash::Inputs::Generator < LogStash::Inputs::Threadable
   config_name "generator"
   milestone 3
 
+  default :codec, "plain"
+
   # The message string to use in the event.
   #
   # If you set this to 'stdin' then this plugin will read a single line from
@@ -53,7 +55,6 @@ def register
   end # def register
 
   def run(queue)
-
     number = 0
     source = "generator://#{@host}/"
 
diff --git a/lib/logstash/inputs/heroku.rb b/lib/logstash/inputs/heroku.rb
index f65ae49d5b2..6353f01666a 100644
--- a/lib/logstash/inputs/heroku.rb
+++ b/lib/logstash/inputs/heroku.rb
@@ -18,6 +18,8 @@ class LogStash::Inputs::Heroku < LogStash::Inputs::Base
   config_name "heroku"
   milestone 1
 
+  default :codec, "plain"
+
   # The name of your heroku application. This is usually the first part of the 
   # the domain name 'my-app-name.herokuapp.com'
   config :app, :validate => :string, :required => true
@@ -31,21 +33,17 @@ def register
   public
   def run(queue)
     client = Heroku::Client.new(Heroku::Auth.user, Heroku::Auth.password)
-    source = "heroku://#{@app}"
 
     # The 'Herok::Client#read_logs' method emits chunks of text not bounded
     # by event barriers like newlines.
-    buffer = FileWatch::BufferedTokenizer.new
     # tail=1 means to follow logs
     # I *think* setting num=1 means we only get 1 historical event. Setting
     # this to 0 makes it fetch *all* events, not what I want.
     client.read_logs(@app, ["tail=1", "num=1"]) do |chunk|
-      buffer.extract(chunk).each do |line|
-        # 'line' is plain text.
-        @logger.debug("Received line", :app => @app, :line => line)
-        e = to_event(line, source)
-        queue << e if e
-      end # buffer.extract
+      @codec.decode(chunk).each do |event|
+        event["app"] = @app
+        queue << event
+      end
     end
   end # def run
 end # class LogStash::Inputs::Heroku
diff --git a/lib/logstash/inputs/imap.rb b/lib/logstash/inputs/imap.rb
index 6d941fdebd4..9c8bb0cb88c 100644
--- a/lib/logstash/inputs/imap.rb
+++ b/lib/logstash/inputs/imap.rb
@@ -60,7 +60,7 @@ def check_mail(queue)
       items = imap.fetch(id_set, "RFC822")
       items.each do |item|
         mail = Mail.read_from_string(item.attr["RFC822"])
-        queue << mail_to_event(mail)
+        queue << parse_mail(mail)
       end
       imap.store(id_set, '+FLAGS', :Seen)
     end
@@ -69,7 +69,7 @@ def check_mail(queue)
     imap.disconnect
   end # def run
 
-  def mail_to_event(mail)
+  def parse_mail(mail)
     # TODO(sissel): What should a multipart message look like as an event?
     # For now, just take the plain-text part and set it as the message.
     if mail.parts.count == 0
@@ -80,13 +80,10 @@ def mail_to_event(mail)
       message = mail.parts.find { |p| p.content_type =~ /^text\/plain/ }.decoded
     end
 
-    event = to_event(message, "imap://#{@user}@#{@host}/#{m.from.first rescue ""}")
+    event = LogStash::Event.new("message" => message)
 
     # Use the 'Date' field as the timestamp
-    t = mail.date.to_time.gmtime
-    event["@timestamp"] = sprintf(ISO8601_STRFTIME, t.year, t.month,
-                                  t.day, t.hour, t.min, t.sec, t.tv_usec,
-                                  t.utc_offset / 3600)
+    event["@timestamp"] = mail.date.to_time.gmtime
 
     # Add fields: Add message.header_fields { |h| h.name=> h.value }
     mail.header_fields.each do |header|
diff --git a/lib/logstash/inputs/irc.rb b/lib/logstash/inputs/irc.rb
index f5ada71dc62..2c478dc0b14 100644
--- a/lib/logstash/inputs/irc.rb
+++ b/lib/logstash/inputs/irc.rb
@@ -9,6 +9,8 @@ class LogStash::Inputs::Irc < LogStash::Inputs::Base
   config_name "irc"
   milestone 1
 
+  default :codec, "plain"
+
   # Host of the IRC Server to connect to.
   config :host, :validate => :string, :required => true
 
@@ -73,10 +75,12 @@ def run(output_queue)
     loop do
       msg = @irc_queue.pop
       if msg.user
-        event = self.to_event(msg.message, "irc://#{@host}:#{@port}/#{msg.channel}")
-        event["channel"] = msg.channel
-        event["nick"] = msg.user.nick
-        output_queue << event
+        @codec.decode(msg.message) do |event|
+          event["channel"] = msg.channel
+          event["nick"] = msg.user.nick
+          event["server"] = "#{@host}:#{@port}"
+          output_queue << event
+        end
       end
     end
   end # def run
diff --git a/lib/logstash/inputs/log4j.rb b/lib/logstash/inputs/log4j.rb
index c27af32c12f..facdfa710b2 100644
--- a/lib/logstash/inputs/log4j.rb
+++ b/lib/logstash/inputs/log4j.rb
@@ -54,29 +54,28 @@ def handle_socket(socket, output_queue, event_source)
       ois = JRubyObjectInputStream.new(java.io.BufferedInputStream.new(socket.to_inputstream))
       loop do
         # NOTE: event_raw is org.apache.log4j.spi.LoggingEvent
-        event_obj = ois.readObject()
-        e = to_event(event_obj.getRenderedMessage(), event_source)
-        e.source_host = socket.peer
-        e.source_path = event_obj.getLoggerName()
-        e["priority"] = event_obj.getLevel().toString()
-        e["logger_name"] = event_obj.getLoggerName()
-        e["thread"] = event_obj.getThreadName()
-        e["class"] = event_obj.getLocationInformation().getClassName()
-        e["file"] = event_obj.getLocationInformation().getFileName() + ":" + event_obj.getLocationInformation().getLineNumber(),
-        e["method"] = event_obj.getLocationInformation().getMethodName()
-        e["NDC"] = event_obj.getNDC() if event_obj.getNDC()
-        e["stack_trace"] = event_obj.getThrowableStrRep().to_a.join("\n") if event_obj.getThrowableInformation()
+        log4j_obj = ois.readObject
+        event = LogStash::Event.new("message" => log4j_obj.getRenderedMessage,
+                                    "source" => event_source)
+        event["source_host"] = socket.peer
+        event["source_path"] = log4j_obj.getLoggerName
+        event["priority"] = log4j_obj.getLevel.toString
+        event["logger_name"] = log4j_obj.getLoggerName
+        event["thread"] = log4j_obj.getThreadName
+        event["class"] = log4j_obj.getLocationInformation.getClassName
+        event["file"] = log4j_obj.getLocationInformation.getFileName + ":" + log4j_obj.getLocationInformation.getLineNumber,
+        event["method"] = log4j_obj.getLocationInformation.getMethodName
+        event["NDC"] = log4j_obj.getNDC if log4j_obj.getNDC
+        event["stack_trace"] = log4j_obj.getThrowableStrRep.to_a.join("\n") if log4j_obj.getThrowableInformation
         
         # Add the MDC context properties to '@fields'
-        if event_obj.getProperties()
-          event_obj.getPropertyKeySet().each do |key|
-            e[key] = event_obj.getProperty(key)
+        if log4j_obj.getProperties
+          log4j_obj.getPropertyKeySet.each do |key|
+            event[key] = log4j_obj.getProperty(key)
           end  
         end  
 
-        if e
-          output_queue << e
-        end
+        output_queue << e
       end # loop do
     rescue => e
       @logger.debug("Closing connection", :client => socket.peer,
diff --git a/lib/logstash/inputs/lumberjack2.rb b/lib/logstash/inputs/lumberjack2.rb
deleted file mode 100644
index e90b0e98a01..00000000000
--- a/lib/logstash/inputs/lumberjack2.rb
+++ /dev/null
@@ -1,59 +0,0 @@
-require "logstash/inputs/base"
-require "logstash/namespace"
-
-# Receive events using the lumberjack2 protocol.
-#
-# This is mainly to receive events shipped with lumberjack,
-# <http://github.com/jordansissel/lumberjack>
-class LogStash::Inputs::Lumberjack2 < LogStash::Inputs::Base
-
-  config_name "lumberjack2"
-  milestone 1
-
-  # The address to listen on.
-  config :host, :validate => :string, :default => "0.0.0.0"
-
-  # The port to listen on.
-  config :port, :validate => :number, :default => 5005
-
-  # The path to your nacl private key. 
-  # You can generate this with the lumberjack 'keygen' tool
-  config :my_secret_key, :validate => :path, :required => true
-
-  # The path to the client's nacl public key. 
-  # You can generate this with the lumberjack 'keygen' tool
-  config :their_public_key, :validate => :path, :required => true
-
-  # The number of workers to use when processing lumberjack payloads.
-  config :threads, :validate => :number, :default => 1
-
-  public
-  def register
-    require "lumberjack/server2"
-
-    @logger.info("Starting lumberjack2 input listener", :address => "tcp://#{@host}:#{@port}")
-
-    @lumberjack = Lumberjack::Server2.new(
-      :endpoint => "tcp://#{@host}:#{@port}",
-      :workers => @threads,
-      :my_secret_key => File.read(@my_secret_key),
-      :their_public_key => File.read(@their_public_key))
-  end # def register
-
-  public
-  def run(output_queue)
-    @lumberjack.run do |l|
-      event = to_event(l.delete("text"), l.delete("source") || "-")
-
-      # TODO(sissel): We shoudln't use 'fields' here explicitly, but the new
-      # 'event[key]' code seems... slow, so work around it for now.
-      # TODO(sissel): Once Event_v1 is live, we can just merge 'l' directly into it.
-      l.each do |key, value|
-        event[key] = value
-      end
-      event.fields.merge(l)
-
-      output_queue << event
-    end
-  end # def run
-end # class LogStash::Inputs::Lumberjack
diff --git a/lib/logstash/inputs/pipe.rb b/lib/logstash/inputs/pipe.rb
index fdd4b909eb9..9b6dcad15c0 100644
--- a/lib/logstash/inputs/pipe.rb
+++ b/lib/logstash/inputs/pipe.rb
@@ -11,6 +11,10 @@ class LogStash::Inputs::Pipe < LogStash::Inputs::Base
   config_name "pipe"
   milestone 1
 
+  # TODO(sissel): This should switch to use the 'line' codec by default
+  # once we switch away from doing 'readline'
+  default :codec, "plain"
+
   # Command to run and read events from, one line at a time.
   #
   # Example:
@@ -32,10 +36,10 @@ def run(queue)
     @pipe.each do |line|
       line = line.chomp
       source = "pipe://#{hostname}/#{command}"
-      @logger.debug("Received line", :command => command, :line => line)
-      e = to_event(line, source)
-      if e
-        queue << e
+      @logger.debug? && @logger.debug("Received line", :command => command, :line => line)
+      @codec.decode(line) do |event|
+        event["source"] = source
+        queue << event
       end
     end
   end # def run
diff --git a/lib/logstash/inputs/redis.rb b/lib/logstash/inputs/redis.rb
index 58ea1221511..6e199d23ea3 100644
--- a/lib/logstash/inputs/redis.rb
+++ b/lib/logstash/inputs/redis.rb
@@ -15,6 +15,8 @@ class LogStash::Inputs::Redis < LogStash::Inputs::Threadable
   config_name "redis"
   milestone 2
 
+  default :codec, "json"
+
   # Name is used for logging in case there are multiple instances.
   # This feature has no real function and will be removed in future versions.
   config :name, :validate => :string, :default => "default", :deprecated => true
@@ -51,13 +53,6 @@ class LogStash::Inputs::Redis < LogStash::Inputs::Threadable
   # How many events to return from redis using EVAL
   config :batch_count, :validate => :number, :default => 1
 
-  public
-  def initialize(params)
-    super
-
-    @format ||= "json_event"
-  end # def initialize
-
   public
   def register
     require 'redis'
@@ -131,8 +126,9 @@ def load_batch_script(redis)
   private
   def queue_event(msg, output_queue)
     begin
-      event = to_event msg, identity
-      output_queue << event if event
+      @codec.decode(msg) do |event|
+        output_queue << event
+      end
     rescue => e # parse or event creation error
       @logger.error("Failed to create event", :message => msg, :exception => e,
                     :backtrace => e.backtrace);
diff --git a/lib/logstash/inputs/relp.rb b/lib/logstash/inputs/relp.rb
index 2f21c277c0b..ec423efbffc 100644
--- a/lib/logstash/inputs/relp.rb
+++ b/lib/logstash/inputs/relp.rb
@@ -20,6 +20,8 @@ class Interrupted < StandardError; end
   config_name "relp"
   milestone 1
 
+  default :codec, "plain"
+
   # The address to listen on.
   config :host, :validate => :string, :default => "0.0.0.0"
 
@@ -40,8 +42,11 @@ def register
   def relp_stream(relpserver,socket,output_queue,event_source)
     loop do
       frame = relpserver.syslog_read(socket)
-      event = self.to_event(frame['message'],event_source)
-      output_queue << event
+      @codec.decode(frame["message"]) do |event|
+        event["source"] = event_source
+        output_queue << event
+      end
+
       #To get this far, the message must have made it into the queue for 
       #filtering. I don't think it's possible to wait for output before ack
       #without fundamentally breaking the plugin architecture
diff --git a/lib/logstash/inputs/s3.rb b/lib/logstash/inputs/s3.rb
index 712afeb1a3e..7dc3576d46b 100644
--- a/lib/logstash/inputs/s3.rb
+++ b/lib/logstash/inputs/s3.rb
@@ -13,6 +13,10 @@ class LogStash::Inputs::S3 < LogStash::Inputs::Base
   config_name "s3"
   milestone 1
 
+  # TODO(sissel): refactor to use 'line' codec (requires removing both gzip
+  # support and readline usage). Support gzip through a gzip codec! ;)
+  default :codec, "plain"
+
   # The credentials of the AWS account used to access the bucket.
   # Credentials can be specified:
   # - As an ["id","secret"] array
diff --git a/lib/logstash/inputs/snmptrap.rb b/lib/logstash/inputs/snmptrap.rb
index 6844b17effb..230d281abcc 100644
--- a/lib/logstash/inputs/snmptrap.rb
+++ b/lib/logstash/inputs/snmptrap.rb
@@ -70,12 +70,12 @@ def snmptrap_listener(output_queue)
 
     @snmptrap.on_trap_default do |trap|
       begin
-        event = to_event(trap.inspect, trap.source_ip)
+        event = LogStash::Event.new("message" => trap.inspect, "source" => trap.source_ip)
         trap.each_varbind do |vb|
           event[vb.name.to_s] = vb.value.to_s
         end
         @logger.debug("SNMP Trap received: ", :trap_object => trap.inspect)
-        output_queue << event if event
+        output_queue << event
       rescue => event
         @logger.error("Failed to create event", :trap_object => trap.inspect)
       end
diff --git a/lib/logstash/inputs/sqlite.rb b/lib/logstash/inputs/sqlite.rb
index 3a3619f6de5..0504ccc1054 100644
--- a/lib/logstash/inputs/sqlite.rb
+++ b/lib/logstash/inputs/sqlite.rb
@@ -154,14 +154,13 @@ def run(queue)
           rows = get_n_rows_from_table(@db, table_name, offset, @batch)
           count += rows.count
           rows.each do |row| 
-            e = to_event("", "sqlite://#{@host}/#{@path}")
-
+            event = LogStash::Event.new("host" => @host, "db" => @db)
             # store each column as a field in the event.
             row.each do |column, element|
               next if column == :id
-              e[column.to_s] = element
+              event[column.to_s] = element
             end
-            queue << e
+            queue << event
             @table_data[k][:place] = row[:id]
           end
           # Store the last-seen row in the database
diff --git a/lib/logstash/inputs/sqs.rb b/lib/logstash/inputs/sqs.rb
index cd000297455..7504816032f 100644
--- a/lib/logstash/inputs/sqs.rb
+++ b/lib/logstash/inputs/sqs.rb
@@ -60,6 +60,8 @@ class LogStash::Inputs::SQS < LogStash::Inputs::Threadable
   config_name "sqs"
   milestone 1
 
+  default :codec, "json"
+
   # Name of the SQS Queue name to pull messages from. Note that this is just the name of the queue, not the URL or ARN.
   config :queue, :validate => :string, :required => true
 
@@ -79,11 +81,6 @@ def aws_service_endpoint(region)
     }
   end
 
-  def initialize(params)
-    super
-    @format ||= "json_event"
-  end # def initialize
-
   public
   def register
     @logger.info("Registering SQS input", :queue => @queue)
@@ -116,21 +113,21 @@ def run(output_queue)
       continue_polling = run_with_backoff(60, 1) do
         @sqs_queue.receive_message(receive_opts) do |message|
           if message
-            e = to_event(message.body, @sqs_queue)
-            if e
+            @codec.decode(message.body) do |event|
+              event["source"] = @sqs_queue
               if @id_field
-                e[@id_field] = message.id
+                event[@id_field] = message.id
               end
               if @md5_field
-                e[@md5_field] = message.md5
+                event[@md5_field] = message.md5
               end
               if @sent_timestamp_field
-                e[@sent_timestamp_field] = message.sent_timestamp.utc
+                event[@sent_timestamp_field] = message.sent_timestamp.utc
               end
-              @logger.debug("Processed SQS message", :message_id => message.id, :message_md5 => message.md5, :sent_timestamp => message.sent_timestamp, :queue => @queue)
-              output_queue << e
+              @logger.debug? && @logger.debug("Processed SQS message", :message_id => message.id, :message_md5 => message.md5, :sent_timestamp => message.sent_timestamp, :queue => @queue)
+              output_queue << event
               message.delete
-            end # valid event
+            end # codec.decode
           end # valid SQS message
         end # receive_message
       end # run_with_backoff
diff --git a/lib/logstash/inputs/stdin.rb b/lib/logstash/inputs/stdin.rb
index 7f7ff960ccd..b6283873b8b 100644
--- a/lib/logstash/inputs/stdin.rb
+++ b/lib/logstash/inputs/stdin.rb
@@ -10,6 +10,8 @@ class LogStash::Inputs::Stdin < LogStash::Inputs::Base
   config_name "stdin"
   milestone 3
 
+  default :codec, "line"
+
   public
   def register
     @host = Socket.gethostname
diff --git a/lib/logstash/inputs/stomp.rb b/lib/logstash/inputs/stomp.rb
index 94bf418e928..4f40a4a4e36 100644
--- a/lib/logstash/inputs/stomp.rb
+++ b/lib/logstash/inputs/stomp.rb
@@ -6,6 +6,8 @@ class LogStash::Inputs::Stomp < LogStash::Inputs::Base
   config_name "stomp"
   milestone 2
 
+  default :codec, "plain"
+
   # The address of the STOMP server.
   config :host, :validate => :string, :default => "localhost", :required => true
 
@@ -59,8 +61,9 @@ def register
   private
   def subscription_handler
     @client.subscribe(@destination) do |msg|
-      e = to_event(msg.body, @stomp_url)
-      @output_queue << e if e
+      @codec.decode(msg.body) do |event|
+        @output_queue << event
+      end
     end
     #In the event that there is only Stomp input plugin instances
     #the process ends prematurely. The above code runs, and return
diff --git a/lib/logstash/inputs/syslog.rb b/lib/logstash/inputs/syslog.rb
index 50652dde65f..647a57dace1 100644
--- a/lib/logstash/inputs/syslog.rb
+++ b/lib/logstash/inputs/syslog.rb
@@ -22,6 +22,8 @@ class LogStash::Inputs::Syslog < LogStash::Inputs::Base
   config_name "syslog"
   milestone 1
 
+  default :codec, "plain"
+
   # The address to listen on
   config :host, :validate => :string, :default => "0.0.0.0"
 
@@ -45,9 +47,6 @@ def initialize(params)
     super
     @shutdown_requested = false
     BasicSocket.do_not_reverse_lookup = true
-
-    # force "plain" format. others don't make sense here.
-    @format = "plain"
   end # def initialize
 
   public
@@ -119,13 +118,13 @@ def udp_listener(output_queue)
     @udp.bind(@host, @port)
 
     loop do
-      line, client = @udp.recvfrom(9000)
+      payload, client = @udp.recvfrom(9000)
       # Ruby uri sucks, so don't use it.
       source = "syslog://#{client[3]}/"
-      e = to_event(line.chomp, source)
-      if e
-        syslog_relay(e, source)
-        output_queue << e
+      @codec.decode(payload) do |event|
+        event["source"] = client[3]
+        syslog_relay(event)
+        output_queue << event
       end
     end
   ensure
@@ -152,13 +151,13 @@ def tcp_listener(output_queue)
         end
 
         begin
-        client.each do |line|
-          e = to_event(line.chomp, source)
-          if e
-            syslog_relay(e, source)
-            output_queue << e
-          end # e
-        end # client.each
+          client.each do |line|
+            @codec.decode(line) do |event|
+              event["source"] = ip
+              syslog_relay(event)
+              output_queue << event
+            end
+          end
         rescue Errno::ECONNRESET
         end
       end # Thread.new
@@ -200,13 +199,13 @@ def close_tcp
   # treat it like the whole event.message is correct and try to fill
   # the missing pieces (host, priority, etc)
   public
-  def syslog_relay(event, url)
+  def syslog_relay(event)
     @grok_filter.filter(event)
 
     if !event.tags.include?("_grokparsefailure")
       # Per RFC3164, priority = (facility * 8) + severity
       #                       = (facility << 3) & (severity)
-      priority = event.fields["priority"].first.to_i rescue 13
+      priority = event["priority"].first.to_i rescue 13
       severity = priority & 7   # 7 is 111 (3 bits)
       facility = priority >> 3
       event["priority"] = priority
@@ -217,32 +216,29 @@ def syslog_relay(event, url)
       @date_filter.filter(event)
     else
       @logger.info("NOT SYSLOG", :message => event.message)
-      url = "syslog://#{Socket.gethostname}/" if url == "syslog://127.0.0.1/"
 
       # RFC3164 says unknown messages get pri=13
       priority = 13
-      event.fields["priority"] = 13
-      event.fields["severity"] = 5   # 13 & 7 == 5
-      event.fields["facility"] = 1   # 13 >> 3 == 1
+      event["priority"] = 13
+      event["severity"] = 5   # 13 & 7 == 5
+      event["facility"] = 1   # 13 >> 3 == 1
 
       # Don't need to modify the message, here.
       # event.message = ...
-
-      event.source = url
     end
 
     # Apply severity and facility metadata if
     # use_labels => true
     if @use_labels
-      facility_number = event.fields["facility"]
-      severity_number = event.fields["severity"]
+      facility_number = event["facility"]
+      severity_number = event["severity"]
 
       if @facility_labels[facility_number]
-        event.fields["facility_label"] = @facility_labels[facility_number]
+        event["facility_label"] = @facility_labels[facility_number]
       end
 
       if @severity_labels[severity_number]
-        event.fields["severity_label"] = @severity_labels[severity_number]
+        event["severity_label"] = @severity_labels[severity_number]
       end
     end
   end # def syslog_relay
diff --git a/lib/logstash/inputs/tcp.rb b/lib/logstash/inputs/tcp.rb
index 607c7e3471c..1fdbef9de1b 100644
--- a/lib/logstash/inputs/tcp.rb
+++ b/lib/logstash/inputs/tcp.rb
@@ -13,6 +13,9 @@ class Interrupted < StandardError; end
   config_name "tcp"
   milestone 2
 
+  # XXX Refactor this to use the 'line' codec by default.
+  default :codec => "plain"
+
   # When mode is `server`, the address to listen on.
   # When mode is `client`, the address to connect to.
   config :host, :validate => :string, :default => "0.0.0.0"
diff --git a/lib/logstash/inputs/udp.rb b/lib/logstash/inputs/udp.rb
index f7b62ea6189..71f96ad0085 100644
--- a/lib/logstash/inputs/udp.rb
+++ b/lib/logstash/inputs/udp.rb
@@ -9,6 +9,8 @@ class LogStash::Inputs::Udp < LogStash::Inputs::Base
   config_name "udp"
   milestone 2
 
+  default :codec, "plain"
+
   # The address to listen on
   config :host, :validate => :string, :default => "0.0.0.0"
 
@@ -55,13 +57,13 @@ def udp_listener(output_queue)
     @udp.bind(@host, @port)
 
     loop do
-      line, client = @udp.recvfrom(@buffer_size)
+      payload, client = @udp.recvfrom(@buffer_size)
       # Ruby uri sucks, so don't use it.
       source = "udp://#{client[3]}:#{client[1]}/"
 
-      e = to_event(line, source)
-      if e
-        output_queue << e
+      @codec.decode(payload) do |event|
+        event["source"] = "#{client[3]}:#{client[1]}"
+        output_queue << event
       end
     end
   ensure
diff --git a/lib/logstash/inputs/unix.rb b/lib/logstash/inputs/unix.rb
index f68436f9897..166c1a88f50 100644
--- a/lib/logstash/inputs/unix.rb
+++ b/lib/logstash/inputs/unix.rb
@@ -12,6 +12,8 @@ class Interrupted < StandardError; end
   config_name "unix"
   milestone 2
 
+  default :codec, "line"
+
   # When mode is `server`, the path to listen on.
   # When mode is `client`, the path to connect to.
   config :path, :validate => :string, :required => true
@@ -70,14 +72,14 @@ def handle_socket(socket, output_queue, event_source)
         # or socket dies
         # TODO(sissel): Why do we have a timeout here? What's the point?
         if @data_timeout == -1
-          buf = readline(socket)
+          buf = socket.readpartial(16384
         else
           Timeout::timeout(@data_timeout) do
-            buf = readline(socket)
+            buf = socket.readpartial(16384)
           end
         end
-        e = self.to_event(buf, event_source)
-        if e
+        @codec.decode(buf) do |event|
+          event["source"] = event_source
           output_queue << e
         end
       end # loop do
@@ -102,11 +104,6 @@ def server?
     @mode == "server"
   end # def server?
 
-  private
-  def readline(socket)
-    line = socket.readline
-  end # def readline
-
   public
   def run(output_queue)
     if server?
diff --git a/lib/logstash/inputs/varnishlog.rb b/lib/logstash/inputs/varnishlog.rb
index 6c32752af41..5505300a3ec 100644
--- a/lib/logstash/inputs/varnishlog.rb
+++ b/lib/logstash/inputs/varnishlog.rb
@@ -26,7 +26,7 @@ def run(queue)
   def cb(priv, tag, fd, len, spec, ptr, bitmap)
     begin
       str = ptr.read_string(len)
-      event = to_event(str, @source)
+      event = LogStash::Event.new("message" => str, "source" => @source)
       event["varnish_tag"] = tag
       event["varnish_fd"] = fd
       event["varnish_spec"] = spec
diff --git a/lib/logstash/inputs/websocket.rb b/lib/logstash/inputs/websocket.rb
index af44ac15c8a..df4c2a00700 100644
--- a/lib/logstash/inputs/websocket.rb
+++ b/lib/logstash/inputs/websocket.rb
@@ -7,6 +7,8 @@ class LogStash::Inputs::Websocket < LogStash::Inputs::Base
   config_name "websocket"
   milestone 1
 
+  default :codec, "json"
+
   # The url to connect to or serve from
   config :url, :validate => :string, :default => "0.0.0.0"
 
@@ -21,7 +23,6 @@ class LogStash::Inputs::Websocket < LogStash::Inputs::Base
   config :mode, :validate => [ "server", "client" ], :default => "client"
 
   def register
-    @format ||= "json_event"
     require "ftw"
   end # def register
 
@@ -33,8 +34,9 @@ def run(output_queue)
     begin
       websocket = agent.websocket!(@url)
       websocket.each do |payload|
-        event = to_event(payload, @url)
-        output_queue << event
+        @codec.decode(payload) do |event|
+          output_queue << event
+        end
       end
     rescue => e
       @logger.warn("websocket input client threw exception, restarting",
diff --git a/lib/logstash/inputs/wmi.rb b/lib/logstash/inputs/wmi.rb
index 9f75240c1aa..03213d9436a 100644
--- a/lib/logstash/inputs/wmi.rb
+++ b/lib/logstash/inputs/wmi.rb
@@ -50,13 +50,14 @@ def run(queue)
     begin
       @logger.debug("Executing WMI query '#{@query}'")
       loop do
-        @wmi.ExecQuery(@query).each do |event|
+        @wmi.ExecQuery(@query).each do |wmiobj|
           # create a single event for all properties in the collection
-          e = to_event("", "wmi://#{@host}/#{@query}")
-          event.Properties_.each do |prop|
-            e[prop.name] = prop.value
+          event = LogStash::Event.new
+          event["source"] = @host
+          wmiobj.Properties_.each do |prop|
+            event[prop.name] = prop.value
           end
-          queue << e
+          queue << event
         end
         sleep @interval
       end # loop
diff --git a/lib/logstash/inputs/xmpp.rb b/lib/logstash/inputs/xmpp.rb
index 5c6cefebaa5..6e22f45bfd9 100644
--- a/lib/logstash/inputs/xmpp.rb
+++ b/lib/logstash/inputs/xmpp.rb
@@ -11,6 +11,8 @@ class LogStash::Inputs::Xmpp < LogStash::Inputs::Base
   config_name "xmpp"
   milestone 2
 
+  default :codec, "plain"
+
   # The user or resource ID, like foo@example.com.
   config :user, :validate => :string, :required => :true
 
@@ -50,8 +52,11 @@ def run(queue)
         @muc = Jabber::MUC::SimpleMUCClient.new(@client)
         @muc.join(room)
         @muc.on_message do |time,from,body|
-          e = to_event(body, "#{room}/#{from}")
-          queue << e if e
+          @codec.decode(body) do |event|
+            event["room"] = room
+            event["from"] = from
+            queue << event
+          end
         end # @muc.on_message
       end # @rooms.each
     end # if @rooms
@@ -61,8 +66,10 @@ def run(queue)
 
       # accept normal msgs (skip presence updates, etc)
       if msg.body != nil
-        e = to_event(msg.body, source)
-        queue << e
+        @codec.decode(msg.body) do |event|
+          event["from"] = "#{msg.from.node}@#{msg.from.domain}/#{msg.from.resource}"
+          queue << event
+        end
       end
     end # @client.add_message_callback
     sleep
diff --git a/lib/logstash/inputs/zeromq.rb b/lib/logstash/inputs/zeromq.rb
index 4bf9e6eb6da..b9d011e1a02 100644
--- a/lib/logstash/inputs/zeromq.rb
+++ b/lib/logstash/inputs/zeromq.rb
@@ -16,6 +16,8 @@ class LogStash::Inputs::ZeroMQ < LogStash::Inputs::Base
   config_name "zeromq"
   milestone 2
 
+  default :codec, "json"
+
   # 0mq socket address to connect or bind
   # Please note that `inproc://` will not work with logstash
   # as each we use a context per thread.
@@ -72,7 +74,6 @@ class LogStash::Inputs::ZeroMQ < LogStash::Inputs::Base
   def register
     require "ffi-rzmq"
     require "logstash/util/zeromq"
-    @format ||= "json_event"
     self.class.send(:include, LogStash::Util::ZeroMQ)
 
     case @topology
@@ -141,9 +142,9 @@ def run(output_queue)
           msg = m2
         end
         @sender ||= "zmq+#{@topology}://#{host}/#{@type}"
-        e = self.to_event(msg, @sender)
-        if e
-          output_queue << e
+
+        @codec.decode(msg) do |event|
+          output_queue << event
         end
       end
     rescue => e
diff --git a/lib/logstash/outputs/gelf.rb b/lib/logstash/outputs/gelf.rb
index 780ccf916cb..321d47eff5e 100644
--- a/lib/logstash/outputs/gelf.rb
+++ b/lib/logstash/outputs/gelf.rb
@@ -128,8 +128,8 @@ def receive(event)
     m = Hash.new
 
     m["short_message"] = event.message
-    if event.fields[@short_message]
-      v = event.fields[@short_message]
+    if event[@short_message]
+      v = event[@short_message]
       short_message = (v.is_a?(Array) && v.length == 1) ? v.first : v
       short_message = short_message.to_s
       if !short_message.empty?
@@ -145,7 +145,7 @@ def receive(event)
     m["line"] = m["line"].to_i if m["line"].is_a?(String) and m["line"] === /^[\d]+$/
 
     if @ship_metadata
-      event.fields.each do |name, value|
+      event.to_hash.each do |name, value|
         next if value == nil
 
         # Trim leading '_' in the event
diff --git a/lib/logstash/outputs/graphite.rb b/lib/logstash/outputs/graphite.rb
index 41d5aade377..4a3c5b5369a 100644
--- a/lib/logstash/outputs/graphite.rb
+++ b/lib/logstash/outputs/graphite.rb
@@ -100,8 +100,8 @@ def receive(event)
     timestamp = event.sprintf("%{+%s}")
 
     if @fields_are_metrics
-      @logger.debug("got metrics event", :metrics => event.fields)
-      event.fields.each do |metric,value|
+      @logger.debug("got metrics event", :metrics => event.to_hash)
+      event.to_hash.each do |metric,value|
         next unless @include_metrics.empty? || @include_metrics.any? { |regexp| metric.match(regexp) }
         next if @exclude_metrics.any? {|regexp| metric.match(regexp)}
         messages << "#{construct_metric_name(metric)} #{event.sprintf(value.to_s).to_f} #{timestamp}"
diff --git a/lib/logstash/outputs/redis.rb b/lib/logstash/outputs/redis.rb
index eb30f97ae0b..cb05698763a 100644
--- a/lib/logstash/outputs/redis.rb
+++ b/lib/logstash/outputs/redis.rb
@@ -141,16 +141,27 @@ def receive(event)
       return
     end
 
-    event_key = event.sprintf(@key)
-    event_key_and_payload = [event_key, event.to_json]
+    key = event.sprintf(@key)
+    # TODO(sissel): We really should not drop an event, but historically
+    # we have dropped events that fail to be converted to json.
+    # TODO(sissel): Find a way to continue passing events through even
+    # if they fail to convert properly.
+    begin
+      payload = event.to_json
+    rescue Encoding::UndefinedConversionError, ArgumentError
+      puts "FAILUREENCODING"
+      @logger.error("Failed to convert event to JSON. Invalid UTF-8, maybe?",
+                    :event => event.inspect)
+      return
+    end
 
     begin
       @redis ||= connect
       if @data_type == 'list'
-        congestion_check(event_key)
-        @redis.rpush *event_key_and_payload
+        congestion_check(key)
+        @redis.rpush(key, payload)
       else
-        @redis.publish *event_key_and_payload
+        @redis.publish(key, payload)
       end
     rescue => e
       @logger.warn("Failed to send event to redis", :event => event,
diff --git a/lib/logstash/outputs/s3.rb b/lib/logstash/outputs/s3.rb
index af75a1ec4f4..c9631995787 100644
--- a/lib/logstash/outputs/s3.rb
+++ b/lib/logstash/outputs/s3.rb
@@ -337,11 +337,11 @@ def receive(event)
  end
 
  def self.format_message(event)
-    message = "Date: #{event.timestamp}\n"
-    message << "Source: #{event.source}\n"
-    message << "Tags: #{event.tags.join(', ')}\n"
-    message << "Fields: #{event.fields.inspect}\n"
-    message << "Message: #{event.message}"
+    message = "Date: #{event["@timestamp"]}\n"
+    message << "Source: #{event["source"]}\n"
+    message << "Tags: #{event["tags"].join(', ')}\n"
+    message << "Fields: #{event.to_hash.inspect}\n"
+    message << "Message: #{event["message"]}"
  end
 
 end
diff --git a/lib/logstash/outputs/sns.rb b/lib/logstash/outputs/sns.rb
index d2f0a2c6ef7..2bf972dda91 100644
--- a/lib/logstash/outputs/sns.rb
+++ b/lib/logstash/outputs/sns.rb
@@ -70,12 +70,12 @@ def register
   def receive(event)
     return unless output?(event)
 
-    arn     = Array(event.fields["sns"]).first || @arn
+    arn     = Array(event["sns"]).first || @arn
 
     raise "An SNS ARN required." unless arn
 
-    message = Array(event.fields["sns_message"]).first
-    subject = Array(event.fields["sns_subject"]).first || event.source
+    message = Array(event["sns_message"]).first
+    subject = Array(event["sns_subject"]).first || event.source
 
     # Ensure message doesn't exceed the maximum size.
     if message
@@ -111,11 +111,11 @@ def self.json_message(event)
   end
 
   def self.format_message(event)
-    message =  "Date: #{event.timestamp}\n"
-    message << "Source: #{event.source}\n"
-    message << "Tags: #{event.tags.join(', ')}\n"
-    message << "Fields: #{event.fields.inspect}\n"
-    message << "Message: #{event.message}"
+    message =  "Date: #{event["@timestamp"]}\n"
+    message << "Source: #{event["source"]}\n"
+    message << "Tags: #{event["tags"].join(', ')}\n"
+    message << "Fields: #{event.to_hash.inspect}\n"
+    message << "Message: #{event["message"]}"
 
     # TODO: Utilize `byteslice` in JRuby 1.7: http://jira.codehaus.org/browse/JRUBY-5547
     message.slice(0, MAX_MESSAGE_SIZE_IN_BYTES)
diff --git a/lib/logstash/outputs/stdout.rb b/lib/logstash/outputs/stdout.rb
index 1769f8c2d72..f5fcab4209a 100644
--- a/lib/logstash/outputs/stdout.rb
+++ b/lib/logstash/outputs/stdout.rb
@@ -23,7 +23,7 @@ class LogStash::Outputs::Stdout < LogStash::Outputs::Base
   def register
     @print_method = method(:ap) rescue method(:p)
     @codec.on_event do |event|
-      $stdout.write(event)
+      $stdout.puts(event)
     end
   end
 
diff --git a/lib/logstash/outputs/zabbix.rb b/lib/logstash/outputs/zabbix.rb
index e53480592e8..18155bf1b67 100644
--- a/lib/logstash/outputs/zabbix.rb
+++ b/lib/logstash/outputs/zabbix.rb
@@ -71,7 +71,7 @@ def receive(event)
       return
     end
  
-    host = event.fields["zabbix_host"]
+    host = event["zabbix_host"]
     if !host
       @logger.warn("Skipping zabbix output; zabbix_host field is missing",
                    :missed_event => event)
@@ -79,7 +79,7 @@ def receive(event)
     end
     host = host.first if host.is_a?(Array)
  
-    item = event.fields["zabbix_item"]
+    item = event["zabbix_item"]
     if !item
       @logger.warn("Skipping zabbix output; zabbix_item field is missing",
                    :missed_event => event)
diff --git a/lib/logstash/pipeline.rb b/lib/logstash/pipeline.rb
index 93af1a24a33..f69d736c7ec 100644
--- a/lib/logstash/pipeline.rb
+++ b/lib/logstash/pipeline.rb
@@ -22,7 +22,12 @@ def initialize(configstr)
     # The config code is hard to represent as a log message...
     # So just print it.
     @logger.debug? && @logger.debug("Compiled pipeline code:\n#{code}")
-    eval(code)
+    begin
+      eval(code)
+    rescue => e
+      p e.backtrace[1]
+      raise
+    end
 
     @input_to_filter = SizedQueue.new(20)
 
@@ -149,7 +154,8 @@ def inputworker(plugin)
     rescue => e
       if @logger.debug?
         @logger.error(I18n.t("logstash.pipeline.worker-error-debug",
-                             :plugin => plugin.inspect, :error => e,
+                             :plugin => plugin.inspect, :error => e.to_s,
+                             :exception => e.class,
                              :stacktrace => e.backtrace.join("\n")))
       else
         @logger.error(I18n.t("logstash.pipeline.worker-error",
diff --git a/locales/en.yml b/locales/en.yml
index 86c7b97570a..b21a4e0e60f 100644
--- a/locales/en.yml
+++ b/locales/en.yml
@@ -26,6 +26,7 @@ en:
         A plugin had an unrecoverable error. Will restart this plugin.
           Plugin: %{plugin}
           Error: %{error}
+          Exception: %{exception}
           Stack: %{stacktrace}
       plugin-loading-error: >-
         Couldn't find any %{type} plugin named '%{name}'. Are you 
diff --git a/spec/inputs/redis.rb b/spec/inputs/redis.rb
index 6a145ef84e0..bec6d6a45d9 100644
--- a/spec/inputs/redis.rb
+++ b/spec/inputs/redis.rb
@@ -5,23 +5,21 @@ def populate(key, event_count)
   require "logstash/event"
   redis = Redis.new(:host => "localhost")
   event_count.times do |value|
-    event = LogStash::Event.new("@fields" => { "sequence" => value })
+    event = LogStash::Event.new("sequence" => value)
     Stud::try(10.times) do
       redis.rpush(key, event.to_json)
     end
   end
 end
 
-def process(plugins, event_count)
+def process(pipeline, queue, event_count)
   sequence = 0
-  redis = plugins.first
-  output = Shiftback.new do |event|
-    insist { event["sequence"] } == sequence
-    sequence += 1
-    redis.teardown if sequence == event_count
+  Thread.new { pipeline.run }
+  event_count.times do |i|
+    event = queue.pop
+    insist { event["sequence"] } == i
   end
-  redis.register
-  redis.run(output)
+  pipeline.shutdown
 end # process
 
 describe "inputs/redis" do
@@ -36,13 +34,13 @@ def process(plugins, event_count)
           type => "blah"
           key => "#{key}"
           data_type => "list"
-          format => json_event
         }
       }
     CONFIG
 
     before(:each) { populate(key, event_count) }
-    input { |plugins| process(plugins, event_count) }
+
+    input { |pipeline, queue| process(pipeline, queue, event_count) }
   end
 
   describe "read events from a list with batch_count=5" do
@@ -55,12 +53,11 @@ def process(plugins, event_count)
           key => "#{key}"
           data_type => "list"
           batch_count => #{rand(20)+1}
-          format => json_event
         }
       }
     CONFIG
 
     before(:each) { populate(key, event_count) }
-    input { |plugins| process(plugins, event_count) }
+    input { |pipeline, queue| process(pipeline, queue, event_count) }
   end
 end
diff --git a/spec/outputs/redis.rb b/spec/outputs/redis.rb
index 2a3edf04064..3a50e6a4e4e 100644
--- a/spec/outputs/redis.rb
+++ b/spec/outputs/redis.rb
@@ -38,8 +38,7 @@
         id, element = redis.blpop(key, 0)
         event = LogStash::Event.new(JSON.parse(element))
         insist { event["sequence"] } == value
-        insist { event.message } == "hello world"
-        insist { event.type } == "generator"
+        insist { event["message"] } == "hello world"
       end
 
       # The list should now be empty
@@ -47,35 +46,6 @@
     end # agent
   end
 
-  describe "skips a message which can't be encoded as json" do
-    key = 10.times.collect { rand(10).to_s }.join("")
-
-    config <<-CONFIG
-      input {
-        generator {
-          message => "\xAD\u0000"
-          count => 1
-          type => "generator"
-        }
-      }
-      output {
-        redis {
-          host => "127.0.0.1"
-          key => "#{key}"
-          data_type => list
-        }
-      }
-    CONFIG
-
-    agent do
-      # Query redis directly and inspect the goodness.
-      redis = Redis.new(:host => "127.0.0.1")
-
-      # The list should contain no elements.
-      insist { redis.llen(key) } == 0
-    end # agent
-  end
-
   describe "batch mode" do
     key = 10.times.collect { rand(10).to_s }.join("")
     event_count = 200000
@@ -116,8 +86,7 @@
         id, element = redis.blpop(key, 0)
         event = LogStash::Event.new(JSON.parse(element))
         insist { event["sequence"] } == value
-        insist { event.message } == "hello world"
-        insist { event.type } == "generator"
+        insist { event["message"] } == "hello world"
       end
 
       # The list should now be empty
diff --git a/spec/test_utils.rb b/spec/test_utils.rb
index 8161f11c8bb..86cf0fb4dad 100644
--- a/spec/test_utils.rb
+++ b/spec/test_utils.rb
@@ -77,33 +77,24 @@ def sample(sample_event, &block)
 
     def input(&block)
       it "inputs" do
-        queue = Queue.new
         pipeline = LogStash::Pipeline.new(config)
-        #(class << pipeline; self; end).send(:define_method, :output) do |event|
-          #p :event => event
-          #queue << event
-        #end
-        #p pipeline.method(:output)
+        queue = Queue.new
+        pipeline.instance_eval do 
+          @output_func = lambda { |event| queue << event }
+        end
         block.call(pipeline, queue)
         pipeline.shutdown
       end
     end # def input
 
     def agent(&block)
-      @agent_count ||= 0
       require "logstash/pipeline"
 
-      # scoping is hard, let's go shopping!
-      describe "agent(#{@agent_count}) #{caller[1]}" do
-        before :each do
-          start = ::Time.now
-          pipeline = LogStash::Pipeline.new(config)
-          pipeline.run
-          @duration = ::Time.now - start
-        end
-        it("looks good", &block)
+      it("agent(#{caller[0].gsub(/ .*/, "")}) runs") do
+        pipeline = LogStash::Pipeline.new(config)
+        pipeline.run
+        block.call
       end
-      @agent_count += 1
     end # def agent
 
   end # module RSpec
