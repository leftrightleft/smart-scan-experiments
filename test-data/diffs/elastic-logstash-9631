diff --git a/logstash-core/lib/logstash/java_pipeline.rb b/logstash-core/lib/logstash/java_pipeline.rb
index e8edb5acb6b..896af5e4294 100644
--- a/logstash-core/lib/logstash/java_pipeline.rb
+++ b/logstash-core/lib/logstash/java_pipeline.rb
@@ -6,7 +6,6 @@
 require "logstash/inputs/base"
 require "logstash/outputs/base"
 require "logstash/shutdown_watcher"
-require "logstash/pipeline_reporter"
 require "logstash/instrument/collector"
 require "logstash/queue_factory"
 require "logstash/compiler"
diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 354512f79b7..2f40de40957 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -9,7 +9,6 @@
 require "logstash/inputs/base"
 require "logstash/outputs/base"
 require "logstash/shutdown_watcher"
-require "logstash/pipeline_reporter"
 require "logstash/instrument/collector"
 require "logstash/filter_delegator"
 require "logstash/queue_factory"
diff --git a/logstash-core/lib/logstash/pipeline_reporter.rb b/logstash-core/lib/logstash/pipeline_reporter.rb
index eb02adc88d2..4dfe43e4ccc 100644
--- a/logstash-core/lib/logstash/pipeline_reporter.rb
+++ b/logstash-core/lib/logstash/pipeline_reporter.rb
@@ -1,108 +1,2 @@
-# encoding: utf-8
-require 'ostruct'
-
-module LogStash; class PipelineReporter
-  attr_reader :logger, :pipeline
-
-  # This is an immutable copy of the pipeline state,
-  # It is a proxy to a hash to allow us to add methods dynamically to the hash
-  class Snapshot
-    def initialize(data)
-      @data = data
-    end
-
-    def to_hash
-      @data
-    end
-
-    def to_simple_hash
-      {"inflight_count" => inflight_count, "stalling_thread_info" => format_threads_by_plugin}
-    end
-
-    def to_str
-      to_simple_hash.to_s
-    end
-    alias_method :to_s, :to_str
-
-    def method_missing(meth)
-      @data[meth]
-    end
-
-    def format_threads_by_plugin
-      stalled_plugins = {}
-      stalling_threads_info.each do |thr|
-        key = (thr.delete("plugin") || "other")
-        stalled_plugins[key] ||= []
-        stalled_plugins[key] << thr
-      end
-      stalled_plugins
-    end
-  end
-
-  def initialize(logger, pipeline)
-    @logger = logger
-    @pipeline = pipeline
-  end
-
-  # The main way of accessing data from the reporter,,
-  # this provides a (more or less) consistent snapshot of what's going on in the
-  # pipeline with some extra decoration
-  def snapshot
-    Snapshot.new(self.to_hash)
-  end
-
-  def to_hash
-    # pipeline.filter_queue_client.inflight_batches is synchronized
-    batch_map = pipeline.filter_queue_client.inflight_batches
-    worker_states_snap = worker_states(batch_map) # We only want to run this once
-    inflight_count = worker_states_snap.map {|s| s[:inflight_count]}.reduce(0, :+)
-    {
-        :events_filtered => events_filtered,
-        :events_consumed => events_consumed,
-        :inflight_count => inflight_count,
-        :worker_states => worker_states_snap,
-        :output_info => output_info,
-        :thread_info => pipeline.plugin_threads_info,
-        :stalling_threads_info => pipeline.stalling_threads_info
-    }
-  end
-
-  private
-
-  def events_filtered
-    pipeline.events_filtered.sum
-  end
-
-  def events_consumed
-    pipeline.events_consumed.sum
-  end
-
-  def plugin_threads
-    pipeline.plugin_threads
-  end
-
-  # Not threadsafe! ensure synchronization
-  def worker_states(batch_map)
-    pipeline.worker_threads.map.with_index do |thread, idx|
-      status = thread.status || "dead"
-      batch = batch_map[thread]
-      inflight_count = batch ? batch.size : 0
-      {
-        :status => status,
-        :alive => thread.alive?,
-        :index => idx,
-        :inflight_count => inflight_count
-      }
-    end
-  end
-
-  def output_info
-    pipeline.outputs.map do |output_delegator|
-      {
-        :type => output_delegator.config_name,
-        :id => output_delegator.id,
-        :concurrency => output_delegator.concurrency,
-      }
-    end
-  end
-end end
+# The contents of this file have been ported to Java. It is included for for compatibility
+# with plugins that directly require it.
diff --git a/logstash-core/spec/logstash/pipeline_reporter_spec.rb b/logstash-core/spec/logstash/pipeline_reporter_spec.rb
index 636f98c34ce..e73e1a31407 100644
--- a/logstash-core/spec/logstash/pipeline_reporter_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_reporter_spec.rb
@@ -1,7 +1,6 @@
 # encoding: utf-8
 require "spec_helper"
 require "logstash/pipeline"
-require "logstash/pipeline_reporter"
 require_relative "../support/helpers"
 require_relative "../support/mocks_classes"
 
@@ -21,7 +20,7 @@
     allow(LogStash::Plugin).to receive(:lookup).with("codec", "plain").and_call_original
 
     @pre_snapshot = reporter.snapshot
-    
+
     pipeline.run
     @post_snapshot = reporter.snapshot
   end
diff --git a/logstash-core/src/main/java/org/logstash/RubyUtil.java b/logstash-core/src/main/java/org/logstash/RubyUtil.java
index 533d805882a..69463a7ba7a 100644
--- a/logstash-core/src/main/java/org/logstash/RubyUtil.java
+++ b/logstash-core/src/main/java/org/logstash/RubyUtil.java
@@ -17,6 +17,7 @@
 import org.logstash.config.ir.compiler.OutputStrategyExt;
 import org.logstash.execution.EventDispatcherExt;
 import org.logstash.execution.ExecutionContextExt;
+import org.logstash.execution.PipelineReporterExt;
 import org.logstash.execution.QueueReadClientBase;
 import org.logstash.ext.JRubyLogstashErrorsExt;
 import org.logstash.ext.JRubyWrappedWriteClientExt;
@@ -156,6 +157,10 @@ public final class RubyUtil {
 
     public static final RubyClass EVENT_DISPATCHER_CLASS;
 
+    public static final RubyClass PIPELINE_REPORTER_CLASS;
+
+    public static final RubyClass PIPELINE_REPORTER_SNAPSHOT_CLASS;
+
     /**
      * Logstash Ruby Module.
      */
@@ -348,7 +353,7 @@ public final class RubyUtil {
         LOGGER = loggingModule.defineClassUnder("Logger", RUBY.getObject(), LoggerExt::new);
         LOGGER.defineAnnotatedMethods(LoggerExt.class);
         SLOW_LOGGER = loggingModule.defineClassUnder(
-                "SlowLogger", RUBY.getObject(), SlowLoggerExt::new);
+            "SlowLogger", RUBY.getObject(), SlowLoggerExt::new);
         SLOW_LOGGER.defineAnnotatedMethods(SlowLoggerExt.class);
         LOGGABLE_MODULE = UTIL_MODULE.defineModuleUnder("Loggable");
         LOGGABLE_MODULE.defineAnnotatedMethods(LoggableExt.class);
@@ -421,6 +426,15 @@ public final class RubyUtil {
             setupLogstashClass(UniversalPluginExt::new, UniversalPluginExt.class);
         EVENT_DISPATCHER_CLASS =
             setupLogstashClass(EventDispatcherExt::new, EventDispatcherExt.class);
+        PIPELINE_REPORTER_CLASS =
+            setupLogstashClass(PipelineReporterExt::new, PipelineReporterExt.class);
+        PIPELINE_REPORTER_CLASS.defineAnnotatedMethods(PipelineReporterExt.class);
+        PIPELINE_REPORTER_SNAPSHOT_CLASS = PIPELINE_REPORTER_CLASS.defineClassUnder(
+            "Snapshot", RUBY.getObject(), PipelineReporterExt.SnapshotExt::new
+        );
+        PIPELINE_REPORTER_SNAPSHOT_CLASS.defineAnnotatedMethods(
+            PipelineReporterExt.SnapshotExt.class
+        );
         RUBY.getGlobalVariables().set("$LS_JARS_LOADED", RUBY.newString("true"));
         RubyJavaIntegration.setupRubyJavaIntegration(RUBY);
     }
diff --git a/logstash-core/src/main/java/org/logstash/execution/PipelineReporterExt.java b/logstash-core/src/main/java/org/logstash/execution/PipelineReporterExt.java
new file mode 100644
index 00000000000..45240e4dec4
--- /dev/null
+++ b/logstash-core/src/main/java/org/logstash/execution/PipelineReporterExt.java
@@ -0,0 +1,252 @@
+package org.logstash.execution;
+
+import java.util.Collection;
+import org.jruby.Ruby;
+import org.jruby.RubyArray;
+import org.jruby.RubyBasicObject;
+import org.jruby.RubyClass;
+import org.jruby.RubyHash;
+import org.jruby.RubyString;
+import org.jruby.RubySymbol;
+import org.jruby.anno.JRubyClass;
+import org.jruby.anno.JRubyMethod;
+import org.jruby.runtime.Block;
+import org.jruby.runtime.ThreadContext;
+import org.jruby.runtime.builtin.IRubyObject;
+import org.logstash.RubyUtil;
+import org.logstash.config.ir.compiler.OutputDelegatorExt;
+
+@JRubyClass(name = "PipelineReporter")
+public final class PipelineReporterExt extends RubyBasicObject {
+
+    private static final RubySymbol EVENTS_FILTERED_KEY =
+        RubyUtil.RUBY.newSymbol("events_filtered");
+
+    private static final RubySymbol EVENTS_CONSUMED_KEY =
+        RubyUtil.RUBY.newSymbol("events_consumed");
+
+    private static final RubySymbol INFLIGHT_COUNT_KEY =
+        RubyUtil.RUBY.newSymbol("inflight_count");
+
+    private static final RubySymbol WORKER_STATES_KEY =
+        RubyUtil.RUBY.newSymbol("worker_states");
+
+    private static final RubySymbol OUTPUT_INFO_KEY =
+        RubyUtil.RUBY.newSymbol("output_info");
+
+    private static final RubySymbol THREAD_INFO_KEY =
+        RubyUtil.RUBY.newSymbol("thread_info");
+
+    private static final RubySymbol STALLING_THREADS_INFO_KEY =
+        RubyUtil.RUBY.newSymbol("stalling_threads_info");
+
+    private static final RubySymbol TYPE_KEY = RubyUtil.RUBY.newSymbol("type");
+
+    private static final RubySymbol ID_KEY = RubyUtil.RUBY.newSymbol("id");
+
+    private static final RubySymbol STATUS_KEY = RubyUtil.RUBY.newSymbol("status");
+
+    private static final RubySymbol ALIVE_KEY = RubyUtil.RUBY.newSymbol("alive");
+
+    private static final RubySymbol INDEX_KEY = RubyUtil.RUBY.newSymbol("index");
+
+    private static final RubySymbol CONCURRENCY_KEY = RubyUtil.RUBY.newSymbol("concurrency");
+
+    private static final RubyString DEAD_STATUS =
+        RubyUtil.RUBY.newString("dead").newFrozen();
+
+    private IRubyObject logger;
+
+    private IRubyObject pipeline;
+
+    public PipelineReporterExt(final Ruby runtime, final RubyClass metaClass) {
+        super(runtime, metaClass);
+    }
+
+    @JRubyMethod
+    public PipelineReporterExt initialize(final ThreadContext context, final IRubyObject logger,
+        final IRubyObject pipeline) {
+        this.logger = logger;
+        this.pipeline = pipeline;
+        return this;
+    }
+
+    @JRubyMethod
+    public IRubyObject pipeline() {
+        return pipeline;
+    }
+
+    @JRubyMethod
+    public IRubyObject logger() {
+        return logger;
+    }
+
+    /**
+     * The main way of accessing data from the reporter,,
+     * this provides a (more or less) consistent snapshot of what's going on in the
+     * pipeline with some extra decoration
+     * @param context Thread Context
+     * @return Snapshot
+     */
+    @JRubyMethod
+    public PipelineReporterExt.SnapshotExt snapshot(final ThreadContext context) {
+        return new PipelineReporterExt.SnapshotExt(
+            context.runtime, RubyUtil.PIPELINE_REPORTER_SNAPSHOT_CLASS).initialize(toHash(context)
+        );
+    }
+
+    @JRubyMethod(name = "to_hash")
+    public RubyHash toHash(final ThreadContext context) {
+        final RubyHash result = RubyHash.newHash(context.runtime);
+        final RubyHash batchMap = (RubyHash) pipeline
+            .callMethod(context, "filter_queue_client")
+            .callMethod(context, "inflight_batches");
+        final RubyArray workerStates = workerStates(context, batchMap);
+        result.op_aset(context, WORKER_STATES_KEY, workerStates);
+        result.op_aset(
+            context,
+            EVENTS_FILTERED_KEY,
+            pipeline.callMethod(context, "events_filtered").callMethod(context, "sum")
+        );
+        result.op_aset(
+            context,
+            EVENTS_CONSUMED_KEY,
+            pipeline.callMethod(context, "events_consumed").callMethod(context, "sum")
+        );
+        result.op_aset(context, OUTPUT_INFO_KEY, outputInfo(context));
+        result.op_aset(
+            context, THREAD_INFO_KEY, pipeline.callMethod(context, "plugin_threads_info")
+        );
+        result.op_aset(
+            context, STALLING_THREADS_INFO_KEY,
+            pipeline.callMethod(context, "stalling_threads_info")
+        );
+        result.op_aset(
+            context, INFLIGHT_COUNT_KEY,
+            context.runtime.newFixnum(calcInflightCount(context, workerStates))
+        );
+        return result;
+    }
+
+    @SuppressWarnings("unchecked")
+    private RubyArray workerStates(final ThreadContext context, final RubyHash batchMap) {
+        final RubyArray result = context.runtime.newArray();
+        ((Iterable<IRubyObject>) pipeline.callMethod(context, "worker_threads"))
+            .forEach(thread -> {
+                final RubyHash hash = RubyHash.newHash(context.runtime);
+                IRubyObject status = thread.callMethod(context, "status");
+                if (status.isNil()) {
+                    status = DEAD_STATUS;
+                }
+                hash.op_aset(context, STATUS_KEY, status);
+                hash.op_aset(context, ALIVE_KEY, thread.callMethod(context, "alive?"));
+                hash.op_aset(context, INDEX_KEY, context.runtime.newFixnum(result.size()));
+                final IRubyObject batch = batchMap.op_aref(context, thread);
+                hash.op_aset(
+                    context, INFLIGHT_COUNT_KEY,
+                    batch.isNil() ?
+                        context.runtime.newFixnum(0) : batch.callMethod(context, "size")
+                );
+                result.add(hash);
+            });
+        return result;
+    }
+
+    @SuppressWarnings("unchecked")
+    private RubyArray outputInfo(final ThreadContext context) {
+        final RubyArray result = context.runtime.newArray();
+        ((Iterable<?>) pipeline.callMethod(context, "outputs")).forEach(output -> {
+            final OutputDelegatorExt delegator = (OutputDelegatorExt) output;
+            final RubyHash hash = RubyHash.newHash(context.runtime);
+            hash.op_aset(context, TYPE_KEY, delegator.configName(context));
+            hash.op_aset(context, ID_KEY, delegator.id(context));
+            hash.op_aset(context, CONCURRENCY_KEY, delegator.concurrency(context));
+            result.add(hash);
+        });
+        return result;
+    }
+
+    @SuppressWarnings("unchecked")
+    private static int calcInflightCount(final ThreadContext context,
+        final Collection<?> workerStates) {
+        return workerStates.stream().mapToInt(
+            state -> ((RubyHash) state).op_aref(context, INFLIGHT_COUNT_KEY)
+                .convertToInteger().getIntValue()
+        ).sum();
+    }
+
+    /**
+     * This is an immutable copy of the pipeline state,
+     * It is a proxy to a hash to allow us to add methods dynamically to the hash.
+     */
+    @JRubyClass(name = "Snapshot")
+    public static final class SnapshotExt extends RubyBasicObject {
+
+        private static final RubyString INFLIGHT_COUNT_KEY =
+            RubyUtil.RUBY.newString("inflight_count").newFrozen();
+
+        private static final RubyString STALLING_THREADS_KEY =
+            RubyUtil.RUBY.newString("stalling_thread_info").newFrozen();
+
+        private static final RubyString PLUGIN_KEY =
+            RubyUtil.RUBY.newString("plugin").newFrozen();
+
+        private static final RubyString OTHER_KEY =
+            RubyUtil.RUBY.newString("other").newFrozen();
+
+        private RubyHash data;
+
+        public SnapshotExt(final Ruby runtime, final RubyClass metaClass) {
+            super(runtime, metaClass);
+        }
+
+        @JRubyMethod
+        public PipelineReporterExt.SnapshotExt initialize(final IRubyObject data) {
+            this.data = (RubyHash) data;
+            return this;
+        }
+
+        @JRubyMethod(name = "to_hash")
+        public RubyHash toHash() {
+            return data;
+        }
+
+        @JRubyMethod(name = "to_simple_hash")
+        public RubyHash toSimpleHash(final ThreadContext context) {
+            final RubyHash result = RubyHash.newHash(context.runtime);
+            result.op_aset(
+                context, INFLIGHT_COUNT_KEY, data.op_aref(context, INFLIGHT_COUNT_KEY.intern())
+            );
+            result.op_aset(context, STALLING_THREADS_KEY, formatThreadsByPlugin(context));
+            return result;
+        }
+
+        @JRubyMethod(name = {"to_s", "to_str"})
+        public RubyString toStr(final ThreadContext context) {
+            return (RubyString) toSimpleHash(context).to_s(context);
+        }
+
+        @JRubyMethod(name = "method_missing")
+        public IRubyObject methodMissing(final ThreadContext context, final IRubyObject method) {
+            return data.op_aref(context, method);
+        }
+
+        @JRubyMethod(name = "format_threads_by_plugin")
+        @SuppressWarnings("unchecked")
+        public RubyHash formatThreadsByPlugin(final ThreadContext context) {
+            final RubyHash result = RubyHash.newHash(context.runtime);
+            ((Iterable<?>) data.get(STALLING_THREADS_KEY.intern())).forEach(thr -> {
+                final RubyHash threadInfo = (RubyHash) thr;
+                IRubyObject key = threadInfo.delete(context, PLUGIN_KEY, Block.NULL_BLOCK);
+                if (key.isNil()) {
+                    key = OTHER_KEY;
+                }
+                if (result.op_aref(context, key).isNil()) {
+                    result.op_aset(context, key, context.runtime.newArray());
+                }
+                ((RubyArray) result.op_aref(context, key)).append(threadInfo);
+            });
+            return result;
+        }
+    }
+}
