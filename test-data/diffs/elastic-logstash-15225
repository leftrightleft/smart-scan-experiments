diff --git a/docs/index.asciidoc b/docs/index.asciidoc
index ef4f1f7b86a..bf8bfe2b7b2 100644
--- a/docs/index.asciidoc
+++ b/docs/index.asciidoc
@@ -112,6 +112,21 @@ include::static/config-management.asciidoc[]
 
 include::static/management/configuring-centralized-pipelines.asciidoc[]
 
+// Data resiliency
+include::static/resiliency.asciidoc[]
+
+include::static/mem-queue.asciidoc[]
+
+include::static/persistent-queues.asciidoc[]
+
+include::static/dead-letter-queues.asciidoc[]
+
+// Transforming Data
+include::static/transforming-data.asciidoc[]
+
+// Ingest pipeline processing in Logstash
+include::static/ls-ingest-pipeline.asciidoc[]
+
 // Working with Logstash Modules
 include::static/modules.asciidoc[]
 
@@ -127,17 +142,6 @@ include::static/filebeat-modules.asciidoc[]
 // Working with Winlogbeat Modules
 include::static/winlogbeat-modules.asciidoc[]
 
-// Data resiliency
-include::static/resiliency.asciidoc[]
-
-include::static/mem-queue.asciidoc[]
-
-include::static/persistent-queues.asciidoc[]
-
-include::static/dead-letter-queues.asciidoc[]
-
-// Transforming Data
-include::static/transforming-data.asciidoc[]
 
 // Deploying & Scaling
 include::static/deploying.asciidoc[]
diff --git a/docs/static/ls-ingest-pipeline.asciidoc b/docs/static/ls-ingest-pipeline.asciidoc
new file mode 100644
index 00000000000..f705fd1751a
--- /dev/null
+++ b/docs/static/ls-ingest-pipeline.asciidoc
@@ -0,0 +1,20 @@
+[[ls-ingest-pipeline]]
+== Enriching data using {ls} ingest pipelines
+
+Do you want to collect sensitive, important data from endpoints quickly, but you need to transform the data before it is indexed into {es}? 
+{ls} ingest pipelines can help.
+
+{ls} ingest pipelines bring the power of {ref}/ingest.html[{es} ingest pipelines] into {ls} so that you can transform data _before_ it is sent to {es}.
+Legal, regulatory, or privacy reasons are common use cases, creating the need to obfuscate or redact some data before it goes to {es} for storage.  
+ 
+[discrete]
+[[how-to-set]]
+=== Add {ls} ingest pipeline processing
+
+{ls} ingest pipeline functionality is implemented as a filter plugin, and is easy to integrate into new or existing {ls} pipeline configurations. 
+Add and configure the logstash-filter-elastic_integration filter as the _first_ filter in your {ls} pipeline. 
+
+// ToDo: Add code sample
+// ToDo: Add link to plugin doc for settings and additional instructions after those docs are published.
+// For now: https://github.com/elastic/logstash-filter-elastic_integration
+
