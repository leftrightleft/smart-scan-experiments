diff --git a/lib/logstash/filters/advisor.rb b/lib/logstash/filters/advisor.rb
index 46f4d9e9b26..8d12e23ca4f 100644
--- a/lib/logstash/filters/advisor.rb
+++ b/lib/logstash/filters/advisor.rb
@@ -3,14 +3,14 @@
 require "logstash/namespace"
 
 # INFORMATION:
-# The filter Advisor is designed for capture and confrontation the events. 
-# The events must be grep by a filter first, then it can pull out a copy of it, like clone, whit tags "advisor_first",
+# The Advisor filter is designed for capture and confrontation the events. 
+# The events must be grep by a filter first, then it can pull out a copy of it, like clone, with tags "advisor_first",
 # this copy is the first occurrence of this event verified in time_adv.
 # After time_adv Advisor will pull out an event tagged "advisor_info" who will tell you the number of same events verified in time_adv.
 
 # INFORMATION ABOUT CLASS:
- 
-# For do this job, i used a thread that will sleep time adv. I assume that events coming on advisor are tagged, then i use an array for storing different events.
+
+# To do this job, I used a thread that will sleep time adv. I assume that events coming on advisor are tagged, then I use an array for storing different events.
 # If an events is not present on array, then is the first and if the option is activate then  advisor push out a copy of event.
 # Else if the event is present on array, then is another same event and not the first, let's count it.  
 
@@ -25,7 +25,7 @@
 #  }
 # }
 
-# We analize this:
+# We analyze this:
 
 # time_adv => 1
 # Means the time when the events matched and collected are pushed on outputs with tag "advisor_info".
@@ -35,143 +35,143 @@
 
 class LogStash::Filters::Advisor < LogStash::Filters::Base
 
- config_name "advisor"
- milestone 1
-
- # If you do not set time_adv the plugin does nothing.
- config :time_adv, :validate => :number, :default => 0
- 
- # If you want the first different event will be pushed out like a copy
- config :send_first, :validate => :boolean, :default => true
- 
- public
- def register
-
-  # Control the correct config
-  if (!(@time_adv == 0))
-    
-    @flag = false
-    @first = false
-    # Is used for store the different events.
-    @sarray = Array.new
-    # Is used for count the number of equals events.
-    @carray = Array.new
-
-    @thread = time_alert(@time_adv.to_i*60) do
-     # if collected any events then pushed out a new event after time_adv
-     if (@sarray.size !=0) 
-        @flag = true
-     end
+  config_name "advisor"
+  milestone 1
+
+  # If you do not set time_adv the plugin does nothing.
+  config :time_adv, :validate => :number, :default => 0
+
+  # If you want the first different event will be pushed out like a copy
+  config :send_first, :validate => :boolean, :default => true
+
+  public
+  def register
+
+    # Control the correct config
+    if (!(@time_adv == 0))
+
+      @flag = false
+      @first = false
+      # Is used to store the different events.
+      @sarray = Array.new
+      # Is used to count the number of equals events.
+      @carray = Array.new
+
+      @thread = time_alert(@time_adv.to_i*60) do
+        # if collected any events then pushed out a new event after time_adv
+        if (@sarray.size !=0) 
+          @flag = true
+        end
+      end
+
+    else
+      @logger.warn("Advisor: you have not specified Time_adv. This filter will do nothing!")
     end
-  
-  else
-   @logger.warn("Advisor: you have not specified Time_adv. This filter will do nothing!")
+
   end
 
- end
- 
- # This method is used to manage sleep and awaken threads (thanks StackOverflow for the support)
+  # This method is used to manage sleep and awaken threads (thanks StackOverflow for the support)
   def time_alert(interval)
-     Thread.new do
+    Thread.new do
       loop do
-       start_time = Time.now
-       yield
-       elapsed = Time.now - start_time
-       sleep([interval - elapsed, 0].max)
-     end
-   end
+        start_time = Time.now
+        yield
+        elapsed = Time.now - start_time
+        sleep([interval - elapsed, 0].max)
+      end
+    end
   end
 
- public
- def filter(event)
-  return unless filter?(event)
-  
-  # Control the correct config
-  if(!(@time_adv == 0))
-
-    new_event = true
-    @message = event["message"]
-    
-    # control if the events are new or they are came before
-    for i in (0..@sarray.size-1)
-      if (@message == @sarray[i].to_s)
-        @logger.debug("Avisor: Event match")
-        # if came before then count it
-        new_event = false
-        @carray[i] = @carray[i].to_i+1
-        @logger.debug("Advisor: "+@carray[i].to_s+" Events matched")
-        break
+  public
+  def filter(event)
+    return unless filter?(event)
+
+    # Control the correct config
+    if(!(@time_adv == 0))
+
+      new_event = true
+      @message = event["message"]
+
+      # control if the events are new or they are came before
+      for i in (0..@sarray.size-1)
+        if (@message == @sarray[i].to_s)
+          @logger.debug("Avisor: Event match")
+          # if came before then count it
+          new_event = false
+          @carray[i] = @carray[i].to_i+1
+          @logger.debug("Advisor: "+@carray[i].to_s+" Events matched")
+          break
+        end
       end
+
+      if (new_event == true)
+        # else is a new event
+
+        @sarray << @message
+        @carray << 1
+        if (send_first == true)
+          @logger.debug("Advisor: is the first to send out")
+          @first = true
+        end
+      end
+
+    else
+      @logger.warn("Advisor: you have not specified Time_adv. This filter will do nothing!")
     end
-     
-    if (new_event == true)
-       # else is a new event
-
-       @sarray << @message
-       @carray << 1
-       if (send_first == true)
-           @logger.debug("Advisor: is the first to send out")
-           @first = true
-       end
-    end
-     
-  else
-   @logger.warn("Advisor: you have not specified Time_adv. This filter will do nothing!")
   end
- end
 
 
   # This method is used for generate events every 5 seconds (Thanks Jordan Sissel for explanation).
   # In this case we generate an event when advisor thread trigger the flag or is the first different event. 
 
   def flush
-      
-        if (@first == true)
-          event = LogStash::Event.new
-          event["host"] = Socket.gethostname
-          event["message"] = @message
-          event.tag "advisor_first"
-          filter_matched(event)
-         
-          @first = false
-          return [event]
+
+    if (@first == true)
+      event = LogStash::Event.new
+      event["host"] = Socket.gethostname
+      event["message"] = @message
+      event.tag "advisor_first"
+      filter_matched(event)
+
+      @first = false
+      return [event]
+    end
+
+    if (@flag == true)
+
+      if (@tags.size != 0)
+        @tag_path = ""
+        for i in (0..@tags.size-1)
+          @tag_path += @tags[i].to_s+"."
         end
-   
-         if (@flag == true)
- 
-          if (@tags.size != 0)
-            @tag_path = ""
-            for i in (0..@tags.size-1)
-              @tag_path += @tags[i].to_s+"."
-            end
-          end
-            
-          # Prepare message 
-          message = "Advisor: Found events who match: "+@tag_path.to_s+"\n\n"
-
-          # See on messagge partial part of different events
-          for i in (0..@sarray.size-1)
-            message = message+@carray[i].to_s+" events like: "+(@sarray[i].to_s).slice(0, 300)+"\n\n"
-          end
-         
-          event = LogStash::Event.new
-          event["host"] = Socket.gethostname 
-          event["message"] = message  
-          event.tag << "advisor_info"
-          filter_matched(event)
-   
-          # reset flag and counter 
-          @flag = false
-          @carray = nil
-          @sarray = nil
-          @carray = Array.new
-          @sarray = Array.new
-
-          # push the event
-          return [event]
-         end
+      end
+
+      # Prepare message 
+      message = "Advisor: Found events which match: "+@tag_path.to_s+"\n\n"
+
+      # See on messagge partial part of different events
+      for i in (0..@sarray.size-1)
+        message = message+@carray[i].to_s+" events like: "+(@sarray[i].to_s).slice(0, 300)+"\n\n"
+      end
+
+      event = LogStash::Event.new
+      event["host"] = Socket.gethostname 
+      event["message"] = message  
+      event.tag << "advisor_info"
+      filter_matched(event)
+
+      # reset flag and counter 
+      @flag = false
+      @carray = nil
+      @sarray = nil
+      @carray = Array.new
+      @sarray = Array.new
+
+      # push the event
+      return [event]
+    end
     return
- 
+
   end
 
 end
diff --git a/lib/logstash/outputs/s3.rb b/lib/logstash/outputs/s3.rb
index 257356b25e8..162154ace9f 100644
--- a/lib/logstash/outputs/s3.rb
+++ b/lib/logstash/outputs/s3.rb
@@ -1,26 +1,26 @@
 # encoding: utf-8
-require "logstash/outputs/base"
-require "logstash/namespace"
+require 'logstash/outputs/base'
+require 'logstash/namespace'
 
 # TODO integrate aws_config in the future 
 #require "logstash/plugin_mixins/aws_config"
 
 # INFORMATION:
 
-# This plugin was created for store the logstash's events into Amazon Simple Storage Service (Amazon S3).
-# For use it you needs authentications and an s3 bucket. 
-# Be careful to have the permission to write file on S3's bucket and run logstash with super user for establish connection.
+# This plugin was created to store logstash's events into Amazon Simple Storage Service (Amazon S3).
+# To use it you need authentications and an s3 bucket. 
+# Be careful to have the permission to write file on S3's bucket and run logstash with super user to establish connection.
 
-# S3 plugin allows you to do something complex, let's explain:)
+# The S3 plugin allows you to do something complex, let's explain:)
 
-# S3 outputs create temporary files into "/opt/logstash/S3_temp/". If you want, you can change the path at the start of register method.
-# This files have a special name, for example:
+# S3 outputs create temporary files in "/opt/logstash/S3_temp/". If you want, you can change the path at the start of register method.
+# These files have a special name, for example:
 
 # ls.s3.ip-10-228-27-95.2013-04-18T10.00.tag_hello.part0.txt
 
 # ls.s3 : indicate logstash plugin s3
 
-# "ip-10-228-27-95" : indicate you ip machine, if you have more logstash and writing on the same bucket for example.
+# "ip-10-228-27-95" : Indicates your machine IP. This is useful in cases where you have multiple instances of Logstash writing to the same bucket.
 # "2013-04-18T10.00" : represents the time whenever you specify time_file.
 # "tag_hello" : this indicate the event's tag, you can collect events with the same tag. 
 # "part0" : this means if you indicate size_file then it will generate more parts if you file.size > size_file. 
@@ -45,7 +45,7 @@
 
 # INFORMATION ABOUT CLASS:
 
-# I tried to comment the class at best i could do. 
+# I tried to comment the class at best I could do. 
 # I think there are much thing to improve, but if you want some points to develop here a list:
 
 # TODO Integrate aws_config in the future 
@@ -74,7 +74,7 @@
 #    }
 # }
 
-# We analize this:
+# We analyze this:
 
 # access_key_id => "crazy_key" 
 # Amazon will give you the key for use their service if you buy it or try it. (not very much open source anyway)
@@ -89,12 +89,12 @@
 # Be careful you have the permission to write on bucket and know the name.
 
 # size_file => 2048
-# Means the size, in KB, of files who can store on temporary directory before you will be pushed on bucket.
+# Means the size, in KB, of files which can store in temporary directory before you will be pushed on bucket.
 # Is useful if you have a little server with poor space on disk and you don't want blow up the server with unnecessary temporary log files.
 
 # time_file => 5
-# Means, in minutes, the time  before the files will be pushed on bucket. Is useful if you want to push the files every specific time.
- 
+# Means, in minutes, the time before the files will be pushed to the S3 bucket. Is useful if you want to push the files every specific time.
+
 # format => "plain"
 # Means the format of events you want to store in the files
 
@@ -104,252 +104,251 @@
 # LET'S ROCK AND ROLL ON THE CODE!
 
 class LogStash::Outputs::S3 < LogStash::Outputs::Base
- #TODO integrate aws_config in the future 
- #  include LogStash::PluginMixins::AwsConfig
-
- config_name "s3"
- milestone 1
-
- # Aws access_key.
- config :access_key_id, :validate => :string
- 
- # Aws secret_access_key
- config :secret_access_key, :validate => :string
-
- # S3 bucket
- config :bucket, :validate => :string
-
- # Aws endpoint_region
- config :endpoint_region, :validate => ["us-east-1", "us-west-1", "us-west-2",
-                                        "eu-west-1", "ap-southeast-1", "ap-southeast-2",
-                                        "ap-northeast-1", "sa-east-1", "us-gov-west-1"], :default => "us-east-1"
-
- # Set the size of file in KB, this means that files on bucket when have dimension > file_size, they are stored in two or more file. 
- # If you have tags then it will generate a specific size file for every tags
- ##NOTE: define size of file is the better thing, because generate a local temporary file on disk and then put it in bucket. 
- config :size_file, :validate => :number, :default => 0
-
- # Set the time, in minutes, to close the current sub_time_section of bucket. 
- # If you define file_size you have a number of files in consideration of the section and the current tag.
- # 0 stay all time on listerner, beware if you specific 0 and size_file 0, because you will not put the file on bucket,
- # for now the only thing this plugin can do is to put the file when logstash restart.
- config :time_file, :validate => :number, :default => 0 
- 
- # The event format you want to store in files. Defaults to plain text.
- config :format, :validate => [ "json", "plain", "nil" ], :default => "plain"
-
- ## IMPORTANT: if you use multiple instance of s3, you should specify on one of them the "restore=> true" and on the others "restore => false".
- ## This is hack for not destroy the new files after restoring the initial files. 
- ## If you do not specify "restore => true" when logstash crashes or is restarted, the files are not sent into the bucket,
- ## for example if you have single Instance. 
- config :restore, :validate => :boolean, :default => false
-
- # Aws canned ACL
- config :canned_acl, :validate => ["private", "public_read", "public_read_write", "authenticated_read"],
-        :default => "private"
-
- # Method to set up the aws configuration and establish connection
- def aws_s3_config
-
-  @endpoint_region == 'us-east-1' ? @endpoint_region = 's3.amazonaws.com' : @endpoint_region = 's3-'+@endpoint_region+'.amazonaws.com'
-
-  @logger.info("Registering s3 output", :bucket => @bucket, :endpoint_region => @endpoint_region)
-
-  AWS.config(
-    :access_key_id => @access_key_id,
-    :secret_access_key => @secret_access_key,
-    :s3_endpoint => @endpoint_region
-  )
-  @s3 = AWS::S3.new 
-
- end
-
- # This method is used to manage sleep and awaken thread.
- def time_alert(interval)
-
-   Thread.new do
-    loop do
-      start_time = Time.now
-      yield
-      elapsed = Time.now - start_time
-      sleep([interval - elapsed, 0].max)
+  #TODO integrate aws_config in the future 
+  #  include LogStash::PluginMixins::AwsConfig
+
+  config_name 's3'
+  milestone 1
+
+  # Aws access_key.
+  config :access_key_id, :validate => :string
+
+  # Aws secret_access_key
+  config :secret_access_key, :validate => :string
+
+  # S3 bucket
+  config :bucket, :validate => :string
+
+  # Aws endpoint_region
+  config :endpoint_region, :validate => ["us-east-1", "us-west-1", "us-west-2",
+                                         "eu-west-1", "ap-southeast-1", "ap-southeast-2",
+                                         "ap-northeast-1", "sa-east-1", "us-gov-west-1"], :default => "us-east-1"
+
+  # Set the size of file in KB, this means that files on bucket when have dimension > file_size, they are stored in two or more files. 
+  # If you have tags then it will generate a specific size file for every tag
+  ##NOTE: define size of file is the better thing, because generate a local temporary file on disk and then put it in bucket. 
+  config :size_file, :validate => :number, :default => 0
+
+  # Set the time, in minutes, to close the current sub_time_section of bucket. 
+  # If you define file_size you have a number of files in consideration of the section and the current tag.
+  # 0 stay all time on listerner, beware if you specific 0 and size_file 0, because you will not put the file on bucket,
+  # for now the only thing this plugin can do is to put the file when logstash restart.
+  config :time_file, :validate => :number, :default => 0 
+
+  # The event format you want to store in files. Defaults to plain text.
+  config :format, :validate => [ "json", "plain", "nil" ], :default => "plain"
+
+  ## IMPORTANT: if you use multiple instance of s3, you should specify on one of them the "restore=> true" and on the others "restore => false".
+  ## This is hack for not destroy the new files after restoring the initial files. 
+  ## If you do not specify "restore => true" when logstash crashes or is restarted, the files are not sent into the bucket,
+  ## for example if you have single Instance. 
+  config :restore, :validate => :boolean, :default => false
+
+  # Aws canned ACL
+  config :canned_acl, :validate => ["private", "public_read", "public_read_write", "authenticated_read"],
+    :default => "private"
+
+  # Method to set up the aws configuration and establish connection
+  def aws_s3_config
+
+    @endpoint_region == 'us-east-1' ? @endpoint_region = 's3.amazonaws.com' : @endpoint_region = 's3-'+@endpoint_region+'.amazonaws.com'
+
+    @logger.info("Registering s3 output", :bucket => @bucket, :endpoint_region => @endpoint_region)
+
+    AWS.config(
+      :access_key_id => @access_key_id,
+      :secret_access_key => @secret_access_key,
+      :s3_endpoint => @endpoint_region
+    )
+    @s3 = AWS::S3.new 
+
+  end
+
+  # This method is used to manage sleep and awaken thread.
+  def time_alert(interval)
+
+    Thread.new do
+      loop do
+        start_time = Time.now
+        yield
+        elapsed = Time.now - start_time
+        sleep([interval - elapsed, 0].max)
+      end
+    end
+
+  end
+
+  # this method is used for write files on bucket. It accept the file and the name of file.
+  def write_on_bucket (file_data, file_basename)
+
+    # if you lose connection with s3, bad control implementation.
+    if ( @s3 == nil) 
+      aws_s3_config
     end
-   end
 
- end
+    # find and use the bucket
+    bucket = @s3.buckets[@bucket]
+
+    @logger.debug "S3: ready to write "+file_basename+" in bucket "+@bucket+", Fire in the hole!"
+
+    # prepare for write the file
+    object = bucket.objects[file_basename]
+    object.write(:file => file_data, :acl => @canned_acl)
+
+    @logger.debug "S3: has written "+file_basename+" in bucket "+@bucket + " with canned ACL \"" + @canned_acl + "\""
+
+  end
+
+  # this method is used for create new path for name the file
+  def getFinalPath
+
+    @pass_time = Time.now 
+    return @temp_directory+"ls.s3."+Socket.gethostname+"."+(@pass_time).strftime("%Y-%m-%dT%H.%M")
 
- # this method is used for write files on bucket. It accept the file and the name of file.
- def write_on_bucket (file_data, file_basename)
- 
-  # if you lose connection with s3, bad control implementation.
-  if ( @s3 == nil) 
-    aws_s3_config
   end
 
-  # find and use the bucket
-  bucket = @s3.buckets[@bucket]
-
-  @logger.debug "S3: ready to write "+file_basename+" in bucket "+@bucket+", Fire in the hole!"
-
-  # prepare for write the file
-  object = bucket.objects[file_basename]
-  object.write(:file => file_data, :acl => @canned_acl)
- 
-  @logger.debug "S3: has written "+file_basename+" in bucket "+@bucket + " with canned ACL \"" + @canned_acl + "\""
-
- end
-  
- # this method is used for create new path for name the file
- def getFinalPath
-   
-   @pass_time = Time.now 
-   return @temp_directory+"ls.s3."+Socket.gethostname+"."+(@pass_time).strftime("%Y-%m-%dT%H.%M")
-
- end
-
- # This method is used for restore the previous crash of logstash or to prepare the files to send in bucket. 
- # Take two parameter: flag and name. Flag indicate if you want to restore or not, name is the name of file 
- def upFile(flag, name)
-   
-   Dir[@temp_directory+name].each do |file|
-     name_file = File.basename(file)
-    
-     if (flag == true)
-      @logger.warn "S3: have found temporary file: "+name_file+", something has crashed before... Prepare for upload in bucket!"
-     end
-    
-     if (!File.zero?(file))  
-       write_on_bucket(file, name_file)
-
-       if (flag == true)
+  # This method is used for restore the previous crash of logstash or to prepare the files to send in bucket. 
+  # Take two parameter: flag and name. Flag indicate if you want to restore or not, name is the name of file 
+  def upFile(flag, name)
+
+    Dir[@temp_directory+name].each do |file|
+      name_file = File.basename(file)
+
+      if (flag == true)
+        @logger.warn "S3: have found temporary file: "+name_file+", something has crashed before... Prepare for upload in bucket!"
+      end
+
+      if (!File.zero?(file))  
+        write_on_bucket(file, name_file)
+
+        if (flag == true)
           @logger.debug "S3: file: "+name_file+" restored on bucket "+@bucket
-       else
+        else
           @logger.debug "S3: file: "+name_file+" was put on bucket "+@bucket
-       end
-     end
-
-     File.delete (file)
-
-   end
- end
-
- # This method is used for create new empty temporary files for use. Flag is needed for indicate new subsection time_file.
- def newFile (flag)
-  
-   if (flag == true)
-     @current_final_path = getFinalPath
-     @sizeCounter = 0
-   end
-
-   if (@tags.size != 0)
-     @tempFile = File.new(@current_final_path+".tag_"+@tag_path+"part"+@sizeCounter.to_s+".txt", "w")
-   else
-     @tempFile = File.new(@current_final_path+".part"+@sizeCounter.to_s+".txt", "w")
-   end
-
- end
-
- public
- def register
-   require "aws-sdk"
-   @temp_directory = "/opt/logstash/S3_temp/"
-
-   if (@tags.size != 0)
-       @tag_path = ""
-       for i in (0..@tags.size-1)
-          @tag_path += @tags[i].to_s+"." 
-       end
-   end
-
-   if !(File.directory? @temp_directory)
-    @logger.debug "S3: Directory "+@temp_directory+" doesn't exist, let's make it!"
-    Dir.mkdir(@temp_directory)
-   else
-    @logger.debug "S3: Directory "+@temp_directory+" exist, nothing to do"
-   end 
-   
-   if (@restore == true )
-     @logger.debug "S3: is attempting to verify previous crashes..."
-   
-     upFile(true, "*.txt")    
-   end
-   
-   newFile(true)
-   
-   if (time_file != 0)
+        end
+      end
+
+      File.delete(file)
+
+    end
+  end
+
+  # This method is used for create new empty temporary files for use. Flag is needed for indicate new subsection time_file.
+  def newFile(flag)
+
+    if (flag == true)
+      @current_final_path = getFinalPath
+      @sizeCounter = 0
+    end
+
+    if (@tags.size != 0)
+      @tempFile = File.new(@current_final_path+".tag_"+@tag_path+"part"+@sizeCounter.to_s+".txt", "w")
+    else
+      @tempFile = File.new(@current_final_path+".part"+@sizeCounter.to_s+".txt", "w")
+    end
+
+  end
+
+  public
+  def register
+    require "aws-sdk"
+    @temp_directory = "/opt/logstash/S3_temp/"
+
+    if (@tags.size != 0)
+      @tag_path = ""
+      for i in (0..@tags.size-1)
+        @tag_path += @tags[i].to_s+"." 
+      end
+    end
+
+    if !(File.directory? @temp_directory)
+      @logger.debug "S3: Directory "+@temp_directory+" doesn't exist, let's make it!"
+      Dir.mkdir(@temp_directory)
+    else
+      @logger.debug "S3: Directory "+@temp_directory+" exist, nothing to do"
+    end 
+
+    if (@restore == true )
+      @logger.debug "S3: is attempting to verify previous crashes..."
+
+      upFile(true, "*.txt")    
+    end
+
+    newFile(true)
+
+    if (time_file != 0)
       first_time = true
       @thread = time_alert(@time_file*60) do
-       if (first_time == false)
-         @logger.debug "S3: time_file triggered,  let's bucket the file if dosen't empty  and create new file "
-         upFile(false, File.basename(@tempFile))
-         newFile(true)
-       else
-         first_time = false
-       end
-     end
-   end
- 
- end
- 
- public
- def receive(event)
-  return unless output?(event)
-   
-  # Prepare format of Events 
-  if (@format == "plain")
-     message = self.class.format_message(event)
-  elsif (@format == "json")
-     message = event.to_json
-  else
-     message = event.to_s
-  end
-  
-  if(time_file !=0)
-     @logger.debug "S3: trigger files after "+((@pass_time+60*time_file)-Time.now).to_s
+        if (first_time == false)
+          @logger.debug "S3: time_file triggered, let's bucket the file if doesn't empty and create new file."
+          upFile(false, File.basename(@tempFile))
+          newFile(true)
+        else
+          first_time = false
+        end
+      end
+    end
+
   end
 
-  # if specific the size
-  if(size_file !=0)
-    
-    if (@tempFile.size < @size_file )
+  public
+  def receive(event)
+    return unless output?(event)
+
+    # Prepare format of Events 
+    if (@format == "plain")
+      message = self.class.format_message(event)
+    elsif (@format == "json")
+      message = event.to_json
+    else
+      message = event.to_s
+    end
+
+    if(time_file !=0)
+      @logger.debug "S3: trigger files after "+((@pass_time+60*time_file)-Time.now).to_s
+    end
+
+    # if specific the size
+    if(size_file !=0)
+
+      if (@tempFile.size < @size_file )
 
-       @logger.debug "S3: File have size: "+@tempFile.size.to_s+" and size_file is: "+ @size_file.to_s
-       @logger.debug "S3: put event into: "+File.basename(@tempFile)
+        @logger.debug "S3: File have size: "+@tempFile.size.to_s+" and size_file is: "+ @size_file.to_s
+        @logger.debug "S3: put event into: "+File.basename(@tempFile)
 
-       # Put the event in the file, now! 
-       File.open(@tempFile, 'a') do |file|
-         file.puts message
-         file.write "\n"
-       end
+        # Put the event in the file, now! 
+        File.open(@tempFile, 'a') do |file|
+          file.puts message
+          file.write "\n"
+        end
 
-     else
+      else
 
-       @logger.debug "S3: file: "+File.basename(@tempFile)+" is too large, let's bucket it and create new file"
-       upFile(false, File.basename(@tempFile))
-       @sizeCounter += 1
-       newFile(false)
+        @logger.debug "S3: file: "+File.basename(@tempFile)+" is too large, let's bucket it and create a new file"
+        upFile(false, File.basename(@tempFile))
+        @sizeCounter += 1
+        newFile(false)
+      end
 
-     end
-     
-  # else we put all in one file 
-  else
+      # else we put all in one file 
+    else
 
-    @logger.debug "S3: put event into "+File.basename(@tempFile)
-    File.open(@tempFile, 'a') do |file|
-      file.puts message
-      file.write "\n"
+      @logger.debug "S3: put event into "+File.basename(@tempFile)
+      File.open(@tempFile, 'a') do |file|
+        file.puts message
+        file.write "\n"
+      end
     end
+
   end
-    
- end
 
- def self.format_message(event)
+  def self.format_message(event)
     message = "Date: #{event["@timestamp"]}\n"
     message << "Source: #{event["source"]}\n"
     message << "Tags: #{event["tags"].join(', ')}\n"
     message << "Fields: #{event.to_hash.inspect}\n"
     message << "Message: #{event["message"]}"
- end
+  end
 
 end
 
