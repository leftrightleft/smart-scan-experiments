diff --git a/logstash-core/lib/logstash/pipeline.rb b/logstash-core/lib/logstash/pipeline.rb
index 94f47c5c554..d3fb2b0bbc4 100644
--- a/logstash-core/lib/logstash/pipeline.rb
+++ b/logstash-core/lib/logstash/pipeline.rb
@@ -32,12 +32,14 @@ module LogStash; class BasePipeline
   include LogStash::Util::Loggable
 
   attr_reader :settings, :config_str, :config_hash, :inputs, :filters, :outputs, :pipeline_id, :lir, :execution_context
+  attr_reader :pipeline_settings
 
-  def initialize(config_str, settings = SETTINGS, namespaced_metric = nil, agent = nil)
+  def initialize(pipeline_config, namespaced_metric = nil, agent = nil)
     @logger = self.logger
 
-    @config_str = config_str
-    @settings = settings
+    @pipeline_config = pipeline_config
+    @config_str = @pipeline_config.config_string
+    @settings = @pipeline_config.settings
     @config_hash = Digest::SHA1.hexdigest(@config_str)
 
     @lir = compile_lir
@@ -160,21 +162,20 @@ module LogStash; class Pipeline < BasePipeline
 
   MAX_INFLIGHT_WARN_THRESHOLD = 10_000
 
-  def initialize(config_str, settings = SETTINGS, namespaced_metric = nil, agent = nil)
+  def initialize(pipeline_config, namespaced_metric = nil, agent = nil)
     # This needs to be configured before we call super which will evaluate the code to make
     # sure the metric instance is correctly send to the plugins to make the namespace scoping work
     @metric = if namespaced_metric
-      settings.get("metric.collect") ? namespaced_metric : Instrument::NullMetric.new(namespaced_metric.collector)
+      pipeline_config.settings.get("metric.collect") ? namespaced_metric : Instrument::NullMetric.new(namespaced_metric.collector)
     else
       Instrument::NullMetric.new
     end
 
-    @settings = settings
+    super
+
     @reporter = PipelineReporter.new(@logger, self)
     @worker_threads = []
 
-    super
-
     begin
       @queue = LogStash::QueueFactory.create(settings)
     rescue => e
diff --git a/logstash-core/lib/logstash/pipeline_action/create.rb b/logstash-core/lib/logstash/pipeline_action/create.rb
index 1e5628d0c54..d04706b86f0 100644
--- a/logstash-core/lib/logstash/pipeline_action/create.rb
+++ b/logstash-core/lib/logstash/pipeline_action/create.rb
@@ -32,8 +32,8 @@ def execution_priority
     # The execute assume that the thread safety access of the pipeline
     # is managed by the caller.
     def execute(agent, pipelines)
-      pipeline = LogStash::Pipeline.new(@pipeline_config.config_string, @pipeline_config.settings, @metric, agent)
-      
+      pipeline = LogStash::Pipeline.new(@pipeline_config, @metric, agent)
+
       status = pipeline.start # block until the pipeline is correctly started or crashed
 
       if status
diff --git a/logstash-core/lib/logstash/pipeline_action/reload.rb b/logstash-core/lib/logstash/pipeline_action/reload.rb
index 1e53533d6e9..ed58bb5ce29 100644
--- a/logstash-core/lib/logstash/pipeline_action/reload.rb
+++ b/logstash-core/lib/logstash/pipeline_action/reload.rb
@@ -27,7 +27,7 @@ def execute(agent, pipelines)
       end
 
       begin
-        pipeline_validator = LogStash::BasePipeline.new(@pipeline_config.config_string, @pipeline_config.settings)
+        pipeline_validator = LogStash::BasePipeline.new(@pipeline_config)
       rescue => e
         return LogStash::ConvergeResult::FailedAction.from_exception(e)
       end
diff --git a/logstash-core/lib/logstash/runner.rb b/logstash-core/lib/logstash/runner.rb
index 9f073e30696..4b7b21cfa82 100644
--- a/logstash-core/lib/logstash/runner.rb
+++ b/logstash-core/lib/logstash/runner.rb
@@ -272,7 +272,7 @@ def execute
         # TODO(ph): make it better for multiple pipeline
         if results.success?
           results.response.each do |pipeline_config|
-            LogStash::BasePipeline.new(pipeline_config.config_string)
+            LogStash::BasePipeline.new(pipeline_config)
           end
           puts "Configuration OK"
           logger.info "Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash"
diff --git a/logstash-core/spec/logstash/pipeline_reporter_spec.rb b/logstash-core/spec/logstash/pipeline_reporter_spec.rb
index 68b48181996..2c3f7132adf 100644
--- a/logstash-core/spec/logstash/pipeline_reporter_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_reporter_spec.rb
@@ -1,6 +1,7 @@
 # encoding: utf-8
 require "spec_helper"
 require "logstash/pipeline"
+require "logstash/config/source/local"
 require "logstash/pipeline_reporter"
 require_relative "../support/mocks_classes"
 
@@ -11,7 +12,12 @@
   let(:config) do
     "input { generator { count => #{generator_count} } } output { dummyoutput {} } "
   end
-  let(:pipeline) { LogStash::Pipeline.new(config)}
+  let(:metric) { nil }
+  let(:pipeline_id) { :main }
+  let(:settings) { LogStash::SETTINGS }
+  let(:config_parts) { ::LogStash::Config::Source::Local::ConfigStringLoader.read(config) }
+  let(:pipeline_config) { ::LogStash::Config::PipelineConfig.new(nil, pipeline_id, config_parts, settings) }
+  let(:pipeline) { LogStash::Pipeline.new(pipeline_config, metric) }
   let(:reporter) { pipeline.reporter }
 
   before do
diff --git a/logstash-core/spec/logstash/pipeline_spec.rb b/logstash-core/spec/logstash/pipeline_spec.rb
index fa819f400cc..68233016830 100644
--- a/logstash-core/spec/logstash/pipeline_spec.rb
+++ b/logstash-core/spec/logstash/pipeline_spec.rb
@@ -2,6 +2,7 @@
 require "spec_helper"
 require "logstash/inputs/generator"
 require "logstash/filters/multiline"
+require "logstash/config/source/local"
 require_relative "../support/mocks_classes"
 require_relative "../support/helpers"
 require_relative "../logstash/pipeline_reporter_spec" # for DummyOutput class
@@ -89,19 +90,24 @@ class TestPipeline < LogStash::Pipeline
   let(:worker_thread_count)     { 5 }
   let(:safe_thread_count)       { 1 }
   let(:override_thread_count)   { 42 }
-  let(:pipeline_settings_obj) { LogStash::SETTINGS }
+  let(:settings) { LogStash::SETTINGS }
   let(:pipeline_settings) { {} }
+  let(:pipeline_id) { :main }
+  let(:metric) { nil }
 
   before :each do
     pipeline_workers_setting = LogStash::SETTINGS.get_setting("pipeline.workers")
     allow(pipeline_workers_setting).to receive(:default).and_return(worker_thread_count)
-    pipeline_settings.each {|k, v| pipeline_settings_obj.set(k, v) }
+    pipeline_settings.each {|k, v| settings.set(k, v) }
   end
 
   after :each do
-    pipeline_settings_obj.reset
+    settings.reset
   end
 
+  let(:config_parts) { ::LogStash::Config::Source::Local::ConfigStringLoader.read(config) }
+  let(:pipeline_config) { ::LogStash::Config::PipelineConfig.new(nil, pipeline_id, config_parts, settings) }
+  subject { described_class.new(pipeline_config, metric) }
 
   describe "event cancellation" do
     # test harness for https://github.com/elastic/logstash/issues/6055
@@ -139,7 +145,7 @@ class TestPipeline < LogStash::Pipeline
       abort_on_exception_state = Thread.abort_on_exception
       Thread.abort_on_exception = true
 
-      pipeline = LogStash::Pipeline.new(config, pipeline_settings_obj)
+      pipeline = LogStash::Pipeline.new(pipeline_config)
       t = Thread.new { pipeline.run }
       sleep(0.1) until pipeline.ready?
       wait(3).for do
@@ -182,6 +188,7 @@ class TestPipeline < LogStash::Pipeline
         }
         eos
       }
+      let(:config) { test_config_with_filters }
 
       describe "debug compiled" do
         let(:logger) { double("pipeline logger").as_null_object }
@@ -192,16 +199,16 @@ class TestPipeline < LogStash::Pipeline
         end
 
         it "should not receive a debug message with the compiled code" do
-          pipeline_settings_obj.set("config.debug", false)
+          settings.set("config.debug", false)
           expect(logger).not_to receive(:debug).with(/Compiled pipeline/, anything)
-          pipeline = TestPipeline.new(test_config_with_filters)
+          pipeline = TestPipeline.new(pipeline_config)
           pipeline.close
         end
 
         it "should print the compiled code if config.debug is set to true" do
-          pipeline_settings_obj.set("config.debug", true)
+          settings.set("config.debug", true)
           expect(logger).to receive(:debug).with(/Compiled pipeline/, anything)
-          pipeline = TestPipeline.new(test_config_with_filters, pipeline_settings_obj)
+          pipeline = TestPipeline.new(pipeline_config)
           pipeline.close
         end
       end
@@ -209,7 +216,7 @@ class TestPipeline < LogStash::Pipeline
       context "when there is no command line -w N set" do
         it "starts one filter thread" do
           msg = "Defaulting pipeline worker threads to 1 because there are some filters that might not work with multiple worker threads"
-          pipeline = TestPipeline.new(test_config_with_filters)
+          pipeline = TestPipeline.new(pipeline_config)
           expect(pipeline.logger).to receive(:warn).with(msg,
             hash_including({:count_was=>worker_thread_count, :filters=>["dummyfilter"]}))
           pipeline.run
@@ -223,7 +230,7 @@ class TestPipeline < LogStash::Pipeline
         it "starts multiple filter thread" do
           msg = "Warning: Manual override - there are filters that might" +
                 " not work with multiple worker threads"
-          pipeline = TestPipeline.new(test_config_with_filters, pipeline_settings_obj)
+          pipeline = TestPipeline.new(pipeline_config)
           expect(pipeline.logger).to receive(:warn).with(msg, hash_including({:worker_threads=> override_thread_count, :filters=>["dummyfilter"]}))
           pipeline.run
           expect(pipeline.worker_threads.size).to eq(override_thread_count)
@@ -248,10 +255,11 @@ class TestPipeline < LogStash::Pipeline
         }
         eos
       }
+      let(:config) { test_config_with_filters }
 
       it "starts multiple filter threads" do
         skip("This test has been failing periodically since November 2016. Tracked as https://github.com/elastic/logstash/issues/6245")
-        pipeline = TestPipeline.new(test_config_with_filters)
+        pipeline = TestPipeline.new(pipeline_config)
         pipeline.run
         expect(pipeline.worker_threads.size).to eq(worker_thread_count)
         pipeline.shutdown
@@ -292,9 +300,10 @@ class TestPipeline < LogStash::Pipeline
       }
       eos
     }
+    let(:config) { test_config_with_output_workers }
 
     context "output close" do
-      let(:pipeline) { TestPipeline.new(test_config_without_output_workers) }
+      let(:pipeline) { TestPipeline.new(pipeline_config) }
       let(:output) { pipeline.outputs.first }
 
       before do
@@ -324,7 +333,7 @@ class TestPipeline < LogStash::Pipeline
       let(:config) { "input { dummyinput {} } output { dummyoutput {} }"}
 
       it "should start the flusher thread only after the pipeline is running" do
-        pipeline = TestPipeline.new(config)
+        pipeline = TestPipeline.new(pipeline_config)
 
         expect(pipeline).to receive(:transition_to_running).ordered.and_call_original
         expect(pipeline).to receive(:start_flusher).ordered.and_call_original
@@ -380,7 +389,7 @@ class TestPipeline < LogStash::Pipeline
     let(:config) { "input { dummyinput {} } output { dummyoutput {} }" }
     let(:batch_size) { 1 }
     let(:pipeline_settings) { { "pipeline.batch.size" => batch_size, "pipeline.workers" => 1 } }
-    let(:pipeline) { LogStash::Pipeline.new(config, pipeline_settings_obj) }
+    let(:pipeline) { LogStash::Pipeline.new(pipeline_config) }
     let(:logger) { pipeline.logger }
     let(:warning_prefix) { Regexp.new("CAUTION: Recommended inflight events max exceeded!") }
 
@@ -444,10 +453,9 @@ class TestPipeline < LogStash::Pipeline
   end
 
   context "metrics" do
-    config = "input { } filter { } output { }"
+    let(:config) { "input { } filter { } output { }" }
 
     let(:settings) { LogStash::SETTINGS.clone }
-    subject { LogStash::Pipeline.new(config, settings, metric) }
 
     after :each do
       subject.close
@@ -545,11 +553,11 @@ class TestPipeline < LogStash::Pipeline
     before :each do
       pipeline_workers_setting = LogStash::SETTINGS.get_setting("queue.type")
       allow(pipeline_workers_setting).to receive(:value).and_return("memory")
-      pipeline_settings.each {|k, v| pipeline_settings_obj.set(k, v) }
+      pipeline_settings.each {|k, v| settings.set(k, v) }
     end
 
-    let(:pipeline1) { LogStash::Pipeline.new("input { dummyinputgenerator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
-    let(:pipeline2) { LogStash::Pipeline.new("input { dummyinputgenerator {} } filter { dummyfilter {} } output { dummyoutputmore {}}") }
+    let(:pipeline1) { mock_pipeline_from_string("input { dummyinputgenerator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
+    let(:pipeline2) { mock_pipeline_from_string("input { dummyinputgenerator {} } filter { dummyfilter {} } output { dummyoutputmore {}}") }
 
     after  do
       pipeline1.close
@@ -597,7 +605,7 @@ class TestPipeline < LogStash::Pipeline
 
     it "flushes the buffered contents of the filter" do
       Thread.abort_on_exception = true
-      pipeline = LogStash::Pipeline.new(config, pipeline_settings_obj)
+      pipeline = LogStash::Pipeline.new(pipeline_config)
       t = Thread.new { pipeline.run }
       sleep(0.1) until pipeline.ready?
       wait(3).for do
@@ -619,14 +627,14 @@ class TestPipeline < LogStash::Pipeline
       allow(LogStash::Plugin).to receive(:lookup).with("output", "dummyoutput").and_return(::LogStash::Outputs::DummyOutput)
     end
 
-    let(:pipeline1) { LogStash::Pipeline.new("input { generator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
-    let(:pipeline2) { LogStash::Pipeline.new("input { generator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
+    let(:pipeline1) { mock_pipeline_from_string("input { generator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
+    let(:pipeline2) { mock_pipeline_from_string("input { generator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
 
     # multiple pipelines cannot be instantiated using the same PQ settings, force memory queue
     before :each do
       pipeline_workers_setting = LogStash::SETTINGS.get_setting("queue.type")
       allow(pipeline_workers_setting).to receive(:value).and_return("memory")
-      pipeline_settings.each {|k, v| pipeline_settings_obj.set(k, v) }
+      pipeline_settings.each {|k, v| settings.set(k, v) }
     end
 
     it "should handle evaluating different config" do
@@ -657,8 +665,6 @@ class TestPipeline < LogStash::Pipeline
       EOS
     end
 
-    subject { described_class.new(config) }
-
     context "when the pipeline is not started" do
       after :each do
         subject.close
@@ -684,7 +690,6 @@ class TestPipeline < LogStash::Pipeline
       }
       EOS
     end
-    subject { described_class.new(config) }
 
     context "when the pipeline is not started" do
       after :each do
@@ -714,8 +719,6 @@ class TestPipeline < LogStash::Pipeline
   context "when collecting metrics in the pipeline" do
     let(:metric) { LogStash::Instrument::Metric.new(LogStash::Instrument::Collector.new) }
 
-    subject { described_class.new(config, pipeline_settings_obj, metric) }
-
     let(:pipeline_settings) { { "pipeline.id" => pipeline_id } }
     let(:pipeline_id) { "main" }
     let(:number_of_events) { 420 }
@@ -841,14 +844,14 @@ class TestPipeline < LogStash::Pipeline
       allow(LogStash::Plugin).to receive(:lookup).with("output", "dummyoutput").and_return(::LogStash::Outputs::DummyOutput)
     end
 
-    let(:pipeline1) { LogStash::Pipeline.new("input { generator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
-    let(:pipeline2) { LogStash::Pipeline.new("input { generator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
+    let(:pipeline1) { mock_pipeline_from_string("input { generator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
+    let(:pipeline2) { mock_pipeline_from_string("input { generator {} } filter { dummyfilter {} } output { dummyoutput {}}") }
 
     # multiple pipelines cannot be instantiated using the same PQ settings, force memory queue
     before :each do
       pipeline_workers_setting = LogStash::SETTINGS.get_setting("queue.type")
       allow(pipeline_workers_setting).to receive(:value).and_return("memory")
-      pipeline_settings.each {|k, v| pipeline_settings_obj.set(k, v) }
+      pipeline_settings.each {|k, v| settings.set(k, v) }
     end
 
     it "should not add ivars" do
@@ -858,50 +861,57 @@ class TestPipeline < LogStash::Pipeline
 
   context "#system" do
     after do
-      pipeline.close # close the queue
+      subject.close # close the queue
     end
+    let(:config) { "input { generator {} } output { null {} }" }
 
     context "when the pipeline is a system pipeline" do
-      let(:pipeline) { LogStash::Pipeline.new("input { generator {} } output { null {} }", mock_settings("pipeline.system" => true)) }
+      let(:pipeline_settings) { { "pipeline.system" => true } }
       it "returns true" do
-        expect(pipeline.system?).to be_truthy
+        expect(subject.system?).to be_truthy
       end
     end
 
     context "when the pipeline is not a system pipeline" do
-      let(:pipeline) { LogStash::Pipeline.new("input { generator {} } output { null {} }", mock_settings("pipeline.system" => false)) }
+      let(:pipeline_settings) { { "pipeline.system" => false } }
       it "returns true" do
-        expect(pipeline.system?).to be_falsey
+        expect(subject.system?).to be_falsey
       end
     end
   end
 
   context "#reloadable?" do
     after do
-      pipeline.close # close the queue
+      subject.close # close the queue
     end
 
-    context "when all plugins are reloadable and pipeline is configured as reloadable" do
-      let(:pipeline) { LogStash::Pipeline.new("input { generator {} } output { null {} }", mock_settings("pipeline.reloadable" => true)) }
+    context "when the pipeline is configured as reloadable" do
+      let(:pipeline_settings) { { "pipeline.reloadable" => true } }
 
-      it "returns true" do
-        expect(pipeline.reloadable?).to be_truthy
+      context "and all plugins are reloadable" do
+        let(:config) { "input { generator {} } output { null {} }" }
+        it "returns true" do
+          expect(subject.reloadable?).to be_truthy
+        end
       end
-    end
 
-    context "when the plugins are not reloadable and pipeline is configured as reloadable" do
-      let(:pipeline) { LogStash::Pipeline.new("input { stdin {} } output { null {} }", mock_settings("pipeline.reloadable" => true)) }
+      context "and some plugins are not reloadable" do
+        let(:config) { "input { stdin {} } output { null {} }" }
 
-      it "returns true" do
-        expect(pipeline.reloadable?).to be_falsey
+        it "returns true" do
+          expect(subject.reloadable?).to be_falsey
+        end
       end
     end
 
-    context "when all plugins are reloadable and pipeline is configured as non-reloadable" do
-      let(:pipeline) { LogStash::Pipeline.new("input { generator {} } output { null {} }", mock_settings("pipeline.reloadable" => false)) }
+    context "pipeline is configured as non-reloadable" do
+      let(:pipeline_settings) { { "pipeline.reloadable" => false } }
 
-      it "returns true" do
-        expect(pipeline.reloadable?).to be_falsey
+      context "and all plugins are reloadable" do
+        let(:config) { "input { generator {} } output { null {} }" }
+        it "returns true" do
+          expect(subject.reloadable?).to be_falsey
+        end
       end
     end
   end
diff --git a/logstash-core/spec/support/helpers.rb b/logstash-core/spec/support/helpers.rb
index 4426b97256a..3a93b1e4f26 100644
--- a/logstash-core/spec/support/helpers.rb
+++ b/logstash-core/spec/support/helpers.rb
@@ -55,6 +55,11 @@ def mock_pipeline_config(pipeline_id, config_string = nil, settings = {})
   LogStash::Config::PipelineConfig.new(LogStash::Config::Source::Local, pipeline_id, config_part, settings)
 end
 
+def mock_pipeline_from_string(config_string)
+  pipeline_config = mock_pipeline_config(:main, config_string)
+  LogStash::Pipeline.new(pipeline_config)
+end
+
 def start_agent(agent)
   agent_task = Stud::Task.new do
     begin
